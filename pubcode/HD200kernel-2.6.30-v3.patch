diff -Naur linux-2.6.30-ori/Makefile linux-2.6.30-test/Makefile
--- linux-2.6.30-ori/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -190,8 +190,8 @@
 # Default value for CROSS_COMPILE is not to prefix executables
 # Note: Some architectures assign CROSS_COMPILE in their arch/*/Makefile
 export KBUILD_BUILDHOST := $(SUBARCH)
-ARCH		?= $(SUBARCH)
-CROSS_COMPILE	?=
+ARCH		?= mips
+CROSS_COMPILE	?= mipsel-unknown-linux-gnu-
 
 # Architecture as present in compile.h
 UTS_MACHINE 	:= $(ARCH)
diff -Naur linux-2.6.30-ori/README.0000.shared.patch linux-2.6.30-test/README.0000.shared.patch
--- linux-2.6.30-ori/README.0000.shared.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.0000.shared.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+-------
+Common patch
+
+Prerequisite patch numbers:
+--------------------------
+None
+
+Primary author:
+--------------
+YH Lin & Emmanuel Michon
+
+Related to which chip version?
+-----------------------------
+Tango2 ES6/RevA or above.
+
+(linux patches) which CONFIG_... are provided:
+---------------------------------------------
+*** TBD
diff -Naur linux-2.6.30-ori/README.1000.tangox.patch linux-2.6.30-test/README.1000.tangox.patch
--- linux-2.6.30-ori/README.1000.tangox.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1000.tangox.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,18 @@
+Feature:
+--------
+Core support for SMP86xx chips.
+
+Prerequisite patch numbers:
+---------------------------
+0000
+
+Primary author:
+---------------
+External (YH Lin)
+
+Related to which chip version SMP86xx xx=?
+-----------------------------------------
+Tango2 ES6/RevA or above, or Tango3 ES1 or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/README.1003.mbus.patch linux-2.6.30-test/README.1003.mbus.patch
--- linux-2.6.30-ori/README.1003.mbus.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1003.mbus.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+--------
+MBUS and SBOX support for SMP86xx
+
+Prerequisite patch numbers:
+---------------------------
+0000
+1000
+
+Primary author:
+---------------
+(External) YH Lin
+
+Related to which chip version SMP86xx xx=?
+------------------------------------------
+Tango2 ES6/RevA or above, or Tango3 ES1 or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/README.1005.tango2enet.patch linux-2.6.30-test/README.1005.tango2enet.patch
--- linux-2.6.30-ori/README.1005.tango2enet.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1005.tango2enet.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+--------
+Builtin ethernet controller support for SMP863x
+
+Prerequisite patch numbers:
+---------------------------
+0000
+1000
+
+Primary author:
+---------------
+External (Craig Qu)
+
+Related to which chip version SMP86xx xx=?
+------------------------------------------
+Tango2 ES6/RevA or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/README.1006.usb.patch linux-2.6.30-test/README.1006.usb.patch
--- linux-2.6.30-ori/README.1006.usb.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1006.usb.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+--------
+Support for SMP86xx builtin EHCI/OHCI USB controllers.
+
+Prerequisite patch numbers:
+---------------------------
+0000
+1000
+
+Primary author:
+---------------
+Craig Qu
+
+Related to which chip version SMP86xx xx=?
+------------------------------------------
+Tango2 ES6/RevA or above, or Tango3 ES1 or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/README.1007.mtd.patch linux-2.6.30-test/README.1007.mtd.patch
--- linux-2.6.30-ori/README.1007.mtd.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1007.mtd.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+--------
+Customization of MTD layer for SMP863x/SMP865x
+
+Prerequisite patch numbers:
+---------------------------
+0000
+1000
+
+Primary author:
+---------------
+YH Lin
+
+Related to which chip version SMP86xx xx=?
+------------------------------------------
+Tango2 ES6/RevA or above, or Tango3 ES1 or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/README.1008.ir.patch linux-2.6.30-test/README.1008.ir.patch
--- linux-2.6.30-ori/README.1008.ir.patch	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/README.1008.ir.patch	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,19 @@
+Feature:
+--------
+Support for SMP86xx InfraRed (IR) controller.
+
+Prerequisite patch numbers:
+---------------------------
+0000
+1000
+
+Primary author:
+---------------
+YH Lin
+
+Related to which chip version SMP86xx xx=?
+-----------------------------------------
+Tango2 ES6/RevA or above, or Tango3 ES1 or above
+
+(linux patches) which CONFIG_... are provided:
+----------------------------------------------
diff -Naur linux-2.6.30-ori/arch/mips/Kconfig linux-2.6.30-test/arch/mips/Kconfig
--- linux-2.6.30-ori/arch/mips/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -547,6 +547,45 @@
 	  Technology and now in turn merged with Fujitsu.  Say Y here to
 	  support this machine type.
 
+config TANGO2
+	bool "Support for SigmaDesigns Tango2 board"
+	select TANGOX
+	select TANGO2_SMP863X
+	select CEVT_R4K
+	select CSRC_R4K
+ 	select CRYPTO_SHA1
+	select DMA_NONCOHERENT
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select IRQ_CPU
+	select OWN_DMA
+	select DMA_TANGOX
+	select DMA_NONCOHERENT
+	help
+	  Add support for Sigma Designs SMP863x board. Say Y here to
+	  support this machine type.
+
+config TANGO3
+	bool "Support for SigmaDesigns Tango3 board"
+	select TANGOX
+	select TANGO3_SMP865X
+ 	select CRYPTO_SHA1
+ 	select CRYPTO_SHA256
+	select DMA_NONCOHERENT
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select IRQ_CPU
+	select OWN_DMA
+	select DMA_TANGOX
+	select DMA_NONCOHERENT
+	help
+	  Add support for Sigma Designs SMP86xx board. Say Y here to
+	  support this machine type.
+
 config MACH_TX39XX
 	bool "Toshiba TX39 series based machines"
 
@@ -640,6 +679,7 @@
 source "arch/mips/pmc-sierra/Kconfig"
 source "arch/mips/sgi-ip27/Kconfig"
 source "arch/mips/sibyte/Kconfig"
+source "arch/mips/tangox/Kconfig"
 source "arch/mips/txx9/Kconfig"
 source "arch/mips/vr41xx/Kconfig"
 source "arch/mips/cavium-octeon/Kconfig"
@@ -757,6 +797,13 @@
 config DMA_COHERENT
 	bool
 
+config TANGOX
+	bool 
+
+config DMA_TANGOX
+	bool
+	select DMA_NEED_PCI_MAP_STATE
+
 config DMA_NONCOHERENT
 	bool
 	select DMA_NEED_PCI_MAP_STATE
@@ -974,6 +1021,8 @@
 	default "4" if MACH_DECSTATION || MIKROTIK_RB532
 	default "7" if SGI_IP22 || SGI_IP27 || SGI_IP28 || SNI_RM || CPU_CAVIUM_OCTEON
 	default "4" if PMC_MSP4200_EVAL
+	default "4" if TANGO2
+	default "5" if TANGO3
 	default "5"
 
 config HAVE_STD_PC_SERIAL_PORT
diff -Naur linux-2.6.30-ori/arch/mips/Kconfig.orig linux-2.6.30-test/arch/mips/Kconfig.orig
--- linux-2.6.30-ori/arch/mips/Kconfig.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/Kconfig.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,2144 @@
+config MIPS
+	bool
+	default y
+	select HAVE_IDE
+	select HAVE_OPROFILE
+	select HAVE_ARCH_KGDB
+	# Horrible source of confusion.  Die, die, die ...
+	select EMBEDDED
+	select RTC_LIB
+
+mainmenu "Linux/MIPS Kernel Configuration"
+
+menu "Machine selection"
+
+config ZONE_DMA
+	bool
+
+choice
+	prompt "System type"
+	default SGI_IP22
+
+config MACH_ALCHEMY
+	bool "Alchemy processor based machines"
+
+config BASLER_EXCITE
+	bool "Basler eXcite smart camera"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_COHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select IRQ_CPU_RM7K
+	select IRQ_CPU_RM9K
+	select MIPS_RM9122
+	select SYS_HAS_CPU_RM9000
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	help
+	  The eXcite is a smart camera platform manufactured by
+	  Basler Vision Technologies AG.
+
+config BCM47XX
+	bool "BCM47XX based boards"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SSB
+	select SSB_DRIVER_MIPS
+	select SSB_DRIVER_EXTIF
+	select SSB_EMBEDDED
+	select SSB_PCICORE_HOSTMODE if PCI
+	select GENERIC_GPIO
+	select SYS_HAS_EARLY_PRINTK
+	select CFE
+	help
+	 Support for BCM47XX based boards
+
+config MIPS_COBALT
+	bool "Cobalt Server"
+	select CEVT_R4K
+	select CSRC_R4K
+	select CEVT_GT641XX
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select I8253
+	select I8259
+	select IRQ_CPU
+	select IRQ_GT641XX
+	select PCI_GT64XXX_PCI0
+	select PCI
+	select SYS_HAS_CPU_NEVADA
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config MACH_DECSTATION
+	bool "DECstations"
+	select BOOT_ELF32
+	select CEVT_DS1287
+	select CEVT_R4K
+	select CSRC_IOASIC
+	select CSRC_R4K
+	select CPU_DADDI_WORKAROUNDS if 64BIT
+	select CPU_R4000_WORKAROUNDS if 64BIT
+	select CPU_R4400_WORKAROUNDS if 64BIT
+	select DMA_NONCOHERENT
+	select NO_IOPORT
+	select IRQ_CPU
+	select SYS_HAS_CPU_R3000
+	select SYS_HAS_CPU_R4X00
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL if EXPERIMENTAL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_128HZ
+	select SYS_SUPPORTS_256HZ
+	select SYS_SUPPORTS_1024HZ
+	help
+	  This enables support for DEC's MIPS based workstations.  For details
+	  see the Linux/MIPS FAQ on <http://www.linux-mips.org/> and the
+	  DECstation porting pages on <http://decstation.unix-ag.org/>.
+
+	  If you have one of the following DECstation Models you definitely
+	  want to choose R4xx0 for the CPU Type:
+
+		DECstation 5000/50
+		DECstation 5000/150
+		DECstation 5000/260
+		DECsystem 5900/260
+
+	  otherwise choose R3000.
+
+config MACH_JAZZ
+	bool "Jazz family of machines"
+	select ARC
+	select ARC32
+	select ARCH_MAY_HAVE_PC_FDC
+	select CEVT_R4K
+	select CSRC_R4K
+	select DEFAULT_SGI_PARTITION if CPU_BIG_ENDIAN
+	select GENERIC_ISA_DMA
+	select IRQ_CPU
+	select I8253
+	select I8259
+	select ISA
+	select SYS_HAS_CPU_R4X00
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL if EXPERIMENTAL
+	select SYS_SUPPORTS_100HZ
+	help
+	 This a family of machines based on the MIPS R4030 chipset which was
+	 used by several vendors to build RISC/os and Windows NT workstations.
+	 Members include the Acer PICA, MIPS Magnum 4000, MIPS Millennium and
+	 Olivetti M700-10 workstations.
+
+config LASAT
+	bool "LASAT Networks platforms"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select SYS_HAS_EARLY_PRINTK
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select PCI_GT64XXX_PCI0
+	select MIPS_NILE4
+	select R5000_CPU_SCACHE
+	select SYS_HAS_CPU_R5000
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL if BROKEN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config LEMOTE_FULONG
+	bool "Lemote Fulong mini-PC"
+	select ARCH_SPARSEMEM_ENABLE
+	select CEVT_R4K
+	select CSRC_R4K
+	select SYS_HAS_CPU_LOONGSON2
+	select DMA_NONCOHERENT
+	select BOOT_ELF32
+	select BOARD_SCACHE
+	select HAVE_STD_PC_SERIAL_PORT
+	select HW_HAS_PCI
+	select I8259
+	select ISA
+	select IRQ_CPU
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_HAS_EARLY_PRINTK
+	select GENERIC_ISA_DMA_SUPPORT_BROKEN
+	select CPU_HAS_WB
+	help
+	  Lemote Fulong mini-PC board based on the Chinese Loongson-2E CPU and
+	  an FPGA northbridge
+
+config MIPS_MALTA
+	bool "MIPS Malta board"
+	select ARCH_MAY_HAVE_PC_FDC
+	select BOOT_ELF32
+	select BOOT_RAW
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select GENERIC_ISA_DMA
+	select IRQ_CPU
+	select IRQ_GIC
+	select HW_HAS_PCI
+	select I8253
+	select I8259
+	select MIPS_BOARDS_GEN
+	select MIPS_BONITO64
+	select MIPS_CPU_SCACHE
+	select PCI_GT64XXX_PCI0
+	select MIPS_MSC
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_HAS_CPU_MIPS64_R1
+	select SYS_HAS_CPU_NEVADA
+	select SYS_HAS_CPU_RM7000
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_MIPS_CMP if BROKEN	# because SYNC_R4K is broken
+	select SYS_SUPPORTS_MULTITHREADING
+	select SYS_SUPPORTS_SMARTMIPS
+	help
+	  This enables support for the MIPS Technologies Malta evaluation
+	  board.
+
+config MIPS_SIM
+	bool 'MIPS simulator (MIPSsim)'
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select SYS_HAS_EARLY_PRINTK
+	select IRQ_CPU
+	select BOOT_RAW
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_MULTITHREADING
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	help
+	  This option enables support for MIPS Technologies MIPSsim software
+	  emulator.
+
+config NEC_MARKEINS
+	bool "NEC EMMA2RH Mark-eins board"
+	select SOC_EMMA2RH
+	select HW_HAS_PCI
+	help
+	  This enables support for the NEC Electronics Mark-eins boards.
+
+config MACH_VR41XX
+	bool "NEC VR4100 series based machines"
+	select CEVT_R4K
+	select CSRC_R4K
+	select SYS_HAS_CPU_VR41XX
+
+config NXP_STB220
+	bool "NXP STB220 board"
+	select SOC_PNX833X
+	help
+	 Support for NXP Semiconductors STB220 Development Board.
+
+config NXP_STB225
+	bool "NXP 225 board"
+	select SOC_PNX833X
+	select SOC_PNX8335
+	help
+	 Support for NXP Semiconductors STB225 Development Board.
+
+config PNX8550_JBS
+	bool "NXP PNX8550 based JBS board"
+	select PNX8550
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config PNX8550_STB810
+	bool "NXP PNX8550 based STB810 board"
+	select PNX8550
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config PMC_MSP
+	bool "PMC-Sierra MSP chipsets"
+	depends on EXPERIMENTAL
+	select DMA_NONCOHERENT
+	select SWAP_IO_SPACE
+	select NO_EXCEPT_FILL
+	select BOOT_RAW
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select IRQ_CPU
+	select SERIAL_8250
+	select SERIAL_8250_CONSOLE
+	help
+	  This adds support for the PMC-Sierra family of Multi-Service
+	  Processor System-On-A-Chips.  These parts include a number
+	  of integrated peripherals, interfaces and DSPs in addition to
+	  a variety of MIPS cores.
+
+config PMC_YOSEMITE
+	bool "PMC-Sierra Yosemite eval board"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_COHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select IRQ_CPU_RM7K
+	select IRQ_CPU_RM9K
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_RM9000
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_SMP
+	help
+	  Yosemite is an evaluation board for the RM9000x2 processor
+	  manufactured by PMC-Sierra.
+
+config SGI_IP22
+	bool "SGI IP22 (Indy/Indigo2)"
+	select ARC
+	select ARC32
+	select BOOT_ELF32
+	select CEVT_R4K
+	select CSRC_R4K
+	select DEFAULT_SGI_PARTITION
+	select DMA_NONCOHERENT
+	select HW_HAS_EISA
+	select I8253
+	select I8259
+	select IP22_CPU_SCACHE
+	select IRQ_CPU
+	select GENERIC_ISA_DMA_SUPPORT_BROKEN
+	select SGI_HAS_I8042
+	select SGI_HAS_INDYDOG
+	select SGI_HAS_HAL2
+	select SGI_HAS_SEEQ
+	select SGI_HAS_WD93
+	select SGI_HAS_ZILOG
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_R4X00
+	select SYS_HAS_CPU_R5000
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	help
+	  This are the SGI Indy, Challenge S and Indigo2, as well as certain
+	  OEM variants like the Tandem CMN B006S. To compile a Linux kernel
+	  that runs on these, say Y here.
+
+config SGI_IP27
+	bool "SGI IP27 (Origin200/2000)"
+	select ARC
+	select ARC64
+	select BOOT_ELF64
+	select DEFAULT_SGI_PARTITION
+	select DMA_COHERENT
+	select SYS_HAS_EARLY_PRINTK
+	select HW_HAS_PCI
+	select NR_CPUS_DEFAULT_64
+	select SYS_HAS_CPU_R10000
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_NUMA
+	select SYS_SUPPORTS_SMP
+	help
+	  This are the SGI Origin 200, Origin 2000 and Onyx 2 Graphics
+	  workstations.  To compile a Linux kernel that runs on these, say Y
+	  here.
+
+config SGI_IP28
+	bool "SGI IP28 (Indigo2 R10k) (EXPERIMENTAL)"
+	depends on EXPERIMENTAL
+	select ARC
+	select ARC64
+	select BOOT_ELF64
+	select CEVT_R4K
+	select CSRC_R4K
+	select DEFAULT_SGI_PARTITION
+	select DMA_NONCOHERENT
+	select GENERIC_ISA_DMA_SUPPORT_BROKEN
+	select IRQ_CPU
+	select HW_HAS_EISA
+	select I8253
+	select I8259
+	select SGI_HAS_I8042
+	select SGI_HAS_INDYDOG
+	select SGI_HAS_HAL2
+	select SGI_HAS_SEEQ
+	select SGI_HAS_WD93
+	select SGI_HAS_ZILOG
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_R10000
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+      help
+        This is the SGI Indigo2 with R10000 processor.  To compile a Linux
+        kernel that runs on these, say Y here.
+
+config SGI_IP32
+	bool "SGI IP32 (O2)"
+	select ARC
+	select ARC32
+	select BOOT_ELF32
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select R5000_CPU_SCACHE
+	select RM7000_CPU_SCACHE
+	select SYS_HAS_CPU_R5000
+	select SYS_HAS_CPU_R10000 if BROKEN
+	select SYS_HAS_CPU_RM7000
+	select SYS_HAS_CPU_NEVADA
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	help
+	  If you want this kernel to run on SGI O2 workstation, say Y here.
+
+config SIBYTE_CRHINE
+	bool "Sibyte BCM91120C-CRhine"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select SIBYTE_BCM1120
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_CARMEL
+	bool "Sibyte BCM91120x-Carmel"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select SIBYTE_BCM1120
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_CRHONE
+	bool "Sibyte BCM91125C-CRhone"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select SIBYTE_BCM1125
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_RHONE
+	bool "Sibyte BCM91125E-Rhone"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select SIBYTE_BCM1125H
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_SWARM
+	bool "Sibyte BCM91250A-SWARM"
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select NR_CPUS_DEFAULT_2
+	select SIBYTE_SB1250
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select ZONE_DMA32 if 64BIT
+
+config SIBYTE_LITTLESUR
+	bool "Sibyte BCM91250C2-LittleSur"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select NR_CPUS_DEFAULT_2
+	select SIBYTE_SB1250
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_SENTOSA
+	bool "Sibyte BCM91250E-Sentosa"
+	depends on EXPERIMENTAL
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select NR_CPUS_DEFAULT_2
+	select SIBYTE_SB1250
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+
+config SIBYTE_BIGSUR
+	bool "Sibyte BCM91480B-BigSur"
+	select BOOT_ELF32
+	select DMA_COHERENT
+	select NR_CPUS_DEFAULT_4
+	select SIBYTE_BCM1x80
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_SB1
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select ZONE_DMA32 if 64BIT
+
+config SNI_RM
+	bool "SNI RM200/300/400"
+	select ARC if CPU_LITTLE_ENDIAN
+	select ARC32 if CPU_LITTLE_ENDIAN
+	select SNIPROM if CPU_BIG_ENDIAN
+	select ARCH_MAY_HAVE_PC_FDC
+	select BOOT_ELF32
+	select CEVT_R4K
+	select CSRC_R4K
+	select DEFAULT_SGI_PARTITION if CPU_BIG_ENDIAN
+	select DMA_NONCOHERENT
+	select GENERIC_ISA_DMA
+	select HW_HAS_EISA
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select I8253
+	select I8259
+	select ISA
+	select SWAP_IO_SPACE if CPU_BIG_ENDIAN
+	select SYS_HAS_CPU_R4X00
+	select SYS_HAS_CPU_R5000
+	select SYS_HAS_CPU_R10000
+	select R5000_CPU_SCACHE
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL if EXPERIMENTAL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	help
+	  The SNI RM200/300/400 are MIPS-based machines manufactured by
+	  Siemens Nixdorf Informationssysteme (SNI), parent company of Pyramid
+	  Technology and now in turn merged with Fujitsu.  Say Y here to
+	  support this machine type.
+
+config MACH_TX39XX
+	bool "Toshiba TX39 series based machines"
+
+config MACH_TX49XX
+	bool "Toshiba TX49 series based machines"
+
+config MIKROTIK_RB532
+	bool "Mikrotik RB532 boards"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SWAP_IO_SPACE
+	select BOOT_RAW
+	select ARCH_REQUIRE_GPIOLIB
+	help
+	  Support the Mikrotik(tm) RouterBoard 532 series,
+	  based on the IDT RC32434 SoC.
+
+config WR_PPMC
+	bool "Wind River PPMC board"
+	select CEVT_R4K
+	select CSRC_R4K
+	select IRQ_CPU
+	select BOOT_ELF32
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select PCI_GT64XXX_PCI0
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_HAS_CPU_MIPS64_R1
+	select SYS_HAS_CPU_NEVADA
+	select SYS_HAS_CPU_RM7000
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	help
+	  This enables support for the Wind River MIPS32 4KC PPMC evaluation
+	  board, which is based on GT64120 bridge chip.
+
+config CAVIUM_OCTEON_SIMULATOR
+	bool "Cavium Networks Octeon Simulator"
+	select CEVT_R4K
+	select 64BIT_PHYS_ADDR
+	select DMA_COHERENT
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_HAS_CPU_CAVIUM_OCTEON
+	help
+	  The Octeon simulator is software performance model of the Cavium
+	  Octeon Processor. It supports simulating Octeon processors on x86
+	  hardware.
+
+config CAVIUM_OCTEON_REFERENCE_BOARD
+	bool "Cavium Networks Octeon reference board"
+	select CEVT_R4K
+	select 64BIT_PHYS_ADDR
+	select DMA_COHERENT
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_HAS_CPU_CAVIUM_OCTEON
+	select SWAP_IO_SPACE
+	help
+	  This option supports all of the Octeon reference boards from Cavium
+	  Networks. It builds a kernel that dynamically determines the Octeon
+	  CPU type and supports all known board reference implementations.
+	  Some of the supported boards are:
+		EBT3000
+		EBH3000
+		EBH3100
+		Thunder
+		Kodama
+		Hikari
+	  Say Y here for most Octeon reference boards.
+
+endchoice
+
+source "arch/mips/alchemy/Kconfig"
+source "arch/mips/basler/excite/Kconfig"
+source "arch/mips/jazz/Kconfig"
+source "arch/mips/lasat/Kconfig"
+source "arch/mips/pmc-sierra/Kconfig"
+source "arch/mips/sgi-ip27/Kconfig"
+source "arch/mips/sibyte/Kconfig"
+source "arch/mips/txx9/Kconfig"
+source "arch/mips/vr41xx/Kconfig"
+source "arch/mips/cavium-octeon/Kconfig"
+
+endmenu
+
+config RWSEM_GENERIC_SPINLOCK
+	bool
+	default y
+
+config RWSEM_XCHGADD_ALGORITHM
+	bool
+
+config ARCH_HAS_ILOG2_U32
+	bool
+	default n
+
+config ARCH_HAS_ILOG2_U64
+	bool
+	default n
+
+config ARCH_SUPPORTS_OPROFILE
+	bool
+	default y if !MIPS_MT_SMTC
+
+config GENERIC_FIND_NEXT_BIT
+	bool
+	default y
+
+config GENERIC_HWEIGHT
+	bool
+	default y
+
+config GENERIC_CALIBRATE_DELAY
+	bool
+	default y
+
+config GENERIC_CLOCKEVENTS
+	bool
+	default y
+
+config GENERIC_TIME
+	bool
+	default y
+
+config GENERIC_CMOS_UPDATE
+	bool
+	default y
+
+config SCHED_OMIT_FRAME_POINTER
+	bool
+	default y
+
+config GENERIC_HARDIRQS_NO__DO_IRQ
+	def_bool y
+
+#
+# Select some configuration options automatically based on user selections.
+#
+config ARC
+	bool
+
+config ARCH_MAY_HAVE_PC_FDC
+	bool
+
+config BOOT_RAW
+	bool
+
+config CEVT_BCM1480
+	bool
+
+config CEVT_DS1287
+	bool
+
+config CEVT_GT641XX
+	bool
+
+config CEVT_R4K_LIB
+	bool
+
+config CEVT_R4K
+	select CEVT_R4K_LIB
+	bool
+
+config CEVT_SB1250
+	bool
+
+config CEVT_TXX9
+	bool
+
+config CSRC_BCM1480
+	bool
+
+config CSRC_IOASIC
+	bool
+
+config CSRC_R4K_LIB
+	bool
+
+config CSRC_R4K
+	select CSRC_R4K_LIB
+	bool
+
+config CSRC_SB1250
+	bool
+
+config GPIO_TXX9
+	select GENERIC_GPIO
+	select ARCH_REQUIRE_GPIOLIB
+	bool
+
+config CFE
+	bool
+
+config DMA_COHERENT
+	bool
+
+config DMA_NONCOHERENT
+	bool
+	select DMA_NEED_PCI_MAP_STATE
+
+config DMA_NEED_PCI_MAP_STATE
+	bool
+
+config EARLY_PRINTK
+	bool "Early printk" if EMBEDDED && DEBUG_KERNEL
+	depends on SYS_HAS_EARLY_PRINTK
+	default y
+	help
+	  This option enables special console drivers which allow the kernel
+	  to print messages very early in the bootup process.
+
+	  This is useful for kernel debugging when your machine crashes very
+	  early before the console code is initialized. For normal operation,
+	  it is not recommended because it looks ugly on some machines and
+	  doesn't cooperate with an X server. You should normally say N here,
+	  unless you want to debug such a crash.
+
+config SYS_HAS_EARLY_PRINTK
+	bool
+
+config HOTPLUG_CPU
+	bool
+	default n
+
+config I8259
+	bool
+
+config MIPS_BONITO64
+	bool
+
+config MIPS_MSC
+	bool
+
+config MIPS_NILE4
+	bool
+
+config MIPS_DISABLE_OBSOLETE_IDE
+	bool
+
+config SYNC_R4K
+	bool
+
+config NO_IOPORT
+	def_bool n
+
+config GENERIC_ISA_DMA
+	bool
+	select ZONE_DMA if GENERIC_ISA_DMA_SUPPORT_BROKEN=n
+
+config GENERIC_ISA_DMA_SUPPORT_BROKEN
+	bool
+	select GENERIC_ISA_DMA
+
+config GENERIC_GPIO
+	bool
+
+#
+# Endianess selection.  Sufficiently obscure so many users don't know what to
+# answer,so we try hard to limit the available choices.  Also the use of a
+# choice statement should be more obvious to the user.
+#
+choice
+	prompt "Endianess selection"
+	help
+	  Some MIPS machines can be configured for either little or big endian
+	  byte order. These modes require different kernels and a different
+	  Linux distribution.  In general there is one preferred byteorder for a
+	  particular system but some systems are just as commonly used in the
+	  one or the other endianness.
+
+config CPU_BIG_ENDIAN
+	bool "Big endian"
+	depends on SYS_SUPPORTS_BIG_ENDIAN
+
+config CPU_LITTLE_ENDIAN
+	bool "Little endian"
+	depends on SYS_SUPPORTS_LITTLE_ENDIAN
+	help
+
+endchoice
+
+config SYS_SUPPORTS_APM_EMULATION
+	bool
+
+config SYS_SUPPORTS_BIG_ENDIAN
+	bool
+
+config SYS_SUPPORTS_LITTLE_ENDIAN
+	bool
+
+config IRQ_CPU
+	bool
+
+config IRQ_CPU_RM7K
+	bool
+
+config IRQ_CPU_RM9K
+	bool
+
+config IRQ_MSP_SLP
+	bool
+
+config IRQ_MSP_CIC
+	bool
+
+config IRQ_TXX9
+	bool
+
+config IRQ_GT641XX
+	bool
+
+config IRQ_GIC
+	bool
+
+config IRQ_CPU_OCTEON
+	bool
+
+config MIPS_BOARDS_GEN
+	bool
+
+config PCI_GT64XXX_PCI0
+	bool
+
+config NO_EXCEPT_FILL
+	bool
+
+config MIPS_RM9122
+	bool
+	select SERIAL_RM9000
+
+config SOC_EMMA2RH
+	bool
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select IRQ_CPU
+	select SWAP_IO_SPACE
+	select SYS_HAS_CPU_R5500
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+
+config SOC_PNX833X
+	bool
+	select CEVT_R4K
+	select CSRC_R4K
+	select IRQ_CPU
+	select DMA_NONCOHERENT
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select GENERIC_GPIO
+	select CPU_MIPSR2_IRQ_VI
+
+config SOC_PNX8335
+	bool
+	select SOC_PNX833X
+
+config PNX8550
+	bool
+	select SOC_PNX8550
+
+config SOC_PNX8550
+	bool
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select GENERIC_GPIO
+
+config SWAP_IO_SPACE
+	bool
+
+config SERIAL_RM9000
+	bool
+
+config SGI_HAS_INDYDOG
+	bool
+
+config SGI_HAS_HAL2
+	bool
+
+config SGI_HAS_SEEQ
+	bool
+
+config SGI_HAS_WD93
+	bool
+
+config SGI_HAS_ZILOG
+	bool
+
+config SGI_HAS_I8042
+	bool
+
+config DEFAULT_SGI_PARTITION
+	bool
+
+config ARC32
+	bool
+
+config SNIPROM
+	bool
+
+config BOOT_ELF32
+	bool
+
+config MIPS_L1_CACHE_SHIFT
+	int
+	default "4" if MACH_DECSTATION || MIKROTIK_RB532
+	default "7" if SGI_IP22 || SGI_IP27 || SGI_IP28 || SNI_RM || CPU_CAVIUM_OCTEON
+	default "4" if PMC_MSP4200_EVAL
+	default "5"
+
+config HAVE_STD_PC_SERIAL_PORT
+	bool
+
+config ARC_CONSOLE
+	bool "ARC console support"
+	depends on SGI_IP22 || SGI_IP28 || (SNI_RM && CPU_LITTLE_ENDIAN)
+
+config ARC_MEMORY
+	bool
+	depends on MACH_JAZZ || SNI_RM || SGI_IP32
+	default y
+
+config ARC_PROMLIB
+	bool
+	depends on MACH_JAZZ || SNI_RM || SGI_IP22 || SGI_IP28 || SGI_IP32
+	default y
+
+config ARC64
+	bool
+
+config BOOT_ELF64
+	bool
+
+menu "CPU selection"
+
+choice
+	prompt "CPU type"
+	default CPU_R4X00
+
+config CPU_LOONGSON2
+	bool "Loongson 2"
+	depends on SYS_HAS_CPU_LOONGSON2
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  The Loongson 2E processor implements the MIPS III instruction set
+	  with many extensions.
+
+config CPU_MIPS32_R1
+	bool "MIPS32 Release 1"
+	depends on SYS_HAS_CPU_MIPS32_R1
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  Choose this option to build a kernel for release 1 or later of the
+	  MIPS32 architecture.  Most modern embedded systems with a 32-bit
+	  MIPS processor are based on a MIPS32 processor.  If you know the
+	  specific type of processor in your system, choose those that one
+	  otherwise CPU_MIPS32_R1 is a safe bet for any MIPS32 system.
+	  Release 2 of the MIPS32 architecture is available since several
+	  years so chances are you even have a MIPS32 Release 2 processor
+	  in which case you should choose CPU_MIPS32_R2 instead for better
+	  performance.
+
+config CPU_MIPS32_R2
+	bool "MIPS32 Release 2"
+	depends on SYS_HAS_CPU_MIPS32_R2
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  Choose this option to build a kernel for release 2 or later of the
+	  MIPS32 architecture.  Most modern embedded systems with a 32-bit
+	  MIPS processor are based on a MIPS32 processor.  If you know the
+	  specific type of processor in your system, choose those that one
+	  otherwise CPU_MIPS32_R1 is a safe bet for any MIPS32 system.
+
+config CPU_MIPS64_R1
+	bool "MIPS64 Release 1"
+	depends on SYS_HAS_CPU_MIPS64_R1
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  Choose this option to build a kernel for release 1 or later of the
+	  MIPS64 architecture.  Many modern embedded systems with a 64-bit
+	  MIPS processor are based on a MIPS64 processor.  If you know the
+	  specific type of processor in your system, choose those that one
+	  otherwise CPU_MIPS64_R1 is a safe bet for any MIPS64 system.
+	  Release 2 of the MIPS64 architecture is available since several
+	  years so chances are you even have a MIPS64 Release 2 processor
+	  in which case you should choose CPU_MIPS64_R2 instead for better
+	  performance.
+
+config CPU_MIPS64_R2
+	bool "MIPS64 Release 2"
+	depends on SYS_HAS_CPU_MIPS64_R2
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  Choose this option to build a kernel for release 2 or later of the
+	  MIPS64 architecture.  Many modern embedded systems with a 64-bit
+	  MIPS processor are based on a MIPS64 processor.  If you know the
+	  specific type of processor in your system, choose those that one
+	  otherwise CPU_MIPS64_R1 is a safe bet for any MIPS64 system.
+
+config CPU_R3000
+	bool "R3000"
+	depends on SYS_HAS_CPU_R3000
+	select CPU_HAS_WB
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  Please make sure to pick the right CPU type. Linux/MIPS is not
+	  designed to be generic, i.e. Kernels compiled for R3000 CPUs will
+	  *not* work on R4000 machines and vice versa.  However, since most
+	  of the supported machines have an R4000 (or similar) CPU, R4x00
+	  might be a safe bet.  If the resulting kernel does not work,
+	  try to recompile with R3000.
+
+config CPU_TX39XX
+	bool "R39XX"
+	depends on SYS_HAS_CPU_TX39XX
+	select CPU_SUPPORTS_32BIT_KERNEL
+
+config CPU_VR41XX
+	bool "R41xx"
+	depends on SYS_HAS_CPU_VR41XX
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  The options selects support for the NEC VR4100 series of processors.
+	  Only choose this option if you have one of these processors as a
+	  kernel built with this option will not run on any other type of
+	  processor or vice versa.
+
+config CPU_R4300
+	bool "R4300"
+	depends on SYS_HAS_CPU_R4300
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  MIPS Technologies R4300-series processors.
+
+config CPU_R4X00
+	bool "R4x00"
+	depends on SYS_HAS_CPU_R4X00
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  MIPS Technologies R4000-series processors other than 4300, including
+	  the R4000, R4400, R4600, and 4700.
+
+config CPU_TX49XX
+	bool "R49XX"
+	depends on SYS_HAS_CPU_TX49XX
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+
+config CPU_R5000
+	bool "R5000"
+	depends on SYS_HAS_CPU_R5000
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  MIPS Technologies R5000-series processors other than the Nevada.
+
+config CPU_R5432
+	bool "R5432"
+	depends on SYS_HAS_CPU_R5432
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+
+config CPU_R5500
+	bool "R5500"
+	depends on SYS_HAS_CPU_R5500
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  NEC VR5500 and VR5500A series processors implement 64-bit MIPS IV
+	  instruction set.
+
+config CPU_R6000
+	bool "R6000"
+	depends on EXPERIMENTAL
+	select CPU_HAS_LLSC
+	depends on SYS_HAS_CPU_R6000
+	select CPU_SUPPORTS_32BIT_KERNEL
+	help
+	  MIPS Technologies R6000 and R6000A series processors.  Note these
+	  processors are extremely rare and the support for them is incomplete.
+
+config CPU_NEVADA
+	bool "RM52xx"
+	depends on SYS_HAS_CPU_NEVADA
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  QED / PMC-Sierra RM52xx-series ("Nevada") processors.
+
+config CPU_R8000
+	bool "R8000"
+	depends on EXPERIMENTAL
+	depends on SYS_HAS_CPU_R8000
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_64BIT_KERNEL
+	help
+	  MIPS Technologies R8000 processors.  Note these processors are
+	  uncommon and the support for them is incomplete.
+
+config CPU_R10000
+	bool "R10000"
+	depends on SYS_HAS_CPU_R10000
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  MIPS Technologies R10000-series processors.
+
+config CPU_RM7000
+	bool "RM7000"
+	depends on SYS_HAS_CPU_RM7000
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+
+config CPU_RM9000
+	bool "RM9000"
+	depends on SYS_HAS_CPU_RM9000
+	select CPU_HAS_LLSC
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	select WEAK_ORDERING
+
+config CPU_SB1
+	bool "SB1"
+	depends on SYS_HAS_CPU_SB1
+	select CPU_HAS_LLSC
+	select CPU_SUPPORTS_32BIT_KERNEL
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select CPU_SUPPORTS_HIGHMEM
+	select WEAK_ORDERING
+
+config CPU_CAVIUM_OCTEON
+	bool "Cavium Octeon processor"
+	depends on SYS_HAS_CPU_CAVIUM_OCTEON
+	select IRQ_CPU
+	select IRQ_CPU_OCTEON
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_SMP
+	select NR_CPUS_DEFAULT_16
+	select WEAK_ORDERING
+	select WEAK_REORDERING_BEYOND_LLSC
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  The Cavium Octeon processor is a highly integrated chip containing
+	  many ethernet hardware widgets for networking tasks. The processor
+	  can have up to 16 Mips64v2 cores and 8 integrated gigabit ethernets.
+	  Full details can be found at http://www.caviumnetworks.com.
+
+endchoice
+
+config SYS_HAS_CPU_LOONGSON2
+	bool
+
+config SYS_HAS_CPU_MIPS32_R1
+	bool
+
+config SYS_HAS_CPU_MIPS32_R2
+	bool
+
+config SYS_HAS_CPU_MIPS64_R1
+	bool
+
+config SYS_HAS_CPU_MIPS64_R2
+	bool
+
+config SYS_HAS_CPU_R3000
+	bool
+
+config SYS_HAS_CPU_TX39XX
+	bool
+
+config SYS_HAS_CPU_VR41XX
+	bool
+
+config SYS_HAS_CPU_R4300
+	bool
+
+config SYS_HAS_CPU_R4X00
+	bool
+
+config SYS_HAS_CPU_TX49XX
+	bool
+
+config SYS_HAS_CPU_R5000
+	bool
+
+config SYS_HAS_CPU_R5432
+	bool
+
+config SYS_HAS_CPU_R5500
+	bool
+
+config SYS_HAS_CPU_R6000
+	bool
+
+config SYS_HAS_CPU_NEVADA
+	bool
+
+config SYS_HAS_CPU_R8000
+	bool
+
+config SYS_HAS_CPU_R10000
+	bool
+
+config SYS_HAS_CPU_RM7000
+	bool
+
+config SYS_HAS_CPU_RM9000
+	bool
+
+config SYS_HAS_CPU_SB1
+	bool
+
+config SYS_HAS_CPU_CAVIUM_OCTEON
+	bool
+
+#
+# CPU may reorder R->R, R->W, W->R, W->W
+# Reordering beyond LL and SC is handled in WEAK_REORDERING_BEYOND_LLSC
+#
+config WEAK_ORDERING
+	bool
+
+#
+# CPU may reorder reads and writes beyond LL/SC
+# CPU may reorder R->LL, R->LL, W->LL, W->LL, R->SC, R->SC, W->SC, W->SC
+#
+config WEAK_REORDERING_BEYOND_LLSC
+	bool
+endmenu
+
+#
+# These two indicate any level of the MIPS32 and MIPS64 architecture
+#
+config CPU_MIPS32
+	bool
+	default y if CPU_MIPS32_R1 || CPU_MIPS32_R2
+
+config CPU_MIPS64
+	bool
+	default y if CPU_MIPS64_R1 || CPU_MIPS64_R2
+
+#
+# These two indicate the revision of the architecture, either Release 1 or Release 2
+#
+config CPU_MIPSR1
+	bool
+	default y if CPU_MIPS32_R1 || CPU_MIPS64_R1
+
+config CPU_MIPSR2
+	bool
+	default y if CPU_MIPS32_R2 || CPU_MIPS64_R2 || CPU_CAVIUM_OCTEON
+
+config SYS_SUPPORTS_32BIT_KERNEL
+	bool
+config SYS_SUPPORTS_64BIT_KERNEL
+	bool
+config CPU_SUPPORTS_32BIT_KERNEL
+	bool
+config CPU_SUPPORTS_64BIT_KERNEL
+	bool
+
+#
+# Set to y for ptrace access to watch registers.
+#
+config HARDWARE_WATCHPOINTS
+       bool
+       default y if CPU_MIPSR1 || CPU_MIPSR2
+
+menu "Kernel type"
+
+choice
+
+	prompt "Kernel code model"
+	help
+	  You should only select this option if you have a workload that
+	  actually benefits from 64-bit processing or if your machine has
+	  large memory.  You will only be presented a single option in this
+	  menu if your system does not support both 32-bit and 64-bit kernels.
+
+config 32BIT
+	bool "32-bit kernel"
+	depends on CPU_SUPPORTS_32BIT_KERNEL && SYS_SUPPORTS_32BIT_KERNEL
+	select TRAD_SIGNALS
+	help
+	  Select this option if you want to build a 32-bit kernel.
+config 64BIT
+	bool "64-bit kernel"
+	depends on CPU_SUPPORTS_64BIT_KERNEL && SYS_SUPPORTS_64BIT_KERNEL
+	select HAVE_SYSCALL_WRAPPERS
+	help
+	  Select this option if you want to build a 64-bit kernel.
+
+endchoice
+
+choice
+	prompt "Kernel page size"
+	default PAGE_SIZE_4KB
+
+config PAGE_SIZE_4KB
+	bool "4kB"
+	help
+	 This option select the standard 4kB Linux page size.  On some
+	 R3000-family processors this is the only available page size.  Using
+	 4kB page size will minimize memory consumption and is therefore
+	 recommended for low memory systems.
+
+config PAGE_SIZE_8KB
+	bool "8kB"
+	depends on (EXPERIMENTAL && CPU_R8000) || CPU_CAVIUM_OCTEON
+	help
+	  Using 8kB page size will result in higher performance kernel at
+	  the price of higher memory consumption.  This option is available
+	  only on R8000 and cnMIPS processors.  Note that you will need a
+	  suitable Linux distribution to support this.
+
+config PAGE_SIZE_16KB
+	bool "16kB"
+	depends on !CPU_R3000 && !CPU_TX39XX
+	help
+	  Using 16kB page size will result in higher performance kernel at
+	  the price of higher memory consumption.  This option is available on
+	  all non-R3000 family processors.  Note that you will need a suitable
+	  Linux distribution to support this.
+
+config PAGE_SIZE_32KB
+	bool "32kB"
+	depends on CPU_CAVIUM_OCTEON
+	help
+	  Using 32kB page size will result in higher performance kernel at
+	  the price of higher memory consumption.  This option is available
+	  only on cnMIPS cores.  Note that you will need a suitable Linux
+	  distribution to support this.
+
+config PAGE_SIZE_64KB
+	bool "64kB"
+	depends on EXPERIMENTAL && !CPU_R3000 && !CPU_TX39XX
+	help
+	  Using 64kB page size will result in higher performance kernel at
+	  the price of higher memory consumption.  This option is available on
+	  all non-R3000 family processor.  Not that at the time of this
+	  writing this option is still high experimental.
+
+endchoice
+
+config BOARD_SCACHE
+	bool
+
+config IP22_CPU_SCACHE
+	bool
+	select BOARD_SCACHE
+
+#
+# Support for a MIPS32 / MIPS64 style S-caches
+#
+config MIPS_CPU_SCACHE
+	bool
+	select BOARD_SCACHE
+
+config R5000_CPU_SCACHE
+	bool
+	select BOARD_SCACHE
+
+config RM7000_CPU_SCACHE
+	bool
+	select BOARD_SCACHE
+
+config SIBYTE_DMA_PAGEOPS
+	bool "Use DMA to clear/copy pages"
+	depends on CPU_SB1
+	help
+	  Instead of using the CPU to zero and copy pages, use a Data Mover
+	  channel.  These DMA channels are otherwise unused by the standard
+	  SiByte Linux port.  Seems to give a small performance benefit.
+
+config CPU_HAS_PREFETCH
+	bool
+
+choice
+	prompt "MIPS MT options"
+
+config MIPS_MT_DISABLED
+	bool "Disable multithreading support."
+	help
+	  Use this option if your workload can't take advantage of
+	  MIPS hardware multithreading support.  On systems that don't have
+	  the option of an MT-enabled processor this option will be the only
+	  option in this menu.
+
+config MIPS_MT_SMP
+	bool "Use 1 TC on each available VPE for SMP"
+	depends on SYS_SUPPORTS_MULTITHREADING
+	select CPU_MIPSR2_IRQ_VI
+	select CPU_MIPSR2_IRQ_EI
+	select MIPS_MT
+	select NR_CPUS_DEFAULT_2
+	select SMP
+	select SYS_SUPPORTS_SCHED_SMT if SMP
+	select SYS_SUPPORTS_SMP
+	select SMP_UP
+	help
+	  This is a kernel model which is also known a VSMP or lately
+	  has been marketesed into SMVP.
+
+config MIPS_MT_SMTC
+	bool "SMTC: Use all TCs on all VPEs for SMP"
+	depends on CPU_MIPS32_R2
+	#depends on CPU_MIPS64_R2		# once there is hardware ...
+	depends on SYS_SUPPORTS_MULTITHREADING
+	select CPU_MIPSR2_IRQ_VI
+	select CPU_MIPSR2_IRQ_EI
+	select MIPS_MT
+	select NR_CPUS_DEFAULT_8
+	select SMP
+	select SYS_SUPPORTS_SMP
+	select SMP_UP
+	help
+	  This is a kernel model which is known a SMTC or lately has been
+	  marketesed into SMVP.
+
+endchoice
+
+config MIPS_MT
+	bool
+
+config SCHED_SMT
+	bool "SMT (multithreading) scheduler support"
+	depends on SYS_SUPPORTS_SCHED_SMT
+	default n
+	help
+	  SMT scheduler support improves the CPU scheduler's decision making
+	  when dealing with MIPS MT enabled cores at a cost of slightly
+	  increased overhead in some places. If unsure say N here.
+
+config SYS_SUPPORTS_SCHED_SMT
+	bool
+
+
+config SYS_SUPPORTS_MULTITHREADING
+	bool
+
+config MIPS_MT_FPAFF
+	bool "Dynamic FPU affinity for FP-intensive threads"
+	default y
+	depends on MIPS_MT_SMP || MIPS_MT_SMTC
+
+config MIPS_VPE_LOADER
+	bool "VPE loader support."
+	depends on SYS_SUPPORTS_MULTITHREADING
+	select CPU_MIPSR2_IRQ_VI
+	select CPU_MIPSR2_IRQ_EI
+	select MIPS_MT
+	help
+	  Includes a loader for loading an elf relocatable object
+	  onto another VPE and running it.
+
+config MIPS_MT_SMTC_IM_BACKSTOP
+	bool "Use per-TC register bits as backstop for inhibited IM bits"
+	depends on MIPS_MT_SMTC
+	default n
+	help
+	  To support multiple TC microthreads acting as "CPUs" within
+	  a VPE, VPE-wide interrupt mask bits must be specially manipulated
+	  during interrupt handling. To support legacy drivers and interrupt
+	  controller management code, SMTC has a "backstop" to track and
+	  if necessary restore the interrupt mask. This has some performance
+	  impact on interrupt service overhead.
+
+config MIPS_MT_SMTC_IRQAFF
+	bool "Support IRQ affinity API"
+	depends on MIPS_MT_SMTC
+	default n
+	help
+	  Enables SMP IRQ affinity API (/proc/irq/*/smp_affinity, etc.)
+	  for SMTC Linux kernel. Requires platform support, of which
+	  an example can be found in the MIPS kernel i8259 and Malta
+	  platform code.  Adds some overhead to interrupt dispatch, and
+	  should be used only if you know what you are doing.
+
+config MIPS_VPE_LOADER_TOM
+	bool "Load VPE program into memory hidden from linux"
+	depends on MIPS_VPE_LOADER
+	default y
+	help
+	  The loader can use memory that is present but has been hidden from
+	  Linux using the kernel command line option "mem=xxMB". It's up to
+	  you to ensure the amount you put in the option and the space your
+	  program requires is less or equal to the amount physically present.
+
+# this should possibly be in drivers/char, but it is rather cpu related. Hmmm
+config MIPS_VPE_APSP_API
+	bool "Enable support for AP/SP API (RTLX)"
+	depends on MIPS_VPE_LOADER
+	help
+
+config MIPS_APSP_KSPD
+	bool "Enable KSPD"
+	depends on MIPS_VPE_APSP_API
+	default y
+	help
+	  KSPD is a kernel daemon that accepts syscall requests from the SP
+	  side, actions them and returns the results. It also handles the
+	  "exit" syscall notifying other kernel modules the SP program is
+	  exiting.  You probably want to say yes here.
+
+config MIPS_CMP
+	bool "MIPS CMP framework support"
+	depends on SYS_SUPPORTS_MIPS_CMP
+	select SYNC_R4K if BROKEN
+	select SYS_SUPPORTS_SMP
+	select SYS_SUPPORTS_SCHED_SMT if SMP
+	select WEAK_ORDERING
+	default n
+	help
+	  This is a placeholder option for the GCMP work. It will need to
+	  be handled differently...
+
+config SB1_PASS_1_WORKAROUNDS
+	bool
+	depends on CPU_SB1_PASS_1
+	default y
+
+config SB1_PASS_2_WORKAROUNDS
+	bool
+	depends on CPU_SB1 && (CPU_SB1_PASS_2_2 || CPU_SB1_PASS_2)
+	default y
+
+config SB1_PASS_2_1_WORKAROUNDS
+	bool
+	depends on CPU_SB1 && CPU_SB1_PASS_2
+	default y
+
+config 64BIT_PHYS_ADDR
+	bool
+
+config CPU_HAS_LLSC
+	bool
+
+config CPU_HAS_SMARTMIPS
+	depends on SYS_SUPPORTS_SMARTMIPS
+	bool "Support for the SmartMIPS ASE"
+	help
+	  SmartMIPS is a extension of the MIPS32 architecture aimed at
+	  increased security at both hardware and software level for
+	  smartcards.  Enabling this option will allow proper use of the
+	  SmartMIPS instructions by Linux applications.  However a kernel with
+	  this option will not work on a MIPS core without SmartMIPS core.  If
+	  you don't know you probably don't have SmartMIPS and should say N
+	  here.
+
+config CPU_HAS_WB
+	bool
+
+#
+# Vectored interrupt mode is an R2 feature
+#
+config CPU_MIPSR2_IRQ_VI
+	bool
+
+#
+# Extended interrupt mode is an R2 feature
+#
+config CPU_MIPSR2_IRQ_EI
+	bool
+
+config CPU_HAS_SYNC
+	bool
+	depends on !CPU_R3000
+	default y
+
+config GENERIC_CLOCKEVENTS_BROADCAST
+	bool
+
+#
+# CPU non-features
+#
+config CPU_DADDI_WORKAROUNDS
+	bool
+
+config CPU_R4000_WORKAROUNDS
+	bool
+	select CPU_R4400_WORKAROUNDS
+
+config CPU_R4400_WORKAROUNDS
+	bool
+
+#
+# Use the generic interrupt handling code in kernel/irq/:
+#
+config GENERIC_HARDIRQS
+	bool
+	default y
+
+config GENERIC_IRQ_PROBE
+	bool
+	default y
+
+config IRQ_PER_CPU
+	bool
+
+#
+# - Highmem only makes sense for the 32-bit kernel.
+# - The current highmem code will only work properly on physically indexed
+#   caches such as R3000, SB1, R7000 or those that look like they're virtually
+#   indexed such as R4000/R4400 SC and MC versions or R10000.  So for the
+#   moment we protect the user and offer the highmem option only on machines
+#   where it's known to be safe.  This will not offer highmem on a few systems
+#   such as MIPS32 and MIPS64 CPUs which may have virtual and physically
+#   indexed CPUs but we're playing safe.
+# - We use SYS_SUPPORTS_HIGHMEM to offer highmem only for systems where we
+#   know they might have memory configurations that could make use of highmem
+#   support.
+#
+config HIGHMEM
+	bool "High Memory Support"
+	depends on 32BIT && CPU_SUPPORTS_HIGHMEM && SYS_SUPPORTS_HIGHMEM
+
+config CPU_SUPPORTS_HIGHMEM
+	bool
+
+config SYS_SUPPORTS_HIGHMEM
+	bool
+
+config SYS_SUPPORTS_SMARTMIPS
+	bool
+
+config ARCH_FLATMEM_ENABLE
+	def_bool y
+	depends on !NUMA
+
+config ARCH_DISCONTIGMEM_ENABLE
+	bool
+	default y if SGI_IP27
+	help
+	  Say Y to support efficient handling of discontiguous physical memory,
+	  for architectures which are either NUMA (Non-Uniform Memory Access)
+	  or have huge holes in the physical address space for other reasons.
+	  See <file:Documentation/vm/numa> for more.
+
+config ARCH_POPULATES_NODE_MAP
+	def_bool y
+
+config ARCH_SPARSEMEM_ENABLE
+	bool
+	select SPARSEMEM_STATIC
+
+config NUMA
+	bool "NUMA Support"
+	depends on SYS_SUPPORTS_NUMA
+	help
+	  Say Y to compile the kernel to support NUMA (Non-Uniform Memory
+	  Access).  This option improves performance on systems with more
+	  than two nodes; on two node systems it is generally better to
+	  leave it disabled; on single node systems disable this option
+	  disabled.
+
+config SYS_SUPPORTS_NUMA
+	bool
+
+config NODES_SHIFT
+	int
+	default "6"
+	depends on NEED_MULTIPLE_NODES
+
+source "mm/Kconfig"
+
+config SMP
+	bool "Multi-Processing support"
+	depends on SYS_SUPPORTS_SMP
+	select IRQ_PER_CPU
+	select USE_GENERIC_SMP_HELPERS
+	help
+	  This enables support for systems with more than one CPU. If you have
+	  a system with only one CPU, like most personal computers, say N. If
+	  you have a system with more than one CPU, say Y.
+
+	  If you say N here, the kernel will run on single and multiprocessor
+	  machines, but will use only one CPU of a multiprocessor machine. If
+	  you say Y here, the kernel will run on many, but not all,
+	  singleprocessor machines. On a singleprocessor machine, the kernel
+	  will run faster if you say N here.
+
+	  People using multiprocessor machines who say Y here should also say
+	  Y to "Enhanced Real Time Clock Support", below.
+
+	  See also the SMP-HOWTO available at
+	  <http://www.tldp.org/docs.html#howto>.
+
+	  If you don't know what to do here, say N.
+
+config SMP_UP
+	bool
+
+config SYS_SUPPORTS_MIPS_CMP
+	bool
+
+config SYS_SUPPORTS_SMP
+	bool
+
+config NR_CPUS_DEFAULT_1
+	bool
+
+config NR_CPUS_DEFAULT_2
+	bool
+
+config NR_CPUS_DEFAULT_4
+	bool
+
+config NR_CPUS_DEFAULT_8
+	bool
+
+config NR_CPUS_DEFAULT_16
+	bool
+
+config NR_CPUS_DEFAULT_32
+	bool
+
+config NR_CPUS_DEFAULT_64
+	bool
+
+config NR_CPUS
+	int "Maximum number of CPUs (2-64)"
+	range 1 64 if NR_CPUS_DEFAULT_1
+	depends on SMP
+	default "1" if NR_CPUS_DEFAULT_1
+	default "2" if NR_CPUS_DEFAULT_2
+	default "4" if NR_CPUS_DEFAULT_4
+	default "8" if NR_CPUS_DEFAULT_8
+	default "16" if NR_CPUS_DEFAULT_16
+	default "32" if NR_CPUS_DEFAULT_32
+	default "64" if NR_CPUS_DEFAULT_64
+	help
+	  This allows you to specify the maximum number of CPUs which this
+	  kernel will support.  The maximum supported value is 32 for 32-bit
+	  kernel and 64 for 64-bit kernels; the minimum value which makes
+	  sense is 1 for Qemu (useful only for kernel debugging purposes)
+	  and 2 for all others.
+
+	  This is purely to save memory - each supported CPU adds
+	  approximately eight kilobytes to the kernel image.  For best
+	  performance should round up your number of processors to the next
+	  power of two.
+
+source "kernel/time/Kconfig"
+
+#
+# Timer Interrupt Frequency Configuration
+#
+
+choice
+	prompt "Timer frequency"
+	default HZ_250
+	help
+	 Allows the configuration of the timer frequency.
+
+	config HZ_48
+		bool "48 HZ" if SYS_SUPPORTS_48HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_100
+		bool "100 HZ" if SYS_SUPPORTS_100HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_128
+		bool "128 HZ" if SYS_SUPPORTS_128HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_250
+		bool "250 HZ" if SYS_SUPPORTS_250HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_256
+		bool "256 HZ" if SYS_SUPPORTS_256HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_1000
+		bool "1000 HZ" if SYS_SUPPORTS_1000HZ || SYS_SUPPORTS_ARBIT_HZ
+
+	config HZ_1024
+		bool "1024 HZ" if SYS_SUPPORTS_1024HZ || SYS_SUPPORTS_ARBIT_HZ
+
+endchoice
+
+config SYS_SUPPORTS_48HZ
+	bool
+
+config SYS_SUPPORTS_100HZ
+	bool
+
+config SYS_SUPPORTS_128HZ
+	bool
+
+config SYS_SUPPORTS_250HZ
+	bool
+
+config SYS_SUPPORTS_256HZ
+	bool
+
+config SYS_SUPPORTS_1000HZ
+	bool
+
+config SYS_SUPPORTS_1024HZ
+	bool
+
+config SYS_SUPPORTS_ARBIT_HZ
+	bool
+	default y if !SYS_SUPPORTS_48HZ && !SYS_SUPPORTS_100HZ && \
+		     !SYS_SUPPORTS_128HZ && !SYS_SUPPORTS_250HZ && \
+		     !SYS_SUPPORTS_256HZ && !SYS_SUPPORTS_1000HZ && \
+		     !SYS_SUPPORTS_1024HZ
+
+config HZ
+	int
+	default 48 if HZ_48
+	default 100 if HZ_100
+	default 128 if HZ_128
+	default 250 if HZ_250
+	default 256 if HZ_256
+	default 1000 if HZ_1000
+	default 1024 if HZ_1024
+
+source "kernel/Kconfig.preempt"
+
+config MIPS_INSANE_LARGE
+	bool "Support for large 64-bit configurations"
+	depends on CPU_R10000 && 64BIT
+	help
+	  MIPS R10000 does support a 44 bit / 16TB address space as opposed to
+	  previous 64-bit processors which only supported 40 bit / 1TB. If you
+	  need processes of more than 1TB virtual address space, say Y here.
+	  This will result in additional memory usage, so it is not
+	  recommended for normal users.
+
+config KEXEC
+	bool "Kexec system call (EXPERIMENTAL)"
+	depends on EXPERIMENTAL
+	help
+	  kexec is a system call that implements the ability to shutdown your
+	  current kernel, and to start another kernel.  It is like a reboot
+	  but it is independent of the system firmware.   And like a reboot
+	  you can start any kernel with it, not just Linux.
+
+	  The name comes from the similarity to the exec system call.
+
+	  It is an ongoing process to be certain the hardware in a machine
+	  is properly shutdown, so do not be surprised if this code does not
+	  initially work for you.  It may help to enable device hotplugging
+	  support.  As of this writing the exact hardware interface is
+	  strongly in flux, so no good recommendation can be made.
+
+config SECCOMP
+	bool "Enable seccomp to safely compute untrusted bytecode"
+	depends on PROC_FS
+	default y
+	help
+	  This kernel feature is useful for number crunching applications
+	  that may need to compute untrusted bytecode during their
+	  execution. By using pipes or other transports made available to
+	  the process as file descriptors supporting the read/write
+	  syscalls, it's possible to isolate those applications in
+	  their own address space using seccomp. Once seccomp is
+	  enabled via /proc/<pid>/seccomp, it cannot be disabled
+	  and the task is only allowed to execute a few safe syscalls
+	  defined by each seccomp mode.
+
+	  If unsure, say Y. Only embedded should say N here.
+
+endmenu
+
+config LOCKDEP_SUPPORT
+	bool
+	default y
+
+config STACKTRACE_SUPPORT
+	bool
+	default y
+
+source "init/Kconfig"
+
+config PROBE_INITRD_HEADER
+	bool "Probe initrd header created by addinitrd"
+	depends on BLK_DEV_INITRD
+	help
+	  Probe initrd header at the last page of kernel image.
+	  Say Y here if you are using arch/mips/boot/addinitrd.c to
+	  add initrd or initramfs image to the kernel image.
+	  Otherwise, say N.
+
+source "kernel/Kconfig.freezer"
+
+menu "Bus options (PCI, PCMCIA, EISA, ISA, TC)"
+
+config HW_HAS_EISA
+	bool
+config HW_HAS_PCI
+	bool
+
+config PCI
+	bool "Support for PCI controller"
+	depends on HW_HAS_PCI
+	select PCI_DOMAINS
+	help
+	  Find out whether you have a PCI motherboard. PCI is the name of a
+	  bus system, i.e. the way the CPU talks to the other stuff inside
+	  your box. Other bus systems are ISA, EISA, or VESA. If you have PCI,
+	  say Y, otherwise N.
+
+config PCI_DOMAINS
+	bool
+
+source "drivers/pci/Kconfig"
+
+#
+# ISA support is now enabled via select.  Too many systems still have the one
+# or other ISA chip on the board that users don't know about so don't expect
+# users to choose the right thing ...
+#
+config ISA
+	bool
+
+config EISA
+	bool "EISA support"
+	depends on HW_HAS_EISA
+	select ISA
+	select GENERIC_ISA_DMA
+	---help---
+	  The Extended Industry Standard Architecture (EISA) bus was
+	  developed as an open alternative to the IBM MicroChannel bus.
+
+	  The EISA bus provided some of the features of the IBM MicroChannel
+	  bus while maintaining backward compatibility with cards made for
+	  the older ISA bus.  The EISA bus saw limited use between 1988 and
+	  1995 when it was made obsolete by the PCI bus.
+
+	  Say Y here if you are building a kernel for an EISA-based machine.
+
+	  Otherwise, say N.
+
+source "drivers/eisa/Kconfig"
+
+config TC
+	bool "TURBOchannel support"
+	depends on MACH_DECSTATION
+	help
+	  TurboChannel is a DEC (now Compaq (now HP)) bus for Alpha and MIPS
+	  processors.  Documentation on writing device drivers for TurboChannel
+	  is available at:
+	  <http://www.cs.arizona.edu/computer.help/policy/DIGITAL_unix/AA-PS3HD-TET1_html/TITLE.html>.
+
+#config ACCESSBUS
+#	bool "Access.Bus support"
+#	depends on TC
+
+config MMU
+	bool
+	default y
+
+config I8253
+	bool
+
+config ZONE_DMA32
+	bool
+
+source "drivers/pcmcia/Kconfig"
+
+source "drivers/pci/hotplug/Kconfig"
+
+endmenu
+
+menu "Executable file formats"
+
+source "fs/Kconfig.binfmt"
+
+config TRAD_SIGNALS
+	bool
+
+config MIPS32_COMPAT
+	bool "Kernel support for Linux/MIPS 32-bit binary compatibility"
+	depends on 64BIT
+	help
+	  Select this option if you want Linux/MIPS 32-bit binary
+	  compatibility. Since all software available for Linux/MIPS is
+	  currently 32-bit you should say Y here.
+
+config COMPAT
+	bool
+	depends on MIPS32_COMPAT
+	default y
+
+config SYSVIPC_COMPAT
+	bool
+	depends on COMPAT && SYSVIPC
+	default y
+
+config MIPS32_O32
+	bool "Kernel support for o32 binaries"
+	depends on MIPS32_COMPAT
+	help
+	  Select this option if you want to run o32 binaries.  These are pure
+	  32-bit binaries as used by the 32-bit Linux/MIPS port.  Most of
+	  existing binaries are in this format.
+
+	  If unsure, say Y.
+
+config MIPS32_N32
+	bool "Kernel support for n32 binaries"
+	depends on MIPS32_COMPAT
+	help
+	  Select this option if you want to run n32 binaries.  These are
+	  64-bit binaries using 32-bit quantities for addressing and certain
+	  data that would normally be 64-bit.  They are used in special
+	  cases.
+
+	  If unsure, say N.
+
+config BINFMT_ELF32
+	bool
+	default y if MIPS32_O32 || MIPS32_N32
+
+endmenu
+
+menu "Power management options"
+
+config ARCH_SUSPEND_POSSIBLE
+	def_bool y
+	depends on !SMP
+
+source "kernel/power/Kconfig"
+
+endmenu
+
+source "net/Kconfig"
+
+source "drivers/Kconfig"
+
+source "fs/Kconfig"
+
+source "arch/mips/Kconfig.debug"
+
+source "security/Kconfig"
+
+source "crypto/Kconfig"
+
+source "lib/Kconfig"
diff -Naur linux-2.6.30-ori/arch/mips/Makefile linux-2.6.30-test/arch/mips/Makefile
--- linux-2.6.30-ori/arch/mips/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -603,6 +603,82 @@
 load-$(CONFIG_CPU_CAVIUM_OCTEON) 	+= 0xffffffff81100000
 endif
 
+ifdef CONFIG_TANGO2
+#
+# Tango2 board
+#
+include arch/mips/include/asm/tango2/emhwlib_registers_tango2.inc
+include arch/mips/include/asm/tango2/emhwlib_dram_tango2.inc
+else
+ifdef CONFIG_TANGO3
+#
+# Tango3 board
+#
+include arch/mips/include/asm/tango3/emhwlib_registers_tango3.inc
+include arch/mips/include/asm/tango3/emhwlib_dram_tango3.inc
+endif
+endif
+
+ifdef CONFIG_TANGO2
+ifneq '$(filter -DWITH_PROD=1 -DWITH_FACSPROD=1, $(RMCFLAGS))' ''
+CERT_ID=000c
+CERT_TYPE=8634_ES4_prod
+else
+CERT_ID=000b
+CERT_TYPE=8634_ES4_dev
+endif
+else
+ifdef CONFIG_TANGO3
+ifneq '$(filter -DWITH_PROD=1 -DWITH_FACSPROD=1, $(RMCFLAGS))' ''
+# Not yet defined for prod chip
+CERT_ID=000c
+CERT_TYPE=8644_ES1_prod
+else
+CERT_ID=0001
+CERT_TYPE=8644_ES1_dev
+endif
+endif
+endif
+
+internal_hex = 0x$(shell printf "%x" $$(($(1))))
+
+core-$(CONFIG_TANGOX)		+= arch/mips/tangox/
+
+ifdef CONFIG_TANGO2
+cflags-$(CONFIG_TANGO2)		+= -Iarch/mips/include/asm/mach-tango2
+load-$(CONFIG_TANGO2)		:= $(call internal_hex,0x80000000+	\
+					$(MEM_BASE_dram_controller_0_alias)+	\
+					$(FM_linuxmips__ftext))
+#ifdef RMCFLAGS
+#cflags-$(CONFIG_TANGO2)		+= $(RMCFLAGS)
+#else
+cflags-$(CONFIG_TANGO2)		+= -DEM86XX_CHIP=EM86XX_CHIPID_TANGO2
+cflags-$(CONFIG_TANGO2_ES1)	+= -DEM86XX_REVISION=1
+cflags-$(CONFIG_TANGO2_ES2)	+= -DEM86XX_REVISION=2
+cflags-$(CONFIG_TANGO2_ES3)	+= -DEM86XX_REVISION=3
+cflags-$(CONFIG_TANGO2_ES4)	+= -DEM86XX_REVISION=4
+cflags-$(CONFIG_TANGO2_ES5)	+= -DEM86XX_REVISION=5
+cflags-$(CONFIG_TANGO2_ES6)	+= -DEM86XX_REVISION=6
+cflags-$(CONFIG_TANGO2_SD)	+= -DEM86XX_REVISION=6
+#endif
+else
+ifdef CONFIG_TANGO3
+KERNEL_START_ADDRESS		:= $(CPU_remap2_address)
+cflags-$(CONFIG_TANGO3)		+= -Iarch/mips/include/asm/mach-tango3
+load-$(CONFIG_TANGO3)		:= $(call internal_hex,0x80000000+	\
+					$(KERNEL_START_ADDRESS))
+#ifdef RMCFLAGS
+#cflags-$(CONFIG_TANGO3)		+= $(RMCFLAGS)
+#else
+cflags-$(CONFIG_TANGO3)		+= -DEM86XX_CHIP=EM86XX_CHIPID_TANGO3
+cflags-$(CONFIG_TANGO3_ES1)	+= -DEM86XX_REVISION=1
+cflags-$(CONFIG_TANGO3_ES2)	+= -DEM86XX_REVISION=2
+cflags-$(CONFIG_TANGO3_ES3)	+= -DEM86XX_REVISION=3
+#endif
+cflags-$(CONFIG_TANGO3)		+= -DCPU_REMAP_SPACE=$(KERNEL_START_ADDRESS)
+endif
+endif
+
 cflags-y			+= -I$(srctree)/arch/mips/include/asm/mach-generic
 drivers-$(CONFIG_PCI)		+= arch/mips/pci/
 
@@ -616,6 +692,7 @@
 JIFFIES			= jiffies_64
 endif
 
+
 #
 # Automatically detect the build format. By default we choose
 # the elf format according to the load address.
@@ -688,6 +765,14 @@
 vmlinux.32: vmlinux
 	$(OBJCOPY) -O $(32bit-bfd) $(OBJCOPYFLAGS) $< $@
 
+
+CLEAN_FILES += arch/mips/boot/vmlinux.gz \
+		arch/mips/boot/*.bin \
+		arch/mips/boot/*.xload \
+		arch/mips/boot/*.zbf \
+		arch/mips/boot/zbimage-linux-* 
+
+
 #
 # The 64-bit ELF tools are pretty broken so at this time we generate 64-bit
 # ELF files from 32-bit files by conversion.
@@ -695,7 +780,11 @@
 vmlinux.64: vmlinux
 	$(OBJCOPY) -O $(64bit-bfd) $(OBJCOPYFLAGS) $< $@
 
-makeboot =$(Q)$(MAKE) $(build)=arch/mips/boot VMLINUX=$(vmlinux-32) $(1)
+ifdef CONFIG_TANGOX
+makeboot =$(Q)$(MAKE) $(build)=arch/mips/boot VMLINUX=$(vmlinux-32) $(1) loadaddr=$(2) certtype=$(3) certid=$(4)
+else
+makeboot =$(Q)$(MAKE) $(build)=arch/mips/boot VMLINUX=$(vmlinux-32) $(1) 
+endif
 
 all:	$(all-y)
 
diff -Naur linux-2.6.30-ori/arch/mips/Makefile.orig linux-2.6.30-test/arch/mips/Makefile.orig
--- linux-2.6.30-ori/arch/mips/Makefile.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/Makefile.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,744 @@
+#
+# This file is subject to the terms and conditions of the GNU General Public
+# License.  See the file "COPYING" in the main directory of this archive
+# for more details.
+#
+# Copyright (C) 1994, 95, 96, 2003 by Ralf Baechle
+# DECStation modifications by Paul M. Antoine, 1996
+# Copyright (C) 2002, 2003, 2004  Maciej W. Rozycki
+#
+# This file is included by the global makefile so that you can add your own
+# architecture-specific flags and dependencies. Remember to do have actions
+# for "archclean" cleaning up for this architecture.
+#
+
+KBUILD_DEFCONFIG := ip22_defconfig
+
+#
+# Select the object file format to substitute into the linker script.
+#
+ifdef CONFIG_CPU_LITTLE_ENDIAN
+32bit-tool-archpref	= mipsel
+64bit-tool-archpref	= mips64el
+32bit-bfd		= elf32-tradlittlemips
+64bit-bfd		= elf64-tradlittlemips
+32bit-emul		= elf32ltsmip
+64bit-emul		= elf64ltsmip
+else
+32bit-tool-archpref	= mips
+64bit-tool-archpref	= mips64
+32bit-bfd		= elf32-tradbigmips
+64bit-bfd		= elf64-tradbigmips
+32bit-emul		= elf32btsmip
+64bit-emul		= elf64btsmip
+endif
+
+ifdef CONFIG_32BIT
+tool-archpref		= $(32bit-tool-archpref)
+UTS_MACHINE		:= mips
+endif
+ifdef CONFIG_64BIT
+tool-archpref		= $(64bit-tool-archpref)
+UTS_MACHINE		:= mips64
+endif
+
+ifneq ($(SUBARCH),$(ARCH))
+  ifeq ($(CROSS_COMPILE),)
+    CROSS_COMPILE := $(call cc-cross-prefix, $(tool-archpref)-linux-  $(tool-archpref)-linux-gnu-  $(tool-archpref)-unknown-linux-gnu-)
+  endif
+endif
+
+cflags-y := -ffunction-sections
+cflags-y += $(call cc-option, -mno-check-zero-division)
+
+ifdef CONFIG_32BIT
+ld-emul			= $(32bit-emul)
+vmlinux-32		= vmlinux
+vmlinux-64		= vmlinux.64
+
+cflags-y		+= -mabi=32
+endif
+
+ifdef CONFIG_64BIT
+ld-emul			= $(64bit-emul)
+vmlinux-32		= vmlinux.32
+vmlinux-64		= vmlinux
+
+cflags-y		+= -mabi=64
+endif
+
+all-$(CONFIG_BOOT_ELF32)	:= $(vmlinux-32)
+all-$(CONFIG_BOOT_ELF64)	:= $(vmlinux-64)
+
+#
+# GCC uses -G 0 -mabicalls -fpic as default.  We don't want PIC in the kernel
+# code since it only slows down the whole thing.  At some point we might make
+# use of global pointer optimizations but their use of $28 conflicts with
+# the current pointer optimization.
+#
+# The DECStation requires an ECOFF kernel for remote booting, other MIPS
+# machines may also.  Since BFD is incredibly buggy with respect to
+# crossformat linking we rely on the elf2ecoff tool for format conversion.
+#
+cflags-y			+= -G 0 -mno-abicalls -fno-pic -pipe
+cflags-y			+= -msoft-float
+LDFLAGS_vmlinux			+= -G 0 -static -n -nostdlib
+MODFLAGS			+= -mlong-calls
+
+cflags-y += -ffreestanding
+
+#
+# We explicitly add the endianness specifier if needed, this allows
+# to compile kernels with a toolchain for the other endianness. We
+# carefully avoid to add it redundantly because gcc 3.3/3.4 complains
+# when fed the toolchain default!
+#
+# Certain gcc versions upto gcc 4.1.1 (probably 4.2-subversion as of
+# 2006-10-10 don't properly change the predefined symbols if -EB / -EL
+# are used, so we kludge that here.  A bug has been filed at
+# http://gcc.gnu.org/bugzilla/show_bug.cgi?id=29413.
+#
+undef-all += -UMIPSEB -U_MIPSEB -U__MIPSEB -U__MIPSEB__
+undef-all += -UMIPSEL -U_MIPSEL -U__MIPSEL -U__MIPSEL__
+predef-be += -DMIPSEB -D_MIPSEB -D__MIPSEB -D__MIPSEB__
+predef-le += -DMIPSEL -D_MIPSEL -D__MIPSEL -D__MIPSEL__
+cflags-$(CONFIG_CPU_BIG_ENDIAN)		+= $(shell $(CC) -dumpmachine |grep -q 'mips.*el-.*' && echo -EB $(undef-all) $(predef-be))
+cflags-$(CONFIG_CPU_LITTLE_ENDIAN)	+= $(shell $(CC) -dumpmachine |grep -q 'mips.*el-.*' || echo -EL $(undef-all) $(predef-le))
+
+cflags-$(CONFIG_CPU_HAS_SMARTMIPS)	+= $(call cc-option,-msmartmips)
+
+cflags-$(CONFIG_SB1XXX_CORELIS)	+= $(call cc-option,-mno-sched-prolog) \
+				   -fno-omit-frame-pointer
+
+#
+# CPU-dependent compiler/assembler options for optimization.
+#
+cflags-$(CONFIG_CPU_R3000)	+= -march=r3000
+cflags-$(CONFIG_CPU_TX39XX)	+= -march=r3900
+cflags-$(CONFIG_CPU_R6000)	+= -march=r6000 -Wa,--trap
+cflags-$(CONFIG_CPU_R4300)	+= -march=r4300 -Wa,--trap
+cflags-$(CONFIG_CPU_VR41XX)	+= -march=r4100 -Wa,--trap
+cflags-$(CONFIG_CPU_R4X00)	+= -march=r4600 -Wa,--trap
+cflags-$(CONFIG_CPU_TX49XX)	+= -march=r4600 -Wa,--trap
+cflags-$(CONFIG_CPU_LOONGSON2)	+= -march=r4600 -Wa,--trap
+cflags-$(CONFIG_CPU_MIPS32_R1)	+= $(call cc-option,-march=mips32,-mips32 -U_MIPS_ISA -D_MIPS_ISA=_MIPS_ISA_MIPS32) \
+			-Wa,-mips32 -Wa,--trap
+cflags-$(CONFIG_CPU_MIPS32_R2)	+= $(call cc-option,-march=mips32r2,-mips32r2 -U_MIPS_ISA -D_MIPS_ISA=_MIPS_ISA_MIPS32) \
+			-Wa,-mips32r2 -Wa,--trap
+cflags-$(CONFIG_CPU_MIPS64_R1)	+= $(call cc-option,-march=mips64,-mips64 -U_MIPS_ISA -D_MIPS_ISA=_MIPS_ISA_MIPS64) \
+			-Wa,-mips64 -Wa,--trap
+cflags-$(CONFIG_CPU_MIPS64_R2)	+= $(call cc-option,-march=mips64r2,-mips64r2 -U_MIPS_ISA -D_MIPS_ISA=_MIPS_ISA_MIPS64) \
+			-Wa,-mips64r2 -Wa,--trap
+cflags-$(CONFIG_CPU_R5000)	+= -march=r5000 -Wa,--trap
+cflags-$(CONFIG_CPU_R5432)	+= $(call cc-option,-march=r5400,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_R5500)	+= $(call cc-option,-march=r5500,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_NEVADA)	+= $(call cc-option,-march=rm5200,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_RM7000)	+= $(call cc-option,-march=rm7000,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_RM9000)	+= $(call cc-option,-march=rm9000,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_SB1)	+= $(call cc-option,-march=sb1,-march=r5000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_R8000)	+= -march=r8000 -Wa,--trap
+cflags-$(CONFIG_CPU_R10000)	+= $(call cc-option,-march=r10000,-march=r8000) \
+			-Wa,--trap
+cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += $(call cc-option,-march=octeon) -Wa,--trap
+ifeq (,$(findstring march=octeon, $(cflags-$(CONFIG_CPU_CAVIUM_OCTEON))))
+cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += -Wa,-march=octeon
+endif
+
+cflags-$(CONFIG_CPU_R4000_WORKAROUNDS)	+= $(call cc-option,-mfix-r4000,)
+cflags-$(CONFIG_CPU_R4400_WORKAROUNDS)	+= $(call cc-option,-mfix-r4400,)
+cflags-$(CONFIG_CPU_DADDI_WORKAROUNDS)	+= $(call cc-option,-mno-daddi,)
+
+ifdef CONFIG_CPU_SB1
+ifdef CONFIG_SB1_PASS_1_WORKAROUNDS
+MODFLAGS	+= -msb1-pass1-workarounds
+endif
+endif
+
+#
+# Firmware support
+#
+libs-$(CONFIG_ARC)		+= arch/mips/fw/arc/
+libs-$(CONFIG_CFE)		+= arch/mips/fw/cfe/
+libs-$(CONFIG_SNIPROM)		+= arch/mips/fw/sni/
+libs-y				+= arch/mips/fw/lib/
+libs-$(CONFIG_SIBYTE_CFE)	+= arch/mips/sibyte/cfe/
+
+#
+# Board-dependent options and extra files
+#
+
+#
+# Acer PICA 61, Mips Magnum 4000 and Olivetti M700.
+#
+core-$(CONFIG_MACH_JAZZ)	+= arch/mips/jazz/
+cflags-$(CONFIG_MACH_JAZZ)	+= -I$(srctree)/arch/mips/include/asm/mach-jazz
+load-$(CONFIG_MACH_JAZZ)	+= 0xffffffff80080000
+
+#
+# Common Alchemy Au1x00 stuff
+#
+core-$(CONFIG_SOC_AU1X00)	+= arch/mips/alchemy/common/
+cflags-$(CONFIG_SOC_AU1X00)	+= -I$(srctree)/arch/mips/include/asm/mach-au1x00
+
+#
+# AMD Alchemy Pb1000 eval board
+#
+core-$(CONFIG_MIPS_PB1000)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_PB1000)	+= -I$(srctree)/arch/mips/include/asm/mach-pb1x00
+load-$(CONFIG_MIPS_PB1000)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Pb1100 eval board
+#
+core-$(CONFIG_MIPS_PB1100)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_PB1100)	+= -I$(srctree)/arch/mips/include/asm/mach-pb1x00
+load-$(CONFIG_MIPS_PB1100)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Pb1500 eval board
+#
+core-$(CONFIG_MIPS_PB1500)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_PB1500)	+= -I$(srctree)/arch/mips/include/asm/mach-pb1x00
+load-$(CONFIG_MIPS_PB1500)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Pb1550 eval board
+#
+core-$(CONFIG_MIPS_PB1550)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_PB1550)	+= -I$(srctree)/arch/mips/include/asm/mach-pb1x00
+load-$(CONFIG_MIPS_PB1550)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Pb1200 eval board
+#
+core-$(CONFIG_MIPS_PB1200)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_PB1200)	+= -I$(srctree)/arch/mips/include/asm/mach-pb1x00
+load-$(CONFIG_MIPS_PB1200)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Db1000 eval board
+#
+core-$(CONFIG_MIPS_DB1000)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_DB1000)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_DB1000)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Db1100 eval board
+#
+core-$(CONFIG_MIPS_DB1100)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_DB1100)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_DB1100)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Db1500 eval board
+#
+core-$(CONFIG_MIPS_DB1500)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_DB1500)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_DB1500)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Db1550 eval board
+#
+core-$(CONFIG_MIPS_DB1550)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_DB1550)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_DB1550)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Db1200 eval board
+#
+core-$(CONFIG_MIPS_DB1200)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_DB1200)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_DB1200)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Bosporus eval board
+#
+core-$(CONFIG_MIPS_BOSPORUS)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_BOSPORUS)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_BOSPORUS)	+= 0xffffffff80100000
+
+#
+# AMD Alchemy Mirage eval board
+#
+core-$(CONFIG_MIPS_MIRAGE)	+= arch/mips/alchemy/devboards/
+cflags-$(CONFIG_MIPS_MIRAGE)	+= -I$(srctree)/arch/mips/include/asm/mach-db1x00
+load-$(CONFIG_MIPS_MIRAGE)	+= 0xffffffff80100000
+
+#
+# 4G-Systems eval board
+#
+libs-$(CONFIG_MIPS_MTX1)	+= arch/mips/alchemy/mtx-1/
+load-$(CONFIG_MIPS_MTX1)	+= 0xffffffff80100000
+
+#
+# MyCable eval board
+#
+libs-$(CONFIG_MIPS_XXS1500)	+= arch/mips/alchemy/xxs1500/
+load-$(CONFIG_MIPS_XXS1500)	+= 0xffffffff80100000
+
+#
+# Cobalt Server
+#
+core-$(CONFIG_MIPS_COBALT)	+= arch/mips/cobalt/
+cflags-$(CONFIG_MIPS_COBALT)	+= -I$(srctree)/arch/mips/include/asm/mach-cobalt
+load-$(CONFIG_MIPS_COBALT)	+= 0xffffffff80080000
+
+#
+# DECstation family
+#
+core-$(CONFIG_MACH_DECSTATION)	+= arch/mips/dec/
+cflags-$(CONFIG_MACH_DECSTATION)+= -I$(srctree)/arch/mips/include/asm/mach-dec
+libs-$(CONFIG_MACH_DECSTATION)	+= arch/mips/dec/prom/
+load-$(CONFIG_MACH_DECSTATION)	+= 0xffffffff80040000
+
+#
+# Wind River PPMC Board (4KC + GT64120)
+#
+core-$(CONFIG_WR_PPMC)		+= arch/mips/gt64120/wrppmc/
+cflags-$(CONFIG_WR_PPMC)		+= -I$(srctree)/arch/mips/include/asm/mach-wrppmc
+load-$(CONFIG_WR_PPMC)		+= 0xffffffff80100000
+
+#
+# lemote fulong mini-PC board
+#
+core-$(CONFIG_LEMOTE_FULONG) +=arch/mips/lemote/lm2e/
+load-$(CONFIG_LEMOTE_FULONG) +=0xffffffff80100000
+cflags-$(CONFIG_LEMOTE_FULONG) += -I$(srctree)/arch/mips/include/asm/mach-lemote
+
+#
+# MIPS Malta board
+#
+core-$(CONFIG_MIPS_MALTA)	+= arch/mips/mti-malta/
+cflags-$(CONFIG_MIPS_MALTA)	+= -I$(srctree)/arch/mips/include/asm/mach-malta
+load-$(CONFIG_MIPS_MALTA)	+= 0xffffffff80100000
+all-$(CONFIG_MIPS_MALTA)	:= vmlinux.bin
+
+#
+# MIPS SIM
+#
+core-$(CONFIG_MIPS_SIM)		+= arch/mips/mipssim/
+cflags-$(CONFIG_MIPS_SIM)	+= -I$(srctree)/arch/mips/include/asm/mach-mipssim
+load-$(CONFIG_MIPS_SIM)		+= 0x80100000
+
+#
+# PMC-Sierra MSP SOCs
+#
+core-$(CONFIG_PMC_MSP)		+= arch/mips/pmc-sierra/msp71xx/
+cflags-$(CONFIG_PMC_MSP)	+= -I$(srctree)/arch/mips/include/asm/pmc-sierra/msp71xx \
+					-mno-branch-likely
+load-$(CONFIG_PMC_MSP)		+= 0xffffffff80100000
+
+#
+# PMC-Sierra Yosemite
+#
+core-$(CONFIG_PMC_YOSEMITE)	+= arch/mips/pmc-sierra/yosemite/
+cflags-$(CONFIG_PMC_YOSEMITE)	+= -I$(srctree)/arch/mips/include/asm/mach-yosemite
+load-$(CONFIG_PMC_YOSEMITE)	+= 0xffffffff80100000
+
+#
+# Basler eXcite
+#
+core-$(CONFIG_BASLER_EXCITE)	+= arch/mips/basler/excite/
+cflags-$(CONFIG_BASLER_EXCITE)	+= -I$(srctree)/arch/mips/include/asm/mach-excite
+load-$(CONFIG_BASLER_EXCITE)	+= 0x80100000
+
+#
+# LASAT platforms
+#
+core-$(CONFIG_LASAT)		+= arch/mips/lasat/
+cflags-$(CONFIG_LASAT)		+= -I$(srctree)/arch/mips/include/asm/mach-lasat
+load-$(CONFIG_LASAT)		+= 0xffffffff80000000
+
+#
+# Common VR41xx
+#
+core-$(CONFIG_MACH_VR41XX)	+= arch/mips/vr41xx/common/
+cflags-$(CONFIG_MACH_VR41XX)	+= -I$(srctree)/arch/mips/include/asm/mach-vr41xx
+
+#
+# ZAO Networks Capcella (VR4131)
+#
+load-$(CONFIG_ZAO_CAPCELLA)	+= 0xffffffff80000000
+
+#
+# Victor MP-C303/304 (VR4122)
+#
+load-$(CONFIG_VICTOR_MPC30X)	+= 0xffffffff80001000
+
+#
+# IBM WorkPad z50 (VR4121)
+#
+core-$(CONFIG_IBM_WORKPAD)	+= arch/mips/vr41xx/ibm-workpad/
+load-$(CONFIG_IBM_WORKPAD)	+= 0xffffffff80004000
+
+#
+# CASIO CASSIPEIA E-55/65 (VR4111)
+#
+core-$(CONFIG_CASIO_E55)	+= arch/mips/vr41xx/casio-e55/
+load-$(CONFIG_CASIO_E55)	+= 0xffffffff80004000
+
+#
+# TANBAC VR4131 multichip module(TB0225) and TANBAC VR4131DIMM(TB0229) (VR4131)
+#
+load-$(CONFIG_TANBAC_TB022X)	+= 0xffffffff80000000
+
+# NXP STB225
+core-$(CONFIG_SOC_PNX833X)		+= arch/mips/nxp/pnx833x/common/
+cflags-$(CONFIG_SOC_PNX833X)	+= -Iarch/mips/include/asm/mach-pnx833x
+libs-$(CONFIG_NXP_STB220)		+= arch/mips/nxp/pnx833x/stb22x/
+load-$(CONFIG_NXP_STB220)		+= 0xffffffff80001000
+libs-$(CONFIG_NXP_STB225)		+= arch/mips/nxp/pnx833x/stb22x/
+load-$(CONFIG_NXP_STB225)		+= 0xffffffff80001000
+
+#
+# Common NXP PNX8550
+#
+core-$(CONFIG_SOC_PNX8550)	+= arch/mips/nxp/pnx8550/common/
+cflags-$(CONFIG_SOC_PNX8550)	+= -I$(srctree)/arch/mips/include/asm/mach-pnx8550
+
+#
+# NXP PNX8550 JBS board
+#
+libs-$(CONFIG_PNX8550_JBS)	+= arch/mips/nxp/pnx8550/jbs/
+#cflags-$(CONFIG_PNX8550_JBS)	+= -I$(srctree)/arch/mips/include/asm/mach-pnx8550
+load-$(CONFIG_PNX8550_JBS)	+= 0xffffffff80060000
+
+# NXP PNX8550 STB810 board
+#
+libs-$(CONFIG_PNX8550_STB810)	+= arch/mips/nxp/pnx8550/stb810/
+load-$(CONFIG_PNX8550_STB810)	+= 0xffffffff80060000
+
+#
+# Common NEC EMMAXXX
+#
+core-$(CONFIG_SOC_EMMA2RH)	+= arch/mips/emma/common/
+cflags-$(CONFIG_SOC_EMMA2RH)	+= -I$(srctree)/arch/mips/include/asm/mach-emma2rh
+
+#
+# NEC EMMA2RH Mark-eins
+#
+core-$(CONFIG_NEC_MARKEINS)	+= arch/mips/emma/markeins/
+load-$(CONFIG_NEC_MARKEINS)	+= 0xffffffff88100000
+
+#
+# SGI IP22 (Indy/Indigo2)
+#
+# Set the load address to >= 0xffffffff88069000 if you want to leave space for
+# symmon, 0xffffffff80002000 for production kernels.  Note that the value must
+# be aligned to a multiple of the kernel stack size or the handling of the
+# current variable will break so for 64-bit kernels we have to raise the start
+# address by 8kb.
+#
+core-$(CONFIG_SGI_IP22)		+= arch/mips/sgi-ip22/
+cflags-$(CONFIG_SGI_IP22)	+= -I$(srctree)/arch/mips/include/asm/mach-ip22
+ifdef CONFIG_32BIT
+load-$(CONFIG_SGI_IP22)		+= 0xffffffff88002000
+endif
+ifdef CONFIG_64BIT
+load-$(CONFIG_SGI_IP22)		+= 0xffffffff88004000
+endif
+
+#
+# SGI-IP27 (Origin200/2000)
+#
+# Set the load address to >= 0xc000000000300000 if you want to leave space for
+# symmon, 0xc00000000001c000 for production kernels.  Note that the value must
+# be 16kb aligned or the handling of the current variable will break.
+#
+ifdef CONFIG_SGI_IP27
+core-$(CONFIG_SGI_IP27)		+= arch/mips/sgi-ip27/
+cflags-$(CONFIG_SGI_IP27)	+= -I$(srctree)/arch/mips/include/asm/mach-ip27
+ifdef CONFIG_MAPPED_KERNEL
+load-$(CONFIG_SGI_IP27)		+= 0xc00000004001c000
+OBJCOPYFLAGS			:= --change-addresses=0x3fffffff80000000
+dataoffset-$(CONFIG_SGI_IP27)	+= 0x01000000
+else
+load-$(CONFIG_SGI_IP27)		+= 0xa80000000001c000
+OBJCOPYFLAGS			:= --change-addresses=0x57ffffff80000000
+endif
+endif
+
+#
+# SGI IP28 (Indigo2 R10k)
+#
+# Set the load address to >= 0xa800000020080000 if you want to leave space for
+# symmon, 0xa800000020004000 for production kernels ?  Note that the value must
+# be 16kb aligned or the handling of the current variable will break.
+# Simplified: what IP22 does at 128MB+ in ksegN, IP28 does at 512MB+ in xkphys
+#
+ifdef CONFIG_SGI_IP28
+  ifeq ($(call cc-option-yn,-mr10k-cache-barrier=store), n)
+      $(error gcc doesn't support needed option -mr10k-cache-barrier=store)
+  endif
+endif
+core-$(CONFIG_SGI_IP28)		+= arch/mips/sgi-ip22/
+cflags-$(CONFIG_SGI_IP28)	+= -mr10k-cache-barrier=store -I$(srctree)/arch/mips/include/asm/mach-ip28
+load-$(CONFIG_SGI_IP28)		+= 0xa800000020004000
+
+#
+# SGI-IP32 (O2)
+#
+# Set the load address to >= 80069000 if you want to leave space for symmon,
+# 0xffffffff80004000 for production kernels.  Note that the value must be aligned to
+# a multiple of the kernel stack size or the handling of the current variable
+# will break.
+#
+core-$(CONFIG_SGI_IP32)		+= arch/mips/sgi-ip32/
+cflags-$(CONFIG_SGI_IP32)	+= -I$(srctree)/arch/mips/include/asm/mach-ip32
+load-$(CONFIG_SGI_IP32)		+= 0xffffffff80004000
+
+#
+# Sibyte SB1250/BCM1480 SOC
+#
+# This is a LIB so that it links at the end, and initcalls are later
+# the sequence; but it is built as an object so that modules don't get
+# removed (as happens, even if they have __initcall/module_init)
+#
+core-$(CONFIG_SIBYTE_BCM112X)	+= arch/mips/sibyte/sb1250/
+core-$(CONFIG_SIBYTE_BCM112X)	+= arch/mips/sibyte/common/
+cflags-$(CONFIG_SIBYTE_BCM112X)	+= -I$(srctree)/arch/mips/include/asm/mach-sibyte \
+			-DSIBYTE_HDR_FEATURES=SIBYTE_HDR_FMASK_1250_112x_ALL
+
+core-$(CONFIG_SIBYTE_SB1250)	+= arch/mips/sibyte/sb1250/
+core-$(CONFIG_SIBYTE_SB1250)	+= arch/mips/sibyte/common/
+cflags-$(CONFIG_SIBYTE_SB1250)	+= -I$(srctree)/arch/mips/include/asm/mach-sibyte \
+			-DSIBYTE_HDR_FEATURES=SIBYTE_HDR_FMASK_1250_112x_ALL
+
+core-$(CONFIG_SIBYTE_BCM1x55)	+= arch/mips/sibyte/bcm1480/
+core-$(CONFIG_SIBYTE_BCM1x55)	+= arch/mips/sibyte/common/
+cflags-$(CONFIG_SIBYTE_BCM1x55)	+= -I$(srctree)/arch/mips/include/asm/mach-sibyte \
+			-DSIBYTE_HDR_FEATURES=SIBYTE_HDR_FMASK_1480_ALL
+
+core-$(CONFIG_SIBYTE_BCM1x80)	+= arch/mips/sibyte/bcm1480/
+core-$(CONFIG_SIBYTE_BCM1x80)	+= arch/mips/sibyte/common/
+cflags-$(CONFIG_SIBYTE_BCM1x80)	+= -I$(srctree)/arch/mips/include/asm/mach-sibyte \
+			-DSIBYTE_HDR_FEATURES=SIBYTE_HDR_FMASK_1480_ALL
+
+#
+# Sibyte BCM91120x (Carmel) board
+# Sibyte BCM91120C (CRhine) board
+# Sibyte BCM91125C (CRhone) board
+# Sibyte BCM91125E (Rhone) board
+# Sibyte SWARM board
+# Sibyte BCM91x80 (BigSur) board
+#
+core-$(CONFIG_SIBYTE_CARMEL)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_CARMEL)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_CRHINE)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_CRHINE)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_CRHONE)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_CRHONE)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_RHONE)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_RHONE)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_SENTOSA)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_SENTOSA)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_SWARM)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_SWARM)	:= 0xffffffff80100000
+core-$(CONFIG_SIBYTE_BIGSUR)	+= arch/mips/sibyte/swarm/
+load-$(CONFIG_SIBYTE_BIGSUR)	:= 0xffffffff80100000
+
+#
+# Broadcom BCM47XX boards
+#
+core-$(CONFIG_BCM47XX)		+= arch/mips/bcm47xx/
+cflags-$(CONFIG_BCM47XX)	+= -I$(srctree)/arch/mips/include/asm/mach-bcm47xx
+load-$(CONFIG_BCM47XX)		:= 0xffffffff80001000
+
+#
+# SNI RM
+#
+core-$(CONFIG_SNI_RM)		+= arch/mips/sni/
+cflags-$(CONFIG_SNI_RM)		+= -I$(srctree)/arch/mips/include/asm/mach-rm
+ifdef CONFIG_CPU_LITTLE_ENDIAN
+load-$(CONFIG_SNI_RM)		+= 0xffffffff80600000
+else
+load-$(CONFIG_SNI_RM)		+= 0xffffffff80030000
+endif
+all-$(CONFIG_SNI_RM)		:= vmlinux.ecoff
+
+#
+# Common TXx9
+#
+core-$(CONFIG_MACH_TX39XX)	+= arch/mips/txx9/generic/
+cflags-$(CONFIG_MACH_TX39XX) += -I$(srctree)/arch/mips/include/asm/mach-tx39xx
+load-$(CONFIG_MACH_TX39XX)	+= 0xffffffff80050000
+core-$(CONFIG_MACH_TX49XX)	+= arch/mips/txx9/generic/
+cflags-$(CONFIG_MACH_TX49XX) += -I$(srctree)/arch/mips/include/asm/mach-tx49xx
+load-$(CONFIG_MACH_TX49XX)	+= 0xffffffff80100000
+
+#
+# Toshiba JMR-TX3927 board
+#
+core-$(CONFIG_TOSHIBA_JMR3927)	+= arch/mips/txx9/jmr3927/
+
+#
+# Routerboard 532 board
+#
+core-$(CONFIG_MIKROTIK_RB532)	+= arch/mips/rb532/
+cflags-$(CONFIG_MIKROTIK_RB532) += -I$(srctree)/arch/mips/include/asm/mach-rc32434
+load-$(CONFIG_MIKROTIK_RB532)	+= 0xffffffff80101000
+
+#
+# Toshiba RBTX49XX boards
+#
+core-$(CONFIG_TOSHIBA_RBTX4927)	+= arch/mips/txx9/rbtx4927/
+core-$(CONFIG_TOSHIBA_RBTX4938) += arch/mips/txx9/rbtx4938/
+core-$(CONFIG_TOSHIBA_RBTX4939) += arch/mips/txx9/rbtx4939/
+
+#
+# Cavium Octeon
+#
+core-$(CONFIG_CPU_CAVIUM_OCTEON)	+= arch/mips/cavium-octeon/
+cflags-$(CONFIG_CPU_CAVIUM_OCTEON)	+= -I$(srctree)/arch/mips/include/asm/mach-cavium-octeon
+core-$(CONFIG_CPU_CAVIUM_OCTEON)	+= arch/mips/cavium-octeon/executive/
+ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+load-$(CONFIG_CPU_CAVIUM_OCTEON)	+= 0xffffffff84100000
+else
+load-$(CONFIG_CPU_CAVIUM_OCTEON) 	+= 0xffffffff81100000
+endif
+
+cflags-y			+= -I$(srctree)/arch/mips/include/asm/mach-generic
+drivers-$(CONFIG_PCI)		+= arch/mips/pci/
+
+ifdef CONFIG_32BIT
+ifdef CONFIG_CPU_LITTLE_ENDIAN
+JIFFIES			= jiffies_64
+else
+JIFFIES			= jiffies_64 + 4
+endif
+else
+JIFFIES			= jiffies_64
+endif
+
+#
+# Automatically detect the build format. By default we choose
+# the elf format according to the load address.
+# We can always force a build with a 64-bits symbol format by
+# passing 'KBUILD_SYM32=no' option to the make's command line.
+#
+ifdef CONFIG_64BIT
+  ifndef KBUILD_SYM32
+    ifeq ($(shell expr $(load-y) \< 0xffffffff80000000), 0)
+      KBUILD_SYM32 = y
+    endif
+  endif
+
+  ifeq ($(KBUILD_SYM32)$(call cc-option-yn,-msym32), yy)
+    cflags-y += -msym32 -DKBUILD_64BIT_SYM32
+  else
+    ifeq ($(CONFIG_CPU_DADDI_WORKAROUNDS), y)
+      $(error CONFIG_CPU_DADDI_WORKAROUNDS unsupported without -msym32)
+    endif
+  endif
+endif
+
+KBUILD_AFLAGS	+= $(cflags-y)
+KBUILD_CFLAGS	+= $(cflags-y) \
+			-D"VMLINUX_LOAD_ADDRESS=$(load-y)"
+
+LDFLAGS			+= -m $(ld-emul)
+
+ifdef CONFIG_MIPS
+CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -xc /dev/null | \
+	egrep -vw '__GNUC_(|MINOR_|PATCHLEVEL_)_' | \
+	sed -e 's/^\#define /-D/' -e "s/ /='/" -e "s/$$/'/")
+ifdef CONFIG_64BIT
+CHECKFLAGS		+= -m64
+endif
+endif
+
+OBJCOPYFLAGS		+= --remove-section=.reginfo
+
+#
+# Choosing incompatible machines durings configuration will result in
+# error messages during linking.  Select a default linkscript if
+# none has been choosen above.
+#
+
+CPPFLAGS_vmlinux.lds := \
+	$(KBUILD_CFLAGS) \
+	-D"LOADADDR=$(load-y)" \
+	-D"JIFFIES=$(JIFFIES)" \
+	-D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
+
+head-y := arch/mips/kernel/head.o arch/mips/kernel/init_task.o
+
+libs-y			+= arch/mips/lib/
+
+core-y			+= arch/mips/kernel/ arch/mips/mm/ arch/mips/math-emu/
+
+drivers-$(CONFIG_OPROFILE)	+= arch/mips/oprofile/
+
+ifdef CONFIG_LASAT
+rom.bin rom.sw: vmlinux
+	$(Q)$(MAKE) $(build)=arch/mips/lasat/image $@
+endif
+
+#
+# Some machines like the Indy need 32-bit ELF binaries for booting purposes.
+# Other need ECOFF, so we build a 32-bit ELF binary for them which we then
+# convert to ECOFF using elf2ecoff.
+#
+vmlinux.32: vmlinux
+	$(OBJCOPY) -O $(32bit-bfd) $(OBJCOPYFLAGS) $< $@
+
+#
+# The 64-bit ELF tools are pretty broken so at this time we generate 64-bit
+# ELF files from 32-bit files by conversion.
+#
+vmlinux.64: vmlinux
+	$(OBJCOPY) -O $(64bit-bfd) $(OBJCOPYFLAGS) $< $@
+
+makeboot =$(Q)$(MAKE) $(build)=arch/mips/boot VMLINUX=$(vmlinux-32) $(1)
+
+all:	$(all-y)
+
+vmlinux.bin: $(vmlinux-32)
+	+@$(call makeboot,$@)
+
+vmlinux.ecoff: $(vmlinux-32)
+	+@$(call makeboot,$@)
+
+vmlinux.srec: $(vmlinux-32)
+	+@$(call makeboot,$@)
+
+CLEAN_FILES += vmlinux.ecoff \
+	       vmlinux.srec
+
+archprepare:
+ifdef CONFIG_MIPS32_N32
+	@echo '  Checking missing-syscalls for N32'
+	$(Q)$(MAKE) $(build)=. missing-syscalls EXTRA_CFLAGS="-mabi=n32"
+endif
+ifdef CONFIG_MIPS32_O32
+	@echo '  Checking missing-syscalls for O32'
+	$(Q)$(MAKE) $(build)=. missing-syscalls EXTRA_CFLAGS="-mabi=32"
+endif
+
+install:
+	$(Q)install -D -m 755 vmlinux $(INSTALL_PATH)/vmlinux-$(KERNELRELEASE)
+	$(Q)install -D -m 644 .config $(INSTALL_PATH)/config-$(KERNELRELEASE)
+	$(Q)install -D -m 644 System.map $(INSTALL_PATH)/System.map-$(KERNELRELEASE)
+
+archclean:
+	@$(MAKE) $(clean)=arch/mips/boot
+	@$(MAKE) $(clean)=arch/mips/lasat
+
+define archhelp
+	echo '  install              - install kernel into $(INSTALL_PATH)'
+	echo '  vmlinux.ecoff        - ECOFF boot image'
+	echo '  vmlinux.bin          - Raw binary boot image'
+	echo '  vmlinux.srec         - SREC boot image'
+	echo
+	echo '  These will be default as apropriate for a configured platform.'
+endef
+
+CLEAN_FILES += vmlinux.32 \
+	       vmlinux.64 \
+	       vmlinux.ecoff
diff -Naur linux-2.6.30-ori/arch/mips/boot/build_cpu_xload.bash linux-2.6.30-test/arch/mips/boot/build_cpu_xload.bash
--- linux-2.6.30-ori/arch/mips/boot/build_cpu_xload.bash	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/build_cpu_xload.bash	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,40 @@
+#!/bin/bash
+set -e
+#
+if [ $# != 3 ]; then 
+    cat <<EOF
+
+Syntax: $0 cpupkg 000b ES4_dev
+
+The cpupkg came with .zbf extension. You have to specify cpu binary xtask to wrap, 
+the certificate id you plan to use, and the chip revision (ES1_dev or ES4_dev) .
+also make sure that the scripts below are accessible and in your PATH variable
+EOF
+    exit -1 
+fi
+#
+if [ -z "$XSDK_ROOT" ]; then echo "*** You need to define the XSDK_ROOT variable ***"; exit -1; fi
+#
+CPUPKG=$1
+CERTID=$2
+REV=$3
+TMPADDR=0x13000000
+
+CPUPKG_BIN=${CPUPKG}.zbf
+CPUPKG_SIG=${CPUPKG}.8634_${REV}_${CERTID}.bin
+XLOAD_BIN=${CPUPKG}_${REV}.xload
+XRPC_BIN=xrpc_xload_${CPUPKG}_${REV}.bin
+PRIVATE_KEY=$XSDK_ROOT/dummy_private_keys/8634_${REV}_${CERTID}_keyboth.pem
+
+echo Using $CERT_BIN
+
+# aes128 pad!
+zeropad.bash $CPUPKG_BIN 16
+SIZE=`wc -c $CPUPKG_BIN | awk '{print $1}'`
+
+echo CPUPKG Image Map : size=$SIZE
+
+openssl sha1 -sign $PRIVATE_KEY < $CPUPKG_BIN | revbytes.pl > $CPUPKG_SIG
+mkxload.bash $XSDK_ROOT $REV $CERTID $CPUPKG_BIN $CPUPKG_SIG  $XLOAD_BIN
+buildxrpc.bash XRPC_CALLERID_IGNORED XRPC_ID_XLOAD $SIZE $TMPADDR 2 3 4 $XLOAD_BIN $XRPC_BIN
+
diff -Naur linux-2.6.30-ori/arch/mips/boot/build_xload.bash linux-2.6.30-test/arch/mips/boot/build_xload.bash
--- linux-2.6.30-ori/arch/mips/boot/build_xload.bash	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/build_xload.bash	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,30 @@
+#!/bin/bash
+if [ -z "$XSDK_ROOT" ]; then 
+	echo "*** define your XSDK_ROOT please ***"
+	exit -1
+fi
+#
+
+ZBOOT=vmlinux
+CERTID=000a
+REV=ES4_prod
+ADDR=0x13000000
+
+ZBOOT_BIN=${ZBOOT}.zbf
+ZBOOT_SIG=${ZBOOT}.8634_${REV}_${CERTID}.bin
+XLOAD_BIN=${ZBOOT}_${REV}.xload
+XRPC_BIN=xrpc_xload_${ZBOOT}_${REV}.bin
+PRIVATE_KEY=$XSDK_ROOT/dummy_private_keys/8634_${REV}_${CERTID}_keyboth.pem
+
+echo Using $CERT_BIN
+
+# aes128 pad!
+zeropad.bash $ZBOOT_BIN 16
+SIZE=`wc -c $ZBOOT_BIN | awk '{print $1}'`
+
+echo ZBOOT Image Map : size=$SIZE
+
+openssl sha1 -sign $PRIVATE_KEY < $ZBOOT_BIN | revbytes.pl > $ZBOOT_SIG
+mkxload.bash $XSDK_ROOT $REV $CERTID $ZBOOT_BIN $ZBOOT_SIG  $XLOAD_BIN
+buildxrpc.bash XRPC_CALLERID_IGNORED XRPC_ID_XLOAD $SIZE $ADDR 2 3 4 $XLOAD_BIN $XRPC_BIN
+
diff -Naur linux-2.6.30-ori/arch/mips/boot/buildenczbf.sh linux-2.6.30-test/arch/mips/boot/buildenczbf.sh
--- linux-2.6.30-ori/arch/mips/boot/buildenczbf.sh	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/buildenczbf.sh	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,6 @@
+#!/bin/sh
+lzma -c -z vmlinux.bin > vmlinux.bin.lz
+tobin.bash `sha1sum -b vmlinux.bin.lz | awk '{ print $1 }'` > vmlinux_sha1.zbf
+sh build_cpu_xload.bash vmlinux_sha1 000a ES4_prod
+cat xrpc_xload_vmlinux_sha1_ES4_prod.bin vmlinux.bin.lz > vmlinux_enc.bin
+genzbf -l 0x90020000 -s 0x90020000 -e `stat --format=%s xrpc_xload_vmlinux_sha1_ES4_prod.bin` -a lzexf -o vmlinux_enc.zbf vmlinux_enc.bin
diff -Naur linux-2.6.30-ori/arch/mips/boot/buildzbf.sh linux-2.6.30-test/arch/mips/boot/buildzbf.sh
--- linux-2.6.30-ori/arch/mips/boot/buildzbf.sh	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/buildzbf.sh	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,3 @@
+#!/bin/sh
+gzip -c vmlinux.bin > vmlinux.bin.gz
+genzbf -l 0x90020000 -s 0x90020000 -a lxzf -o vmlinux.zbf vmlinux.bin.gz
diff -Naur linux-2.6.30-ori/arch/mips/boot/devbuildenczbf.sh linux-2.6.30-test/arch/mips/boot/devbuildenczbf.sh
--- linux-2.6.30-ori/arch/mips/boot/devbuildenczbf.sh	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/devbuildenczbf.sh	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,6 @@
+#!/bin/sh
+gzip -c vmlinux.bin > vmlinux.bin.gz
+tobin.bash `sha1sum -b vmlinux.bin.gz | awk '{ print $1 }'` > vmlinux_sha1.zbf
+sh build_cpu_xload.bash vmlinux_sha1 000b ES4_dev
+cat xrpc_xload_vmlinux_sha1_ES4_dev.bin vmlinux.bin.gz > vmlinux_enc.bin
+genzbf -l 0x90020000 -s 0x90020000 -e `stat --format=%s xrpc_xload_vmlinux_sha1_ES4_dev.bin` -a lzef -o devvmlinux_enc.zbf vmlinux_enc.bin
diff -Naur linux-2.6.30-ori/arch/mips/boot/test.sh linux-2.6.30-test/arch/mips/boot/test.sh
--- linux-2.6.30-ori/arch/mips/boot/test.sh	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/boot/test.sh	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,6 @@
+#!/bin/sh
+./buildenczbf.sh
+cp vmlinux_enc.zbf /sage/smp86xx/build_mips/romfs/99vmlinux_enc.zbf
+cd /sage/smp86xx/build_mips/
+genromfs -d romfs -f 8634test.romfs
+cp 8634test.romfs /tftproot/
diff -Naur linux-2.6.30-ori/arch/mips/configs/tango2_defconfig linux-2.6.30-test/arch/mips/configs/tango2_defconfig
--- linux-2.6.30-ori/arch/mips/configs/tango2_defconfig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/configs/tango2_defconfig	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,896 @@
+#
+# Automatically generated make config: don't edit
+# Linux kernel version: 2.6.15
+# Tue Mar  6 10:24:42 2007
+#
+CONFIG_MIPS=y
+
+#
+# Machine selection
+#
+# CONFIG_MIPS_MTX1 is not set
+# CONFIG_MIPS_BOSPORUS is not set
+# CONFIG_MIPS_PB1000 is not set
+# CONFIG_MIPS_PB1100 is not set
+# CONFIG_MIPS_PB1500 is not set
+# CONFIG_MIPS_PB1550 is not set
+# CONFIG_MIPS_PB1200 is not set
+# CONFIG_MIPS_DB1000 is not set
+# CONFIG_MIPS_DB1100 is not set
+# CONFIG_MIPS_DB1500 is not set
+# CONFIG_MIPS_DB1550 is not set
+# CONFIG_MIPS_DB1200 is not set
+# CONFIG_MIPS_MIRAGE is not set
+# CONFIG_MIPS_COBALT is not set
+# CONFIG_MACH_DECSTATION is not set
+# CONFIG_MIPS_EV64120 is not set
+# CONFIG_MIPS_EV96100 is not set
+# CONFIG_MIPS_IVR is not set
+# CONFIG_MIPS_ITE8172 is not set
+# CONFIG_MACH_JAZZ is not set
+# CONFIG_LASAT is not set
+# CONFIG_MIPS_ATLAS is not set
+# CONFIG_MIPS_MALTA is not set
+# CONFIG_MIPS_SEAD is not set
+# CONFIG_MIPS_SIM is not set
+# CONFIG_MOMENCO_JAGUAR_ATX is not set
+# CONFIG_MOMENCO_OCELOT is not set
+# CONFIG_MOMENCO_OCELOT_3 is not set
+# CONFIG_MOMENCO_OCELOT_C is not set
+# CONFIG_MOMENCO_OCELOT_G is not set
+# CONFIG_MIPS_XXS1500 is not set
+# CONFIG_PNX8550_V2PCI is not set
+# CONFIG_PNX8550_JBS is not set
+# CONFIG_DDB5074 is not set
+# CONFIG_DDB5476 is not set
+# CONFIG_DDB5477 is not set
+# CONFIG_MACH_VR41XX is not set
+# CONFIG_PMC_YOSEMITE is not set
+# CONFIG_QEMU is not set
+# CONFIG_SGI_IP22 is not set
+# CONFIG_SGI_IP27 is not set
+# CONFIG_SGI_IP32 is not set
+# CONFIG_SIBYTE_BIGSUR is not set
+# CONFIG_SIBYTE_SWARM is not set
+# CONFIG_SIBYTE_SENTOSA is not set
+# CONFIG_SIBYTE_RHONE is not set
+# CONFIG_SIBYTE_CARMEL is not set
+# CONFIG_SIBYTE_PTSWARM is not set
+# CONFIG_SIBYTE_LITTLESUR is not set
+# CONFIG_SIBYTE_CRHINE is not set
+# CONFIG_SIBYTE_CRHONE is not set
+# CONFIG_SNI_RM200_PCI is not set
+CONFIG_TANGO2=y
+# CONFIG_TANGO3 is not set
+# CONFIG_TOSHIBA_JMR3927 is not set
+# CONFIG_TOSHIBA_RBTX4927 is not set
+# CONFIG_TOSHIBA_RBTX4938 is not set
+CONFIG_TANGO2_SMP863X=y
+# CONFIG_TANGO2_ES1 is not set
+# CONFIG_TANGO2_ES2 is not set
+# CONFIG_TANGO2_ES3 is not set
+# CONFIG_TANGO2_ES4 is not set
+# CONFIG_TANGO2_ES5 is not set
+CONFIG_TANGO2_ES6=y
+
+#
+# 
+#
+CONFIG_TANGOX_HZ_VALUE=1000
+CONFIG_TANGOX_SYSTEMRAM_ACTUALSIZE=64
+# CONFIG_TANGOX_IGNORE_CMDLINE is not set
+# CONFIG_TANGOX_PROM_CONSOLE is not set
+# CONFIG_TANGOX_FIXED_FREQUENCIES is not set
+# CONFIG_TANGOX_USE_CPU_CLOCK is not set
+# CONFIG_TANGOX_UART_USE_SYSCLK is not set
+CONFIG_TANGOX_USE_TLB_REMAP_DRAM1=y
+
+#
+# 
+#
+CONFIG_TANGOX_XENV_READ=y
+# CONFIG_TANGOX_XENV_DUMP is not set
+CONFIG_TANGOX_XENV_READ_SAFE=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_TANGOX=y
+CONFIG_DMA_TANGOX=y
+CONFIG_DMA_NONCOHERENT=y
+CONFIG_DMA_NEED_PCI_MAP_STATE=y
+CONFIG_OWN_DMA=y
+# CONFIG_CPU_BIG_ENDIAN is not set
+CONFIG_CPU_LITTLE_ENDIAN=y
+CONFIG_SYS_SUPPORTS_LITTLE_ENDIAN=y
+CONFIG_IRQ_CPU=y
+CONFIG_MIPS_L1_CACHE_SHIFT=4
+
+#
+# CPU selection
+#
+# CONFIG_CPU_MIPS32_R1 is not set
+CONFIG_CPU_MIPS32_R2=y
+# CONFIG_CPU_MIPS64_R1 is not set
+# CONFIG_CPU_MIPS64_R2 is not set
+# CONFIG_CPU_R3000 is not set
+# CONFIG_CPU_TX39XX is not set
+# CONFIG_CPU_VR41XX is not set
+# CONFIG_CPU_R4300 is not set
+# CONFIG_CPU_R4X00 is not set
+# CONFIG_CPU_TX49XX is not set
+# CONFIG_CPU_R5000 is not set
+# CONFIG_CPU_R5432 is not set
+# CONFIG_CPU_R6000 is not set
+# CONFIG_CPU_NEVADA is not set
+# CONFIG_CPU_R8000 is not set
+# CONFIG_CPU_R10000 is not set
+# CONFIG_CPU_RM7000 is not set
+# CONFIG_CPU_RM9000 is not set
+# CONFIG_CPU_SB1 is not set
+CONFIG_SYS_HAS_CPU_MIPS32_R1=y
+CONFIG_SYS_HAS_CPU_MIPS32_R2=y
+CONFIG_CPU_MIPS32=y
+CONFIG_CPU_MIPSR2=y
+CONFIG_SYS_SUPPORTS_32BIT_KERNEL=y
+CONFIG_CPU_SUPPORTS_32BIT_KERNEL=y
+
+#
+# Kernel type
+#
+CONFIG_32BIT=y
+# CONFIG_64BIT is not set
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_CPU_HAS_PREFETCH=y
+# CONFIG_MIPS_MT is not set
+# CONFIG_64BIT_PHYS_ADDR is not set
+# CONFIG_CPU_ADVANCED is not set
+CONFIG_CPU_HAS_LLSC=y
+CONFIG_CPU_HAS_SYNC=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_SELECT_MEMORY_MODEL=y
+CONFIG_FLATMEM_MANUAL=y
+# CONFIG_DISCONTIGMEM_MANUAL is not set
+# CONFIG_SPARSEMEM_MANUAL is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+# CONFIG_SPARSEMEM_STATIC is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+
+#
+# Code maturity level options
+#
+CONFIG_EXPERIMENTAL=y
+CONFIG_CLEAN_COMPILE=y
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+
+#
+# General setup
+#
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+# CONFIG_SWAP is not set
+CONFIG_SYSVIPC=y
+# CONFIG_POSIX_MQUEUE is not set
+# CONFIG_BSD_PROCESS_ACCT is not set
+CONFIG_SYSCTL=y
+# CONFIG_AUDIT is not set
+# CONFIG_HOTPLUG is not set
+CONFIG_KOBJECT_UEVENT=y
+# CONFIG_IKCONFIG is not set
+CONFIG_INITRAMFS_SOURCE="/tmp/CR/CR-26/"
+CONFIG_INITRAMFS_ROOT_UID=0
+CONFIG_INITRAMFS_ROOT_GID=0
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_EMBEDDED=y
+# CONFIG_KALLSYMS is not set
+CONFIG_PRINTK=y
+CONFIG_BUG=y
+CONFIG_BASE_FULL=y
+# CONFIG_FUTEX is not set
+# CONFIG_EPOLL is not set
+# CONFIG_SHMEM is not set
+CONFIG_CC_ALIGN_FUNCTIONS=0
+CONFIG_CC_ALIGN_LABELS=0
+CONFIG_CC_ALIGN_LOOPS=0
+CONFIG_CC_ALIGN_JUMPS=0
+CONFIG_TINY_SHMEM=y
+CONFIG_BASE_SMALL=0
+
+#
+# Loadable module support
+#
+CONFIG_MODULES=y
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+CONFIG_OBSOLETE_MODPARM=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_KMOD is not set
+
+#
+# Block layer
+#
+# CONFIG_LBD is not set
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+# CONFIG_IOSCHED_AS is not set
+# CONFIG_IOSCHED_DEADLINE is not set
+# CONFIG_IOSCHED_CFQ is not set
+# CONFIG_DEFAULT_AS is not set
+# CONFIG_DEFAULT_DEADLINE is not set
+# CONFIG_DEFAULT_CFQ is not set
+CONFIG_DEFAULT_NOOP=y
+CONFIG_DEFAULT_IOSCHED="noop"
+
+#
+# Bus options (PCI, PCMCIA, EISA, ISA, TC)
+#
+CONFIG_MMU=y
+
+#
+# PCCARD (PCMCIA/CardBus) support
+#
+# CONFIG_PCCARD is not set
+
+#
+# PCI Hotplug Support
+#
+
+#
+# Executable file formats
+#
+CONFIG_BINFMT_ELF=y
+# CONFIG_BINFMT_MISC is not set
+CONFIG_TRAD_SIGNALS=y
+
+#
+# Networking
+#
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_MMAP is not set
+CONFIG_UNIX=y
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+# CONFIG_IP_MULTICAST is not set
+# CONFIG_IP_ADVANCED_ROUTER is not set
+CONFIG_IP_FIB_HASH=y
+# CONFIG_IP_PNP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE is not set
+# CONFIG_ARPD is not set
+# CONFIG_SYN_COOKIES is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_DIAG is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_BIC=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETFILTER is not set
+
+#
+# DCCP Configuration (EXPERIMENTAL)
+#
+# CONFIG_IP_DCCP is not set
+
+#
+# SCTP Configuration (EXPERIMENTAL)
+#
+# CONFIG_IP_SCTP is not set
+# CONFIG_ATM is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_NET_DIVERT is not set
+# CONFIG_ECONET is not set
+# CONFIG_WAN_ROUTER is not set
+
+#
+# QoS and/or fair queueing
+#
+# CONFIG_NET_SCHED is not set
+
+#
+# Network testing
+#
+CONFIG_NET_PKTGEN=y
+# CONFIG_HAMRADIO is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_IEEE80211 is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+# CONFIG_FW_LOADER is not set
+
+#
+# Connector - unified userspace <-> kernelspace linker
+#
+# CONFIG_CONNECTOR is not set
+
+#
+# Memory Technology Devices (MTD)
+#
+CONFIG_MTD=y
+# CONFIG_MTD_DEBUG is not set
+CONFIG_MTD_CONCAT=y
+CONFIG_MTD_PARTITIONS=y
+# CONFIG_MTD_REDBOOT_PARTS is not set
+# CONFIG_MTD_CMDLINE_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_CHAR=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+CONFIG_MTD_CFI=y
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_GEN_PROBE=y
+# CONFIG_MTD_CFI_ADV_OPTIONS is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+CONFIG_MTD_CFI_INTELEXT=y
+CONFIG_MTD_CFI_AMDSTD=y
+CONFIG_MTD_CFI_AMDSTD_RETRY=0
+CONFIG_MTD_CFI_STAA=y
+CONFIG_MTD_CFI_UTIL=y
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+CONFIG_MTD_PHYSMAP=y
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_PMC551 is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLKMTD is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOC2000 is not set
+# CONFIG_MTD_DOC2001 is not set
+# CONFIG_MTD_DOC2001PLUS is not set
+
+#
+# NAND Flash Device Drivers
+#
+# CONFIG_MTD_NAND is not set
+
+#
+# OneNAND Flash Device Drivers
+#
+# CONFIG_MTD_ONENAND is not set
+
+#
+# Parallel port support
+#
+# CONFIG_PARPORT is not set
+
+#
+# Plug and Play support
+#
+
+#
+# Block devices
+#
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_NBD is not set
+# CONFIG_BLK_DEV_RAM is not set
+CONFIG_BLK_DEV_RAM_COUNT=16
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+
+#
+# ATA/ATAPI/MFM/RLL support
+#
+CONFIG_IDE=y
+CONFIG_BLK_DEV_IDE=y
+
+#
+# Please see Documentation/ide.txt for help/info on IDE drives
+#
+# CONFIG_BLK_DEV_IDE_SATA is not set
+CONFIG_BLK_DEV_IDEDISK=y
+# CONFIG_IDEDISK_MULTI_MODE is not set
+CONFIG_BLK_DEV_IDECD=y
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_BLK_DEV_IDESCSI is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+
+#
+# IDE chipset support/bugfixes
+#
+CONFIG_IDE_GENERIC=y
+# CONFIG_IDE_ARM is not set
+CONFIG_BLK_DEV_BMIDE_TANGOX=y
+CONFIG_BLK_DEV_BMIDE_TANGOX_DMA=y
+CONFIG_BLK_DEV_PBIDE_TANGOX=y
+CONFIG_BLK_DEV_PBIDE_TANGOX_DMA=y
+CONFIG_BLK_DEV_IDEDMA=y
+CONFIG_IDEDMA_AUTO=y
+# CONFIG_BLK_DEV_HD is not set
+
+#
+# SCSI device support
+#
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+
+#
+# Some SCSI devices (e.g. CD jukebox) support multiple LUNs
+#
+# CONFIG_SCSI_MULTI_LUN is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+
+#
+# SCSI Transport Attributes
+#
+CONFIG_SCSI_SPI_ATTRS=y
+# CONFIG_SCSI_FC_ATTRS is not set
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+
+#
+# SCSI low-level drivers
+#
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_SCSI_SATA is not set
+# CONFIG_SCSI_DEBUG is not set
+
+#
+# Multi-device support (RAID and LVM)
+#
+# CONFIG_MD is not set
+
+#
+# Fusion MPT device support
+#
+# CONFIG_FUSION is not set
+
+#
+# IEEE 1394 (FireWire) support
+#
+
+#
+# I2O device support
+#
+
+#
+# Network device support
+#
+CONFIG_NETDEVICES=y
+# CONFIG_DUMMY is not set
+# CONFIG_BONDING is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_TUN is not set
+
+#
+# PHY device support
+#
+# CONFIG_PHYLIB is not set
+
+#
+# Ethernet (10 or 100Mbit)
+#
+CONFIG_NET_ETHERNET=y
+CONFIG_MII=y
+
+#
+# Ethernet (1000 Mbit)
+#
+
+#
+# Ethernet (10000 Mbit)
+#
+
+#
+# Token Ring devices
+#
+
+#
+# Wireless LAN (non-hamradio)
+#
+# CONFIG_NET_RADIO is not set
+
+#
+# Wan interfaces
+#
+# CONFIG_WAN is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+# CONFIG_SHAPER is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+
+#
+# ISDN subsystem
+#
+# CONFIG_ISDN is not set
+
+#
+# Telephony Support
+#
+# CONFIG_PHONE is not set
+
+#
+# Input device support
+#
+# CONFIG_INPUT is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+# CONFIG_VT is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_8250=y
+CONFIG_SERIAL_8250_CONSOLE=y
+CONFIG_SERIAL_8250_NR_UARTS=4
+# CONFIG_SERIAL_8250_EXTENDED is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+
+#
+# IPMI
+#
+# CONFIG_IPMI_HANDLER is not set
+
+#
+# Watchdog Cards
+#
+# CONFIG_WATCHDOG is not set
+# CONFIG_RTC is not set
+# CONFIG_GEN_RTC is not set
+# CONFIG_DTLK is not set
+# CONFIG_R3964 is not set
+
+#
+# Ftape, the floppy tape device driver
+#
+# CONFIG_RAW_DRIVER is not set
+
+#
+# TPM devices
+#
+# CONFIG_TCG_TPM is not set
+# CONFIG_TELCLOCK is not set
+
+#
+# I2C support
+#
+# CONFIG_I2C is not set
+
+#
+# Dallas's 1-wire bus
+#
+# CONFIG_W1 is not set
+
+#
+# Hardware Monitoring support
+#
+# CONFIG_HWMON is not set
+# CONFIG_HWMON_VID is not set
+
+#
+# Misc devices
+#
+
+#
+# Multimedia Capabilities Port drivers
+#
+
+#
+# Multimedia devices
+#
+# CONFIG_VIDEO_DEV is not set
+
+#
+# Digital Video Broadcasting Devices
+#
+# CONFIG_DVB is not set
+
+#
+# Graphics support
+#
+# CONFIG_FB is not set
+
+#
+# Sound
+#
+# CONFIG_SOUND is not set
+
+#
+# USB support
+#
+# CONFIG_USB_ARCH_HAS_HCD is not set
+# CONFIG_USB_ARCH_HAS_OHCI is not set
+
+#
+# NOTE: USB_STORAGE enables SCSI, and 'SCSI disk support'
+#
+
+#
+# USB Gadget Support
+#
+# CONFIG_USB_GADGET is not set
+
+#
+# MMC/SD Card support
+#
+# CONFIG_MMC is not set
+
+#
+# InfiniBand support
+#
+
+#
+# SN Devices
+#
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+# CONFIG_EXT2_FS_XATTR is not set
+# CONFIG_EXT2_FS_XIP is not set
+CONFIG_EXT3_FS=y
+# CONFIG_EXT3_FS_XATTR is not set
+CONFIG_JBD=y
+# CONFIG_JBD_DEBUG is not set
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_INOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_DNOTIFY is not set
+# CONFIG_AUTOFS_FS is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+CONFIG_JOLIET=y
+# CONFIG_ZISOFS is not set
+CONFIG_UDF_FS=y
+CONFIG_UDF_NLS=y
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+# CONFIG_MSDOS_FS is not set
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+# CONFIG_PROC_KCORE is not set
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_RAMFS=y
+# CONFIG_RELAYFS_FS is not set
+
+#
+# Miscellaneous filesystems
+#
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+# CONFIG_JFFS_FS is not set
+# CONFIG_JFFS2_FS is not set
+CONFIG_CRAMFS=y
+# CONFIG_VXFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+
+#
+# Network File Systems
+#
+CONFIG_NFS_FS=y
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+# CONFIG_NFS_V4 is not set
+# CONFIG_NFS_DIRECTIO is not set
+# CONFIG_NFSD is not set
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+# CONFIG_RPCSEC_GSS_KRB5 is not set
+# CONFIG_RPCSEC_GSS_SPKM3 is not set
+# CONFIG_SMB_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+# CONFIG_9P_FS is not set
+
+#
+# Partition Types
+#
+# CONFIG_PARTITION_ADVANCED is not set
+CONFIG_MSDOS_PARTITION=y
+
+#
+# Native Language Support
+#
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+
+#
+# Profiling support
+#
+# CONFIG_PROFILING is not set
+
+#
+# Kernel hacking
+#
+# CONFIG_PRINTK_TIME is not set
+# CONFIG_DEBUG_KERNEL is not set
+CONFIG_LOG_BUF_SHIFT=14
+CONFIG_CROSSCOMPILE=y
+CONFIG_CMDLINE="console=ttyS0"
+
+#
+# Security options
+#
+# CONFIG_KEYS is not set
+# CONFIG_SECURITY is not set
+
+#
+# Cryptographic options
+#
+# CONFIG_CRYPTO is not set
+
+#
+# Hardware crypto devices
+#
+
+#
+# Library routines
+#
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC16 is not set
+CONFIG_CRC32=y
+# CONFIG_LIBCRC32C is not set
+CONFIG_ZLIB_INFLATE=y
diff -Naur linux-2.6.30-ori/arch/mips/configs/tango3_defconfig linux-2.6.30-test/arch/mips/configs/tango3_defconfig
--- linux-2.6.30-ori/arch/mips/configs/tango3_defconfig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/configs/tango3_defconfig	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,891 @@
+#
+# Automatically generated make config: don't edit
+# Linux kernel version: 2.6.15
+# Mon Oct 23 14:23:16 2006
+#
+CONFIG_MIPS=y
+
+#
+# Machine selection
+#
+# CONFIG_MIPS_MTX1 is not set
+# CONFIG_MIPS_BOSPORUS is not set
+# CONFIG_MIPS_PB1000 is not set
+# CONFIG_MIPS_PB1100 is not set
+# CONFIG_MIPS_PB1500 is not set
+# CONFIG_MIPS_PB1550 is not set
+# CONFIG_MIPS_PB1200 is not set
+# CONFIG_MIPS_DB1000 is not set
+# CONFIG_MIPS_DB1100 is not set
+# CONFIG_MIPS_DB1500 is not set
+# CONFIG_MIPS_DB1550 is not set
+# CONFIG_MIPS_DB1200 is not set
+# CONFIG_MIPS_MIRAGE is not set
+# CONFIG_MIPS_COBALT is not set
+# CONFIG_MACH_DECSTATION is not set
+# CONFIG_MIPS_EV64120 is not set
+# CONFIG_MIPS_EV96100 is not set
+# CONFIG_MIPS_IVR is not set
+# CONFIG_MIPS_ITE8172 is not set
+# CONFIG_MACH_JAZZ is not set
+# CONFIG_LASAT is not set
+# CONFIG_MIPS_ATLAS is not set
+# CONFIG_MIPS_MALTA is not set
+# CONFIG_MIPS_SEAD is not set
+# CONFIG_MIPS_SIM is not set
+# CONFIG_MOMENCO_JAGUAR_ATX is not set
+# CONFIG_MOMENCO_OCELOT is not set
+# CONFIG_MOMENCO_OCELOT_3 is not set
+# CONFIG_MOMENCO_OCELOT_C is not set
+# CONFIG_MOMENCO_OCELOT_G is not set
+# CONFIG_MIPS_XXS1500 is not set
+# CONFIG_PNX8550_V2PCI is not set
+# CONFIG_PNX8550_JBS is not set
+# CONFIG_DDB5074 is not set
+# CONFIG_DDB5476 is not set
+# CONFIG_DDB5477 is not set
+# CONFIG_MACH_VR41XX is not set
+# CONFIG_PMC_YOSEMITE is not set
+# CONFIG_QEMU is not set
+# CONFIG_SGI_IP22 is not set
+# CONFIG_SGI_IP27 is not set
+# CONFIG_SGI_IP32 is not set
+# CONFIG_SIBYTE_BIGSUR is not set
+# CONFIG_SIBYTE_SWARM is not set
+# CONFIG_SIBYTE_SENTOSA is not set
+# CONFIG_SIBYTE_RHONE is not set
+# CONFIG_SIBYTE_CARMEL is not set
+# CONFIG_SIBYTE_PTSWARM is not set
+# CONFIG_SIBYTE_LITTLESUR is not set
+# CONFIG_SIBYTE_CRHINE is not set
+# CONFIG_SIBYTE_CRHONE is not set
+# CONFIG_SNI_RM200_PCI is not set
+# CONFIG_TANGO2 is not set
+CONFIG_TANGO3=y
+# CONFIG_TOSHIBA_JMR3927 is not set
+# CONFIG_TOSHIBA_RBTX4927 is not set
+# CONFIG_TOSHIBA_RBTX4938 is not set
+CONFIG_TANGO3_SMP865X=y
+CONFIG_TANGO3_ES1=y
+
+#
+# 
+#
+# CONFIG_TANGO3_DISABLE_HWFPU is not set
+CONFIG_TANGOX_HZ_VALUE=1000
+CONFIG_TANGOX_SYSTEMRAM_ACTUALSIZE=64
+# CONFIG_TANGOX_IGNORE_CMDLINE is not set
+# CONFIG_TANGOX_PROM_CONSOLE is not set
+# CONFIG_TANGOX_FIXED_FREQUENCIES is not set
+# CONFIG_TANGOX_USE_CPU_CLOCK is not set
+# CONFIG_TANGOX_UART_USE_SYSCLK is not set
+
+#
+# 
+#
+CONFIG_TANGOX_XENV_READ=y
+# CONFIG_TANGOX_XENV_DUMP is not set
+CONFIG_TANGOX_XENV_READ_SAFE=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_TANGOX=y
+CONFIG_DMA_TANGOX=y
+CONFIG_DMA_NONCOHERENT=y
+CONFIG_DMA_NEED_PCI_MAP_STATE=y
+CONFIG_OWN_DMA=y
+# CONFIG_CPU_BIG_ENDIAN is not set
+CONFIG_CPU_LITTLE_ENDIAN=y
+CONFIG_SYS_SUPPORTS_LITTLE_ENDIAN=y
+CONFIG_IRQ_CPU=y
+CONFIG_MIPS_L1_CACHE_SHIFT=5
+
+#
+# CPU selection
+#
+# CONFIG_CPU_MIPS32_R1 is not set
+CONFIG_CPU_MIPS32_R2=y
+# CONFIG_CPU_MIPS64_R1 is not set
+# CONFIG_CPU_MIPS64_R2 is not set
+# CONFIG_CPU_R3000 is not set
+# CONFIG_CPU_TX39XX is not set
+# CONFIG_CPU_VR41XX is not set
+# CONFIG_CPU_R4300 is not set
+# CONFIG_CPU_R4X00 is not set
+# CONFIG_CPU_TX49XX is not set
+# CONFIG_CPU_R5000 is not set
+# CONFIG_CPU_R5432 is not set
+# CONFIG_CPU_R6000 is not set
+# CONFIG_CPU_NEVADA is not set
+# CONFIG_CPU_R8000 is not set
+# CONFIG_CPU_R10000 is not set
+# CONFIG_CPU_RM7000 is not set
+# CONFIG_CPU_RM9000 is not set
+# CONFIG_CPU_SB1 is not set
+CONFIG_SYS_HAS_CPU_MIPS32_R1=y
+CONFIG_SYS_HAS_CPU_MIPS32_R2=y
+CONFIG_CPU_MIPS32=y
+CONFIG_CPU_MIPSR2=y
+CONFIG_SYS_SUPPORTS_32BIT_KERNEL=y
+CONFIG_CPU_SUPPORTS_32BIT_KERNEL=y
+
+#
+# Kernel type
+#
+CONFIG_32BIT=y
+# CONFIG_64BIT is not set
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_CPU_HAS_PREFETCH=y
+# CONFIG_MIPS_MT is not set
+# CONFIG_64BIT_PHYS_ADDR is not set
+# CONFIG_CPU_ADVANCED is not set
+CONFIG_CPU_HAS_LLSC=y
+CONFIG_CPU_HAS_SYNC=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_SELECT_MEMORY_MODEL=y
+CONFIG_FLATMEM_MANUAL=y
+# CONFIG_DISCONTIGMEM_MANUAL is not set
+# CONFIG_SPARSEMEM_MANUAL is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+# CONFIG_SPARSEMEM_STATIC is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+
+#
+# Code maturity level options
+#
+CONFIG_EXPERIMENTAL=y
+CONFIG_CLEAN_COMPILE=y
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+
+#
+# General setup
+#
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+# CONFIG_SWAP is not set
+CONFIG_SYSVIPC=y
+# CONFIG_POSIX_MQUEUE is not set
+# CONFIG_BSD_PROCESS_ACCT is not set
+CONFIG_SYSCTL=y
+# CONFIG_AUDIT is not set
+# CONFIG_HOTPLUG is not set
+CONFIG_KOBJECT_UEVENT=y
+# CONFIG_IKCONFIG is not set
+CONFIG_INITRAMFS_SOURCE="/tmp/CR/CR-26/"
+CONFIG_INITRAMFS_ROOT_UID=0
+CONFIG_INITRAMFS_ROOT_GID=0
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_EMBEDDED=y
+# CONFIG_KALLSYMS is not set
+CONFIG_PRINTK=y
+CONFIG_BUG=y
+CONFIG_BASE_FULL=y
+# CONFIG_FUTEX is not set
+# CONFIG_EPOLL is not set
+# CONFIG_SHMEM is not set
+CONFIG_CC_ALIGN_FUNCTIONS=0
+CONFIG_CC_ALIGN_LABELS=0
+CONFIG_CC_ALIGN_LOOPS=0
+CONFIG_CC_ALIGN_JUMPS=0
+CONFIG_TINY_SHMEM=y
+CONFIG_BASE_SMALL=0
+
+#
+# Loadable module support
+#
+CONFIG_MODULES=y
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+CONFIG_OBSOLETE_MODPARM=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_KMOD is not set
+
+#
+# Block layer
+#
+# CONFIG_LBD is not set
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+# CONFIG_IOSCHED_AS is not set
+# CONFIG_IOSCHED_DEADLINE is not set
+# CONFIG_IOSCHED_CFQ is not set
+# CONFIG_DEFAULT_AS is not set
+# CONFIG_DEFAULT_DEADLINE is not set
+# CONFIG_DEFAULT_CFQ is not set
+CONFIG_DEFAULT_NOOP=y
+CONFIG_DEFAULT_IOSCHED="noop"
+
+#
+# Bus options (PCI, PCMCIA, EISA, ISA, TC)
+#
+CONFIG_MMU=y
+
+#
+# PCCARD (PCMCIA/CardBus) support
+#
+# CONFIG_PCCARD is not set
+
+#
+# PCI Hotplug Support
+#
+
+#
+# Executable file formats
+#
+CONFIG_BINFMT_ELF=y
+# CONFIG_BINFMT_MISC is not set
+CONFIG_TRAD_SIGNALS=y
+
+#
+# Networking
+#
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_MMAP is not set
+CONFIG_UNIX=y
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+# CONFIG_IP_MULTICAST is not set
+# CONFIG_IP_ADVANCED_ROUTER is not set
+CONFIG_IP_FIB_HASH=y
+# CONFIG_IP_PNP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE is not set
+# CONFIG_ARPD is not set
+# CONFIG_SYN_COOKIES is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_DIAG is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_BIC=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETFILTER is not set
+
+#
+# DCCP Configuration (EXPERIMENTAL)
+#
+# CONFIG_IP_DCCP is not set
+
+#
+# SCTP Configuration (EXPERIMENTAL)
+#
+# CONFIG_IP_SCTP is not set
+# CONFIG_ATM is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_NET_DIVERT is not set
+# CONFIG_ECONET is not set
+# CONFIG_WAN_ROUTER is not set
+
+#
+# QoS and/or fair queueing
+#
+# CONFIG_NET_SCHED is not set
+
+#
+# Network testing
+#
+CONFIG_NET_PKTGEN=y
+# CONFIG_HAMRADIO is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_IEEE80211 is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+# CONFIG_FW_LOADER is not set
+
+#
+# Connector - unified userspace <-> kernelspace linker
+#
+# CONFIG_CONNECTOR is not set
+
+#
+# Memory Technology Devices (MTD)
+#
+CONFIG_MTD=y
+# CONFIG_MTD_DEBUG is not set
+CONFIG_MTD_CONCAT=y
+CONFIG_MTD_PARTITIONS=y
+# CONFIG_MTD_REDBOOT_PARTS is not set
+# CONFIG_MTD_CMDLINE_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_CHAR=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+CONFIG_MTD_CFI=y
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_GEN_PROBE=y
+# CONFIG_MTD_CFI_ADV_OPTIONS is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+CONFIG_MTD_CFI_INTELEXT=y
+CONFIG_MTD_CFI_AMDSTD=y
+CONFIG_MTD_CFI_AMDSTD_RETRY=0
+CONFIG_MTD_CFI_STAA=y
+CONFIG_MTD_CFI_UTIL=y
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+CONFIG_MTD_PHYSMAP=y
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_PMC551 is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLKMTD is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOC2000 is not set
+# CONFIG_MTD_DOC2001 is not set
+# CONFIG_MTD_DOC2001PLUS is not set
+
+#
+# NAND Flash Device Drivers
+#
+# CONFIG_MTD_NAND is not set
+
+#
+# OneNAND Flash Device Drivers
+#
+# CONFIG_MTD_ONENAND is not set
+
+#
+# Parallel port support
+#
+# CONFIG_PARPORT is not set
+
+#
+# Plug and Play support
+#
+
+#
+# Block devices
+#
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_NBD is not set
+# CONFIG_BLK_DEV_RAM is not set
+CONFIG_BLK_DEV_RAM_COUNT=16
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+
+#
+# ATA/ATAPI/MFM/RLL support
+#
+CONFIG_IDE=y
+CONFIG_BLK_DEV_IDE=y
+
+#
+# Please see Documentation/ide.txt for help/info on IDE drives
+#
+# CONFIG_BLK_DEV_IDE_SATA is not set
+CONFIG_BLK_DEV_IDEDISK=y
+# CONFIG_IDEDISK_MULTI_MODE is not set
+CONFIG_BLK_DEV_IDECD=y
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_BLK_DEV_IDESCSI is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+
+#
+# IDE chipset support/bugfixes
+#
+CONFIG_IDE_GENERIC=y
+# CONFIG_IDE_ARM is not set
+CONFIG_BLK_DEV_BMIDE_TANGOX=y
+CONFIG_BLK_DEV_BMIDE_TANGOX_DMA=y
+CONFIG_BLK_DEV_PBIDE_TANGOX=y
+CONFIG_BLK_DEV_PBIDE_TANGOX_DMA=y
+CONFIG_BLK_DEV_IDEDMA=y
+CONFIG_IDEDMA_AUTO=y
+# CONFIG_BLK_DEV_HD is not set
+
+#
+# SCSI device support
+#
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+
+#
+# Some SCSI devices (e.g. CD jukebox) support multiple LUNs
+#
+# CONFIG_SCSI_MULTI_LUN is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+
+#
+# SCSI Transport Attributes
+#
+CONFIG_SCSI_SPI_ATTRS=y
+# CONFIG_SCSI_FC_ATTRS is not set
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+
+#
+# SCSI low-level drivers
+#
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_SCSI_SATA is not set
+# CONFIG_SCSI_DEBUG is not set
+
+#
+# Multi-device support (RAID and LVM)
+#
+# CONFIG_MD is not set
+
+#
+# Fusion MPT device support
+#
+# CONFIG_FUSION is not set
+
+#
+# IEEE 1394 (FireWire) support
+#
+
+#
+# I2O device support
+#
+
+#
+# Network device support
+#
+CONFIG_NETDEVICES=y
+# CONFIG_DUMMY is not set
+# CONFIG_BONDING is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_TUN is not set
+
+#
+# PHY device support
+#
+# CONFIG_PHYLIB is not set
+
+#
+# Ethernet (10 or 100Mbit)
+#
+CONFIG_NET_ETHERNET=y
+CONFIG_MII=y
+
+#
+# Ethernet (1000 Mbit)
+#
+
+#
+# Ethernet (10000 Mbit)
+#
+
+#
+# Token Ring devices
+#
+
+#
+# Wireless LAN (non-hamradio)
+#
+# CONFIG_NET_RADIO is not set
+
+#
+# Wan interfaces
+#
+# CONFIG_WAN is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+# CONFIG_SHAPER is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+
+#
+# ISDN subsystem
+#
+# CONFIG_ISDN is not set
+
+#
+# Telephony Support
+#
+# CONFIG_PHONE is not set
+
+#
+# Input device support
+#
+# CONFIG_INPUT is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+# CONFIG_VT is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_8250=y
+CONFIG_SERIAL_8250_CONSOLE=y
+CONFIG_SERIAL_8250_NR_UARTS=4
+# CONFIG_SERIAL_8250_EXTENDED is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+
+#
+# IPMI
+#
+# CONFIG_IPMI_HANDLER is not set
+
+#
+# Watchdog Cards
+#
+# CONFIG_WATCHDOG is not set
+# CONFIG_RTC is not set
+# CONFIG_GEN_RTC is not set
+# CONFIG_DTLK is not set
+# CONFIG_R3964 is not set
+
+#
+# Ftape, the floppy tape device driver
+#
+# CONFIG_RAW_DRIVER is not set
+
+#
+# TPM devices
+#
+# CONFIG_TCG_TPM is not set
+# CONFIG_TELCLOCK is not set
+
+#
+# I2C support
+#
+# CONFIG_I2C is not set
+
+#
+# Dallas's 1-wire bus
+#
+# CONFIG_W1 is not set
+
+#
+# Hardware Monitoring support
+#
+# CONFIG_HWMON is not set
+# CONFIG_HWMON_VID is not set
+
+#
+# Misc devices
+#
+
+#
+# Multimedia Capabilities Port drivers
+#
+
+#
+# Multimedia devices
+#
+# CONFIG_VIDEO_DEV is not set
+
+#
+# Digital Video Broadcasting Devices
+#
+# CONFIG_DVB is not set
+
+#
+# Graphics support
+#
+# CONFIG_FB is not set
+
+#
+# Sound
+#
+# CONFIG_SOUND is not set
+
+#
+# USB support
+#
+# CONFIG_USB_ARCH_HAS_HCD is not set
+# CONFIG_USB_ARCH_HAS_OHCI is not set
+
+#
+# NOTE: USB_STORAGE enables SCSI, and 'SCSI disk support'
+#
+
+#
+# USB Gadget Support
+#
+# CONFIG_USB_GADGET is not set
+
+#
+# MMC/SD Card support
+#
+# CONFIG_MMC is not set
+
+#
+# InfiniBand support
+#
+
+#
+# SN Devices
+#
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+# CONFIG_EXT2_FS_XATTR is not set
+# CONFIG_EXT2_FS_XIP is not set
+CONFIG_EXT3_FS=y
+# CONFIG_EXT3_FS_XATTR is not set
+CONFIG_JBD=y
+# CONFIG_JBD_DEBUG is not set
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_INOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_DNOTIFY is not set
+# CONFIG_AUTOFS_FS is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+CONFIG_JOLIET=y
+# CONFIG_ZISOFS is not set
+CONFIG_UDF_FS=y
+CONFIG_UDF_NLS=y
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+# CONFIG_MSDOS_FS is not set
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+# CONFIG_PROC_KCORE is not set
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_RAMFS=y
+# CONFIG_RELAYFS_FS is not set
+
+#
+# Miscellaneous filesystems
+#
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+# CONFIG_JFFS_FS is not set
+# CONFIG_JFFS2_FS is not set
+CONFIG_CRAMFS=y
+# CONFIG_VXFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+
+#
+# Network File Systems
+#
+CONFIG_NFS_FS=y
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+# CONFIG_NFS_V4 is not set
+# CONFIG_NFS_DIRECTIO is not set
+# CONFIG_NFSD is not set
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+# CONFIG_RPCSEC_GSS_KRB5 is not set
+# CONFIG_RPCSEC_GSS_SPKM3 is not set
+# CONFIG_SMB_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+# CONFIG_9P_FS is not set
+
+#
+# Partition Types
+#
+# CONFIG_PARTITION_ADVANCED is not set
+CONFIG_MSDOS_PARTITION=y
+
+#
+# Native Language Support
+#
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+
+#
+# Profiling support
+#
+# CONFIG_PROFILING is not set
+
+#
+# Kernel hacking
+#
+# CONFIG_PRINTK_TIME is not set
+# CONFIG_DEBUG_KERNEL is not set
+CONFIG_LOG_BUF_SHIFT=14
+CONFIG_CROSSCOMPILE=y
+CONFIG_CMDLINE="console=ttyS0"
+
+#
+# Security options
+#
+# CONFIG_KEYS is not set
+# CONFIG_SECURITY is not set
+
+#
+# Cryptographic options
+#
+# CONFIG_CRYPTO is not set
+
+#
+# Hardware crypto devices
+#
+
+#
+# Library routines
+#
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC16 is not set
+CONFIG_CRC32=y
+# CONFIG_LIBCRC32C is not set
+CONFIG_ZLIB_INFLATE=y
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/bootinfo.h linux-2.6.30-test/arch/mips/include/asm/bootinfo.h
--- linux-2.6.30-ori/arch/mips/include/asm/bootinfo.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/bootinfo.h	2009-06-12 18:32:43.000000000 -0400
@@ -57,6 +57,12 @@
 #define	MACH_MIKROTIK_RB532	0	/* Mikrotik RouterBoard 532 	*/
 #define MACH_MIKROTIK_RB532A	1	/* Mikrotik RouterBoard 532A 	*/
 
+/*
+ * Valid machtype for group SIGMADESIGNS
+ */
+#define MACH_GROUP_SIGMADESIGNS	23	/* For SigmaDesigns Tango2/Tango3 board */
+#define  MACH_TANGOX		 1	/* Tango2/Tango3 */
+
 #define CL_SIZE			COMMAND_LINE_SIZE
 
 extern char *system_type;
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/checksum.h linux-2.6.30-test/arch/mips/include/asm/checksum.h
--- linux-2.6.30-ori/arch/mips/include/asm/checksum.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/checksum.h	2009-06-15 11:26:52.000000000 -0400
@@ -32,6 +32,7 @@
 __wsum __csum_partial_copy_user(const void *src, void *dst,
 				int len, __wsum sum, int *err_ptr);
 
+extern long long em86_stats[20];
 /*
  * this is a new version of the above that records errors it finds in *errp,
  * but continues and zeros the rest of the buffer.
@@ -40,6 +41,7 @@
 __wsum csum_partial_copy_from_user(const void __user *src, void *dst, int len,
 				   __wsum sum, int *err_ptr)
 {
+	em86_stats[17]+=len;
 	might_fault();
 	return __csum_partial_copy_user((__force void *)src, dst,
 					len, sum, err_ptr);
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/checksum.h~ linux-2.6.30-test/arch/mips/include/asm/checksum.h~
--- linux-2.6.30-ori/arch/mips/include/asm/checksum.h~	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/checksum.h~	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,260 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 96, 97, 98, 99, 2001 by Ralf Baechle
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) 2001 Thiemo Seufer.
+ * Copyright (C) 2002 Maciej W. Rozycki
+ */
+#ifndef _ASM_CHECKSUM_H
+#define _ASM_CHECKSUM_H
+
+#include <linux/in6.h>
+
+#include <asm/uaccess.h>
+
+/*
+ * computes the checksum of a memory block at buff, length len,
+ * and adds in "sum" (32-bit)
+ *
+ * returns a 32-bit number suitable for feeding into itself
+ * or csum_tcpudp_magic
+ *
+ * this function must be called with even lengths, except
+ * for the last fragment, which may be odd
+ *
+ * it's best to have buff aligned on a 32-bit boundary
+ */
+__wsum csum_partial(const void *buff, int len, __wsum sum);
+
+__wsum __csum_partial_copy_user(const void *src, void *dst,
+				int len, __wsum sum, int *err_ptr);
+
+/*
+ * this is a new version of the above that records errors it finds in *errp,
+ * but continues and zeros the rest of the buffer.
+ */
+static inline
+__wsum csum_partial_copy_from_user(const void __user *src, void *dst, int len,
+				   __wsum sum, int *err_ptr)
+{
+	might_fault();
+	return __csum_partial_copy_user((__force void *)src, dst,
+					len, sum, err_ptr);
+}
+
+/*
+ * Copy and checksum to user
+ */
+#define HAVE_CSUM_COPY_USER
+static inline
+__wsum csum_and_copy_to_user(const void *src, void __user *dst, int len,
+			     __wsum sum, int *err_ptr)
+{
+	might_fault();
+	if (access_ok(VERIFY_WRITE, dst, len))
+		return __csum_partial_copy_user(src, (__force void *)dst,
+						len, sum, err_ptr);
+	if (len)
+		*err_ptr = -EFAULT;
+
+	return (__force __wsum)-1; /* invalid checksum */
+}
+
+/*
+ * the same as csum_partial, but copies from user space (but on MIPS
+ * we have just one address space, so this is identical to the above)
+ */
+__wsum csum_partial_copy_nocheck(const void *src, void *dst,
+				       int len, __wsum sum);
+
+/*
+ *	Fold a partial checksum without adding pseudo headers
+ */
+static inline __sum16 csum_fold(__wsum sum)
+{
+	__asm__(
+	"	.set	push		# csum_fold\n"
+	"	.set	noat		\n"
+	"	sll	$1, %0, 16	\n"
+	"	addu	%0, $1		\n"
+	"	sltu	$1, %0, $1	\n"
+	"	srl	%0, %0, 16	\n"
+	"	addu	%0, $1		\n"
+	"	xori	%0, 0xffff	\n"
+	"	.set	pop"
+	: "=r" (sum)
+	: "0" (sum));
+
+	return (__force __sum16)sum;
+}
+
+/*
+ *	This is a version of ip_compute_csum() optimized for IP headers,
+ *	which always checksum on 4 octet boundaries.
+ *
+ *	By Jorge Cwik <jorge@laser.satlink.net>, adapted for linux by
+ *	Arnt Gulbrandsen.
+ */
+static inline __sum16 ip_fast_csum(const void *iph, unsigned int ihl)
+{
+	const unsigned int *word = iph;
+	const unsigned int *stop = word + ihl;
+	unsigned int csum;
+	int carry;
+
+	csum = word[0];
+	csum += word[1];
+	carry = (csum < word[1]);
+	csum += carry;
+
+	csum += word[2];
+	carry = (csum < word[2]);
+	csum += carry;
+
+	csum += word[3];
+	carry = (csum < word[3]);
+	csum += carry;
+
+	word += 4;
+	do {
+		csum += *word;
+		carry = (csum < *word);
+		csum += carry;
+		word++;
+	} while (word != stop);
+
+	return csum_fold(csum);
+}
+
+static inline __wsum csum_tcpudp_nofold(__be32 saddr,
+	__be32 daddr, unsigned short len, unsigned short proto,
+	__wsum sum)
+{
+	__asm__(
+	"	.set	push		# csum_tcpudp_nofold\n"
+	"	.set	noat		\n"
+#ifdef CONFIG_32BIT
+	"	addu	%0, %2		\n"
+	"	sltu	$1, %0, %2	\n"
+	"	addu	%0, $1		\n"
+
+	"	addu	%0, %3		\n"
+	"	sltu	$1, %0, %3	\n"
+	"	addu	%0, $1		\n"
+
+	"	addu	%0, %4		\n"
+	"	sltu	$1, %0, %4	\n"
+	"	addu	%0, $1		\n"
+#endif
+#ifdef CONFIG_64BIT
+	"	daddu	%0, %2		\n"
+	"	daddu	%0, %3		\n"
+	"	daddu	%0, %4		\n"
+	"	dsll32	$1, %0, 0	\n"
+	"	daddu	%0, $1		\n"
+	"	dsra32	%0, %0, 0	\n"
+#endif
+	"	.set	pop"
+	: "=r" (sum)
+	: "0" ((__force unsigned long)daddr),
+	  "r" ((__force unsigned long)saddr),
+#ifdef __MIPSEL__
+	  "r" ((proto + len) << 8),
+#else
+	  "r" (proto + len),
+#endif
+	  "r" ((__force unsigned long)sum));
+
+	return sum;
+}
+
+/*
+ * computes the checksum of the TCP/UDP pseudo-header
+ * returns a 16-bit checksum, already complemented
+ */
+static inline __sum16 csum_tcpudp_magic(__be32 saddr, __be32 daddr,
+						   unsigned short len,
+						   unsigned short proto,
+						   __wsum sum)
+{
+	return csum_fold(csum_tcpudp_nofold(saddr, daddr, len, proto, sum));
+}
+
+/*
+ * this routine is used for miscellaneous IP-like checksums, mainly
+ * in icmp.c
+ */
+static inline __sum16 ip_compute_csum(const void *buff, int len)
+{
+	return csum_fold(csum_partial(buff, len, 0));
+}
+
+#define _HAVE_ARCH_IPV6_CSUM
+static __inline__ __sum16 csum_ipv6_magic(const struct in6_addr *saddr,
+				          const struct in6_addr *daddr,
+					  __u32 len, unsigned short proto,
+					  __wsum sum)
+{
+	__asm__(
+	"	.set	push		# csum_ipv6_magic\n"
+	"	.set	noreorder	\n"
+	"	.set	noat		\n"
+	"	addu	%0, %5		# proto (long in network byte order)\n"
+	"	sltu	$1, %0, %5	\n"
+	"	addu	%0, $1		\n"
+
+	"	addu	%0, %6		# csum\n"
+	"	sltu	$1, %0, %6	\n"
+	"	lw	%1, 0(%2)	# four words source address\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 4(%2)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 8(%2)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 12(%2)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 0(%3)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 4(%3)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 8(%3)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 12(%3)	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	addu	%0, $1		# Add final carry\n"
+	"	.set	pop"
+	: "=r" (sum), "=r" (proto)
+	: "r" (saddr), "r" (daddr),
+	  "0" (htonl(len)), "1" (htonl(proto)), "r" (sum));
+
+	return csum_fold(sum);
+}
+
+#endif /* _ASM_CHECKSUM_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/delay.h linux-2.6.30-test/arch/mips/include/asm/delay.h
--- linux-2.6.30-ori/arch/mips/include/asm/delay.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/delay.h	2009-06-15 11:34:06.000000000 -0400
@@ -15,8 +15,13 @@
 extern void __ndelay(unsigned int ns);
 extern void __udelay(unsigned int us);
 
-#define ndelay(ns) __udelay(ns)
+#if defined(CONFIG_TANGOX) && !defined(CONFIG_TANGOX_USE_CPU_CLOCK)
+void tangox_udelay(unsigned usec);
+#define udelay(usecs) tangox_udelay(usecs)
+#else
 #define udelay(us) __udelay(us)
+#define ndelay(ns) __udelay(ns)
+#endif
 
 /* make sure "usecs *= ..." in udelay do not overflow. */
 #if HZ >= 1000
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/delay.h~ linux-2.6.30-test/arch/mips/include/asm/delay.h~
--- linux-2.6.30-ori/arch/mips/include/asm/delay.h~	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/delay.h~	2009-06-15 11:32:57.000000000 -0400
@@ -0,0 +1,35 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994 by Waldorf Electronics
+ * Copyright (C) 1995 - 2000, 01, 03 by Ralf Baechle
+ * Copyright (C) 1999, 2000 Silicon Graphics, Inc.
+ * Copyright (C) 2007  Maciej W. Rozycki
+ */
+#ifndef _ASM_DELAY_H
+#define _ASM_DELAY_H
+
+extern void __delay(unsigned int loops);
+extern void __ndelay(unsigned int ns);
+extern void __udelay(unsigned int us);
+
+#if defined(CONFIG_TANGOX) && !defined(CONFIG_TANGOX_USE_CPU_CLOCK)
+void tangox_udelay(unsigned usec);
+#define udelay(usecs) tangox_udelay(usecs)
+#else
+#define udelay(us) __udelay(us)
+#endif
+#define ndelay(ns) __udelay(ns)
+
+/* make sure "usecs *= ..." in udelay do not overflow. */
+#if HZ >= 1000
+#define MAX_UDELAY_MS	1
+#elif HZ <= 200
+#define MAX_UDELAY_MS	5
+#else
+#define MAX_UDELAY_MS	(1000 / HZ)
+#endif
+
+#endif /* _ASM_DELAY_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/dma.h linux-2.6.30-test/arch/mips/include/asm/dma.h
--- linux-2.6.30-ori/arch/mips/include/asm/dma.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/dma.h	2009-06-12 18:32:43.000000000 -0400
@@ -87,6 +87,8 @@
 #if defined(CONFIG_SGI_IP22) || defined(CONFIG_SGI_IP28)
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
+#elif defined(CONFIG_TANGOX)
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x20000000)
 #else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/io.h linux-2.6.30-test/arch/mips/include/asm/io.h
--- linux-2.6.30-ori/arch/mips/include/asm/io.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/io.h	2009-06-12 18:32:43.000000000 -0400
@@ -337,6 +337,7 @@
 			local_irq_restore(__flags);			\
 	} else								\
 		BUG();							\
+	__sync();                                                       \
 }									\
 									\
 static inline type pfx##read##bwlq(const volatile void __iomem *mem)	\
@@ -388,6 +389,7 @@
 	BUILD_BUG_ON(sizeof(type) > sizeof(unsigned long));		\
 									\
 	*__addr = __val;						\
+	__sync();                                                       \
 	slow;								\
 }									\
 									\
@@ -534,6 +536,16 @@
 	memcpy((void __force *) dst, src, count);
 }
 
+/* Create a virtual mapping cookie for an IO port range */
+extern void __iomem *ioport_map(unsigned long port, unsigned int nr);
+extern void ioport_unmap(void __iomem *);
+
+/* Create a virtual mapping cookie for a PCI BAR (memory or IO) */
+struct pci_dev;
+extern void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long
+			       max);
+extern void pci_iounmap(struct pci_dev *dev, void __iomem *);
+
 /*
  * The caches on some architectures aren't dma-coherent and have need to
  * handle this in software.  There are three types of operations that
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/dma-coherence.h linux-2.6.30-test/arch/mips/include/asm/mach-tango2/dma-coherence.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/dma-coherence.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango2/dma-coherence.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,123 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2006  Ralf Baechle <ralf@linux-mips.org>
+ *
+ */
+#ifndef __ASM_MACH_TANGO2_DMA_COHERENCE_H
+#define __ASM_MACH_TANGO2_DMA_COHERENCE_H
+
+struct device;
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/hardware.h>
+#endif
+
+extern unsigned long g_pcimem_busaddr;
+extern unsigned long g_pcimem_physaddr;
+extern unsigned long g_pcimem_physaddr_end;
+
+#ifdef CONFIG_PCI
+#define IS_PCIDEV(x)	((x)->bus == &pci_bus_type)
+#else
+#define IS_PCIDEV(x)	0
+#endif
+
+
+#ifdef CONFIG_PCI
+static inline unsigned long __pci_virt_to_bus(unsigned long addr)
+{
+	if ((CPHYSADDR(addr) < g_pcimem_physaddr) ||
+	    (CPHYSADDR(addr) >= g_pcimem_physaddr_end))
+		printk("virt2bus: Not a dma-able address: 0x%08lx\n", addr);
+	return((unsigned long)(CPHYSADDR(addr) - g_pcimem_physaddr +
+			       g_pcimem_busaddr));
+}
+
+static inline unsigned long __pci_bus_to_virt(unsigned long addr)
+{
+	if ((addr < g_pcimem_busaddr) ||
+	    (addr >= (g_pcimem_busaddr +
+		      (g_pcimem_physaddr_end - g_pcimem_physaddr))))
+		printk("bus2virt: Not a valid bus address: 0x%08lx\n",
+		       addr);
+	return((unsigned long)(addr - g_pcimem_busaddr +
+			       g_pcimem_physaddr + UNCAC_BASE));
+}
+#else
+static inline unsigned long __pci_virt_to_bus(unsigned long addr)
+{
+	return(addr);
+}
+
+static inline unsigned long __pci_bus_to_virt(unsigned long addr)
+{
+	return(addr);
+}
+#endif
+
+static inline dma_addr_t plat_map_dma_mem(struct device *dev, void *addr,
+	size_t size)
+{
+		if (IS_PCIDEV(dev))
+			return __pci_virt_to_bus((unsigned long)addr);
+		else
+			return tangox_dma_address(CPHYSADDR(addr));
+}
+
+static dma_addr_t plat_map_dma_mem_page(struct device *dev, struct page *page)
+{
+	if (IS_PCIDEV(dev))
+		return __pci_virt_to_bus(page_to_phys(page));
+	return tangox_dma_address(page_to_phys(page));
+}
+
+/* This is almost certainly wrong but it's what dma-ip32.c used to use  */
+static unsigned long plat_dma_addr_to_phys(dma_addr_t dma_addr)
+{
+	if (IS_PCIDEV(dev)) {
+		return CAC_ADDR(__pci_bus_to_virt(dma_addr));
+	} else {
+		return tangox_inv_dma_address(dma_addr) + PAGE_OFFSET;
+	}
+}
+
+static inline void plat_unmap_dma_mem(struct device *dev, dma_addr_t dma_addr)
+{
+}
+
+static inline void plat_extra_sync_for_device(struct device *dev)
+{
+	return;
+}
+
+static inline int plat_dma_mapping_error(struct device *dev,
+					 dma_addr_t dma_addr)
+{
+	return 0;
+}
+
+static inline int plat_device_is_coherent(struct device *dev)
+{
+	return 0;
+}
+
+// TODO verify this
+static inline int plat_dma_supported(struct device *dev, u64 mask)
+{
+	/*
+	 * we fall back to GFP_DMA when the mask isn't all 1s,
+	 * so we can't guarantee allocations that must be
+	 * within a tighter range than GFP_DMA..
+	 */
+	if (mask < DMA_BIT_MASK(24))
+		return 0;
+
+	return 1;
+}
+
+#endif /* __ASM_MACH_TANGO2_DMA_COHERENCE_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/irq.h linux-2.6.30-test/arch/mips/include/asm/mach-tango2/irq.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/irq.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango2/irq.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,13 @@
+
+#ifndef __ASM_MACH_TANGO2_IRQ_H
+#define __ASM_MACH_TANGO2_IRQ_H
+
+#define MIPS_CPU_IRQ_BASE 0
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+# define NR_IRQS 256
+#else
+# define NR_IRQS 128
+#endif
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/param.h linux-2.6.30-test/arch/mips/include/asm/mach-tango2/param.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/param.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango2/param.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,11 @@
+
+#ifndef __ASM_MACH_TANGO2_PARAM_H
+#define __ASM_MACH_TANGO2_PARAM_H
+
+#ifndef CONFIG_TANGOX_HZ_VALUE
+#define HZ		1000
+#else
+#define HZ		CONFIG_TANGOX_HZ_VALUE
+#endif
+
+#endif /* __ASM_MACH_TANGO2_PARAM_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/spaces.h linux-2.6.30-test/arch/mips/include/asm/mach-tango2/spaces.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/spaces.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango2/spaces.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,33 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 Sigma Designs, Inc.
+ * Copyright (C) 1994 - 1999, 2000, 03, 04 Ralf Baechle
+ * Copyright (C) 2000, 2002  Maciej W. Rozycki
+ * Copyright (C) 1990, 1999, 2000 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_MACH_TANGO2_SPACES_H
+#define _ASM_MACH_TANGO2_SPACES_H
+
+#define PHYS_OFFSET             0x00000000
+#define CAC_BASE		0x90000000
+#define IO_BASE			0xa0000000
+#define UNCAC_BASE		0xa0000000
+#define MAP_BASE		0xc0000000
+
+/*
+ * This handles the memory map.
+ * We handle pages at KSEG0 for kernels with 32 bit address space.
+ */
+#define PAGE_OFFSET		0x80000000UL
+
+/*
+ * Memory above this physical address will be considered highmem.
+ */
+#ifndef HIGHMEM_START
+#define HIGHMEM_START		0x20000000UL
+#endif
+
+#endif /* __ASM_MACH_TANGO2_SPACES_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/war.h linux-2.6.30-test/arch/mips/include/asm/mach-tango2/war.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango2/war.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango2/war.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,25 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2002, 2004, 2007 by Ralf Baechle <ralf@linux-mips.org>
+ */
+#ifndef __ASM_MIPS_MACH_TANGO2_WAR_H
+#define __ASM_MIPS_MACH_TANGO2_WAR_H
+
+#define R4600_V1_INDEX_ICACHEOP_WAR	0
+#define R4600_V1_HIT_CACHEOP_WAR	0
+#define R4600_V2_HIT_CACHEOP_WAR	0
+#define R5432_CP0_INTERRUPT_WAR		0
+#define BCM1250_M3_WAR			0
+#define SIBYTE_1956_WAR			0
+#define MIPS4K_ICACHE_REFILL_WAR	0
+#define MIPS_CACHE_SYNC_WAR		0
+#define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
+#define ICACHE_REFILLS_WORKAROUND_WAR	0
+#define R10000_LLSC_WAR			0
+#define MIPS34K_MISSED_ITLB_WAR		0
+
+#endif /* __ASM_MIPS_MACH_TANGO2_WAR_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/irq.h linux-2.6.30-test/arch/mips/include/asm/mach-tango3/irq.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/irq.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango3/irq.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,9 @@
+
+#ifndef __ASM_MACH_TANGO3_IRQ_H
+#define __ASM_MACH_TANGO3_IRQ_H
+
+#include <linux/config.h>
+
+#define NR_IRQS 256
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/param.h linux-2.6.30-test/arch/mips/include/asm/mach-tango3/param.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/param.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango3/param.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,11 @@
+
+#ifndef __ASM_MACH_TANGO3_PARAM_H
+#define __ASM_MACH_TANGO3_PARAM_H
+
+#ifndef CONFIG_TANGOX_HZ_VALUE
+#define HZ		1000
+#else
+#define HZ		CONFIG_TANGOX_HZ_VALUE
+#endif
+
+#endif /* __ASM_MACH_TANGO3_PARAM_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/spaces.h linux-2.6.30-test/arch/mips/include/asm/mach-tango3/spaces.h
--- linux-2.6.30-ori/arch/mips/include/asm/mach-tango3/spaces.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/mach-tango3/spaces.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,34 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 Sigma Designs, Inc.
+ * Copyright (C) 1994 - 1999, 2000, 03, 04 Ralf Baechle
+ * Copyright (C) 2000, 2002  Maciej W. Rozycki
+ * Copyright (C) 1990, 1999, 2000 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_MACH_TANGO3_SPACES_H
+#define _ASM_MACH_TANGO3_SPACES_H
+
+#include <linux/config.h>
+
+#define CAC_BASE		0x90000000
+#define IO_BASE			0xa0000000
+#define UNCAC_BASE		0xa0000000
+#define MAP_BASE		0xc0000000
+
+/*
+ * This handles the memory map.
+ * We handle pages at KSEG0 for kernels with 32 bit address space.
+ */
+#define PAGE_OFFSET		0x80000000UL
+
+/*
+ * Memory above this physical address will be considered highmem.
+ */
+#ifndef HIGHMEM_START
+#define HIGHMEM_START		0x20000000UL
+#endif
+
+#endif /* __ASM_MACH_TANGO3_SPACES_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,65 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_dram.h
+  @brief  
+
+  fm stands for: first megabyte.
+
+  THE CODE USING THESE SYMBOLS ASSUMES THAT THE END BOUNDARY OF AN
+  ENTITY IS THE START BOUNDARY OF THE NEXT ENTITY
+  
+  htoinc.pl emhwlib_dram.h emhwlib_dram.inc
+  
+  @author Emmanuel Michon
+  @date   2004-07-26
+*/
+
+#ifndef __EMHWLIB_DRAM_H__
+#define __EMHWLIB_DRAM_H__
+
+#if EM86XX_CHIP>=EM86XX_CHIPID_TANGO2
+#include "emhwlib_dram_tango2.h"
+#else
+#include "emhwlib_dram_others.h"
+#endif
+
+#define MEMCFG_SIGNATURE	0x6766636d // `m' `c' `f' `g'
+
+#ifndef __ASSEMBLY__
+
+/* This is the memory map data structure, the size is 64 bytes */
+typedef struct {
+	unsigned int signature;                                                           // ...fc0
+	unsigned int dram0_size;            /* The size of DRAM0 */
+	unsigned int dram1_size;            /* The size of DRAM1 */
+	unsigned int dram2_size;            /* The size of DRAM2 */
+	unsigned int dram0_removable_topreserved;     /* The size of top reserved in DRAM0   ...fd0 */
+	unsigned int dram1_removable_topreserved;     /* The size of top reserved in DRAM1 */
+	unsigned int dram0_top_removable_area;    /* for special use such as splash screen */ 
+	                                          /* users can use set and get properties on the memory reserved by this variable */
+	unsigned int dram0_fixed_topreserved;     /* The size of top reserved in DRAM0 */
+	unsigned int dram1_fixed_topreserved;     /* The size of top reserved in DRAM1       ...fe0 */
+	unsigned int dram2_fixed_topreserved;     /* The size of top reserved in DRAM2 */
+	unsigned int kernel_end;            /* The end offset of kernel */
+	unsigned int checksum;		    /* The checksum */
+#if EM86XX_CHIP>=EM86XX_CHIPID_TANGO2
+	unsigned int dram1_kernel_end;	    /* The end offset of kernel used data in second dram */
+	unsigned int curtainA0;                                                      
+	unsigned int curtainB0;
+	unsigned int curtainC;
+#else
+	unsigned int reserved[4];           /* Reserved for extension */
+#endif
+} memcfg_t;
+
+#endif /* __ASSEMBLY__ */
+
+#endif // __EMHWLIB_DRAM_H__
+ 
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_others.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_others.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_others.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_others.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,37 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_dram_others.h
+  @brief  
+
+  Addresses appear in increasing order. It is assumed
+  that computing FM_IRQHANDLER_STACKTOP_USR-FM_IRQHANDLER_CODE
+  is a proper way to access the max usable size for
+  FM_IRQHANDLER_CODE.
+
+  @author Emmanuel Michon
+  @date   2005-04-11
+*/
+
+#ifndef __EMHWLIB_DRAM_OTHERS_H__
+#define __EMHWLIB_DRAM_OTHERS_H__
+
+#define FM_MEMCFG                  0x00000fc0
+#define FM_IRQHANDLER_API          0x00001000
+#define FM_IRQHANDLER_CODE         0x00011000
+#define FM_IRQHANDLER_STACKTOP_USR 0x00040000 /* defined, but never used */
+#define FM_IRQHANDLER_STACKTOP_IRQ 0x00048000
+#define FM_IRQHANDLER_STACKTOP_FIQ 0x00050000
+#define FM_STACKTOP_SVC            0x00058000
+#define FM_DRM			   0x00058000
+#define FM_GNET			   0x00058000 /* incompatible with DRM */
+#define FM_BOOTLOADER_CODE         0x00060000
+#define FM_RESERVED                0x00080000 /* The size reserved */
+
+#endif // __EMHWLIB_DRAM_OTHERS_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_others.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_others.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_others.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_others.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,25 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_dram_others.inc (generated from emhwlib/include/emhwlib_dram_others.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+FM_MEMCFG=0xfc0
+FM_IRQHANDLER_API=0x1000
+FM_IRQHANDLER_CODE=0x11000
+FM_IRQHANDLER_STACKTOP_USR=0x40000
+FM_IRQHANDLER_STACKTOP_IRQ=0x48000
+FM_IRQHANDLER_STACKTOP_FIQ=0x50000
+FM_STACKTOP_SVC=0x58000
+FM_DRM=0x58000
+FM_GNET=0x58000
+FM_BOOTLOADER_CODE=0x60000
+FM_RESERVED=0x80000
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_tango2.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_tango2.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_tango2.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_tango2.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,52 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_dram_tango2.h
+  @brief  
+
+  Addresses appear in increasing order. It is assumed that computing
+  FM_Y-FM_X is a proper way to access the max usable size for FM_X.
+
+  See SMP8630 software spec 3.3
+
+  @author Emmanuel Michon, YH Lin, Julien Soulier
+  @date   2005-04-06
+*/
+
+#ifndef __EMHWLIB_DRAM_TANGO2_H__
+#define __EMHWLIB_DRAM_TANGO2_H__
+
+/* Spec 3.3.5: stage (S4) [fully functional player memory map] */
+#define FM_GNET                    0x00000000
+#define FM_SCRATCH                 0x00000f08 /* 184 bytes */
+#define FM_MEMCFG                  0x00000fc0
+#define FM_IRQHANDLER_API          0x00001000
+#define FM_XTASK_API               0x00009e00 /* 512 bytes */
+#define FM_XOSDBG                  0x0000a000
+#define FM_XTASK1DBG               0x0000c000
+#define FM_XTASK2DBG               0x0000d000
+#define FM_XTASK3DBG               0x0000e000
+#define FM_XTASK4DBG               0x0000f000
+#define FM_SCRATCH2                0x00010000
+#define FM_DRAMCALIBRATION         0x0001f000
+#define FM_RESERVED                0x00020000
+
+/*
+  Spec 3.3.5: stage (S0) [bootstrap memory map]
+
+  Because you will use zboot/yamon to download linux/CE
+  at start of DRAM, the former are away from beginning.
+*/
+#define FM_ZBOOT                   0x01000000
+#define FM_YAMON_text_ram          0x01000000
+#define FM_YAMON__ftext_init       0x01200000
+#define FM_yamon_appl__ftext       0x01210000
+#define FM_linuxmips__ftext        0x00020000
+
+#endif // __EMHWLIB_DRAM_TANGO2_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_tango2.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_tango2.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_dram_tango2.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_dram_tango2.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,32 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_dram_tango2.inc (generated from emhwlib/include/emhwlib_dram_tango2.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+FM_GNET=0x0
+FM_SCRATCH=0xf08
+FM_MEMCFG=0xfc0
+FM_IRQHANDLER_API=0x1000
+FM_XTASK_API=0x9e00
+FM_XOSDBG=0xa000
+FM_XTASK1DBG=0xc000
+FM_XTASK2DBG=0xd000
+FM_XTASK3DBG=0xe000
+FM_XTASK4DBG=0xf000
+FM_SCRATCH2=0x10000
+FM_DRAMCALIBRATION=0x1f000
+FM_RESERVED=0x20000
+FM_ZBOOT=0x1000000
+FM_YAMON_text_ram=0x1000000
+FM_YAMON__ftext_init=0x1200000
+FM_yamon_appl__ftext=0x1210000
+FM_linuxmips__ftext=0x20000
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,46 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Emmanuel Michon
+  @date   2005-03-17
+*/
+
+#ifndef __EMHWLIB_LRAM_H__
+#define __EMHWLIB_LRAM_H__
+
+#if (EM86XX_CHIP<EM86XX_CHIPID_TANGO3)
+#include "emhwlib_lram_others.h"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO3)
+#include "emhwlib_lram_tango3.h"
+#else
+#error EM86XX_CHIP is not set in RMCFLAGS: refer to rmdef/rmem86xxid.h. 
+#endif
+
+#endif // __EMHWLIB_LRAM_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,41 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram.inc (generated from emhwlib_hal/include/emhwlib_lram.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x1800
+LR_PCI_INTERRUPT_ENABLE=0x19ac
+LR_HOST_INTERRUPT_STATUS=0x19b0
+LR_DRAM_DMA_SUSPEND=0x19b4
+LR_SUSPEND_ACK_MPEG0=0x19b8
+LR_SUSPEND_ACK_MPEG1=0x19bc
+LR_SUSPEND_ACK_AUDIO0=0x19c0
+LR_SUSPEND_ACK_AUDIO1=0x19c4
+LR_SUSPEND_ACK_DEMUX=0x19c8
+LR_SUSPEND_ACK_IH=0x19cc
+LR_HB_IH=0x19d0
+LR_HB_HOST=0x19d4
+LR_HB_CPU=0x19d8
+LR_HB_MPEG0=0x19dc
+LR_HB_MPEG1=0x19e0
+LR_HB_AUDIO0=0x19e4
+LR_HB_AUDIO1=0x19e8
+LR_HB_DEMUX=0x19ec
+LR_HB_XPU=0x19f0
+LR_HB_VSYNC=0x19f4
+LR_SW_VAL_VSYNC_COUNT=0x19f8
+LR_SW_VAL_PIXEL_ADDR=0x19fc
+LR_XENV2_RW=0x1a00
+LR_XENV2_RO=0x1d00
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_others.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_others.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_others.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_others.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,98 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram_others.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Sebastien Beysserie
+  @date   2007-06-26
+*/
+
+#ifndef __EMHWLIB_LRAM_OTHERS_H__
+#define __EMHWLIB_LRAM_OTHERS_H__
+
+#define LR_CPU_IDLELOOP          0x00000000 /* CPU uses 0x80 bytes, up to 0x0080 */
+#define LR_UCLINUX_END           0x00000100
+
+#define LR_VSYNC_STRUCT          0x00000200 /* 2KB of data structures */
+#define LR_VSYNC_CODE            0x00000a00 /* 2KB of code */
+#define LR_VSYNC_END             0x00001200
+
+#define LR_STACKTOP              0x000017F4 /* in case a bootstrap routine needs a stack in local ram. Use this boundary */
+
+#define LR_PCI_INTERRUPT_ENABLE  0x000017F4
+#define LR_HOST_INTERRUPT_STATUS 0x000017F8
+#define LR_CPU_BRU_JUMP          0x000017FC /* `bootrom_ucos jump' (debug purpose) */
+
+#define LR_MU_PROFILE_STATUS     0x00001800
+
+#define LR_DRAM_DMA_SUSPEND               0x00001c8c
+#define LR_SUSPEND_ACK_MPEG0              0x00001c90
+#define LR_SUSPEND_ACK_MPEG1              0x00001c94
+#define LR_SUSPEND_ACK_AUDIO0             0x00001c98
+#define LR_SUSPEND_ACK_AUDIO1             0x00001c9c
+#define LR_SUSPEND_ACK_DEMUX              0x00001ca0
+#define LR_SUSPEND_ACK_IH                 0x00001ca4
+
+#define LR_HB_IH                 0x00001ca8
+
+#define LR_IH_LOG_FIFO           0x00001cac /* in some cases (splash screen) find the location of the log_fifo is not that easy. Read it here. */
+
+#define LR_HB_HOST               0x00001cb0
+#define LR_HB_CPU                0x00001cb4
+#define LR_HB_MPEG0              0x00001cb8
+#define LR_HB_MPEG1              0x00001cbc
+#define LR_HB_AUDIO0             0x00001cc0
+#define LR_HB_AUDIO1             0x00001cc4
+#define LR_HB_DEMUX              0x00001cc8
+#define LR_HB_XPU                0x00001ccc
+
+#define LR_IDMA                  0x00001cd0 /* 16bytes. Obsoletizes LR_HMMAD */
+
+#define LR_ETH_MAC_LO            0x00001ce0 /* Ethernet MAC addr low 4 bytes */
+#define LR_ETH_MAC_HI            0x00001ce4 /* Ethernet MAC addr high bytes */
+#define LR_HB_VSYNC              0x00001ce8
+ 
+#define LR_SW_VAL_VSYNC_COUNT    0x00001cec /* this location is used to count captured VSYNC */
+#define LR_SW_VAL_PIXEL_ADDR     0x00001cf0 /* this location is used to store a pixel address to write the frame count */
+
+#define LR_HMMAD                 0x00001cf4
+#define LR_KEY_ZONE              0x00001D00 /* 0x200 bytes, up to 0x1F00 */
+#define LR_YAMON_DIGITS          0x00001F00
+#define LR_XPU_DUMP              0x00001F00 /* 0x80 bytes, up to 0x1F80 */
+
+#define LR_VSYNC_PERIOD          0x00001FA0 /* 0x20 bytes, up to 0x1FC0 */
+
+#define LR_RANDOM_SEED           0x00001FC8 /* 0x08 bytes, up to 0x1FD0 */
+#define LR_LOCAL_DEBUG_PROBE     0x00001FD0 /* 0x20 bytes, up to 0x1FF0 */
+
+#define LR_XENV_LOCATION         0x00001FF0 /* Location of XENV, found by XOS */
+#define LR_GNET_MAC              0x00001FF4
+#define LR_ZBOOT_STAGE           0x00001FF8
+#define LR_XPU_STAGE             0x00001FFC
+
+#endif // __EMHWLIB_LRAM_OTHERS_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_others.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_others.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_others.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_others.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,58 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram_others.inc (generated from emhwlib_hal/include/emhwlib_lram_others.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_CPU_IDLELOOP=0x0
+LR_UCLINUX_END=0x100
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x17f4
+LR_PCI_INTERRUPT_ENABLE=0x17f4
+LR_HOST_INTERRUPT_STATUS=0x17f8
+LR_CPU_BRU_JUMP=0x17fc
+LR_MU_PROFILE_STATUS=0x1800
+LR_DRAM_DMA_SUSPEND=0x1c8c
+LR_SUSPEND_ACK_MPEG0=0x1c90
+LR_SUSPEND_ACK_MPEG1=0x1c94
+LR_SUSPEND_ACK_AUDIO0=0x1c98
+LR_SUSPEND_ACK_AUDIO1=0x1c9c
+LR_SUSPEND_ACK_DEMUX=0x1ca0
+LR_SUSPEND_ACK_IH=0x1ca4
+LR_HB_IH=0x1ca8
+LR_IH_LOG_FIFO=0x1cac
+LR_HB_HOST=0x1cb0
+LR_HB_CPU=0x1cb4
+LR_HB_MPEG0=0x1cb8
+LR_HB_MPEG1=0x1cbc
+LR_HB_AUDIO0=0x1cc0
+LR_HB_AUDIO1=0x1cc4
+LR_HB_DEMUX=0x1cc8
+LR_HB_XPU=0x1ccc
+LR_IDMA=0x1cd0
+LR_ETH_MAC_LO=0x1ce0
+LR_ETH_MAC_HI=0x1ce4
+LR_HB_VSYNC=0x1ce8
+LR_SW_VAL_VSYNC_COUNT=0x1cec
+LR_SW_VAL_PIXEL_ADDR=0x1cf0
+LR_HMMAD=0x1cf4
+LR_KEY_ZONE=0x1d00
+LR_YAMON_DIGITS=0x1f00
+LR_XPU_DUMP=0x1f00
+LR_VSYNC_PERIOD=0x1fa0
+LR_RANDOM_SEED=0x1fc8
+LR_LOCAL_DEBUG_PROBE=0x1fd0
+LR_XENV_LOCATION=0x1ff0
+LR_GNET_MAC=0x1ff4
+LR_ZBOOT_STAGE=0x1ff8
+LR_XPU_STAGE=0x1ffc
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_tango3.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,76 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram_tango3.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Sebastien Beysserie
+  @date   2007-06-26
+*/
+
+#ifndef __EMHWLIB_LRAM_TANGO3_H__
+#define __EMHWLIB_LRAM_TANGO3_H__
+
+/* Julien to clarify --- em07may31 */
+#define LR_VSYNC_STRUCT          0x00000200 /* 2KB of data structures */
+#define LR_VSYNC_CODE            0x00000a00 /* 2KB of code */
+#define LR_VSYNC_END             0x00001200
+
+/* as long as the value of this symbol moves only up with time, backward compatibility is ok */
+#define LR_STACKTOP              0x00001800
+
+/*
+  range from LR_STACKTOP to the first of the below block is 
+  reserved for future use (~100 slots)
+ */
+#define LR_PCI_INTERRUPT_ENABLE  0x000019ac
+#define LR_HOST_INTERRUPT_STATUS 0x000019b0
+#define LR_DRAM_DMA_SUSPEND      0x000019b4
+#define LR_SUSPEND_ACK_MPEG0     0x000019b8
+#define LR_SUSPEND_ACK_MPEG1     0x000019bc
+#define LR_SUSPEND_ACK_AUDIO0    0x000019c0
+#define LR_SUSPEND_ACK_AUDIO1    0x000019c4
+#define LR_SUSPEND_ACK_DEMUX     0x000019c8
+#define LR_SUSPEND_ACK_IH        0x000019cc
+#define LR_HB_IH                 0x000019d0
+#define LR_HB_HOST               0x000019d4
+#define LR_HB_CPU                0x000019d8
+#define LR_HB_MPEG0              0x000019dc
+#define LR_HB_MPEG1              0x000019e0
+#define LR_HB_AUDIO0             0x000019e4
+#define LR_HB_AUDIO1             0x000019e8
+#define LR_HB_DEMUX              0x000019ec
+#define LR_HB_XPU                0x000019f0
+#define LR_HB_VSYNC              0x000019f4
+#define LR_SW_VAL_VSYNC_COUNT    0x000019f8 /* this location is used to count captured VSYNC */
+#define LR_SW_VAL_PIXEL_ADDR     0x000019fc /* this location is used to store a pixel address to write the frame count */
+
+#define LR_XENV2_RW              0x00001a00 /* up to 768 bytes */
+
+#define LR_XENV2_RO              0x00001d00 /* up to the end, 768 bytes. This area is written by xpu, r.o. for others */
+
+#endif // __EMHWLIB_LRAM_TANGO3_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_tango3.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_tango3.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_lram_tango3.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_lram_tango3.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,41 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram_tango3.inc (generated from emhwlib_hal/include/emhwlib_lram_tango3.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x1800
+LR_PCI_INTERRUPT_ENABLE=0x19ac
+LR_HOST_INTERRUPT_STATUS=0x19b0
+LR_DRAM_DMA_SUSPEND=0x19b4
+LR_SUSPEND_ACK_MPEG0=0x19b8
+LR_SUSPEND_ACK_MPEG1=0x19bc
+LR_SUSPEND_ACK_AUDIO0=0x19c0
+LR_SUSPEND_ACK_AUDIO1=0x19c4
+LR_SUSPEND_ACK_DEMUX=0x19c8
+LR_SUSPEND_ACK_IH=0x19cc
+LR_HB_IH=0x19d0
+LR_HB_HOST=0x19d4
+LR_HB_CPU=0x19d8
+LR_HB_MPEG0=0x19dc
+LR_HB_MPEG1=0x19e0
+LR_HB_AUDIO0=0x19e4
+LR_HB_AUDIO1=0x19e8
+LR_HB_DEMUX=0x19ec
+LR_HB_XPU=0x19f0
+LR_HB_VSYNC=0x19f4
+LR_SW_VAL_VSYNC_COUNT=0x19f8
+LR_SW_VAL_PIXEL_ADDR=0x19fc
+LR_XENV2_RW=0x1a00
+LR_XENV2_RO=0x1d00
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_registers_tango2.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_registers_tango2.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_registers_tango2.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_registers_tango2.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,675 @@
+/******************************************************/
+/* This file is generated automatically, DO NOT EDIT! */
+/******************************************************/
+/*
+ * ../emhwlib_hal/include/tango2/emhwlib_registers_tango2.h
+ *
+ * Copyright (C) 2001-2007 Sigma Designs, Inc. 
+ * All Rights Reserved. 
+ *
+ */
+ 
+/**
+  @file ../emhwlib_hal/include/tango2/emhwlib_registers_tango2.h
+  @brief emhwlib generated file
+   
+  @author Jacques Mahe, Christian Wolff, Julien Soulier, Emmanuel Michon
+  @ingroup hwlproperties
+*/
+
+#ifndef __EMHWLIB_REGISTERS_TANGO2_H__
+#define __EMHWLIB_REGISTERS_TANGO2_H__
+
+/* SystemBlock registers */
+#define REG_BASE_system_block 0x00010000 /* width RMuint32 */
+#define SYS_clkgen0_pll 0x0000 /* width RMuint32 */
+#define SYS_clkgen0_div 0x0004 /* width RMuint32 */
+#define SYS_clkgen1_pll 0x0008 /* width RMuint32 */
+#define SYS_clkgen1_div 0x000C /* width RMuint32 */
+#define SYS_clkgen2_pll 0x0010 /* width RMuint32 */
+#define SYS_clkgen2_div 0x0014 /* width RMuint32 */
+#define SYS_clkgen3_pll 0x0018 /* width RMuint32 */
+#define SYS_clkgen3_div 0x001C /* width RMuint32 */
+#define SYS_avclk_mux 0x0038 /* width RMuint32 */
+#define SYS_sysclk_mux 0x003C /* width RMuint32 */
+#define SYS_clk_cnt 0x0040 /* width RMuint32 */
+#define SYS_xtal_in_cnt 0x0048 /* width RMuint32 */
+#define DRAM_vbus_w0_cfg 0x0300 /* width RMuint32 */
+#define DRAM_vbus_w1_cfg 0x0304 /* width RMuint32 */
+#define DRAM_vbus_w2_cfg 0x0308 /* width RMuint32 */
+#define DRAM_vbus_w3_cfg 0x030c /* width RMuint32 */
+#define DRAM_vbus_r0_cfg 0x0340 /* width RMuint32 */
+#define DRAM_vbus_r1_cfg 0x0344 /* width RMuint32 */
+#define DRAM_vbus_r2_cfg 0x0348 /* width RMuint32 */
+#define DRAM_vbus_r3_cfg 0x034c /* width RMuint32 */
+#define DRAM_vbus_r4_cfg 0x0350 /* width RMuint32 */
+#define DRAM_vbus_r5_cfg 0x0354 /* width RMuint32 */
+#define DRAM_vbus_r6_cfg 0x0358 /* width RMuint32 */
+#define DRAM_vbus_r7_cfg 0x035c /* width RMuint32 */
+#define DRAM_vbus_r8_cfg 0x0360 /* width RMuint32 */
+#define DRAM_vbus_r9_cfg 0x0364 /* width RMuint32 */
+#define DRAM_vbus_r10_cfg 0x0368 /* width RMuint32 */
+#define DRAM_vbus_r11_cfg 0x036c /* width RMuint32 */
+#define DRAM_mbus_w0_cfg 0x0200 /* width RMuint32 */
+#define DRAM_mbus_w1_cfg 0x0204 /* width RMuint32 */
+#define DRAM_mbus_w2_cfg 0x0208 /* width RMuint32 */
+#define DRAM_mbus_w3_cfg 0x020c /* width RMuint32 */
+#define DRAM_mbus_w4_cfg 0x0210 /* width RMuint32 */
+#define DRAM_mbus_w5_cfg 0x0214 /* width RMuint32 */
+#define DRAM_mbus_w6_cfg 0x0218 /* width RMuint32 */
+#define DRAM_mbus_w7_cfg 0x021c /* width RMuint32 */
+#define DRAM_mbus_w8_cfg 0x0220 /* width RMuint32 */
+#define DRAM_mbus_w9_cfg 0x0224 /* width RMuint32 */
+#define DRAM_mbus_w10_cfg 0x0228 /* width RMuint32 */
+#define DRAM_mbus_r0_cfg 0x0240 /* width RMuint32 */
+#define DRAM_mbus_r1_cfg 0x0244 /* width RMuint32 */
+#define DRAM_mbus_r2_cfg 0x0248 /* width RMuint32 */
+#define DRAM_mbus_r3_cfg 0x024c /* width RMuint32 */
+#define DRAM_mbus_r4_cfg 0x0250 /* width RMuint32 */
+#define DRAM_mbus_r5_cfg 0x0254 /* width RMuint32 */
+#define DRAM_mbus_r6_cfg 0x0258 /* width RMuint32 */
+#define DRAM_mbus_r7_cfg 0x025c /* width RMuint32 */
+#define DRAM_mbus_r8_cfg 0x0260 /* width RMuint32 */
+#define DRAM_mbus_r9_cfg 0x0264 /* width RMuint32 */
+#define DRAM_mbus_r10_cfg 0x0268 /* width RMuint32 */
+#define SYS_hostclk_mux 0x0030 /* width RMuint32 */
+#define SYS_sysclk_premux 0x0034 /* width RMuint32 */
+#define SYS_rnd_cnt 0x0044 /* width RMuint32 */
+#define SYS_cnt_cfg 0x004c /* width RMuint32 */
+#define SYS_cfg_cnt0 0x0050 /* width RMuint32 */
+#define SYS_cfg_cnt1 0x0054 /* width RMuint32 */
+#define SYS_cfg_cnt2 0x0058 /* width RMuint32 */
+#define SYS_cfg_cnt3 0x005c /* width RMuint32 */
+#define SYS_cfg_cnt4 0x0060 /* width RMuint32 */
+#define SYS_cleandiv0_div 0x0080 /* width RMuint32 */
+#define SYS_cleandiv1_div 0x0088 /* width RMuint32 */
+#define SYS_cleandiv2_div 0x0090 /* width RMuint32 */
+#define SYS_cleandiv3_div 0x0098 /* width RMuint32 */
+#define SYS_cleandiv4_div 0x00a0 /* width RMuint32 */
+#define SYS_cleandiv5_div 0x00a8 /* width RMuint32 */
+#define SYS_cleandiv6_div 0x00b0 /* width RMuint32 */
+#define SYS_cleandiv7_div 0x00b8 /* width RMuint32 */
+#define SYS_cleandiv8_div 0x00c0 /* width RMuint32 */
+#define SYS_cleandiv9_div 0x00c8 /* width RMuint32 */
+#define SYS_cleandiv10_div 0x00d0 /* width RMuint32 */
+#define MARB_mid01_cfg 0x0200 /* width RMuint32 */
+#define MARB_mid21_cfg 0x0204 /* width RMuint32 */
+#define MARB_mid02_cfg 0x0208 /* width RMuint32 */
+#define MARB_mid22_cfg 0x020c /* width RMuint32 */
+#define MARB_mid04_cfg 0x0210 /* width RMuint32 */
+#define MARB_mid24_cfg 0x0214 /* width RMuint32 */
+#define MARB_mid25_cfg 0x0218 /* width RMuint32 */
+#define MARB_mid08_cfg 0x021c /* width RMuint32 */
+#define MARB_mid28_cfg 0x0220 /* width RMuint32 */
+#define MARB_mid29_cfg 0x0224 /* width RMuint32 */
+#define MARB_mid0C_cfg 0x0228 /* width RMuint32 */
+#define MARB_mid2C_cfg 0x022c /* width RMuint32 */
+#define MARB_mid10_cfg 0x0230 /* width RMuint32 */
+#define MARB_mid30_cfg 0x0234 /* width RMuint32 */
+#define MARB_mid31_cfg 0x0238 /* width RMuint32 */
+#define MARB_mid12_cfg 0x023c /* width RMuint32 */
+#define MARB_mid32_cfg 0x0240 /* width RMuint32 */
+#define VARB_mid01_cfg 0x0300 /* width RMuint32 */
+#define VARB_mid02_cfg 0x0304 /* width RMuint32 */
+#define VARB_mid21_cfg 0x0308 /* width RMuint32 */
+#define VARB_mid22_cfg 0x030c /* width RMuint32 */
+#define VARB_mid23_cfg 0x0310 /* width RMuint32 */
+#define VARB_mid24_cfg 0x0314 /* width RMuint32 */
+#define VARB_mid25_cfg 0x0318 /* width RMuint32 */
+#define VARB_mid26_cfg 0x031c /* width RMuint32 */
+#define VARB_mid27_cfg 0x0320 /* width RMuint32 */
+#define VARB_mid28_cfg 0x0324 /* width RMuint32 */
+#define VARB_mid29_cfg 0x0328 /* width RMuint32 */
+#define VARB_mid2A_cfg 0x032c /* width RMuint32 */
+#define VARB_mid10_cfg 0x0330 /* width RMuint32 */
+#define VARB_mid30_cfg 0x0334 /* width RMuint32 */
+#define VARB_mid31_cfg 0x0338 /* width RMuint32 */
+#define VARB_mid03_cfg 0x033c /* width RMuint32 */
+#define IARB_mid01_cfg 0x0400 /* width RMuint32 */
+#define IARB_mid02_cfg 0x0404 /* width RMuint32 */
+#define SYS_gpio_dir 0x0500 /* width RMuint32 */
+#define SYS_gpio_data 0x0504 /* width RMuint32 */
+#define SYS_gpio_int 0x0508 /* width RMuint32 */
+#define SYS_gpio15_pwm 0x0510 /* width RMuint32 */
+#define SYS_gpio14_pwm 0x0514 /* width RMuint32 */
+#define REG_BASE_dram_controller_0 0x00030000 /* width RMuint32 */
+#define REG_BASE_dram_controller_1 0x00040000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_0_alias 0x10000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_0 0x10000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_1_alias 0x20000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_1 0x20000000 /* width RMuint32 */
+#define DRAM_dunit_cfg 0x0000 /* width RMuint32 */
+#define DRAM_dunit_delay0_ctrl 0x0004 /* width RMuint32 */
+#define DRAM_dunit_delay1_ctrl 0x0008 /* width RMuint32 */
+#define DRAM_dunit_auto_delay 0x000c /* width RMuint32 */
+#define DRAM_dunit_fall_delay0 0x0010 /* width RMuint32 */
+#define DRAM_dunit_fall_delay1 0x0014 /* width RMuint32 */
+#define DRAM_dunit_bw_lobound 0x0018 /* width RMuint32 */
+#define DRAM_dunit_bw_hibound 0x001c /* width RMuint32 */
+#define DRAM_dunit_bw_probe_cfg 0x0020 /* width RMuint32 */
+#define DRAM_dunit_bw_probe_cnt 0x0024 /* width RMuint32 */
+#define DRAM_dunit_bw_cntall 0x0028 /* width RMuint32 */
+#define DRAM_dunit_calibration_delay 0x0030 /* width RMuint32 */
+#define DRAM_dunit_calibration_rise_err 0x0034 /* width RMuint32 */
+#define DRAM_dunit_calibration_fall_err 0x0038 /* width RMuint32 */
+#define DRAM_dunit_calibration_page 0x0088 /* width RMuint32 */
+#define DRAM_dunit_flush_buffer 0x0104 /* width RMuint32 */
+#define REG_BASE_host_interface 0x00020000 /* width RMuint32 */
+#define MEM_BASE_host_interface 0x40000000 /* width RMuint32 */
+#define IDE_data 0x0000 /* width RMuint32 */
+#define IDE_error 0x0004 /* width RMuint32 */
+#define IDE_count 0x0008 /* width RMuint32 */
+#define IDE_start_sector 0x000c /* width RMuint32 */
+#define IDE_cylinder_lo 0x0010 /* width RMuint32 */
+#define IDE_cylinder_hi 0x0014 /* width RMuint32 */
+#define IDE_head_device 0x0018 /* width RMuint32 */
+#define IDE_cmd_stat 0x001c /* width RMuint32 */
+#define IDE_irq_stat 0x0218 /* width RMuint32 */
+#define IDE_cmd_stat__ 0x021c /* width RMuint32 */
+#define PB_timing0 0x0800 /* width RMuint32 */
+#define PB_timing1 0x0804 /* width RMuint32 */
+#define PB_timing2 0x0808 /* width RMuint32 */
+#define PB_timing3 0x080c /* width RMuint32 */
+#define PB_timing4 0x0810 /* width RMuint32 */
+#define PB_timing5 0x0814 /* width RMuint32 */
+#define PB_default_timing 0x0818 /* width RMuint32 */
+#define PB_use_timing0 0x081c /* width RMuint32 */
+#define PB_use_timing1 0x0820 /* width RMuint32 */
+#define PB_use_timing2 0x0824 /* width RMuint32 */
+#define PB_use_timing3 0x0828 /* width RMuint32 */
+#define PB_use_timing4 0x082c /* width RMuint32 */
+#define PB_use_timing5 0x0830 /* width RMuint32 */
+#define PB_CS_config 0x0834 /* width RMuint32 */
+#define PB_automode_start_address 0x0840 /* width RMuint32 */
+#define PB_automode_control 0x0844 /* width RMuint32 */
+#define EMHWLIB_IS_HOST 0xe000 /* width RMuint32 */
+#define HOST_REG1 0xfed0 /* width RMuint32 */
+#define HOST_REG2 0xfed4 /* width RMuint32 */
+#define READ_ADDRESS 0xfec0 /* width RMuint32 */
+#define READ_COUNTER 0xfec4 /* width RMuint32 */
+#define READ_ENABLE 0xfec8 /* width RMuint32 */
+#define REV_ORDER 0xfecc /* width RMuint32 */
+#define WRITE_ADDRESS 0xfed8 /* width RMuint32 */
+#define WRITE_COUNTER 0xfedc /* width RMuint32 */
+#define WRITE_ENABLE 0xfee0 /* width RMuint32 */
+#define BURST 0xfee4 /* width RMuint32 */
+#define PCI_TIMEOUT 0x8000 /* width RMuint32 */
+#define PCI_TIMEOUT_STATUS 0x8004 /* width RMuint32 */
+#define PCI_TIMER 0x8008 /* width RMuint32 */
+#define PCI_TIMER_TEST 0x800c /* width RMuint32 */
+#define PCI_WAKEUP 0x8010 /* width RMuint32 */
+#define PCI_REGION_0_BASE 0x9000 /* width RMuint32 */
+#define PCI_REGION_1_BASE 0x9004 /* width RMuint32 */
+#define PCI_REGION_2_BASE 0x9008 /* width RMuint32 */
+#define PCI_REGION_3_BASE 0x900c /* width RMuint32 */
+#define PCI_REGION_4_BASE 0x9010 /* width RMuint32 */
+#define PCI_REGION_5_BASE 0x9014 /* width RMuint32 */
+#define PCI_REGION_6_BASE 0x9018 /* width RMuint32 */
+#define PCI_REGION_7_BASE 0x901c /* width RMuint32 */
+#define PCI_irq_status 0x9020 /* width RMuint32 */
+#define PCI_irq_set 0x9024 /* width RMuint32 */
+#define PCI_irq_clear 0x9028 /* width RMuint32 */
+#define SBOX_FIFO_RESET 0x90a0 /* width RMuint32 */
+#define SBOX_ROUTE 0x90a8 /* width RMuint32 */
+#define output_SBOX_MBUS_W0 0x9080 /* width RMuint32 */
+#define output_SBOX_MBUS_W1 0x9084 /* width RMuint32 */
+#define output_SBOX_PCI_MASTER 0x9088 /* width RMuint32 */
+#define output_SBOX_PCI_SLAVE 0x908c /* width RMuint32 */
+#define output_SBOX_CIPHER 0x9090 /* width RMuint32 */
+#define output_SBOX_IDE_ISA 0x9094 /* width RMuint32 */
+#define output_SBOX_IDE_DVD 0x9098 /* width RMuint32 */
+#define input_keep_SBOX 0 /* width RMuint32 */
+#define input_MBUS_R0_SBOX 1 /* width RMuint32 */
+#define input_MBUS_R1_SBOX 2 /* width RMuint32 */
+#define input_PCI_MASTER_SBOX 3 /* width RMuint32 */
+#define input_PCI_SLAVE_SBOX 4 /* width RMuint32 */
+#define input_CIPHER_SBOX 5 /* width RMuint32 */
+#define input_IDE_DVD_SBOX 6 /* width RMuint32 */
+#define input_IDE_ISA_SBOX 7 /* width RMuint32 */
+#define input_SFLA_SBOX 8 /* width RMuint32 */
+#define input_unconnected_SBOX 0xf /* width RMuint32 */
+#define host_mutex0 0x9040 /* width RMuint32 */
+#define host_mutex1 0x9044 /* width RMuint32 */
+#define host_mutex2 0x9048 /* width RMuint32 */
+#define host_mutex3 0x904c /* width RMuint32 */
+#define host_mutex4 0x9050 /* width RMuint32 */
+#define host_mutex5 0x9054 /* width RMuint32 */
+#define host_mutex6 0x9058 /* width RMuint32 */
+#define host_mutex7 0x905c /* width RMuint32 */
+#define host_mutex8 0x9060 /* width RMuint32 */
+#define host_mutex9 0x9064 /* width RMuint32 */
+#define host_mutex10 0x9068 /* width RMuint32 */
+#define host_mutex11 0x906c /* width RMuint32 */
+#define host_mutex12 0x9070 /* width RMuint32 */
+#define host_mutex13 0x9074 /* width RMuint32 */
+#define host_mutex14 0x9078 /* width RMuint32 */
+#define host_mutex15 0x907c /* width RMuint32 */
+#define PCI_host_reg5 0xfe94 /* width RMuint32 */
+#define PCI_chip_is_host 0xfe90 /* width RMuint32 */
+#define IDECTRL_idesrc 0x20d0 /* width RMuint32 */
+#define IDECTRL_pri_drv1udmatim1 0x20e0 /* width RMuint32 */
+#define IDECTRL_pri_drv1udmatim2 0x20f0 /* width RMuint32 */
+#define IDECTRL_pri_idectl 0x2100 /* width RMuint32 */
+#define IDECTRL_pri_drv0tim 0x2110 /* width RMuint32 */
+#define IDECTRL_pri_drv1tim 0x2120 /* width RMuint32 */
+#define IDECTRL_idemisc 0x2130 /* width RMuint32 */
+#define IDECTRL_idestatus 0x2140 /* width RMuint32 */
+#define IDECTRL_udmactl 0x2150 /* width RMuint32 */
+#define IDECTRL_pri_drv0udmatim1 0x2160 /* width RMuint32 */
+#define IDECTRL_pri_drv0udmatim2 0x2170 /* width RMuint32 */
+#define IDECTRL_pref_st 0x2310 /* width RMuint32 */
+#define IDECTRL_pri_ctrlblock 0x2398 /* width RMuint32 */
+#define IDECTRL_pri_cmdblock 0x23c0 /* width RMuint32 */
+#define IDECTRL_bmic 0x2400 /* width RMuint32 */
+#define IDECTRL_bmis 0x2410 /* width RMuint32 */
+#define IDECTRL_bmidtp 0x2420 /* width RMuint32 */
+#define IDECTRL_ide_dmaptr 0x2780 /* width RMuint32 */
+#define IDECTRL_ide_dmalen 0x2790 /* width RMuint32 */
+#define IDECTRL_pio_prefetch_data 0x27c0 /* width RMuint32 */
+#define MEM_BASE_pfla 0x40000000 /* width RMuint32 */
+#define PB_CS0_OFFSET 0x00000000 /* width RMuint32 */
+#define PB_CS1_OFFSET 0x04000000 /* width RMuint32 */
+#define PB_CS2_OFFSET 0x08000000 /* width RMuint32 */
+#define PB_CS3_OFFSET 0x0c000000 /* width RMuint32 */
+#define ETH_gpio_dir1 0x7100 /* width RMuint32 */
+#define ETH_gpio_data1 0x7104 /* width RMuint32 */
+#define ETH_gpio_mask1 0x7108 /* width RMuint32 */
+#define ETH_gpio_dir2 0x710c /* width RMuint32 */
+#define ETH_gpio_data2 0x7110 /* width RMuint32 */
+#define PCI_host_reg1 0xfed0 /* width RMuint32 */
+#define PCI_host_reg2 0xfed4 /* width RMuint32 */
+#define PCI_host_reg3 0xfe80 /* width RMuint32 */
+#define PCI_host_reg4 0xfe84 /* width RMuint32 */
+#define PCI_pcictrl_reg1 0xfe88 /* width RMuint32 */
+#define PCI_pcictrl_reg2 0xfe8c /* width RMuint32 */
+#define PCI_pcictrl_reg3 0xfefc /* width RMuint32 */
+#define PCI_REG0 0xfee8 /* width RMuint32 */
+#define PCI_REG1 0xfeec /* width RMuint32 */
+#define PCI_REG2 0xfef0 /* width RMuint32 */
+#define PCI_REG3 0xfef4 /* width RMuint32 */
+#define PCI_CONFIG 0xfef8 /* width RMuint32 */
+#define MIF_W0_ADD 0xb000 /* width RMuint32 */
+#define MIF_W0_CNT 0xb004 /* width RMuint32 */
+#define MIF_W0_SKIP 0xb008 /* width RMuint32 */
+#define MIF_W0_CMD 0xb00c /* width RMuint32 */
+#define MIF_W1_ADD 0xb040 /* width RMuint32 */
+#define MIF_W1_CNT 0xb044 /* width RMuint32 */
+#define MIF_W1_SKIP 0xb048 /* width RMuint32 */
+#define MIF_W1_CMD 0xb04c /* width RMuint32 */
+#define MIF_R0_ADD 0xb080 /* width RMuint32 */
+#define MIF_R0_CNT 0xb084 /* width RMuint32 */
+#define MIF_R0_SKIP 0xb088 /* width RMuint32 */
+#define MIF_R0_CMD 0xb08c /* width RMuint32 */
+#define MIF_R1_ADD 0xb0c0 /* width RMuint32 */
+#define MIF_R1_CNT 0xb0c4 /* width RMuint32 */
+#define MIF_R1_SKIP 0xb0c8 /* width RMuint32 */
+#define MIF_R1_CMD 0xb0cc /* width RMuint32 */
+#define MBUS_IDLE 0 /* width RMuint32 */
+#define MBUS_LINEAR 1 /* width RMuint32 */
+#define MBUS_DOUBLE 2 /* width RMuint32 */
+#define MBUS_RECTANGLE 3 /* width RMuint32 */
+#define MBUS_VOID 4 /* width RMuint32 */
+#define MBUS_LINEAR_VOID 5 /* width RMuint32 */
+#define MBUS_DOUBLE_VOID 6 /* width RMuint32 */
+#define MBUS_RECTANGLE_VOID 7 /* width RMuint32 */
+#define MBUS_TILED 8 /* width RMuint32 */
+#define GBUS_MUTEX_XPU 0x14 /* width RMuint32 */
+#define GBUS_MUTEX_PT110 0x16 /* width RMuint32 */
+#define GBUS_MUTEX_TDMX 0x19 /* width RMuint32 */
+#define GBUS_MUTEX_AUDIO_0 0x1b /* width RMuint32 */
+#define GBUS_MUTEX_AUDIO_1 0x1c /* width RMuint32 */
+#define GBUS_MUTEX_MPEG_0 0x1d /* width RMuint32 */
+#define GBUS_MUTEX_MPEG_1 0x1e /* width RMuint32 */
+#define GBUS_MUTEX_HOST 0x1f /* width RMuint32 */
+#define GBUS_MUTEX_LOCAL 0x10 /* width RMuint32 */
+/* SystemBlock registers done */
+
+/* CPUBlock registers */
+#define REG_BASE_cpu_block 0x00060000 /* width RMuint32 */
+#define CPU_time0_load 0xc500 /* width RMuint32 */
+#define CPU_time0_value 0xc504 /* width RMuint32 */
+#define CPU_time0_ctrl 0xc508 /* width RMuint32 */
+#define CPU_time0_clr 0xc50c /* width RMuint32 */
+#define CPU_time1_load 0xc600 /* width RMuint32 */
+#define CPU_time1_value 0xc604 /* width RMuint32 */
+#define CPU_time1_ctrl 0xc608 /* width RMuint32 */
+#define CPU_time1_clr 0xc60c /* width RMuint32 */
+#define CPU_rtc_data 0xc800 /* width RMuint32 */
+#define CPU_rtc_match 0xc804 /* width RMuint32 */
+#define CPU_rtc_stat 0xc808 /* width RMuint32 */
+#define CPU_rtc_load 0xc80c /* width RMuint32 */
+#define CPU_rtc_ctrl 0xc810 /* width RMuint32 */
+#define CPU_irq_status 0xe000 /* width RMuint32 */
+#define CPU_irq_rawstat 0xe004 /* width RMuint32 */
+#define CPU_irq_enableset 0xe008 /* width RMuint32 */
+#define CPU_irq_enableclr 0xe00c /* width RMuint32 */
+#define CPU_irq_softset 0xe010 /* width RMuint32 */
+#define CPU_irq_softclr 0xe014 /* width RMuint32 */
+#define CPU_fiq_status 0xe100 /* width RMuint32 */
+#define CPU_fiq_rawstat 0xe104 /* width RMuint32 */
+#define CPU_fiq_enableset 0xe108 /* width RMuint32 */
+#define CPU_fiq_enableclr 0xe10c /* width RMuint32 */
+#define CPU_fiq_softset 0xe110 /* width RMuint32 */
+#define CPU_fiq_softclr 0xe114 /* width RMuint32 */
+#define CPU_edge_status 0xe200 /* width RMuint32 */
+#define CPU_edge_rawstat 0xe204 /* width RMuint32 */
+#define CPU_edge_config_rise 0xe208 /* width RMuint32 */
+#define CPU_edge_config_fall 0xe20c /* width RMuint32 */
+#define CPU_SOFT_INT 0x00000001 /* width RMuint32 */
+#define CPU_UART0_INT 0x00000002 /* width RMuint32 */
+#define CPU_UART1_INT 0x00000004 /* width RMuint32 */
+#define CPU_TIMER0_INT 0x00000020 /* width RMuint32 */
+#define CPU_TIMER1_INT 0x00000040 /* width RMuint32 */
+#define CPU_HOST_MBUS_W0_INT 0x00000200 /* width RMuint32 */
+#define CPU_HOST_MBUS_W1_INT 0x00000400 /* width RMuint32 */
+#define CPU_HOST_MBUS_R0_INT 0x00000800 /* width RMuint32 */
+#define CPU_HOST_MBUS_R1_INT 0x00001000 /* width RMuint32 */
+#define CPU_PCI_INTA 0x00002000 /* width RMuint32 */
+#define CPU_PCI_INTB 0x00004000 /* width RMuint32 */
+#define CPU_PCI_INTC 0x00008000 /* width RMuint32 */
+#define CPU_PCI_INTD 0x00010000 /* width RMuint32 */
+#define CPU_PCI_FAULT_INT 0x00100000 /* width RMuint32 */
+#define CPU_INFRARED_INT 0x00200000 /* width RMuint32 */
+#define CPU_SFLA_INT 0x00000010 /* width RMuint32 */
+#define CPU_DVD_INT 0x00000080 /* width RMuint32 */
+#define CPU_ETH_INT 0x00000100 /* width RMuint32 */
+#define CPU_DMAIDE_INT 0x00020000 /* width RMuint32 */
+#define CPU_IDE_INT 0x00040000 /* width RMuint32 */
+#define CPU_FRONTPANEL_INT 0x00080000 /* width RMuint32 */
+#define CPU_I2C_INT 0x00400000 /* width RMuint32 */
+#define CPU_GFX_ACCEL_INT 0x00800000 /* width RMuint32 */
+#define CPU_VSYNC0_INT 0x01000000 /* width RMuint32 */
+#define CPU_VSYNC1_INT 0x02000000 /* width RMuint32 */
+#define CPU_VSYNC2_INT 0x04000000 /* width RMuint32 */
+#define CPU_VSYNC3_INT 0x08000000 /* width RMuint32 */
+#define CPU_VSYNC4_INT 0x10000000 /* width RMuint32 */
+#define CPU_VSYNC4BKEND_INT 0x20000000 /* width RMuint32 */
+#define CPU_VSYNC5_INT 0x40000000 /* width RMuint32 */
+#define CPU_VSYNC5BKEND_INT 0x80000000 /* width RMuint32 */
+#define CPU_SMARTCARD_HI_INT 0x00000001 /* width RMuint32 */
+#define CPU_HDMI_HI_INT 0x00000002 /* width RMuint32 */
+#define CPU_HDMI_I2C_HI_INT 0x00000004 /* width RMuint32 */
+#define CPU_VBUS_W0_HI_INT 0x00000008 /* width RMuint32 */
+#define CPU_VBUS_W3_HI_INT 0x00000010 /* width RMuint32 */
+#define CPU_ETH_PHY_HI_INT 0x00000020 /* width RMuint32 */
+#define CPU_ETH_MAC_HI_INT 0x00000040 /* width RMuint32 */
+#define CPU_USB_OHCI_MAC_HI_INT 0x00000080 /* width RMuint32 */
+#define CPU_USB_EHCI_MAC_HI_INT 0x00000100 /* width RMuint32 */
+#define LOG2_CPU_SOFT_INT 0 /* width RMuint32 */
+#define LOG2_CPU_UART0_INT 1 /* width RMuint32 */
+#define LOG2_CPU_UART1_INT 2 /* width RMuint32 */
+#define LOG2_CPU_TIMER0_INT 5 /* width RMuint32 */
+#define LOG2_CPU_TIMER1_INT 6 /* width RMuint32 */
+#define LOG2_CPU_DVD_INT 7 /* width RMuint32 */
+#define LOG2_CPU_RTC_INT 8 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_W0_INT 9 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_W1_INT 10 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_R0_INT 11 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_R1_INT 12 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTA 13 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTB 14 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTC 15 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTD 16 /* width RMuint32 */
+#define LOG2_CPU_DMAIDE_INT 17 /* width RMuint32 */
+#define LOG2_CPU_IDE_INT 18 /* width RMuint32 */
+#define LOG2_CPU_FRONTPANEL_INT 19 /* width RMuint32 */
+#define LOG2_CPU_PCI_FAULT_INT 20 /* width RMuint32 */
+#define LOG2_CPU_INFRARED_INT 21 /* width RMuint32 */
+#define LOG2_CPU_I2C_INT 22 /* width RMuint32 */
+#define LOG2_CPU_GFX_ACCEL_INT 23 /* width RMuint32 */
+#define LOG2_CPU_VSYNC0_INT 24 /* width RMuint32 */
+#define LOG2_CPU_VSYNC1_INT 25 /* width RMuint32 */
+#define LOG2_CPU_VSYNC2_INT 26 /* width RMuint32 */
+#define LOG2_CPU_VSYNC3_INT 27 /* width RMuint32 */
+#define LOG2_CPU_VSYNC4_INT 28 /* width RMuint32 */
+#define LOG2_CPU_VSYNC4BKEND_INT 29 /* width RMuint32 */
+#define LOG2_CPU_VSYNC5_INT 30 /* width RMuint32 */
+#define LOG2_CPU_VSYNC5BKEND_INT 31 /* width RMuint32 */
+#define LOG2_CPU_SMARTCARD_INT 32 /* width RMuint32 */
+#define LOG2_CPU_HDMI_INT 33 /* width RMuint32 */
+#define LOG2_CPU_HDMI_I2C_INT 34 /* width RMuint32 */
+#define LOG2_CPU_VBUS_W0_INT 35 /* width RMuint32 */
+#define LOG2_CPU_VBUS_W3_INT 36 /* width RMuint32 */
+#define LOG2_CPU_ETH_PHY_INT 37 /* width RMuint32 */
+#define LOG2_CPU_ETH_MAC_INT 38 /* width RMuint32 */
+#define LOG2_CPU_USB_OHCI_INT 39 /* width RMuint32 */
+#define LOG2_CPU_USB_EHCI_INT 40 /* width RMuint32 */
+#define CPU_edge_status_hi 0xe220 /* width RMuint32 */
+#define CPU_edge_rawstat_hi 0xe224 /* width RMuint32 */
+#define CPU_edge_config_rise_hi 0xe228 /* width RMuint32 */
+#define CPU_edge_config_fall_hi 0xe22c /* width RMuint32 */
+#define CPU_irq_status_hi 0xe018 /* width RMuint32 */
+#define CPU_irq_rawstat_hi 0xe01c /* width RMuint32 */
+#define CPU_irq_enableset_hi 0xe020 /* width RMuint32 */
+#define CPU_irq_enableclr_hi 0xe024 /* width RMuint32 */
+#define CPU_fiq_status_hi 0xe118 /* width RMuint32 */
+#define CPU_fiq_rawstat_hi 0xe11c /* width RMuint32 */
+#define CPU_fiq_enableset_hi 0xe120 /* width RMuint32 */
+#define CPU_fiq_enableclr_hi 0xe124 /* width RMuint32 */
+#define CPU_iiq_status 0xe300 /* width RMuint32 */
+#define CPU_iiq_rawstat 0xe304 /* width RMuint32 */
+#define CPU_iiq_enableset 0xe308 /* width RMuint32 */
+#define CPU_iiq_enableclr 0xe30c /* width RMuint32 */
+#define CPU_iiq_softset 0xe310 /* width RMuint32 */
+#define CPU_iiq_softclr 0xe314 /* width RMuint32 */
+#define CPU_iiq_status_hi 0xe318 /* width RMuint32 */
+#define CPU_iiq_rawstat_hi 0xe31c /* width RMuint32 */
+#define CPU_iiq_enableset_hi 0xe320 /* width RMuint32 */
+#define CPU_iiq_enableclr_hi 0xe324 /* width RMuint32 */
+#define CPU_UART_GPIOMODE 0x38 /* width RMuint32 */
+#define CPU_UART_GPIODIR 0x30 /* width RMuint32 */
+#define CPU_UART_GPIODATA 0x34 /* width RMuint32 */
+#define CPU_edge_config_rise_set 0xe210 /* width RMuint32 */
+#define CPU_edge_config_rise_clr 0xe214 /* width RMuint32 */
+#define CPU_edge_config_fall_set 0xe218 /* width RMuint32 */
+#define CPU_edge_config_fall_clr 0xe21c /* width RMuint32 */
+#define CPU_edge_config_rise_set_hi 0xe230 /* width RMuint32 */
+#define CPU_edge_config_rise_clr_hi 0xe234 /* width RMuint32 */
+#define CPU_edge_config_fall_set_hi 0xe238 /* width RMuint32 */
+#define CPU_edge_config_fall_clr_hi 0xe23c /* width RMuint32 */
+#define CPU_pm_select_0 0xc900 /* width RMuint32 */
+#define CPU_pm_counter_0 0xc904 /* width RMuint32 */
+#define CPU_pm_select_1 0xc908 /* width RMuint32 */
+#define CPU_pm_counter_1 0xc90c /* width RMuint32 */
+#define CPU_remap 0xf000 /* width RMuint32 */
+#define CPU_remap1 0xf004 /* width RMuint32 */
+#define CPU_remap2 0xf008 /* width RMuint32 */
+#define CPU_remap3 0xf00c /* width RMuint32 */
+#define CPU_remap4 0xf010 /* width RMuint32 */
+#define CPU_remap_address 0x1fc00000 /* width RMuint32 */
+#define CPU_remap1_address 0 /* width RMuint32 */
+#define CPU_remap2_address 0x04000000 /* width RMuint32 */
+#define CPU_remap3_address 0x08000000 /* width RMuint32 */
+#define CPU_remap4_address 0x0c000000 /* width RMuint32 */
+#define REG_BASE_irq_handler_block 0xe0000 /* width RMuint32 */
+#define G2L_BIST_BUSY 0xffe0 /* width RMuint32 */
+#define G2L_BIST_PASS 0xffe4 /* width RMuint32 */
+#define G2L_BIST_MASK 0xffe8 /* width RMuint32 */
+#define G2L_RESET_CONTROL 0xfffc /* width RMuint32 */
+#define CPU_UART0_base 0xc100 /* width RMuint32 */
+#define CPU_UART1_base 0xc200 /* width RMuint32 */
+#define CPU_UART_RBR 0x00 /* width RMuint32 */
+#define CPU_UART_THR 0x04 /* width RMuint32 */
+#define CPU_UART_IER 0x08 /* width RMuint32 */
+#define CPU_UART_IIR 0x0c /* width RMuint32 */
+#define CPU_UART_FCR 0x10 /* width RMuint32 */
+#define CPU_UART_LCR 0x14 /* width RMuint32 */
+#define CPU_UART_MCR 0x18 /* width RMuint32 */
+#define CPU_UART_LSR 0x1c /* width RMuint32 */
+#define CPU_UART_MSR 0x20 /* width RMuint32 */
+#define CPU_UART_SCR 0x24 /* width RMuint32 */
+#define CPU_UART_CLKDIV 0x28 /* width RMuint32 */
+#define CPU_UART_CLKSEL 0x2c /* width RMuint32 */
+/* CPUBlock registers done */
+
+/* XPUBlock registers */
+#define REG_BASE_xpu_block 0x000e0000 /* width RMuint32 */
+/* XPUBlock registers done */
+
+/* IPUBlock registers */
+#define REG_BASE_ipu_block 0x000f0000 /* width RMuint32 */
+/* IPUBlock registers done */
+
+/* DisplayBlock registers */
+#define REG_BASE_display_block 0x00070000 /* width RMuint32 */
+#define PMEM_BASE_display_block 0x00300000 /* width RMuint32 */
+#define VBUS_IDLE 0x0 /* width RMuint32 */
+#define VBUS_LINEAR 0x1 /* width RMuint32 */
+#define VBUS_DOUBLE 0x2 /* width RMuint32 */
+#define VBUS_RECTANGLE 0x3 /* width RMuint32 */
+#define VBUS_DOUBLE_FIELD 0x4 /* width RMuint32 */
+#define VBUS_DOUBLE_RECTANGLE 0x5 /* width RMuint32 */
+#define VBUS_8BYTE_COLUMN 0x6 /* width RMuint32 */
+#define VBUS_VOID 0x8 /* width RMuint32 */
+#define VBUS_LINEAR_VOID 0x9 /* width RMuint32 */
+#define VBUS_DOUBLE_VOID 0xa /* width RMuint32 */
+#define VBUS_RECTANGLE_VOID 0xb /* width RMuint32 */
+#define VBUS_DOUBLE_FIELD_VOID 0xc /* width RMuint32 */
+#define VBUS_DOUBLE_RECTANGLE_VOID 0xd /* width RMuint32 */
+#define VBUS_8BYTE_COLUMN_VOID 0xe /* width RMuint32 */
+/* DisplayBlock registers done */
+
+/* DemuxEngine registers */
+#define REG_BASE_demux_engine 0x000A0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine 0x00140000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine 0x00140000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine 0x00150000 /* width RMuint32 */
+#define REG_BASE_demux_engine_0 0x000A0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine_0 0x00140000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine_0 0x00140000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine_0 0x00150000 /* width RMuint32 */
+#define REG_BASE_demux_engine_1 0x000b0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine_1 0x00160000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine_1 0x00160000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine_1 0x00170000 /* width RMuint32 */
+#define TDMX_gpio_data 0x2e0c /* width RMuint32 */
+#define TDMX_gpio_dir 0x2e0d /* width RMuint32 */
+/* DemuxEngine registers done */
+
+/* MpegEngine registers */
+#define REG_BASE_mpeg_engine_0 0x00080000 /* width RMuint32 */
+#define MEM_BASE_mpeg_engine_0 0x00100000 /* width RMuint32 */
+#define PMEM_BASE_mpeg_engine_0 0x00100000 /* width RMuint32 */
+#define DMEM_BASE_mpeg_engine_0 0x00110000 /* width RMuint32 */
+#define REG_BASE_mpeg_engine_1 0x00090000 /* width RMuint32 */
+#define MEM_BASE_mpeg_engine_1 0x00120000 /* width RMuint32 */
+#define PMEM_BASE_mpeg_engine_1 0x00120000 /* width RMuint32 */
+#define DMEM_BASE_mpeg_engine_1 0x00130000 /* width RMuint32 */
+#define RBUS_offset 0x4000 /* width RMuint32 */
+/* MpegEngine registers done */
+
+/* AudioEngine registers */
+#define REG_BASE_audio_engine_0 0x000c0000 /* width RMuint32 */
+#define MEM_BASE_audio_engine_0 0x00180000 /* width RMuint32 */
+#define PMEM_BASE_audio_engine_0 0x00180000 /* width RMuint32 */
+#define DMEM_BASE_audio_engine_0 0x00190000 /* width RMuint32 */
+#define REG_BASE_audio_engine_1 0x000d0000 /* width RMuint32 */
+#define MEM_BASE_audio_engine_1 0x001a0000 /* width RMuint32 */
+#define PMEM_BASE_audio_engine_1 0x001a0000 /* width RMuint32 */
+#define DMEM_BASE_audio_engine_1 0x001b0000 /* width RMuint32 */
+#define audio_mutex0 0x3e90 /* width RMuint32 */
+#define audio_mutex1 0x3e91 /* width RMuint32 */
+#define audio_mutex2 0x3e92 /* width RMuint32 */
+#define audio_mutex3 0x3e93 /* width RMuint32 */
+#define audio_mutex4 0x3e94 /* width RMuint32 */
+#define audio_mutex5 0x3e95 /* width RMuint32 */
+#define audio_mutex6 0x3e96 /* width RMuint32 */
+#define audio_mutex7 0x3e97 /* width RMuint32 */
+/* AudioEngine registers done */
+
+/* AudioDecoder registers */
+/* AudioDecoder registers done */
+
+/* AudioCapture registers */
+/* AudioCapture registers done */
+
+/* VoipCodec registers */
+/* VoipCodec registers done */
+
+/* CRCDecoder registers */
+/* CRCDecoder registers done */
+
+/* XCRCDecoder registers */
+/* XCRCDecoder registers done */
+
+/* StreamCapture registers */
+/* StreamCapture registers done */
+
+/* RawDataTransfer registers */
+/* RawDataTransfer registers done */
+
+/* I2C registers */
+#define I2C_MASTER_CONFIG 0x80 /* width RMuint32 */
+#define I2C_MASTER_CLK_DIV 0x84 /* width RMuint32 */
+#define I2C_MASTER_DEV_ADDR 0x88 /* width RMuint32 */
+#define I2C_MASTER_ADDR 0x8c /* width RMuint32 */
+#define I2C_MASTER_DATA_OUT 0x90 /* width RMuint32 */
+#define I2C_MASTER_DATA_IN 0x94 /* width RMuint32 */
+#define I2C_MASTER_STATUS 0x98 /* width RMuint32 */
+#define I2C_MASTER_STARTXFER 0x9c /* width RMuint32 */
+#define I2C_MASTER_BYTE_CNT 0xa0 /* width RMuint32 */
+#define I2C_MASTER_INTEN 0xa4 /* width RMuint32 */
+#define I2C_MASTER_INT 0xa8 /* width RMuint32 */
+#define I2C_SLAVE_ADDR_REG 0xC0 /* width RMuint32 */
+#define I2C_SLAVE_DATAOUT 0xC4 /* width RMuint32 */
+#define I2C_SLAVE_DATAIN 0xC8 /* width RMuint32 */
+#define I2C_SLAVE_STATUS 0xCC /* width RMuint32 */
+#define I2C_SLAVE_INTEN 0xD0 /* width RMuint32 */
+#define I2C_SLAVE_INT 0xD4 /* width RMuint32 */
+#define I2C_SLAVE_BUS_HOLD 0xD8 /* width RMuint32 */
+/* I2C registers done */
+
+/* MM registers */
+/* MM registers done */
+
+/* SpuDecoder registers */
+/* SpuDecoder registers done */
+
+/* PictureTransform registers */
+/* PictureTransform registers done */
+
+/* ClosedCaptionDecoder registers */
+/* ClosedCaptionDecoder registers done */
+
+/* RTC registers */
+/* RTC registers done */
+
+/* Cipher registers */
+/* Cipher registers done */
+
+/* STC registers */
+/* STC registers done */
+
+/* PLL registers */
+/* PLL registers done */
+
+/* DemuxCipher registers */
+/* DemuxCipher registers done */
+
+/* DemuxTask registers */
+/* DemuxTask registers done */
+
+/* DemuxOutput registers */
+/* DemuxOutput registers done */
+
+/* CCFifo registers */
+/* CCFifo registers done */
+
+/* Sha1Sum registers */
+/* Sha1Sum registers done */
+
+/* XTask registers */
+/* XTask registers done */
+
+/* TTXFifo registers */
+/* TTXFifo registers done */
+
+/* VCXO registers */
+/* VCXO registers done */
+
+/* PPF registers */
+/* PPF registers done */
+
+#endif /* __EMHWLIB_REGISTERS_TANGO2_H__ */
+
+/* End of generated file ../emhwlib_hal/include/tango2/emhwlib_registers_tango2.h */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_registers_tango2.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_registers_tango2.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_registers_tango2.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_registers_tango2.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,565 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/tango2/emhwlib_registers_tango2.inc (generated from emhwlib_hal/include/tango2/emhwlib_registers_tango2.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+REG_BASE_system_block=0x10000
+SYS_clkgen0_pll=0x0
+SYS_clkgen0_div=0x4
+SYS_clkgen1_pll=0x8
+SYS_clkgen1_div=0xc
+SYS_clkgen2_pll=0x10
+SYS_clkgen2_div=0x14
+SYS_clkgen3_pll=0x18
+SYS_clkgen3_div=0x1c
+SYS_avclk_mux=0x38
+SYS_sysclk_mux=0x3c
+SYS_clk_cnt=0x40
+SYS_xtal_in_cnt=0x48
+DRAM_vbus_w0_cfg=0x300
+DRAM_vbus_w1_cfg=0x304
+DRAM_vbus_w2_cfg=0x308
+DRAM_vbus_w3_cfg=0x30c
+DRAM_vbus_r0_cfg=0x340
+DRAM_vbus_r1_cfg=0x344
+DRAM_vbus_r2_cfg=0x348
+DRAM_vbus_r3_cfg=0x34c
+DRAM_vbus_r4_cfg=0x350
+DRAM_vbus_r5_cfg=0x354
+DRAM_vbus_r6_cfg=0x358
+DRAM_vbus_r7_cfg=0x35c
+DRAM_vbus_r8_cfg=0x360
+DRAM_vbus_r9_cfg=0x364
+DRAM_vbus_r10_cfg=0x368
+DRAM_vbus_r11_cfg=0x36c
+DRAM_mbus_w0_cfg=0x200
+DRAM_mbus_w1_cfg=0x204
+DRAM_mbus_w2_cfg=0x208
+DRAM_mbus_w3_cfg=0x20c
+DRAM_mbus_w4_cfg=0x210
+DRAM_mbus_w5_cfg=0x214
+DRAM_mbus_w6_cfg=0x218
+DRAM_mbus_w7_cfg=0x21c
+DRAM_mbus_w8_cfg=0x220
+DRAM_mbus_w9_cfg=0x224
+DRAM_mbus_w10_cfg=0x228
+DRAM_mbus_r0_cfg=0x240
+DRAM_mbus_r1_cfg=0x244
+DRAM_mbus_r2_cfg=0x248
+DRAM_mbus_r3_cfg=0x24c
+DRAM_mbus_r4_cfg=0x250
+DRAM_mbus_r5_cfg=0x254
+DRAM_mbus_r6_cfg=0x258
+DRAM_mbus_r7_cfg=0x25c
+DRAM_mbus_r8_cfg=0x260
+DRAM_mbus_r9_cfg=0x264
+DRAM_mbus_r10_cfg=0x268
+SYS_hostclk_mux=0x30
+SYS_sysclk_premux=0x34
+SYS_rnd_cnt=0x44
+SYS_cnt_cfg=0x4c
+SYS_cfg_cnt0=0x50
+SYS_cfg_cnt1=0x54
+SYS_cfg_cnt2=0x58
+SYS_cfg_cnt3=0x5c
+SYS_cfg_cnt4=0x60
+SYS_cleandiv0_div=0x80
+SYS_cleandiv1_div=0x88
+SYS_cleandiv2_div=0x90
+SYS_cleandiv3_div=0x98
+SYS_cleandiv4_div=0xa0
+SYS_cleandiv5_div=0xa8
+SYS_cleandiv6_div=0xb0
+SYS_cleandiv7_div=0xb8
+SYS_cleandiv8_div=0xc0
+SYS_cleandiv9_div=0xc8
+SYS_cleandiv10_div=0xd0
+MARB_mid01_cfg=0x200
+MARB_mid21_cfg=0x204
+MARB_mid02_cfg=0x208
+MARB_mid22_cfg=0x20c
+MARB_mid04_cfg=0x210
+MARB_mid24_cfg=0x214
+MARB_mid25_cfg=0x218
+MARB_mid08_cfg=0x21c
+MARB_mid28_cfg=0x220
+MARB_mid29_cfg=0x224
+MARB_mid0C_cfg=0x228
+MARB_mid2C_cfg=0x22c
+MARB_mid10_cfg=0x230
+MARB_mid30_cfg=0x234
+MARB_mid31_cfg=0x238
+MARB_mid12_cfg=0x23c
+MARB_mid32_cfg=0x240
+VARB_mid01_cfg=0x300
+VARB_mid02_cfg=0x304
+VARB_mid21_cfg=0x308
+VARB_mid22_cfg=0x30c
+VARB_mid23_cfg=0x310
+VARB_mid24_cfg=0x314
+VARB_mid25_cfg=0x318
+VARB_mid26_cfg=0x31c
+VARB_mid27_cfg=0x320
+VARB_mid28_cfg=0x324
+VARB_mid29_cfg=0x328
+VARB_mid2A_cfg=0x32c
+VARB_mid10_cfg=0x330
+VARB_mid30_cfg=0x334
+VARB_mid31_cfg=0x338
+VARB_mid03_cfg=0x33c
+IARB_mid01_cfg=0x400
+IARB_mid02_cfg=0x404
+SYS_gpio_dir=0x500
+SYS_gpio_data=0x504
+SYS_gpio_int=0x508
+SYS_gpio15_pwm=0x510
+SYS_gpio14_pwm=0x514
+REG_BASE_dram_controller_0=0x30000
+REG_BASE_dram_controller_1=0x40000
+MEM_BASE_dram_controller_0_alias=0x10000000
+MEM_BASE_dram_controller_0=0x10000000
+MEM_BASE_dram_controller_1_alias=0x20000000
+MEM_BASE_dram_controller_1=0x20000000
+DRAM_dunit_cfg=0x0
+DRAM_dunit_delay0_ctrl=0x4
+DRAM_dunit_delay1_ctrl=0x8
+DRAM_dunit_auto_delay=0xc
+DRAM_dunit_fall_delay0=0x10
+DRAM_dunit_fall_delay1=0x14
+DRAM_dunit_bw_lobound=0x18
+DRAM_dunit_bw_hibound=0x1c
+DRAM_dunit_bw_probe_cfg=0x20
+DRAM_dunit_bw_probe_cnt=0x24
+DRAM_dunit_bw_cntall=0x28
+DRAM_dunit_calibration_delay=0x30
+DRAM_dunit_calibration_rise_err=0x34
+DRAM_dunit_calibration_fall_err=0x38
+DRAM_dunit_calibration_page=0x88
+DRAM_dunit_flush_buffer=0x104
+REG_BASE_host_interface=0x20000
+MEM_BASE_host_interface=0x40000000
+IDE_data=0x0
+IDE_error=0x4
+IDE_count=0x8
+IDE_start_sector=0xc
+IDE_cylinder_lo=0x10
+IDE_cylinder_hi=0x14
+IDE_head_device=0x18
+IDE_cmd_stat=0x1c
+IDE_irq_stat=0x218
+IDE_cmd_stat__=0x21c
+PB_timing0=0x800
+PB_timing1=0x804
+PB_timing2=0x808
+PB_timing3=0x80c
+PB_timing4=0x810
+PB_timing5=0x814
+PB_default_timing=0x818
+PB_use_timing0=0x81c
+PB_use_timing1=0x820
+PB_use_timing2=0x824
+PB_use_timing3=0x828
+PB_use_timing4=0x82c
+PB_use_timing5=0x830
+PB_CS_config=0x834
+PB_automode_start_address=0x840
+PB_automode_control=0x844
+EMHWLIB_IS_HOST=0xe000
+HOST_REG1=0xfed0
+HOST_REG2=0xfed4
+READ_ADDRESS=0xfec0
+READ_COUNTER=0xfec4
+READ_ENABLE=0xfec8
+REV_ORDER=0xfecc
+WRITE_ADDRESS=0xfed8
+WRITE_COUNTER=0xfedc
+WRITE_ENABLE=0xfee0
+BURST=0xfee4
+PCI_TIMEOUT=0x8000
+PCI_TIMEOUT_STATUS=0x8004
+PCI_TIMER=0x8008
+PCI_TIMER_TEST=0x800c
+PCI_WAKEUP=0x8010
+PCI_REGION_0_BASE=0x9000
+PCI_REGION_1_BASE=0x9004
+PCI_REGION_2_BASE=0x9008
+PCI_REGION_3_BASE=0x900c
+PCI_REGION_4_BASE=0x9010
+PCI_REGION_5_BASE=0x9014
+PCI_REGION_6_BASE=0x9018
+PCI_REGION_7_BASE=0x901c
+PCI_irq_status=0x9020
+PCI_irq_set=0x9024
+PCI_irq_clear=0x9028
+SBOX_FIFO_RESET=0x90a0
+SBOX_ROUTE=0x90a8
+output_SBOX_MBUS_W0=0x9080
+output_SBOX_MBUS_W1=0x9084
+output_SBOX_PCI_MASTER=0x9088
+output_SBOX_PCI_SLAVE=0x908c
+output_SBOX_CIPHER=0x9090
+output_SBOX_IDE_ISA=0x9094
+output_SBOX_IDE_DVD=0x9098
+input_keep_SBOX=0x0
+input_MBUS_R0_SBOX=0x1
+input_MBUS_R1_SBOX=0x2
+input_PCI_MASTER_SBOX=0x3
+input_PCI_SLAVE_SBOX=0x4
+input_CIPHER_SBOX=0x5
+input_IDE_DVD_SBOX=0x6
+input_IDE_ISA_SBOX=0x7
+input_SFLA_SBOX=0x8
+input_unconnected_SBOX=0xf
+host_mutex0=0x9040
+host_mutex1=0x9044
+host_mutex2=0x9048
+host_mutex3=0x904c
+host_mutex4=0x9050
+host_mutex5=0x9054
+host_mutex6=0x9058
+host_mutex7=0x905c
+host_mutex8=0x9060
+host_mutex9=0x9064
+host_mutex10=0x9068
+host_mutex11=0x906c
+host_mutex12=0x9070
+host_mutex13=0x9074
+host_mutex14=0x9078
+host_mutex15=0x907c
+PCI_host_reg5=0xfe94
+PCI_chip_is_host=0xfe90
+IDECTRL_idesrc=0x20d0
+IDECTRL_pri_drv1udmatim1=0x20e0
+IDECTRL_pri_drv1udmatim2=0x20f0
+IDECTRL_pri_idectl=0x2100
+IDECTRL_pri_drv0tim=0x2110
+IDECTRL_pri_drv1tim=0x2120
+IDECTRL_idemisc=0x2130
+IDECTRL_idestatus=0x2140
+IDECTRL_udmactl=0x2150
+IDECTRL_pri_drv0udmatim1=0x2160
+IDECTRL_pri_drv0udmatim2=0x2170
+IDECTRL_pref_st=0x2310
+IDECTRL_pri_ctrlblock=0x2398
+IDECTRL_pri_cmdblock=0x23c0
+IDECTRL_bmic=0x2400
+IDECTRL_bmis=0x2410
+IDECTRL_bmidtp=0x2420
+IDECTRL_ide_dmaptr=0x2780
+IDECTRL_ide_dmalen=0x2790
+IDECTRL_pio_prefetch_data=0x27c0
+MEM_BASE_pfla=0x40000000
+PB_CS0_OFFSET=0x0
+PB_CS1_OFFSET=0x4000000
+PB_CS2_OFFSET=0x8000000
+PB_CS3_OFFSET=0xc000000
+ETH_gpio_dir1=0x7100
+ETH_gpio_data1=0x7104
+ETH_gpio_mask1=0x7108
+ETH_gpio_dir2=0x710c
+ETH_gpio_data2=0x7110
+PCI_host_reg1=0xfed0
+PCI_host_reg2=0xfed4
+PCI_host_reg3=0xfe80
+PCI_host_reg4=0xfe84
+PCI_pcictrl_reg1=0xfe88
+PCI_pcictrl_reg2=0xfe8c
+PCI_pcictrl_reg3=0xfefc
+PCI_REG0=0xfee8
+PCI_REG1=0xfeec
+PCI_REG2=0xfef0
+PCI_REG3=0xfef4
+PCI_CONFIG=0xfef8
+MIF_W0_ADD=0xb000
+MIF_W0_CNT=0xb004
+MIF_W0_SKIP=0xb008
+MIF_W0_CMD=0xb00c
+MIF_W1_ADD=0xb040
+MIF_W1_CNT=0xb044
+MIF_W1_SKIP=0xb048
+MIF_W1_CMD=0xb04c
+MIF_R0_ADD=0xb080
+MIF_R0_CNT=0xb084
+MIF_R0_SKIP=0xb088
+MIF_R0_CMD=0xb08c
+MIF_R1_ADD=0xb0c0
+MIF_R1_CNT=0xb0c4
+MIF_R1_SKIP=0xb0c8
+MIF_R1_CMD=0xb0cc
+MBUS_IDLE=0x0
+MBUS_LINEAR=0x1
+MBUS_DOUBLE=0x2
+MBUS_RECTANGLE=0x3
+MBUS_VOID=0x4
+MBUS_LINEAR_VOID=0x5
+MBUS_DOUBLE_VOID=0x6
+MBUS_RECTANGLE_VOID=0x7
+MBUS_TILED=0x8
+GBUS_MUTEX_XPU=0x14
+GBUS_MUTEX_PT110=0x16
+GBUS_MUTEX_TDMX=0x19
+GBUS_MUTEX_AUDIO_0=0x1b
+GBUS_MUTEX_AUDIO_1=0x1c
+GBUS_MUTEX_MPEG_0=0x1d
+GBUS_MUTEX_MPEG_1=0x1e
+GBUS_MUTEX_HOST=0x1f
+GBUS_MUTEX_LOCAL=0x10
+REG_BASE_cpu_block=0x60000
+CPU_time0_load=0xc500
+CPU_time0_value=0xc504
+CPU_time0_ctrl=0xc508
+CPU_time0_clr=0xc50c
+CPU_time1_load=0xc600
+CPU_time1_value=0xc604
+CPU_time1_ctrl=0xc608
+CPU_time1_clr=0xc60c
+CPU_rtc_data=0xc800
+CPU_rtc_match=0xc804
+CPU_rtc_stat=0xc808
+CPU_rtc_load=0xc80c
+CPU_rtc_ctrl=0xc810
+CPU_irq_status=0xe000
+CPU_irq_rawstat=0xe004
+CPU_irq_enableset=0xe008
+CPU_irq_enableclr=0xe00c
+CPU_irq_softset=0xe010
+CPU_irq_softclr=0xe014
+CPU_fiq_status=0xe100
+CPU_fiq_rawstat=0xe104
+CPU_fiq_enableset=0xe108
+CPU_fiq_enableclr=0xe10c
+CPU_fiq_softset=0xe110
+CPU_fiq_softclr=0xe114
+CPU_edge_status=0xe200
+CPU_edge_rawstat=0xe204
+CPU_edge_config_rise=0xe208
+CPU_edge_config_fall=0xe20c
+CPU_SOFT_INT=0x1
+CPU_UART0_INT=0x2
+CPU_UART1_INT=0x4
+CPU_TIMER0_INT=0x20
+CPU_TIMER1_INT=0x40
+CPU_HOST_MBUS_W0_INT=0x200
+CPU_HOST_MBUS_W1_INT=0x400
+CPU_HOST_MBUS_R0_INT=0x800
+CPU_HOST_MBUS_R1_INT=0x1000
+CPU_PCI_INTA=0x2000
+CPU_PCI_INTB=0x4000
+CPU_PCI_INTC=0x8000
+CPU_PCI_INTD=0x10000
+CPU_PCI_FAULT_INT=0x100000
+CPU_INFRARED_INT=0x200000
+CPU_SFLA_INT=0x10
+CPU_DVD_INT=0x80
+CPU_ETH_INT=0x100
+CPU_DMAIDE_INT=0x20000
+CPU_IDE_INT=0x40000
+CPU_FRONTPANEL_INT=0x80000
+CPU_I2C_INT=0x400000
+CPU_GFX_ACCEL_INT=0x800000
+CPU_VSYNC0_INT=0x1000000
+CPU_VSYNC1_INT=0x2000000
+CPU_VSYNC2_INT=0x4000000
+CPU_VSYNC3_INT=0x8000000
+CPU_VSYNC4_INT=0x10000000
+CPU_VSYNC4BKEND_INT=0x20000000
+CPU_VSYNC5_INT=0x40000000
+CPU_VSYNC5BKEND_INT=0x80000000
+CPU_SMARTCARD_HI_INT=0x1
+CPU_HDMI_HI_INT=0x2
+CPU_HDMI_I2C_HI_INT=0x4
+CPU_VBUS_W0_HI_INT=0x8
+CPU_VBUS_W3_HI_INT=0x10
+CPU_ETH_PHY_HI_INT=0x20
+CPU_ETH_MAC_HI_INT=0x40
+CPU_USB_OHCI_MAC_HI_INT=0x80
+CPU_USB_EHCI_MAC_HI_INT=0x100
+LOG2_CPU_SOFT_INT=0x0
+LOG2_CPU_UART0_INT=0x1
+LOG2_CPU_UART1_INT=0x2
+LOG2_CPU_TIMER0_INT=0x5
+LOG2_CPU_TIMER1_INT=0x6
+LOG2_CPU_DVD_INT=0x7
+LOG2_CPU_RTC_INT=0x8
+LOG2_CPU_HOST_MBUS_W0_INT=0x9
+LOG2_CPU_HOST_MBUS_W1_INT=0xa
+LOG2_CPU_HOST_MBUS_R0_INT=0xb
+LOG2_CPU_HOST_MBUS_R1_INT=0xc
+LOG2_CPU_PCI_INTA=0xd
+LOG2_CPU_PCI_INTB=0xe
+LOG2_CPU_PCI_INTC=0xf
+LOG2_CPU_PCI_INTD=0x10
+LOG2_CPU_DMAIDE_INT=0x11
+LOG2_CPU_IDE_INT=0x12
+LOG2_CPU_FRONTPANEL_INT=0x13
+LOG2_CPU_PCI_FAULT_INT=0x14
+LOG2_CPU_INFRARED_INT=0x15
+LOG2_CPU_I2C_INT=0x16
+LOG2_CPU_GFX_ACCEL_INT=0x17
+LOG2_CPU_VSYNC0_INT=0x18
+LOG2_CPU_VSYNC1_INT=0x19
+LOG2_CPU_VSYNC2_INT=0x1a
+LOG2_CPU_VSYNC3_INT=0x1b
+LOG2_CPU_VSYNC4_INT=0x1c
+LOG2_CPU_VSYNC4BKEND_INT=0x1d
+LOG2_CPU_VSYNC5_INT=0x1e
+LOG2_CPU_VSYNC5BKEND_INT=0x1f
+LOG2_CPU_SMARTCARD_INT=0x20
+LOG2_CPU_HDMI_INT=0x21
+LOG2_CPU_HDMI_I2C_INT=0x22
+LOG2_CPU_VBUS_W0_INT=0x23
+LOG2_CPU_VBUS_W3_INT=0x24
+LOG2_CPU_ETH_PHY_INT=0x25
+LOG2_CPU_ETH_MAC_INT=0x26
+LOG2_CPU_USB_OHCI_INT=0x27
+LOG2_CPU_USB_EHCI_INT=0x28
+CPU_edge_status_hi=0xe220
+CPU_edge_rawstat_hi=0xe224
+CPU_edge_config_rise_hi=0xe228
+CPU_edge_config_fall_hi=0xe22c
+CPU_irq_status_hi=0xe018
+CPU_irq_rawstat_hi=0xe01c
+CPU_irq_enableset_hi=0xe020
+CPU_irq_enableclr_hi=0xe024
+CPU_fiq_status_hi=0xe118
+CPU_fiq_rawstat_hi=0xe11c
+CPU_fiq_enableset_hi=0xe120
+CPU_fiq_enableclr_hi=0xe124
+CPU_iiq_status=0xe300
+CPU_iiq_rawstat=0xe304
+CPU_iiq_enableset=0xe308
+CPU_iiq_enableclr=0xe30c
+CPU_iiq_softset=0xe310
+CPU_iiq_softclr=0xe314
+CPU_iiq_status_hi=0xe318
+CPU_iiq_rawstat_hi=0xe31c
+CPU_iiq_enableset_hi=0xe320
+CPU_iiq_enableclr_hi=0xe324
+CPU_UART_GPIOMODE=0x38
+CPU_UART_GPIODIR=0x30
+CPU_UART_GPIODATA=0x34
+CPU_edge_config_rise_set=0xe210
+CPU_edge_config_rise_clr=0xe214
+CPU_edge_config_fall_set=0xe218
+CPU_edge_config_fall_clr=0xe21c
+CPU_edge_config_rise_set_hi=0xe230
+CPU_edge_config_rise_clr_hi=0xe234
+CPU_edge_config_fall_set_hi=0xe238
+CPU_edge_config_fall_clr_hi=0xe23c
+CPU_pm_select_0=0xc900
+CPU_pm_counter_0=0xc904
+CPU_pm_select_1=0xc908
+CPU_pm_counter_1=0xc90c
+CPU_remap=0xf000
+CPU_remap1=0xf004
+CPU_remap2=0xf008
+CPU_remap3=0xf00c
+CPU_remap4=0xf010
+CPU_remap_address=0x1fc00000
+CPU_remap1_address=0x0
+CPU_remap2_address=0x4000000
+CPU_remap3_address=0x8000000
+CPU_remap4_address=0xc000000
+REG_BASE_irq_handler_block=0xe0000
+G2L_BIST_BUSY=0xffe0
+G2L_BIST_PASS=0xffe4
+G2L_BIST_MASK=0xffe8
+G2L_RESET_CONTROL=0xfffc
+CPU_UART0_base=0xc100
+CPU_UART1_base=0xc200
+CPU_UART_RBR=0x0
+CPU_UART_THR=0x4
+CPU_UART_IER=0x8
+CPU_UART_IIR=0xc
+CPU_UART_FCR=0x10
+CPU_UART_LCR=0x14
+CPU_UART_MCR=0x18
+CPU_UART_LSR=0x1c
+CPU_UART_MSR=0x20
+CPU_UART_SCR=0x24
+CPU_UART_CLKDIV=0x28
+CPU_UART_CLKSEL=0x2c
+REG_BASE_xpu_block=0xe0000
+REG_BASE_ipu_block=0xf0000
+REG_BASE_display_block=0x70000
+PMEM_BASE_display_block=0x300000
+VBUS_IDLE=0x0
+VBUS_LINEAR=0x1
+VBUS_DOUBLE=0x2
+VBUS_RECTANGLE=0x3
+VBUS_DOUBLE_FIELD=0x4
+VBUS_DOUBLE_RECTANGLE=0x5
+VBUS_8BYTE_COLUMN=0x6
+VBUS_VOID=0x8
+VBUS_LINEAR_VOID=0x9
+VBUS_DOUBLE_VOID=0xa
+VBUS_RECTANGLE_VOID=0xb
+VBUS_DOUBLE_FIELD_VOID=0xc
+VBUS_DOUBLE_RECTANGLE_VOID=0xd
+VBUS_8BYTE_COLUMN_VOID=0xe
+REG_BASE_demux_engine=0xa0000
+MEM_BASE_demux_engine=0x140000
+PMEM_BASE_demux_engine=0x140000
+DMEM_BASE_demux_engine=0x150000
+REG_BASE_demux_engine_0=0xa0000
+MEM_BASE_demux_engine_0=0x140000
+PMEM_BASE_demux_engine_0=0x140000
+DMEM_BASE_demux_engine_0=0x150000
+REG_BASE_demux_engine_1=0xb0000
+MEM_BASE_demux_engine_1=0x160000
+PMEM_BASE_demux_engine_1=0x160000
+DMEM_BASE_demux_engine_1=0x170000
+TDMX_gpio_data=0x2e0c
+TDMX_gpio_dir=0x2e0d
+REG_BASE_mpeg_engine_0=0x80000
+MEM_BASE_mpeg_engine_0=0x100000
+PMEM_BASE_mpeg_engine_0=0x100000
+DMEM_BASE_mpeg_engine_0=0x110000
+REG_BASE_mpeg_engine_1=0x90000
+MEM_BASE_mpeg_engine_1=0x120000
+PMEM_BASE_mpeg_engine_1=0x120000
+DMEM_BASE_mpeg_engine_1=0x130000
+RBUS_offset=0x4000
+REG_BASE_audio_engine_0=0xc0000
+MEM_BASE_audio_engine_0=0x180000
+PMEM_BASE_audio_engine_0=0x180000
+DMEM_BASE_audio_engine_0=0x190000
+REG_BASE_audio_engine_1=0xd0000
+MEM_BASE_audio_engine_1=0x1a0000
+PMEM_BASE_audio_engine_1=0x1a0000
+DMEM_BASE_audio_engine_1=0x1b0000
+audio_mutex0=0x3e90
+audio_mutex1=0x3e91
+audio_mutex2=0x3e92
+audio_mutex3=0x3e93
+audio_mutex4=0x3e94
+audio_mutex5=0x3e95
+audio_mutex6=0x3e96
+audio_mutex7=0x3e97
+I2C_MASTER_CONFIG=0x80
+I2C_MASTER_CLK_DIV=0x84
+I2C_MASTER_DEV_ADDR=0x88
+I2C_MASTER_ADDR=0x8c
+I2C_MASTER_DATA_OUT=0x90
+I2C_MASTER_DATA_IN=0x94
+I2C_MASTER_STATUS=0x98
+I2C_MASTER_STARTXFER=0x9c
+I2C_MASTER_BYTE_CNT=0xa0
+I2C_MASTER_INTEN=0xa4
+I2C_MASTER_INT=0xa8
+I2C_SLAVE_ADDR_REG=0xc0
+I2C_SLAVE_DATAOUT=0xc4
+I2C_SLAVE_DATAIN=0xc8
+I2C_SLAVE_STATUS=0xcc
+I2C_SLAVE_INTEN=0xd0
+I2C_SLAVE_INT=0xd4
+I2C_SLAVE_BUS_HOLD=0xd8
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_shared.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_shared.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_shared.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_shared.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,114 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_resources_shared.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2005-03-22
+*/
+
+#ifndef __EMHWLIB_RESOURCES_SHARED_H__
+#define __EMHWLIB_RESOURCES_SHARED_H__
+
+#define VIDEO_0_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_0  + 4 * mpeg_mutex1))
+#define VIDEO_1_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_1  + 4 * mpeg_mutex1))
+#define AUDIO_0_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_0 + 4 * audio_mutex1))
+#define DEMUX_RPC_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex3))
+
+// pt110 local ram map
+#define UCLINUX_CURRENT_PROCESS (REG_BASE_cpu_block + 0x0000)
+
+#define RESET_VECTOR   (REG_BASE_cpu_block + 0x0000)
+#define UNDEF_VECTOR   (REG_BASE_cpu_block + 0x0004)
+#define SWI_VECTOR     (REG_BASE_cpu_block + 0x0008)
+#define I_ABORT_VECTOR (REG_BASE_cpu_block + 0x000c)
+#define D_ABORT_VECTOR (REG_BASE_cpu_block + 0x0010)
+#define RSV_VECTOR     (REG_BASE_cpu_block + 0x0014)
+#define IRQ_VECTOR     (REG_BASE_cpu_block + 0x0018)
+#define FIQ_VECTOR     (REG_BASE_cpu_block + 0x001c)
+
+#define RESET_JUMP     (REG_BASE_cpu_block + 0x0020)
+#define UNDEF_JUMP     (REG_BASE_cpu_block + 0x0024)
+#define SWI_JUMP       (REG_BASE_cpu_block + 0x0028)
+#define I_ABORT_JUMP   (REG_BASE_cpu_block + 0x002c)
+#define D_ABORT_JUMP   (REG_BASE_cpu_block + 0x0030)
+#define RSV_JUMP       (REG_BASE_cpu_block + 0x0034)
+#define IRQ_JUMP       (REG_BASE_cpu_block + 0x0038)
+#define FIQ_JUMP       (REG_BASE_cpu_block + 0x003c)
+
+#define INFINITE_LOOP  (REG_BASE_cpu_block + 0x0040)
+
+/* where to store uclinux interrupt handler */
+#define UCLINUX_RESET_VECTOR   (REG_BASE_cpu_block + 0x0044)
+#define UCLINUX_UNDEF_VECTOR   (REG_BASE_cpu_block + 0x0048)
+#define UCLINUX_SWI_VECTOR     (REG_BASE_cpu_block + 0x004c)
+#define UCLINUX_I_ABORT_VECTOR (REG_BASE_cpu_block + 0x0050)
+#define UCLINUX_D_ABORT_VECTOR (REG_BASE_cpu_block + 0x0054)
+#define UCLINUX_RSV_VECTOR     (REG_BASE_cpu_block + 0x0058)
+#define UCLINUX_IRQ_VECTOR     (REG_BASE_cpu_block + 0x005c)
+#define UCLINUX_FIQ_VECTOR     (REG_BASE_cpu_block + 0x0060)
+
+/* where to store fiq/irq enable values */
+#define UCLINUX_IRQ_ENABLE      (REG_BASE_cpu_block + 0x0064)
+#define UCLINUX_FIQ_ENABLE      (REG_BASE_cpu_block + 0x0068)
+
+/* we use this in uClinux to handshake llad with the hardware library. llad will 
+   initialize the value to 0. As long as this value is 0, llad will mask the
+   triggered interrupt. When the CPUBlock is done loading the IRQ handler, it
+   will set this value to all the IRQ that are now being handled by itself. Next
+   time llad receives an IRQ, it will read this value and if set to the proper
+   interrupt value, it will return without masking the interrupt.
+   This value is a mask of all the IRQs handled by the IRQ handler (see em8xxx
+   hardware IRQ register).
+
+   *** IMPORTANT *** This value must be update in llad.c if changed.
+*/
+#define UCLINUX_LLAD_IRQHANDLER_HANDSHAKE    (REG_BASE_cpu_block + 0x006C)
+
+/* these symbols are used to store the entry point of the irqhandler
+   loaded by the bootloader.  when uclinux boots it overwrites the
+   interrupt vector, and when we load emhwlib we must restore the RUA
+   entry point in the vector. Since the current version of the emhwlib
+   loaded may not match the irqhandler loaded by bootloader, the entry
+   points should not be determined at compilation time, but rather at
+   runtime.
+*/
+#define IRQHANDLER_ENTRY   (REG_BASE_cpu_block + 0x0070) 
+#define FIQHANDLER_ENTRY   (REG_BASE_cpu_block + 0x0074) 
+#define UNDEFHANDLER_ENTRY (REG_BASE_cpu_block + 0x0078) 
+#define JUMPTABLE_ADDRESS  (REG_BASE_cpu_block + 0x007c)
+
+/* address of linux General exeption handler */
+#define LINUX_GE (REG_BASE_cpu_block + 0x0080)
+
+// random seeds (refer to gbuslib/include/gbus_random.h)
+#define RANDOM0              (REG_BASE_cpu_block + LR_RANDOM_SEED + 0)
+#define RANDOM1              (REG_BASE_cpu_block + LR_RANDOM_SEED + 4)
+
+#define PCI_INTERRUPT_ENABLE    (REG_BASE_cpu_block + LR_PCI_INTERRUPT_ENABLE)
+#define HOST_INTERRUPT_STATUS   (REG_BASE_cpu_block + LR_HOST_INTERRUPT_STATUS)
+
+// next 8 dword locations are for local debug, they are reset to 0 at vsync_init time.
+// Please do not affect them in cvs source.
+#define DEBUG_PROBE0                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x00)
+#define DEBUG_PROBE1                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x04)
+#define DEBUG_PROBE2                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x08)
+#define DEBUG_PROBE3                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x0c)
+#define DEBUG_PROBE4                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x10)
+#define DEBUG_PROBE5                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x14)
+#define DEBUG_PROBE6                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x18)
+#define DEBUG_PROBE7                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x1c)
+
+// uses 8 entries, up to 0x1EF0
+#define PARAM_VSYNC_PERIOD_DEC0        (REG_BASE_cpu_block + LR_VSYNC_PERIOD)  // video decoder 0
+
+#endif // __EMHWLIB_RESOURCES_SHARED_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_shared.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_shared.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_shared.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_shared.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,14 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_resources_shared.inc (generated from emhwlib/include/emhwlib_resources_shared.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_tango2.h linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_tango2.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_tango2.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_tango2.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,47 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_resources_tango2.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2004-01-28y
+*/
+
+#ifndef __EMHWLIB_RESOURCES_TANGO2_H__
+#define __EMHWLIB_RESOURCES_TANGO2_H__
+
+#define VSYNC_PARAM_MUTEX   ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex2))
+#define PCI_IRQ_MUTEX       ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex3))
+#define GFX_MUTEX           ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex4))
+#define HOST_MBUS_MUTEX     ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex5))
+#define SOFT_IRQ_MUTEX_TASK ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex6))
+#define SOFT_IRQ_MUTEX_IRQ  ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex7))
+#define SOFT_IRQ_MUTEX_FIQ  ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex8))
+#define RTC_IRQ_MUTEX       ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex9))
+#define XRPC_MUTEX          ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex10))
+#define XTASK_MUTEX         ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex11))
+#define IDMA_MUTEX          ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex12)) /* keep same as tango15 */
+#define TIMER_IRQ_MUTEX     ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex13)) 
+
+#define AUDIO_0_IRQ_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_audio_engine_0 + 4 * audio_mutex0))
+#define AUDIO_1_IRQ_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex0))
+#define VIDEO_0_FIFO_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_0  + 4 * mpeg_mutex0))
+#define VIDEO_1_FIFO_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_1  + 4 * mpeg_mutex0))
+#define DEMUX_IRQ_MUTEX     ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex0))
+#define DEMUX_EMHWLIB_MUTEX ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex4))
+#define TIMER_UPDATE_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex5))
+
+#define AUDIO_1_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex1))
+#define AUDIO_1_ENET_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex2))
+#define AUDIO_1_INTSTATUS_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex3))
+
+#endif // __EMHWLIB_RESOURCES_TANGO2_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_tango2.inc linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_tango2.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/emhwlib_resources_tango2.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/emhwlib_resources_tango2.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,14 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/tango2/emhwlib_resources_tango2.inc (generated from emhwlib/include/tango2/emhwlib_resources_tango2.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/fip.h linux-2.6.30-test/arch/mips/include/asm/tango2/fip.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/fip.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/fip.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,117 @@
+/*****************************************
+ *  Copyright  2001-2007
+ *  Sigma Designs, Inc. All Rights Reserved
+ *  Proprietary and Confidential
+ ******************************************/
+
+/*
+ * FIP related definitions, and function prototypes.
+ */
+#ifndef _FIP_H_
+#define _FIP_H_
+
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/ioctl.h>
+#endif /* __KERNEL__ */
+
+/* Valid symbols */
+#if defined(CONFIG_TANGOX_FIP_REF1)
+#define DVD_FIP_ON			0
+#define PLAY_FIP_ON			1
+#define DTS_FIP_ON			2
+#define MP3_FIP_ON			3
+#define DOLBYDIGITAL_FIP_ON		4
+#define MPEG4_FIP_ON			5
+#define PAUSE_FIP_ON			6
+#define DVI_FIP_ON              	7
+#define TWIRL_1_FIP_ON			8
+#define TWIRL_2_FIP_ON			9
+#define TWIRL_3_FIP_ON			10
+#define TWIRL_4_FIP_ON			11
+#define TWIRL_5_FIP_ON			12
+#define TWIRL_6_FIP_ON			13
+#define ALL_FIP_ON			14
+#define REPEAT_FIP_ON			15
+#define COLON_MIN_SEC_FIP_ON		16
+#define R1080_FIP_ON			17
+#define R720_FIP_ON			18
+#define COLON_HOUR_MIN_FIP_ON		19
+#define R480_FIP_ON			20
+#define PAL_FIP_ON			21
+#define NTSC_FIP_ON			22
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+#define DVD_FIP				201
+#define VCD_FIP				202
+#define MP3_FIP				203
+#define CD_FIP				204
+#define TITLE_FIP			205
+#define TRACK_CHAPTER_FIP		206
+#else
+#error Unsupport front panel.
+#endif
+
+/* Alignment */
+#define FIP_LEFT		0x0000	/* flags for fip_write_text() */
+#define FIP_CENTER		0x0001
+#define FIP_RIGHT		0x0002
+
+/* FIP Keys */
+#if defined(CONFIG_TANGOX_FIP_REF1)
+#define FIP_KEY_EJECT		0x00000004
+#define FIP_KEY_PREV		0x00000800
+#define FIP_KEY_NEXT		0x00008000
+#define FIP_KEY_FBWD		0x00000008
+#define FIP_KEY_FFWD		0x00000080
+#define FIP_KEY_PLAYPAUSE	0x00000040
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+#define FIP_KEY_EJECT		0x00000001
+#define FIP_KEY_PLAYPAUSE	0x00000002
+#define FIP_KEY_STOP		0x00000004
+#define FIP_KEY_PREV		0x00000008
+#define FIP_KEY_NEXT		0x00000010
+#define FIP_KEY_FBWD		0x00000020
+#define FIP_KEY_FFWD		0x00000040
+#define FIP_KEY_MENU		0x00000080
+#else
+#error Unsupport front panel.
+#endif
+
+#if defined(__KERNEL__) || !defined(BOOTLOADER)
+/* ioctl commands for user level applications*/
+#define FIP_IOC_MAGIC		'F'
+#define FIP_IOCSHOWSYMBOL	_IO(FIP_IOC_MAGIC, 0)
+#define FIP_IOCSHOWHMS		_IO(FIP_IOC_MAGIC, 1)
+#define FIP_IOCDISPCHAR		_IO(FIP_IOC_MAGIC, 2)
+#define FIP_IOCDISPRAW		_IO(FIP_IOC_MAGIC, 3)
+#define FIP_IOCDISPTEXT		_IO(FIP_IOC_MAGIC, 4)
+#define FIP_IOCCLEAR		_IO(FIP_IOC_MAGIC, 5)
+#define FIP_IOCGETFPTYPE	_IO(FIP_IOC_MAGIC, 6)
+#endif /* __KERNEL__ || !BOOTLOADER */
+
+#ifdef __KERNEL__
+static void fip_write_text(const int position, const char *text, const int flags);
+static int fip_show_hms(int hour, int minute, int second);
+static void fip_display_symbol(const int symbol, const int on);
+static int fip_display_character(const int position, const char character);
+static void fip_display_raw(const int byte, const int bit, const int on); 
+static int is_fip_busy(void);
+static void fip_wait_ready(void);
+static void fip_clear(void);
+#elif defined(BOOTLOADER)
+void fip_write_text(const int position, const char *text, const int flags);
+int fip_show_hms(int hour, int minute, int second);
+void fip_display_symbol(const int symbol, const int on);
+int fip_display_character(const int position, const char character);
+void fip_display_raw(const int byte, const int bit, const int on); 
+int is_fip_busy(void);
+void fip_wait_ready(void);
+void fip_clear(void);
+int fip_init(void);
+int fip_exit(void);
+unsigned long fip_readkey(void);
+#endif /* __KERNEL__ */
+
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/hardware.h linux-2.6.30-test/arch/mips/include/asm/tango2/hardware.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/hardware.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/hardware.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,127 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+#ifndef __HARDWARE_H
+#define __HARDWARE_H
+
+#include <linux/version.h>
+#include <asm/tango2/emhwlib_registers_tango2.h>
+#include <asm/tango2/tango2_gbus.h>
+
+// UART0
+#define CPU_uart0_gpio_dir	    (CPU_UART0_base + CPU_UART_GPIODIR)
+#define CPU_uart0_gpio_data	    (CPU_UART0_base + CPU_UART_GPIODATA)
+#define CPU_uart0_gpio_mode	    (CPU_UART0_base + CPU_UART_GPIOMODE)
+
+// UART0
+#define CPU_uart1_gpio_dir	    (CPU_UART1_base + CPU_UART_GPIODIR)
+#define CPU_uart1_gpio_data	    (CPU_UART1_base + CPU_UART_GPIODATA)
+#define CPU_uart1_gpio_mode	    (CPU_UART1_base + CPU_UART_GPIOMODE)
+
+#define MIPS_CPU_IRQ_BASE 0
+
+#if defined(CONFIG_TANGO2_SMP863X) && (EM86XX_REVISION <= 3)
+#define IRQ_CONTROLLER_IRQ_BASE 8
+#define FIQ_CONTROLLER_IRQ_BASE 40
+#define IIQ_CONTROLLER_IRQ_BASE 72 // bit31 of iiq is linux irq 103
+#define IRQ_COUNT               32 // 32 interrupt sources
+#elif defined(CONFIG_TANGO2_SMP863X) && (EM86XX_REVISION > 3)
+#define IRQ_CONTROLLER_IRQ_BASE 8
+#define FIQ_CONTROLLER_IRQ_BASE 72
+#define IIQ_CONTROLLER_IRQ_BASE 136 // bit31 of iiq is linux irq 199
+#define IRQ_COUNT               64  // 64 interrupt sources
+#else
+#error "Unsupported Tango2 chip."
+#endif
+
+#define IRQ_SOFTINT                     (IRQ_CONTROLLER_IRQ_BASE+0)   // gnet compatibility
+// IDE interrupts
+#define IRQ_IDECTRL_IDEDMA	(LOG2_CPU_DMAIDE_INT + IRQ_CONTROLLER_IRQ_BASE)
+#define IRQ_IDECTRL_IDE		(LOG2_CPU_IDE_INT + IRQ_CONTROLLER_IRQ_BASE)
+
+// MBUS interface
+#define MIF_add_offset		    0x0
+#define MIF_cnt_offset              (MIF_W0_CNT - MIF_W0_ADD) //0x04
+#define MIF_add2_skip_offset        (MIF_W0_SKIP - MIF_W0_ADD) //0x08
+#define MIF_cmd_offset              (MIF_W0_CMD - MIF_W0_ADD) //0x0c
+
+// GPIO
+#define GPIO_DIR_INPUT(gpio)        ((1 << (16 + (gpio))))
+#define GPIO_DIR_OUTPUT(gpio)       ((1 << (16 + (gpio))) | (1 << (gpio)))
+#define GPIO_DATA_SET(gpio)         ((1 << (16 + (gpio))) | (1 << (gpio)))
+#define GPIO_DATA_CLEAR(gpio)       ((1 << (16 + (gpio))))
+
+// UART GPIO
+#define UART_GPIO_DIR_INPUT(gpio)        ((1 << (8 + (gpio))))
+#define UART_GPIO_DIR_OUTPUT(gpio)       ((1 << (8 + (gpio))) | (1 << (gpio)))
+#define UART_GPIO_DATA_SET(gpio)         ((1 << (8 + (gpio))) | (1 << (gpio)))
+#define UART_GPIO_DATA_CLEAR(gpio)       ((1 << (8 + (gpio))))
+
+/* PCI Memories */
+#define MEMORY_BASE_PCI_CONFIG      0x50000000UL  /* PCI configuration */
+#define MEMORY_BASE_PCI_IO          0x58000000UL  /* PCI I/O space */
+#define MEMORY_BASE_PCI_MEMORY      0x60000000UL  /* PCI Memory Base */
+
+#define MAX_LOG2_PCIMEM_MAP  	7   	/* 2^7 = 128MB */
+#define MAX_PCIMEM_MAP_SIZE  	(((1<<MAX_LOG2_PCIMEM_MAP)*7)>>3)	/* Max ~112MB */
+
+#define PCIBIOS_MIN_MEM_EM86XX  (MEMORY_BASE_PCI_MEMORY + 0x10000000UL)   /* base address of EM86xx PCI slave */
+
+// Peripheral bus Registers
+#define HOST_pb0_base               0x0000
+#define HOST_pb_base_cs(n)          (HOST_pb0_base + (0x0200 * (n)))
+
+#define PB_timing_slot(n)	    (PB_timing0 + (0x04 * (n)))
+
+// Bus Master IDE
+#define REG_BASE_host_interface_BMIDE         (REG_BASE_host_interface + IDECTRL_pri_cmdblock)
+
+#define REG_BASE_host_interface_ISAIDE(x)  (REG_BASE_host_interface + HOST_pb_base_cs(x))
+
+#ifndef __ASSEMBLY__
+// Physical address mapping
+static inline unsigned long tangox_dma_address(unsigned long physaddr)
+{
+#ifndef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+	if (physaddr >= MEM_BASE_dram_controller_0_alias)
+		return(physaddr); /* for Tango2, it's the same */
+	else if (physaddr >= CPU_remap4_address) 
+		return(gbus_readl(REG_BASE_cpu_block + CPU_remap4) + (physaddr - CPU_remap4_address));
+	else if (physaddr >= CPU_remap3_address) 
+		return(gbus_readl(REG_BASE_cpu_block + CPU_remap3) + (physaddr - CPU_remap3_address));
+	else if (physaddr >= CPU_remap2_address) 
+		return(gbus_readl(REG_BASE_cpu_block + CPU_remap2) + (physaddr - CPU_remap2_address));
+#endif
+	return(physaddr); 
+}
+
+// Inverted physical address mapping
+static inline unsigned long tangox_inv_dma_address(unsigned long mapaddr)
+{
+#ifndef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+	if ((mapaddr >= MEM_BASE_dram_controller_0_alias) && (mapaddr < MEM_BASE_dram_controller_1))
+		return(mapaddr); /* for Tango2, it's the same */
+	else {
+		unsigned long remap;
+		remap = gbus_readl(REG_BASE_cpu_block + CPU_remap4);
+		if ((mapaddr >= remap) && (mapaddr < (remap + 0x04000000)))
+			return(CPU_remap4_address + (mapaddr - remap));
+		remap = gbus_readl(REG_BASE_cpu_block + CPU_remap3);
+		if ((mapaddr >= remap) && (mapaddr < (remap + 0x04000000)))
+			return(CPU_remap3_address + (mapaddr - remap));
+		remap = gbus_readl(REG_BASE_cpu_block + CPU_remap2);
+		if ((mapaddr >= remap) && (mapaddr < (remap + 0x04000000)))
+			return(CPU_remap2_address + (mapaddr - remap));
+	}
+#endif
+	return(mapaddr); /* for Tango2, it's the same */
+}
+#endif
+		
+#endif //__HARDWARE_H
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/ir.h linux-2.6.30-test/arch/mips/include/asm/tango2/ir.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/ir.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/ir.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,36 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+                                                                                
+/*
+ * IR related definitions, and function prototypes.
+ */
+#ifndef _IR_H_
+#define _IR_H_
+                                                                                
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/ioctl.h>
+#elif !defined(BOOTLOADER)
+#include <sys/ioctl.h>
+#endif /* __KERNEL__ */
+
+#if defined(__KERNEL__) || !defined(BOOTLOADER)
+/* ioctl commands for user level applications*/
+#define IR_IOC_MAGIC           'I'
+#define IR_IOCSETREPEATKEYS	_IO(IR_IOC_MAGIC, 0)
+#define IR_IOCGETREPEATKEYS	_IO(IR_IOC_MAGIC, 1)
+#define IR_IOCSETWAITPERIOD	_IO(IR_IOC_MAGIC, 2)
+#define IR_IOCGETWAITPERIOD	_IO(IR_IOC_MAGIC, 3)
+#define FIP_IOC_MAGIC		'F'
+#define FIP_IOCSHOWLED	_IO(FIP_IOC_MAGIC, 7)
+#endif /* __KERNEL__ || !BOOTLOADER */
+                                                                                
+#endif /* _IR_H_ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/memcfg.h linux-2.6.30-test/arch/mips/include/asm/tango2/memcfg.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/memcfg.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/memcfg.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,44 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/* For more memcfg operations */
+
+#ifndef _MEMCFG_H_
+#define _MEMCFG_H_
+
+#include <asm/tango2/tango2.h>
+#include <asm/tango2/rmem86xxid.h>
+#include <asm/tango2/emhwlib_lram.h>
+#include <asm/tango2/emhwlib_dram.h>
+
+static inline int is_valid_memcfg(memcfg_t *memcfg_ptr)
+{
+	unsigned int sum, i, *ptr;
+
+	if ((memcfg_ptr->signature) != MEMCFG_SIGNATURE)
+		return(0);
+	for (sum = i = 0, ptr = (unsigned int *)memcfg_ptr;
+		i < (sizeof(memcfg_t) / sizeof(unsigned int)); i++, ptr++)
+		sum += (*ptr);
+	return((sum == 0) ? 1 : 0);
+}
+
+static inline void gen_memcfg_checksum(memcfg_t *memcfg_ptr)
+{
+	unsigned int sum, i, *ptr;
+
+	memcfg_ptr->checksum = 0;
+	for (sum = i = 0, ptr = (unsigned int *)memcfg_ptr;
+		i < (sizeof(memcfg_t) / sizeof(unsigned int)); i++, ptr++)
+		sum += (*ptr);
+	memcfg_ptr->checksum = ~sum + 1;
+}
+
+#endif /* _MEMCFG_H_ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/rmdefs.h linux-2.6.30-test/arch/mips/include/asm/tango2/rmdefs.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/rmdefs.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/rmdefs.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,11 @@
+
+#ifndef __RMDEFS_H
+#define __RMDEFS_H
+
+typedef unsigned long RMuint32;
+typedef unsigned short RMuint16;
+typedef unsigned char RMuint8;
+typedef char RMascii;
+typedef int RMstatus;
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/rmem86xxid.h linux-2.6.30-test/arch/mips/include/asm/tango2/rmem86xxid.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/rmem86xxid.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/rmem86xxid.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,203 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   rmem86xxid.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2004-09-22
+*/
+
+#ifndef __RMEM86XXID_H__
+#define __RMEM86XXID_H__
+
+/*
+  the main chip ids 
+  
+  tango3 is for asic development (should be tango\infty)
+
+  Usually, users do not set by hand, but thru `rmcflags' helper
+*/
+#define EM86XX_CHIPID_MAMBO      1000
+#define EM86XX_CHIPID_MAMBOLIGHT 2000
+#define EM86XX_CHIPID_TANGO      3000
+#define EM86XX_CHIPID_TANGOLIGHT 4000
+#define EM86XX_CHIPID_TANGO15    4500
+#define EM86XX_CHIPID_TANGO2     5000
+#define EM86XX_CHIPID_TANGO3    10000
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_MAMBO)
+#define S_EM86XX_CHIPID "mambo"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_MAMBOLIGHT)
+#define S_EM86XX_CHIPID "mambolight"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGOLIGHT)
+#define S_EM86XX_CHIPID "tangolight"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO15)
+#define S_EM86XX_CHIPID "tango15"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO2)
+#define S_EM86XX_CHIPID "tango2"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO3)
+#define S_EM86XX_CHIPID "tango3"
+#else
+#error EM86XX_CHIP is not set
+#endif
+
+/* 
+  revisions...
+  
+  Referring to whatever is written at the surface of the BGA,
+  not the PCI revid / subid / etc. This detail is important for some chips
+  are ambiguous software wise.
+  
+  1: ES1
+  2: ES2
+  3: ES3
+  4: ES4 
+  5: ES5 
+  6: ES6 
+  65: revA
+  66: revB
+  67: revC
+  
+  No ID, but numbers. For a 8630ES2 for instance: build with
+  RMCFLAGS="... -DEM86XX_CHIP=EM86XX_CHIPID_TANGO2 -DEM86XX_REVISION=2 ..."
+
+  --------------------------------------------------------------------------
+  package writing          ES1  ES2  ES3  ES4     ES5     ES6  ES7  ES8  ES9 revA revB revC
+
+  EM86XX_REVISION            1    2    3    4       5       6    7    8    9  'A'  'B'  'C'
+
+  8600 `mambo' series                                                           1    2    3
+
+  8620 `tangolight' series                                                    (a)  (b) 0x82
+  8622 `tango15' series   0x81                (d)0x81                   0x82
+                                                                           ^this is the PCI revID
+
+  863x `tango2' series (c)0x81 0x81 0x81 0x82 (e)0x82 (f)0x83 0x84 0x85 0x86                
+
+  (a) don't remember
+  (b) no such chip
+  (c) 8630: FibbedES1 ES1 ES2 ES3 are the same chip
+  (d) 8622: ES1 and revA cannot be distinguished from revID. Software test impossible in practice
+  (e) 8630: ES4 and ES5 cannot be distinguished from revID. Software test with 0x6c900 bit12
+  (f) 8634: ES6 and RevA have the same revID (just different bonding option)
+      8634: ES7 and RevB have the same revID (just different bonding option)
+      8634: ES9 and RevC have the same revID (just different bonding option)
+  --------------------------------------------------------------------------
+
+  Usually, users do not set by hand, but thru `rmcflags' helper
+*/
+#ifndef EM86XX_REVISION
+#error EM86XX_REVISION is not set
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='A') 
+#error inconsistent: 863x revA is actually -DWITH_PROD=1 -DEM86XX_REVISION=6
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='B') 
+#error inconsistent: 863x revB is actually -DWITH_PROD=1 -DEM86XX_REVISION=7
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='C') 
+#error inconsistent: 863x revC is actually -DWITH_PROD=1 -DEM86XX_REVISION=9
+#endif
+
+#if (EM86XX_REVISION==1)
+#define S_EM86XX_REVISION "ES1"
+#elif (EM86XX_REVISION==2)
+#define S_EM86XX_REVISION "ES2"
+#elif (EM86XX_REVISION==3)
+#define S_EM86XX_REVISION "ES3"
+#elif (EM86XX_REVISION==4)
+#define S_EM86XX_REVISION "ES4"
+#elif (EM86XX_REVISION==5)
+#define S_EM86XX_REVISION "ES5"
+#elif (EM86XX_REVISION==6)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revA"
+#else
+#define S_EM86XX_REVISION "ES6"
+#endif
+#elif (EM86XX_REVISION==7)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revB"
+#else
+#define S_EM86XX_REVISION "ES7"
+#endif
+#elif (EM86XX_REVISION==8)
+#define S_EM86XX_REVISION "ES8"
+#elif (EM86XX_REVISION==9)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revC"
+#else
+#define S_EM86XX_REVISION "ES9"
+#endif
+
+#elif (EM86XX_REVISION=='A')
+#define S_EM86XX_REVISION "revA"
+#elif (EM86XX_REVISION=='B')
+#define S_EM86XX_REVISION "revB"
+#elif (EM86XX_REVISION=='C')
+#define S_EM86XX_REVISION "revC"
+#else
+#error complete revision strings
+#endif
+
+/* the compilation modes */
+#define EM86XX_MODEID_WITHHOST   1000
+#define EM86XX_MODEID_STANDALONE 2000
+
+/* the dsps */
+#define EM86XX_ENGINEID_MPEG0 10
+#define EM86XX_ENGINEID_MPEG1 11
+#define EM86XX_ENGINEID_AUDIO0 20
+#define EM86XX_ENGINEID_AUDIO1 21
+#define EM86XX_ENGINEID_DEMUX 30
+
+/* user does not have to set an engine id. This makes sense for mu only */
+#ifdef EM86XX_ENGINE
+#if (EM86XX_ENGINE==EM86XX_ENGINEID_MPEG0)
+#define SENG "mpeg0"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_MPEG1)
+#define SENG "mpeg1"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_AUDIO0)
+#define SENG "audio0"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_AUDIO1)
+#define SENG "audio1"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_DEMUX)
+#define SENG "demux"
+#else
+#endif // end of engine dependent stuff
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2)
+/*
+#if (defined(WITH_PROD) || defined(WITH_FACSPROD)) && !defined WITH_XLOADED_UCODE
+#error inconsistent flag combination.
+#endif
+
+#if (defined(WITH_PROD) || defined(WITH_FACSPROD)) && !defined WITH_IRQHANDLER_BOOTLOADER
+#error inconsistent flag combination.
+#endif
+*/
+#ifdef WITH_UCODE_BOOTLOADER
+#error inconsistent flag combination. You probably want WITH_XLOADED_UCODE
+#endif
+
+#endif
+
+/* the microcode debug mode */
+
+#define EM86XX_DEBUG_CHIP	1000
+#define EM86XX_DEBUG_SIMU	2000
+
+#endif // __RMEM86XXID_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/sigblock.h linux-2.6.30-test/arch/mips/include/asm/tango2/sigblock.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/sigblock.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/sigblock.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,261 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __SIG_BLOCK_H__
+#define __SIG_BLOCK_H__
+
+#define DEFAULT_IRQ_ROUTE1	0x55555555 /* All PCI IRQs route to LOG2_CPU_PCI_INTB */
+#define DEFAULT_IRQ_ROUTE2	0x00030000 /* ISA IDE uses LOG2_CPU_PCU_INTD, Timing slot 0 */
+#define DEFAULT_IRQ_RISE_EDGE_LO	0xff284a00 /* IRQ14 active low level, IRQ19/21 active riseedge */
+#define DEFAULT_IRQ_RISE_EDGE_HI	0x00000000 /* IRQ14 active low level, IRQ19/21 active rise edge */
+#define DEFAULT_IRQ_FALL_EDGE_LO	0x00004000
+#define DEFAULT_IRQ_FALL_EDGE_HI	0x00000000
+#define DEFAULT_IRQ_GPIO_MAP	0x0607080d /* ISA IDE/GPIO 6, PCI/GPIO 8 */
+#define DEFAULT_DEV_ENABLED	0x00003cf7 /* ISAIDE/BMIDE/PCIHOST/IR/FIP/I2CM/I2CS/PCI1-4 enabled */
+#define DEFAULT_PB_DEF_TIMING	0x01090008
+#define DEFAULT_PB_CS_CONFIG	0x00001044
+#define DEFAULT_PB_TIMING0	0x01090008
+#define DEFAULT_PB_USE_TIMING0	0x000001f4
+#define DEFAULT_PB_TIMING1	0x00110101
+#define DEFAULT_PB_USE_TIMING1	0x000003f3
+#define DEFAULT_PB_TIMING2	0
+#define DEFAULT_PB_USE_TIMING2	0
+#define DEFAULT_PB_TIMING3	0
+#define DEFAULT_PB_USE_TIMING3	0
+#define DEFAULT_PB_TIMING4	0
+#define DEFAULT_PB_USE_TIMING4	0
+#define DEFAULT_PB_TIMING5	0
+#define DEFAULT_PB_USE_TIMING5	0
+
+#define DEFAULT_SYSCLK_PLL	0x0 /* Set by XOS */
+#define DEFAULT_SYSCLK_DIV	0x0 /* Not changed */
+
+#define DEFAULT_ETH_MAC_HI	0x00000000 /* MAC address */
+#define DEFAULT_ETH_MAC_LO	0x00000000
+
+/* This list of devices in the enable list field (irq_route2) */
+#define ISAIDE_SHIFT		0
+#define BMIDE_SHIFT		1
+#define PCIHOST_SHIFT		2
+#define ETHERNET_SHIFT		3
+#define IR_SHIFT		4
+#define FIP_SHIFT		5	
+#define I2CM_SHIFT		6
+#define I2CS_SHIFT		7
+#define SDIO_SHIFT		8
+#define USB_SHIFT		9
+#define PCI1_SHIFT		10
+#define PCI2_SHIFT		11
+#define PCI3_SHIFT		12
+#define PCI4_SHIFT		13
+#define PCI5_SHIFT		14
+#define PCI6_SHIFT		15
+#define SATA_SHIFT		16
+#define SCARD_SHIFT		17
+#define GNET_SHIFT		18
+/*				19-32: undefined */
+
+#ifndef __ASSEMBLY__
+
+struct hwinfo {
+	unsigned long sysclk_pll; /* The setting for the PLL */
+	unsigned long sysclk_div;
+
+	/* Only 4 IRQs can be used for PCI devices (LOG2_CPU_PCI_INTA-D,
+	   so we can encode it in 2 bits. Each device can have 4 IRQ
+	   routing and as as result we can use one byte to represent
+	   the IRQ route for a given device (IDSELx). Bu using 8 bytes,
+	   we can represent the PCI devices (IDSEL1-6, 5-6 reserved) as
+	   well as ISA IDE information and device enabling list*/
+	unsigned long irq_route1;	/* PCI dev 1-4 */
+
+	/* PCI dev 5-6, ISA IDE information, device enabling list */
+	unsigned long irq_route2;	/* PCI dev 5-6: bit 0-15 */
+					/* ISA IDE: bit 16-17: IRQ offset */
+
+	unsigned long irq_rise_edge_hi; /* Rising edge config */
+	unsigned long irq_rise_edge_lo; /* Rising edge config */
+	unsigned long irq_fall_edge_hi; /* Falling edge config */
+	unsigned long irq_fall_edge_lo; /* Falling edge config */
+
+	unsigned long gpio_irq_map; /* GPIO pins hook to IRQ13..16 */
+	unsigned long dev_enabled;  /* Device enabling list*/
+
+	unsigned long pb_def_timing;
+	unsigned long pb_cs_config;
+	unsigned long pb_timing0;
+	unsigned long pb_use_timing0;
+	unsigned long pb_timing1;
+	unsigned long pb_use_timing1;
+	unsigned long pb_timing2;
+	unsigned long pb_use_timing2;
+	unsigned long pb_timing3;
+	unsigned long pb_use_timing3;
+	unsigned long pb_timing4;
+	unsigned long pb_use_timing4;
+	unsigned long pb_timing5;
+	unsigned long pb_use_timing5;
+
+	unsigned long mac_hi;	/* Ethernet MAC address */
+	unsigned long mac_lo;
+};
+
+/* Definition of signature block (192bytes), which should start at 0xbfc00000 */
+/* There'll be 20bytes sha1sum afterward (0xbfc000c0-0xbfc000d3) */
+struct signature_block {
+	unsigned long opcodes[2];  /* For opcodes, fixed value 0x10000034/0x00000000 */
+	struct hwinfo hwinfo;
+	/* 
+	   zboot or such specific extensions 
+
+	   Note that YAMON requires extension[2]=0x1105e0 (product ID `thirdparty')
+	 */
+	unsigned long extension[20];	
+};
+
+//RMmustBeEqual(sizeof(struct signature_block),3*64,seed0);
+
+#ifdef __EMHWLIB_REGISTERS_TANGO2_H__
+static inline int isaide_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> ISAIDE_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int bmide_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> BMIDE_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int sata_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SATA_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int scard_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SCARD_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int gnet_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> GNET_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int pci_host_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> PCIHOST_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int ethernet_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> ETHERNET_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int ir_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> IR_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int fip_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> FIP_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int i2cm_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> I2CM_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int i2cs_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> I2CS_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int sdio_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SDIO_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int usb_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> USB_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int pcidev_enabled(const struct signature_block *sigptr, int pci_idsel)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> (pci_idsel - 1 + PCI1_SHIFT)) & 1) != 0) ? 1 : 0);
+}
+
+/* Given PCI device idsel number and INT number, returning the IRQ number
+   for it */
+static inline int pcidev_intr_num(const struct signature_block *sigptr,
+				const int pci_idsel, const int int_num)
+{
+	unsigned long route;
+	int irq;
+
+	if (pcidev_enabled(sigptr, pci_idsel) == 0)
+		return(-1);
+	else if ((pci_idsel >= 1) && (pci_idsel <= 4)) {
+		/* Get the routing information for specific device */
+		route = ((sigptr->hwinfo.irq_route1) >> ((pci_idsel - 1) * 8)) & 0xff;
+		irq = (int)((route >> (int_num * 2)) & 0x3); /* int_num: 0-3 = INTA-D */
+	} else if ((pci_idsel >= 5) && (pci_idsel <= 6)) {
+		/* Get the routing information for specific device */
+		route = ((sigptr->hwinfo.irq_route2) >> ((pci_idsel - 5) * 8)) & 0xff;
+		irq = (int)((route >> (int_num * 2)) & 0x3); /* int_num: 0-3 = INTA-D */
+	} else 
+		return(-1);
+
+	return(LOG2_CPU_PCI_INTA + irq);
+}
+ 
+/* Find out the CS# used by ISA IDE */
+static inline int isaide_cs_select(const struct signature_block *sigptr)
+{
+	unsigned long cs_config = (sigptr->hwinfo.pb_cs_config >> 12) & 0xf;
+	int i;
+
+	if (isaide_enabled(sigptr) == 0)
+		return(-1);
+
+	for (i = 0; i < 4; i++) {
+		if ((cs_config & 0x1) != 0) 
+			return(i);
+		else
+			cs_config >>= 1;
+	}
+	return(-1);
+}
+
+/* Return the IRQ number for ISA IDE */
+static inline int isaide_intr_num(const struct signature_block *sigptr)
+{
+	int irq;
+
+	if (isaide_enabled(sigptr) == 0)
+		return(-1);
+	else
+		irq = (int)(((sigptr->hwinfo.irq_route2) >> 16) & 0x3);
+	return(LOG2_CPU_PCI_INTA + irq);
+}
+
+static inline int isaide_timing_slot(const struct signature_block *sigptr)
+{
+	unsigned long slot;
+
+	slot = ((sigptr->hwinfo.irq_route2) >> 18) & 0x7;
+	return((int)slot);
+}
+#endif /* __EMHWLIB_REGISTERS_TANGO2_H__ */
+
+#endif /* !__ASSEMBLY__ */
+
+#endif /* !__SIG_BLOCK_H__ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/sigblock.inc linux-2.6.30-test/arch/mips/include/asm/tango2/sigblock.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/sigblock.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/sigblock.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,59 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/sigblock.inc (generated from emhwlib_hal/include/sigblock.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+DEFAULT_IRQ_ROUTE1=0x55555555
+DEFAULT_IRQ_ROUTE2=0x30000
+DEFAULT_IRQ_RISE_EDGE_LO=0xff284a00
+DEFAULT_IRQ_RISE_EDGE_HI=0x0
+DEFAULT_IRQ_FALL_EDGE_LO=0x4000
+DEFAULT_IRQ_FALL_EDGE_HI=0x0
+DEFAULT_IRQ_GPIO_MAP=0x607080d
+DEFAULT_DEV_ENABLED=0x3cf7
+DEFAULT_PB_DEF_TIMING=0x1090008
+DEFAULT_PB_CS_CONFIG=0x1044
+DEFAULT_PB_TIMING0=0x1090008
+DEFAULT_PB_USE_TIMING0=0x1f4
+DEFAULT_PB_TIMING1=0x110101
+DEFAULT_PB_USE_TIMING1=0x3f3
+DEFAULT_PB_TIMING2=0x0
+DEFAULT_PB_USE_TIMING2=0x0
+DEFAULT_PB_TIMING3=0x0
+DEFAULT_PB_USE_TIMING3=0x0
+DEFAULT_PB_TIMING4=0x0
+DEFAULT_PB_USE_TIMING4=0x0
+DEFAULT_PB_TIMING5=0x0
+DEFAULT_PB_USE_TIMING5=0x0
+DEFAULT_SYSCLK_PLL=0x0
+DEFAULT_SYSCLK_DIV=0x0
+DEFAULT_ETH_MAC_HI=0x0
+DEFAULT_ETH_MAC_LO=0x0
+ISAIDE_SHIFT=0x0
+BMIDE_SHIFT=0x1
+PCIHOST_SHIFT=0x2
+ETHERNET_SHIFT=0x3
+IR_SHIFT=0x4
+FIP_SHIFT=0x5
+I2CM_SHIFT=0x6
+I2CS_SHIFT=0x7
+SDIO_SHIFT=0x8
+USB_SHIFT=0x9
+PCI1_SHIFT=0xa
+PCI2_SHIFT=0xb
+PCI3_SHIFT=0xc
+PCI4_SHIFT=0xd
+PCI5_SHIFT=0xe
+PCI6_SHIFT=0xf
+SATA_SHIFT=0x10
+SCARD_SHIFT=0x11
+GNET_SHIFT=0x12
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2.h linux-2.6.30-test/arch/mips/include/asm/tango2/tango2.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/tango2.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,65 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   tango2.h
+  @brief  
+
+  <long description>
+
+  @author Emmanuel Michon
+  @date   2004-05-10
+*/
+
+#ifndef __TANGO2_H__
+#define __TANGO2_H__
+#include <asm/tango2/hardware.h>
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO2
+#include <asm/tango2/rmem86xxid.h>
+#include <asm/tango2/emhwlib_lram.h>
+#include <asm/tango2/emhwlib_resources_tango2.h>
+#ifndef CONFIG_TANGOX_BASE_FREQUENCY
+#define TANGOX_BASE_FREQUENCY	27000000 
+#endif
+/* Baudrate setting */
+#if defined(CONFIG_TANGO2_SMP863X)
+#ifndef CONFIG_TANGOX_BASE_BAUD
+#define TANGOX_BASE_BAUD 38400
+#else
+#define TANGOX_BASE_BAUD CONFIG_TANGOX_BASE_BAUD
+#endif
+//#define TANGOX_CPU_FREQUENCY 333000000
+#else
+#error "Unsupported platform"
+#endif /* CONFIG_TANGO2_SMP863X */
+
+/* Memory size used by Linux */
+#ifndef CONFIG_TANGOX_MEMSIZE
+#if defined(CONFIG_TANGO2_SMP863X)
+#define  TANGOX_SYSTEMRAM_ACTUALSIZE   (32*1024*1024)
+#else
+#error "Unsupported platform"
+#endif /* CONFIG_TANGO2_SMP863X */
+#else
+#define TANGOX_SYSTEMRAM_ACTUALSIZE    CONFIG_TANGOX_MEMSIZE
+#endif /* !CONFIG_TANGOX_MEMSIZE */
+
+#define TANGOX_CTRLIRQ 0
+#define TANGOX_CTRLFIQ 1
+#define TANGOX_CTRLIIQ 2
+
+#if defined(CONFIG_TANGO2_SMP863X)
+#if (EM86XX_REVISION <= 3)
+#define SYS_clkgen_pll        SYS_clkgen3_pll
+#else /* For ES4 or above */
+#define SYS_clkgen_pll        SYS_clkgen3_pll
+#endif
+#endif
+
+#endif // __TANGO2_H__
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2_gbus.h linux-2.6.30-test/arch/mips/include/asm/tango2/tango2_gbus.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2_gbus.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/tango2_gbus.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,147 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+  Refer to bug #3644.
+
+  TLB-based implementation works on the ranges:
+  [0x00000000..0x20000000[ access thru kseg1
+  [0x20000000..0x2xxxxxxx (size  of dram1, a  parameter of ioremap())[
+  access thru tlb. Outside: unpredictable/oops.
+
+  Remap-based implementation does:
+  00xy b27b26..b0 to 101y(b27|x)b26..b0.
+  and works  everywhere excepted ranges:  [0x18000000..0x20000000[ and
+  [0x28000000..0xffffffff]
+
+  Test with
+  {
+	volatile int q=gbus_read_uint32(pGBus,0x1020212c); // correct
+	q=gbus_read_uint32(pGBus,0x1f20212c);              // incorrect
+	q=gbus_read_uint32(pGBus,0x2020212c);              // correct
+	q=gbus_read_uint32(pGBus,0x2720212c);              // correct
+	q=gbus_read_uint32(pGBus,0x2820212c);              // incorrect
+	q=gbus_read_uint32(pGBus,0x2f20212c);              // incorrect
+  }
+*/
+
+#ifndef __TANGO2_GBUS_H
+#define __TANGO2_GBUS_H
+
+//#include <linux/config.h>
+
+#ifndef __ASSEMBLY__
+
+#include "rmdefs.h"
+
+#include <asm/addrspace.h>
+
+struct gbus;
+#define pGBus ((struct gbus *)1)
+
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+
+__asm__ (
+	"	.macro gbus_swizzle_addr res tmp addr			\n"
+	"	ext	\\res, \\addr, 29, 1				\n"
+	"	bnez	\\res, 1f					\n"
+	"	lui	\\tmp, 0xa000					\n"
+	"	or	\\res, \\tmp, \\addr				\n"
+	"	j	2f						\n"
+	"	nop							\n"
+	"1:								\n"
+	"	lui	\\tmp, 0x2000					\n"
+	"	sub	\\res, \\addr, \\tmp				\n"
+	"	lw	\\tmp, em86xx_tlb_dram1_map_base		\n"
+	"	add	\\res, \\tmp					\n"
+	"2:								\n"
+	"	.endm");
+
+#else
+
+__asm__ (
+	"	.macro gbus_swizzle_addr res tmp addr			\n"
+	"	rotr	\\res, \\addr, 29				\n"
+	"	ins	\\res, \\res, 30, 1				\n"
+	"	or	\\res, 5					\n"
+	"	rotr	\\res, 3					\n"
+	"	.endm");
+#endif
+
+
+/*
+ * we just want to set kseg1 bit, most of the time address is known at
+ * compile time, so this will usually be reduced to 2 instructions
+ */
+
+#define BUILD_GBUS_READ(size)						\
+static inline RMuint32 gbus_read_dram_uint##size(struct gbus *pgbus,	\
+					    RMuint32 byte_address)	\
+{									\
+	if (__builtin_constant_p(byte_address)) {			\
+		if ((byte_address & 0x70000000) == 0x20000000) {	\
+			byte_address &= ~0x20000000;			\
+			byte_address |= 0x08000000;			\
+		}							\
+		return *((volatile RMuint##size *)KSEG1ADDR(byte_address)); \
+	} else {							\
+		RMuint32 res, tmp;					\
+									\
+		__asm__ __volatile(					\
+			"gbus_swizzle_addr\t%0 %1 %2\n"			\
+			: "=&r" (res), "=&r" (tmp) : "r" (byte_address)); \
+		return *((volatile RMuint##size *)res);			\
+	}								\
+}
+
+BUILD_GBUS_READ(8);
+BUILD_GBUS_READ(16);
+BUILD_GBUS_READ(32);
+
+#define BUILD_GBUS_WRITE(size)						\
+static inline void gbus_write_dram_uint##size(struct gbus *pgbus,	\
+				     RMuint32 byte_address,		\
+				     RMuint##size data)			\
+{									\
+	if (__builtin_constant_p(byte_address)) {			\
+		if ((byte_address & 0x70000000) == 0x20000000) {	\
+			byte_address &= ~0x20000000;			\
+			byte_address |= 0x08000000;			\
+		}							\
+		*((volatile RMuint##size *)KSEG1ADDR(byte_address)) = data; \
+	} else {							\
+		RMuint32 res, tmp;					\
+									\
+		__asm__ __volatile(					\
+			"gbus_swizzle_addr\t%0 %1 %2\n"			\
+			: "=&r" (res), "=&r" (tmp) : "r" (byte_address)); \
+		*((volatile RMuint##size *)res) = data;			\
+	}								\
+}
+
+BUILD_GBUS_WRITE(8);
+BUILD_GBUS_WRITE(16);
+BUILD_GBUS_WRITE(32);
+
+RMuint32 gbus_read_uint32(struct gbus *pgbus, RMuint32 byte_address);
+RMuint16 gbus_read_uint16(struct gbus *pgbus, RMuint32 byte_address);
+RMuint8 gbus_read_uint8(struct gbus *pgbus, RMuint32 byte_address);
+void gbus_write_uint32(struct gbus *pgbus, RMuint32 byte_address, RMuint32 data);
+void gbus_write_uint16(struct gbus *pgbus, RMuint32 byte_address, RMuint16 data);
+void gbus_write_uint8(struct gbus *pgbus, RMuint32 byte_address, RMuint8 data);
+
+#define gbus_readl(r)		gbus_read_uint32(pGBus, (r))
+#define gbus_writel(r, v)	gbus_write_uint32(pGBus, (r), (v))
+#define gbus_readw(r)		gbus_read_uint16(pGBus, (r))
+#define gbus_writew(r, v)	gbus_write_uint16(pGBus, (r), (v))
+#define gbus_readb(r)		gbus_read_uint8(pGBus, (r))
+#define gbus_writeb(r, v)	gbus_write_uint8(pGBus, (r), (v))
+
+#endif /* !__ASSEMBLY__ */
+#endif /* __TANGO2_GBUS_H */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2_usb.h linux-2.6.30-test/arch/mips/include/asm/tango2/tango2_usb.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2_usb.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/tango2_usb.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,38 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __TANGO2_USB_H
+#define __TANGO2_USB_H
+
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+
+#define TANGOX_EHCI_IRQ	(IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_EHCI_INT)
+#define TANGOX_OHCI_IRQ	(IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_OHCI_INT)
+
+#define TANGOX_EHCI_BASE_ADDR		(REG_BASE_host_interface + 0x1400)
+#define TANGOX_OHCI_BASE_ADDR		(REG_BASE_host_interface + 0x1500)
+#define TANGOX_USB_CTL_STATUS_REG_BASE	(REG_BASE_host_interface + 0x1700)
+
+/*
+ * helpers to access USB registers
+ */
+#define RD_OHCI_REG32(r)	\
+		gbus_readl(TANGOX_OHCI_BASE_ADDR + (r))
+
+#define WR_OHCI_REG32(r, v)	\
+		gbus_writel(TANGOX_OHCI_BASE_ADDR + (r), (v))
+
+#define RD_USB_REG32(r)	\
+		gbus_readl(TANGOX_USB_CTL_STATUS_REG_BASE + (r))
+
+#define WR_USB_REG32(r, v)	\
+		gbus_writel(TANGOX_USB_CTL_STATUS_REG_BASE + (r), (v))
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2api.h linux-2.6.30-test/arch/mips/include/asm/tango2/tango2api.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango2/tango2api.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango2/tango2api.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,118 @@
+/*
+ * arch/mips/include/asm/tango2/tangoa2pi.h
+ *
+ * Copyright 2002-2007, Sigma Designs, Inc 
+ *
+ * This file contains SMP86XX controling functions
+ *
+ */
+
+#ifndef __ASM_ARCH_EM86XX_H
+#define __ASM_ARCH_EM86XX_H
+#include <asm/tango2/hardware.h>
+//
+// global variables
+// 
+
+//
+// from arch/arm/arch-em86xx/irq.c
+//
+
+// irq
+void em86xx_mask_irq(unsigned int irq);
+void em86xx_unmask_irq(unsigned int irq);
+void em86xx_wait_irq(unsigned int irq);
+
+// fiq
+void em86xx_mask_fiq(unsigned int fiq);
+void em86xx_unmask_fiq(unsigned int fiq);
+
+// software interrupt
+int em86xx_softirq_isset(int irq);
+void em86xx_softirq_set(int irq);
+void em86xx_softirq_clr(int irq);
+void em86xx_irq_clr(int irq);
+
+//
+// from arch/arm/arch-em86xx/em86xxapi.c
+//
+
+// Cache
+// clean : write dirty buffer (D cache only)
+// invalidate : invalidate the contents of cache (I & D cache)
+// flush : clean + invalidate
+void em86xx_get_cache_state(int *picache, int *pdcache, int *pwriteback);
+void em86xx_enable_cache(int icache, int dcache, int writeback);
+void em86xx_clean_cache_data(void);
+void em86xx_clean_cache_data_region(unsigned int from, unsigned int to);
+void em86xx_invalidate_cache_instruction(void);
+void em86xx_invalidate_cache_instruction_region(unsigned int from, unsigned int to);
+void em86xx_invalidate_cache_data(void);
+void em86xx_invalidate_cache_data_region(unsigned int from, unsigned int to);
+
+void em86xx_flush_cache_all(void);
+void em86xx_flush_cache_data(void);
+void em86xx_flush_cache_data_region(unsigned int from, unsigned int to);
+
+// memory
+unsigned int em86xx_get_pciregionsize(void);
+unsigned int em86xx_get_dmamemorysize(void);
+
+// switchbox (Host interface)
+enum { 
+	SBOX_MBUS_W0 = 0, SBOX_MBUS_W1, SBOX_PCIMASTER, SBOX_PCISLAVE, 
+	SBOX_SATA1, SBOX_IDEFLASH, SBOX_IDEDVD, SBOX_UNUSED1, SBOX_MAX
+};
+
+int em86xx_sbox_init(void);
+#if 0
+void em86xx_sbox_reset(void);
+int em86xx_sbox_setup(void);
+int em86xx_sbox_connect(int iface);
+void em86xx_sbox_disconnect(int port);
+#endif
+
+// MBUS DMA 
+typedef void (*mbus_irq_handler_t)(int irq, void *arg);
+
+int em86xx_mbus_init(void);
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any);
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox);
+
+int em86xx_mbus_setup_dma_common(unsigned int regbase, unsigned int addr, unsigned int count, mbus_irq_handler_t handler, void *arg, unsigned int flags);
+void em86xx_mbus_setup_dma_linear(unsigned int regbase, unsigned int addr, unsigned int count, unsigned int flags);
+void em86xx_mbus_setup_dma_double(unsigned int regbase, unsigned int addr, unsigned int count, unsigned int addr2, unsigned int count2, unsigned int flags);
+void em86xx_mbus_setup_dma_rectangle(unsigned int regbase, unsigned int addr, unsigned int horiz, unsigned int lines, int skip, unsigned int flags);
+void em86xx_mbus_setup_dma_void(unsigned int regbase);
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr, unsigned int count, mbus_irq_handler_t handler, void *arg, unsigned int flags);
+int em86xx_mbus_inuse(unsigned int regbase);
+int em86xx_mbus_wait(unsigned int regbase, int sbox);
+int mbus_memcpy(unsigned int regbase, unsigned int src, unsigned int dst, unsigned int size);
+
+// PCI master
+void em86xx_pcimaster_setup_read(unsigned int addr, unsigned int count);
+void em86xx_pcimaster_start_read(int start);
+void em86xx_pcimaster_setup_write(unsigned int addr, unsigned int count);
+void em86xx_pcimaster_start_write(int start);
+
+// GPIO
+#define GPIO_INPUT		0
+#define GPIO_OUTPUT		1
+
+int em86xx_gpio_read(int gpio);
+void em86xx_gpio_write(int gpio, int data);
+void em86xx_gpio_setdirection(int gpio, int dir);
+
+#if defined(CONFIG_EM86XX_UART0_AS_GPIO_FULL) || defined(CONFIG_EM86XX_UART0_AS_GPIO_PARTIAL)
+int em86xx_uart0_gpio_read(int gpio);
+void em86xx_uart0_gpio_write(int gpio, int data);
+void em86xx_uart0_gpio_setdirection(int gpio, int dir);
+#endif
+#if defined(CONFIG_EM86XX_UART1_AS_GPIO_FULL) || defined(CONFIG_EM86XX_UART1_AS_GPIO_PARTIAL)
+int em86xx_uart1_gpio_read(int gpio);
+void em86xx_uart1_gpio_write(int gpio, int data);
+void em86xx_uart1_gpio_setdirection(int gpio, int dir);
+#endif
+
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,67 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_dram.h
+  @brief  
+
+  fm stands for: first megabyte.
+
+  THE CODE USING THESE SYMBOLS ASSUMES THAT THE END BOUNDARY OF AN
+  ENTITY IS THE START BOUNDARY OF THE NEXT ENTITY
+  
+  htoinc.pl emhwlib_dram.h emhwlib_dram.inc
+  
+  @author Emmanuel Michon
+  @date   2004-07-26
+*/
+
+#ifndef __EMHWLIB_DRAM_H__
+#define __EMHWLIB_DRAM_H__
+
+#if EM86XX_CHIP>=EM86XX_CHIPID_TANGO3
+#include "emhwlib_dram_tango3.h"
+#elif EM86XX_CHIP>=EM86XX_CHIPID_TANGO2
+#include "emhwlib_dram_tango2.h"
+#else
+#include "emhwlib_dram_others.h"
+#endif
+
+#define MEMCFG_SIGNATURE	0x6766636d // `m' `c' `f' `g'
+
+#ifndef __ASSEMBLY__
+
+/* This is the memory map data structure, the size is 64 bytes */
+typedef struct {
+	unsigned int signature;                                                           // ...fc0
+	unsigned int dram0_size;            /* The size of DRAM0 */
+	unsigned int dram1_size;            /* The size of DRAM1 */
+	unsigned int dram2_size;            /* The size of DRAM2 */
+	unsigned int dram0_removable_topreserved;     /* The size of top reserved in DRAM0   ...fd0 */
+	unsigned int dram1_removable_topreserved;     /* The size of top reserved in DRAM1 */
+	unsigned int dram0_top_removable_area;    /* for special use such as splash screen */ 
+	                                          /* users can use set and get properties on the memory reserved by this variable */
+	unsigned int dram0_fixed_topreserved;     /* The size of top reserved in DRAM0 */
+	unsigned int dram1_fixed_topreserved;     /* The size of top reserved in DRAM1       ...fe0 */
+	unsigned int dram2_fixed_topreserved;     /* The size of top reserved in DRAM2 */
+	unsigned int kernel_end;            /* The end offset of kernel */
+	unsigned int checksum;		    /* The checksum */
+#if EM86XX_CHIP>=EM86XX_CHIPID_TANGO2
+	unsigned int dram1_kernel_end;	    /* The end offset of kernel used data in second dram */
+	unsigned int curtainA0;                                                      
+	unsigned int curtainB0;
+	unsigned int curtainC;
+#else
+	unsigned int reserved[4];           /* Reserved for extension */
+#endif
+} memcfg_t;
+
+#endif /* __ASSEMBLY__ */
+
+#endif // __EMHWLIB_DRAM_H__
+ 
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_others.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_others.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_others.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_others.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,37 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_dram_others.h
+  @brief  
+
+  Addresses appear in increasing order. It is assumed
+  that computing FM_IRQHANDLER_STACKTOP_USR-FM_IRQHANDLER_CODE
+  is a proper way to access the max usable size for
+  FM_IRQHANDLER_CODE.
+
+  @author Emmanuel Michon
+  @date   2005-04-11
+*/
+
+#ifndef __EMHWLIB_DRAM_OTHERS_H__
+#define __EMHWLIB_DRAM_OTHERS_H__
+
+#define FM_MEMCFG                  0x00000fc0
+#define FM_IRQHANDLER_API          0x00001000
+#define FM_IRQHANDLER_CODE         0x00011000
+#define FM_IRQHANDLER_STACKTOP_USR 0x00040000 /* defined, but never used */
+#define FM_IRQHANDLER_STACKTOP_IRQ 0x00048000
+#define FM_IRQHANDLER_STACKTOP_FIQ 0x00050000
+#define FM_STACKTOP_SVC            0x00058000
+#define FM_DRM			   0x00058000
+#define FM_GNET			   0x00058000 /* incompatible with DRM */
+#define FM_BOOTLOADER_CODE         0x00060000
+#define FM_RESERVED                0x00080000 /* The size reserved */
+
+#endif // __EMHWLIB_DRAM_OTHERS_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_others.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_others.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_others.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_others.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,25 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_dram_others.inc (generated from emhwlib/include/emhwlib_dram_others.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+FM_MEMCFG=0xfc0
+FM_IRQHANDLER_API=0x1000
+FM_IRQHANDLER_CODE=0x11000
+FM_IRQHANDLER_STACKTOP_USR=0x40000
+FM_IRQHANDLER_STACKTOP_IRQ=0x48000
+FM_IRQHANDLER_STACKTOP_FIQ=0x50000
+FM_STACKTOP_SVC=0x58000
+FM_DRM=0x58000
+FM_GNET=0x58000
+FM_BOOTLOADER_CODE=0x60000
+FM_RESERVED=0x80000
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_tango3.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,49 @@
+/*****************************************
+ Copyright  2004-2005
+ Sigma Designs, Inc. All Rights Reserved
+ Proprietary and Confidential
+ *****************************************/
+/**
+  @file   emhwlib_dram_tango2.h
+  @brief  
+
+  Addresses appear in increasing order. It is assumed that computing
+  FM_Y-FM_X is a proper way to access the max usable size for FM_X.
+
+  See SMP8630 software spec 3.3
+
+  @author Emmanuel Michon, YH Lin, Julien Soulier
+  @date   2005-04-06
+*/
+
+#ifndef __EMHWLIB_DRAM_TANGO2_H__
+#define __EMHWLIB_DRAM_TANGO2_H__
+
+/* Spec 3.3.5: stage (S4) [fully functional player memory map] */
+#define FM_GNET                    0x00000000
+#define FM_SCRATCH                 0x00000f08 /* 184 bytes */
+#define FM_MEMCFG                  0x00000fc0
+#define FM_IRQHANDLER_API          0x00001000
+#define FM_XTASK_API               0x00009e00 /* 512 bytes */
+#define FM_XOSDBG                  0x0000a000
+#define FM_XTASK1DBG               0x0000c000
+#define FM_XTASK2DBG               0x0000d000
+#define FM_XTASK3DBG               0x0000e000
+#define FM_XTASK4DBG               0x0000f000
+#define FM_SCRATCH2                0x00010000
+#define FM_DRAMCALIBRATION         0x0001f000
+#define FM_RESERVED                0x00020000
+
+/*
+  Spec 3.3.5: stage (S0) [bootstrap memory map]
+
+  Because you will use zboot/yamon to download linux/CE
+  at start of DRAM, the former are away from beginning.
+*/
+#define FM_ZBOOT                   0x01000000
+#define FM_YAMON_text_ram          0x01000000
+#define FM_YAMON__ftext_init       0x01200000
+#define FM_yamon_appl__ftext       0x01210000
+#define FM_linuxmips__ftext        0x00020000
+
+#endif // __EMHWLIB_DRAM_TANGO2_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_tango3.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_tango3.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_dram_tango3.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_dram_tango3.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,32 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_dram_tango2.inc (generated from emhwlib/include/emhwlib_dram_tango2.h)
+#*
+#* Copyright (c) Sigma Designs, Inc. 2003. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+FM_GNET=0x0
+FM_SCRATCH=0xf08
+FM_MEMCFG=0xfc0
+FM_IRQHANDLER_API=0x1000
+FM_XTASK_API=0x9e00
+FM_XOSDBG=0xa000
+FM_XTASK1DBG=0xc000
+FM_XTASK2DBG=0xd000
+FM_XTASK3DBG=0xe000
+FM_XTASK4DBG=0xf000
+FM_SCRATCH2=0x10000
+FM_DRAMCALIBRATION=0x1f000
+FM_RESERVED=0x20000
+FM_ZBOOT=0x1000000
+FM_YAMON_text_ram=0x1000000
+FM_YAMON__ftext_init=0x1200000
+FM_yamon_appl__ftext=0x1210000
+FM_linuxmips__ftext=0x20000
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,46 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Emmanuel Michon
+  @date   2005-03-17
+*/
+
+#ifndef __EMHWLIB_LRAM_H__
+#define __EMHWLIB_LRAM_H__
+
+#if (EM86XX_CHIP<EM86XX_CHIPID_TANGO3)
+#include "emhwlib_lram_others.h"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO3)
+#include "emhwlib_lram_tango3.h"
+#else
+#error EM86XX_CHIP is not set in RMCFLAGS: refer to rmdef/rmem86xxid.h. 
+#endif
+
+#endif // __EMHWLIB_LRAM_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,41 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram.inc (generated from emhwlib_hal/include/emhwlib_lram.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x1800
+LR_PCI_INTERRUPT_ENABLE=0x19ac
+LR_HOST_INTERRUPT_STATUS=0x19b0
+LR_DRAM_DMA_SUSPEND=0x19b4
+LR_SUSPEND_ACK_MPEG0=0x19b8
+LR_SUSPEND_ACK_MPEG1=0x19bc
+LR_SUSPEND_ACK_AUDIO0=0x19c0
+LR_SUSPEND_ACK_AUDIO1=0x19c4
+LR_SUSPEND_ACK_DEMUX=0x19c8
+LR_SUSPEND_ACK_IH=0x19cc
+LR_HB_IH=0x19d0
+LR_HB_HOST=0x19d4
+LR_HB_CPU=0x19d8
+LR_HB_MPEG0=0x19dc
+LR_HB_MPEG1=0x19e0
+LR_HB_AUDIO0=0x19e4
+LR_HB_AUDIO1=0x19e8
+LR_HB_DEMUX=0x19ec
+LR_HB_XPU=0x19f0
+LR_HB_VSYNC=0x19f4
+LR_SW_VAL_VSYNC_COUNT=0x19f8
+LR_SW_VAL_PIXEL_ADDR=0x19fc
+LR_XENV2_RW=0x1a00
+LR_XENV2_RO=0x1d00
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_others.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_others.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_others.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_others.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,98 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram_others.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Sebastien Beysserie
+  @date   2007-06-26
+*/
+
+#ifndef __EMHWLIB_LRAM_OTHERS_H__
+#define __EMHWLIB_LRAM_OTHERS_H__
+
+#define LR_CPU_IDLELOOP          0x00000000 /* CPU uses 0x80 bytes, up to 0x0080 */
+#define LR_UCLINUX_END           0x00000100
+
+#define LR_VSYNC_STRUCT          0x00000200 /* 2KB of data structures */
+#define LR_VSYNC_CODE            0x00000a00 /* 2KB of code */
+#define LR_VSYNC_END             0x00001200
+
+#define LR_STACKTOP              0x000017F4 /* in case a bootstrap routine needs a stack in local ram. Use this boundary */
+
+#define LR_PCI_INTERRUPT_ENABLE  0x000017F4
+#define LR_HOST_INTERRUPT_STATUS 0x000017F8
+#define LR_CPU_BRU_JUMP          0x000017FC /* `bootrom_ucos jump' (debug purpose) */
+
+#define LR_MU_PROFILE_STATUS     0x00001800
+
+#define LR_DRAM_DMA_SUSPEND               0x00001c8c
+#define LR_SUSPEND_ACK_MPEG0              0x00001c90
+#define LR_SUSPEND_ACK_MPEG1              0x00001c94
+#define LR_SUSPEND_ACK_AUDIO0             0x00001c98
+#define LR_SUSPEND_ACK_AUDIO1             0x00001c9c
+#define LR_SUSPEND_ACK_DEMUX              0x00001ca0
+#define LR_SUSPEND_ACK_IH                 0x00001ca4
+
+#define LR_HB_IH                 0x00001ca8
+
+#define LR_IH_LOG_FIFO           0x00001cac /* in some cases (splash screen) find the location of the log_fifo is not that easy. Read it here. */
+
+#define LR_HB_HOST               0x00001cb0
+#define LR_HB_CPU                0x00001cb4
+#define LR_HB_MPEG0              0x00001cb8
+#define LR_HB_MPEG1              0x00001cbc
+#define LR_HB_AUDIO0             0x00001cc0
+#define LR_HB_AUDIO1             0x00001cc4
+#define LR_HB_DEMUX              0x00001cc8
+#define LR_HB_XPU                0x00001ccc
+
+#define LR_IDMA                  0x00001cd0 /* 16bytes. Obsoletizes LR_HMMAD */
+
+#define LR_ETH_MAC_LO            0x00001ce0 /* Ethernet MAC addr low 4 bytes */
+#define LR_ETH_MAC_HI            0x00001ce4 /* Ethernet MAC addr high bytes */
+#define LR_HB_VSYNC              0x00001ce8
+ 
+#define LR_SW_VAL_VSYNC_COUNT    0x00001cec /* this location is used to count captured VSYNC */
+#define LR_SW_VAL_PIXEL_ADDR     0x00001cf0 /* this location is used to store a pixel address to write the frame count */
+
+#define LR_HMMAD                 0x00001cf4
+#define LR_KEY_ZONE              0x00001D00 /* 0x200 bytes, up to 0x1F00 */
+#define LR_YAMON_DIGITS          0x00001F00
+#define LR_XPU_DUMP              0x00001F00 /* 0x80 bytes, up to 0x1F80 */
+
+#define LR_VSYNC_PERIOD          0x00001FA0 /* 0x20 bytes, up to 0x1FC0 */
+
+#define LR_RANDOM_SEED           0x00001FC8 /* 0x08 bytes, up to 0x1FD0 */
+#define LR_LOCAL_DEBUG_PROBE     0x00001FD0 /* 0x20 bytes, up to 0x1FF0 */
+
+#define LR_XENV_LOCATION         0x00001FF0 /* Location of XENV, found by XOS */
+#define LR_GNET_MAC              0x00001FF4
+#define LR_ZBOOT_STAGE           0x00001FF8
+#define LR_XPU_STAGE             0x00001FFC
+
+#endif // __EMHWLIB_LRAM_OTHERS_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_others.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_others.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_others.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_others.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,58 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram_others.inc (generated from emhwlib_hal/include/emhwlib_lram_others.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_CPU_IDLELOOP=0x0
+LR_UCLINUX_END=0x100
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x17f4
+LR_PCI_INTERRUPT_ENABLE=0x17f4
+LR_HOST_INTERRUPT_STATUS=0x17f8
+LR_CPU_BRU_JUMP=0x17fc
+LR_MU_PROFILE_STATUS=0x1800
+LR_DRAM_DMA_SUSPEND=0x1c8c
+LR_SUSPEND_ACK_MPEG0=0x1c90
+LR_SUSPEND_ACK_MPEG1=0x1c94
+LR_SUSPEND_ACK_AUDIO0=0x1c98
+LR_SUSPEND_ACK_AUDIO1=0x1c9c
+LR_SUSPEND_ACK_DEMUX=0x1ca0
+LR_SUSPEND_ACK_IH=0x1ca4
+LR_HB_IH=0x1ca8
+LR_IH_LOG_FIFO=0x1cac
+LR_HB_HOST=0x1cb0
+LR_HB_CPU=0x1cb4
+LR_HB_MPEG0=0x1cb8
+LR_HB_MPEG1=0x1cbc
+LR_HB_AUDIO0=0x1cc0
+LR_HB_AUDIO1=0x1cc4
+LR_HB_DEMUX=0x1cc8
+LR_HB_XPU=0x1ccc
+LR_IDMA=0x1cd0
+LR_ETH_MAC_LO=0x1ce0
+LR_ETH_MAC_HI=0x1ce4
+LR_HB_VSYNC=0x1ce8
+LR_SW_VAL_VSYNC_COUNT=0x1cec
+LR_SW_VAL_PIXEL_ADDR=0x1cf0
+LR_HMMAD=0x1cf4
+LR_KEY_ZONE=0x1d00
+LR_YAMON_DIGITS=0x1f00
+LR_XPU_DUMP=0x1f00
+LR_VSYNC_PERIOD=0x1fa0
+LR_RANDOM_SEED=0x1fc8
+LR_LOCAL_DEBUG_PROBE=0x1fd0
+LR_XENV_LOCATION=0x1ff0
+LR_GNET_MAC=0x1ff4
+LR_ZBOOT_STAGE=0x1ff8
+LR_XPU_STAGE=0x1ffc
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_tango3.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,98 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_lram_tango3.h
+  @brief  
+
+  Map of the localram (8KBytes)
+
+  Traditionnally the start of localram is used to setup
+  a few kilobytes bootstrap routine code+data
+  (cache init, tlb init, load something bigger to DRAM, jump there).
+
+  Fixed offsets are defined in this file as communication devices
+  between hardware blocks.
+  Even debug locations must be present here.
+
+  The bootstrap routine is expected to preserve these and setup
+  its stack under LR_STACKTOP.
+
+  Keep addresses increasing in this file.
+
+  See emhwlib_resources_shared.h how some resources bw. 0 and 0x100 are used already
+  only when uCLinux is up with irq handler running
+
+  @author Sebastien Beysserie
+  @date   2007-06-26
+*/
+
+#ifndef __EMHWLIB_LRAM_TANGO3_H__
+#define __EMHWLIB_LRAM_TANGO3_H__
+
+/*
+  Leaving 2.3KB to for some startup code and stack
+  
+  as long as the value of this symbol moves only up with time, backward compatibility is ok */
+#define LR_STACKTOP              0x00000900
+
+#define LR_VSYNC_STRUCT          0x00000900
+
+/*
+  shortcoming to be address with first hw releases
+ */
+#define LR_SHUTTLE_STACKTOP      0x00001800
+
+#define LR_VSYNC_STRUCT_END      0x00001900
+
+/*
+  range from LR_STACKTOP to the first of the below block is 
+  reserved for future use (~100 slots)
+ */
+
+
+
+/* To be approved. */
+#define LR_IDMA                  0x00001968 /* 16bytes. Obsoletizes LR_HMMAD */
+/* To be approved. */
+#define LR_VSYNC_PERIOD          0x00001978 /* 0x20 bytes, up to 0x1998 */
+
+
+#define LR_ZBOOTXENV_LOCATION    0x00001994
+#define LR_BAT_D0                0x00001998
+#define LR_BAT_D1                0x0000199c
+#define LR_BAT_D2                0x000019a0
+#define LR_CHANNEL_INDEX         0x000019a4
+#define LR_HB_IPU                0x000019a8
+#define LR_PCI_INTERRUPT_ENABLE  0x000019ac
+#define LR_HOST_INTERRUPT_STATUS 0x000019b0
+#define LR_DRAM_DMA_SUSPEND      0x000019b4
+#define LR_SUSPEND_ACK_MPEG0     0x000019b8
+#define LR_SUSPEND_ACK_MPEG1     0x000019bc
+#define LR_SUSPEND_ACK_AUDIO0    0x000019c0
+#define LR_SUSPEND_ACK_AUDIO1    0x000019c4
+#define LR_SUSPEND_ACK_DEMUX     0x000019c8
+#define LR_SUSPEND_ACK_IH        0x000019cc
+#define LR_HB_IH                 0x000019d0
+#define LR_HB_HOST               0x000019d4
+#define LR_HB_CPU                0x000019d8
+#define LR_HB_MPEG0              0x000019dc
+#define LR_HB_MPEG1              0x000019e0
+#define LR_HB_AUDIO0             0x000019e4
+#define LR_HB_AUDIO1             0x000019e8
+#define LR_HB_DEMUX              0x000019ec
+#define LR_HB_XPU                0x000019f0
+#define LR_HB_VSYNC              0x000019f4
+#define LR_SW_VAL_VSYNC_COUNT    0x000019f8 /* this location is used to count captured VSYNC */
+#define LR_SW_VAL_PIXEL_ADDR     0x000019fc /* this location is used to store a pixel address to write the frame count */
+
+#define LR_XENV2_RW              0x00001a00 /* up to 768 bytes */
+
+#define LR_XENV2_RO              0x00001d00 /* up to the end, 768 bytes. This area is written by xpu, r.o. for others */
+
+#endif // __EMHWLIB_LRAM_TANGO3_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_tango3.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_tango3.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_lram_tango3.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_lram_tango3.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,43 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/emhwlib_lram_tango3.inc (generated from emhwlib_hal/include/emhwlib_lram_tango3.h)
+#*
+#* Copyright (c) Sigma Designs, Inc. 2003. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+LR_VSYNC_STRUCT=0x200
+LR_VSYNC_CODE=0xa00
+LR_VSYNC_END=0x1200
+LR_STACKTOP=0x1800
+LR_CHANNEL_INDEX=0x19a4
+LR_HB_IPU=0x19a8
+LR_PCI_INTERRUPT_ENABLE=0x19ac
+LR_HOST_INTERRUPT_STATUS=0x19b0
+LR_DRAM_DMA_SUSPEND=0x19b4
+LR_SUSPEND_ACK_MPEG0=0x19b8
+LR_SUSPEND_ACK_MPEG1=0x19bc
+LR_SUSPEND_ACK_AUDIO0=0x19c0
+LR_SUSPEND_ACK_AUDIO1=0x19c4
+LR_SUSPEND_ACK_DEMUX=0x19c8
+LR_SUSPEND_ACK_IH=0x19cc
+LR_HB_IH=0x19d0
+LR_HB_HOST=0x19d4
+LR_HB_CPU=0x19d8
+LR_HB_MPEG0=0x19dc
+LR_HB_MPEG1=0x19e0
+LR_HB_AUDIO0=0x19e4
+LR_HB_AUDIO1=0x19e8
+LR_HB_DEMUX=0x19ec
+LR_HB_XPU=0x19f0
+LR_HB_VSYNC=0x19f4
+LR_SW_VAL_VSYNC_COUNT=0x19f8
+LR_SW_VAL_PIXEL_ADDR=0x19fc
+LR_XENV2_RW=0x1a00
+LR_XENV2_RO=0x1d00
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_registers_tango3.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_registers_tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_registers_tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_registers_tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,758 @@
+/******************************************************/
+/* This file is generated automatically, DO NOT EDIT! */
+/******************************************************/
+/*
+ * ../emhwlib_hal/include/tango3/emhwlib_registers_tango3.h
+ *
+ * Copyright (c) 2001-2007 Sigma Designs, Inc. 
+ * All Rights Reserved. 
+ *
+ */
+ 
+/**
+  @file ../emhwlib_hal/include/tango3/emhwlib_registers_tango3.h
+  @brief emhwlib generated file
+   
+  @author Jacques Mahe, Christian Wolff, Julien Soulier, Emmanuel Michon
+  @ingroup hwlproperties
+*/
+
+#ifndef __EMHWLIB_REGISTERS_TANGO3_H__
+#define __EMHWLIB_REGISTERS_TANGO3_H__
+
+/* SystemBlock registers */
+#define REG_BASE_system_block 0x00010000 /* width RMuint32 */
+#define SYS_clkgen0_pll 0x0000 /* width RMuint32 */
+#define SYS_clkgen0_div 0x0004 /* width RMuint32 */
+#define SYS_clkgen1_pll 0x0008 /* width RMuint32 */
+#define SYS_clkgen1_div 0x000C /* width RMuint32 */
+#define SYS_clkgen2_pll 0x0010 /* width RMuint32 */
+#define SYS_clkgen2_div 0x0014 /* width RMuint32 */
+#define SYS_clkgen3_pll 0x0018 /* width RMuint32 */
+#define SYS_clkgen3_div 0x001C /* width RMuint32 */
+#define SYS_avclk_mux 0x0038 /* width RMuint32 */
+#define SYS_sysclk_mux 0x003C /* width RMuint32 */
+#define SYS_clk_cnt 0x0040 /* width RMuint32 */
+#define SYS_xtal_in_cnt 0x0048 /* width RMuint32 */
+#define DRAM_vbus_w0_cfg 0x0300 /* width RMuint32 */
+#define DRAM_vbus_w1_cfg 0x0304 /* width RMuint32 */
+#define DRAM_vbus_w2_cfg 0x0308 /* width RMuint32 */
+#define DRAM_vbus_w3_cfg 0x030c /* width RMuint32 */
+#define DRAM_vbus_r0_cfg 0x0340 /* width RMuint32 */
+#define DRAM_vbus_r1_cfg 0x0344 /* width RMuint32 */
+#define DRAM_vbus_r2_cfg 0x0348 /* width RMuint32 */
+#define DRAM_vbus_r3_cfg 0x034c /* width RMuint32 */
+#define DRAM_vbus_r4_cfg 0x0350 /* width RMuint32 */
+#define DRAM_vbus_r5_cfg 0x0354 /* width RMuint32 */
+#define DRAM_vbus_r6_cfg 0x0358 /* width RMuint32 */
+#define DRAM_vbus_r7_cfg 0x035c /* width RMuint32 */
+#define DRAM_vbus_r8_cfg 0x0360 /* width RMuint32 */
+#define DRAM_vbus_r9_cfg 0x0364 /* width RMuint32 */
+#define DRAM_vbus_r10_cfg 0x0368 /* width RMuint32 */
+#define DRAM_vbus_r11_cfg 0x036c /* width RMuint32 */
+#define DRAM_mbus_w0_cfg 0x0200 /* width RMuint32 */
+#define DRAM_mbus_w1_cfg 0x0204 /* width RMuint32 */
+#define DRAM_mbus_w2_cfg 0x0208 /* width RMuint32 */
+#define DRAM_mbus_w3_cfg 0x020c /* width RMuint32 */
+#define DRAM_mbus_w4_cfg 0x0210 /* width RMuint32 */
+#define DRAM_mbus_w5_cfg 0x0214 /* width RMuint32 */
+#define DRAM_mbus_w6_cfg 0x0218 /* width RMuint32 */
+#define DRAM_mbus_w7_cfg 0x021c /* width RMuint32 */
+#define DRAM_mbus_w8_cfg 0x0220 /* width RMuint32 */
+#define DRAM_mbus_w9_cfg 0x0224 /* width RMuint32 */
+#define DRAM_mbus_w10_cfg 0x0228 /* width RMuint32 */
+#define DRAM_mbus_r0_cfg 0x0240 /* width RMuint32 */
+#define DRAM_mbus_r1_cfg 0x0244 /* width RMuint32 */
+#define DRAM_mbus_r2_cfg 0x0248 /* width RMuint32 */
+#define DRAM_mbus_r3_cfg 0x024c /* width RMuint32 */
+#define DRAM_mbus_r4_cfg 0x0250 /* width RMuint32 */
+#define DRAM_mbus_r5_cfg 0x0254 /* width RMuint32 */
+#define DRAM_mbus_r6_cfg 0x0258 /* width RMuint32 */
+#define DRAM_mbus_r7_cfg 0x025c /* width RMuint32 */
+#define DRAM_mbus_r8_cfg 0x0260 /* width RMuint32 */
+#define DRAM_mbus_r9_cfg 0x0264 /* width RMuint32 */
+#define DRAM_mbus_r10_cfg 0x0268 /* width RMuint32 */
+#define SYS_hostclk_mux 0x0030 /* width RMuint32 */
+#define SYS_sysclk_premux 0x0034 /* width RMuint32 */
+#define SYS_rnd_cnt 0x0044 /* width RMuint32 */
+#define SYS_cnt_cfg 0x004c /* width RMuint32 */
+#define SYS_cfg_cnt0 0x0050 /* width RMuint32 */
+#define SYS_cfg_cnt1 0x0054 /* width RMuint32 */
+#define SYS_cfg_cnt2 0x0058 /* width RMuint32 */
+#define SYS_cfg_cnt3 0x005c /* width RMuint32 */
+#define SYS_cfg_cnt4 0x0060 /* width RMuint32 */
+#define SYS_cleandiv0_div 0x0080 /* width RMuint32 */
+#define SYS_cleandiv1_div 0x0088 /* width RMuint32 */
+#define SYS_cleandiv2_div 0x0090 /* width RMuint32 */
+#define SYS_cleandiv3_div 0x0098 /* width RMuint32 */
+#define SYS_cleandiv4_div 0x00a0 /* width RMuint32 */
+#define SYS_cleandiv5_div 0x00a8 /* width RMuint32 */
+#define SYS_cleandiv6_div 0x00b0 /* width RMuint32 */
+#define SYS_cleandiv7_div 0x00b8 /* width RMuint32 */
+#define SYS_cleandiv8_div 0x00c0 /* width RMuint32 */
+#define SYS_cleandiv9_div 0x00c8 /* width RMuint32 */
+#define SYS_cleandiv10_div 0x00d0 /* width RMuint32 */
+#define SYS_watchdog_counter 0xfd00 /* width RMuint32 */
+#define SYS_watchdog_configuration 0xfd04 /* width RMuint32 */
+#define MARB_mid01_cfg 0x0200 /* width RMuint32 */
+#define MARB_mid21_cfg 0x0204 /* width RMuint32 */
+#define MARB_mid02_cfg 0x0208 /* width RMuint32 */
+#define MARB_mid22_cfg 0x020c /* width RMuint32 */
+#define MARB_mid03_cfg 0x0210 /* width RMuint32 */
+#define MARB_mid23_cfg 0x0214 /* width RMuint32 */
+#define MARB_mid04_cfg 0x0218 /* width RMuint32 */
+#define MARB_mid24_cfg 0x021c /* width RMuint32 */
+#define MARB_mid25_cfg 0x0220 /* width RMuint32 */
+#define MARB_mid08_cfg 0x0224 /* width RMuint32 */
+#define MARB_mid28_cfg 0x0228 /* width RMuint32 */
+#define MARB_mid29_cfg 0x022c /* width RMuint32 */
+#define MARB_mid0C_cfg 0x0230 /* width RMuint32 */
+#define MARB_mid2C_cfg 0x0234 /* width RMuint32 */
+#define MARB_mid0E_cfg 0x0238 /* width RMuint32 */
+#define MARB_mid2E_cfg 0x023c /* width RMuint32 */
+#define MARB_mid10_cfg 0x0240 /* width RMuint32 */
+#define MARB_mid30_cfg 0x0244 /* width RMuint32 */
+#define MARB_mid14_cfg 0x0248 /* width RMuint32 */
+#define MARB_mid34_cfg 0x024c /* width RMuint32 */
+#define MARB_mid05_cfg 0x0250 /* width RMuint32 */
+#define MARB_mid26_cfg 0x0254 /* width RMuint32 */
+#define MARB_mid09_cfg 0x0258 /* width RMuint32 */
+#define MARB_mid2A_cfg 0x025c /* width RMuint32 */
+#define MARB_mid06_cfg 0x0260 /* width RMuint32 */
+#define MARB_mid0A_cfg 0x0264 /* width RMuint32 */
+#define MARB_mid1C_cfg 0x0268 /* width RMuint32 */
+#define MARB_mid3C_cfg 0x026c /* width RMuint32 */
+#define VARB_mid01_cfg 0x0300 /* width RMuint32 */
+#define VARB_mid02_cfg 0x0304 /* width RMuint32 */
+#define VARB_mid21_cfg 0x0308 /* width RMuint32 */
+#define VARB_mid22_cfg 0x030c /* width RMuint32 */
+#define VARB_mid23_cfg 0x0310 /* width RMuint32 */
+#define VARB_mid24_cfg 0x0314 /* width RMuint32 */
+#define VARB_mid25_cfg 0x0318 /* width RMuint32 */
+#define VARB_mid26_cfg 0x031c /* width RMuint32 */
+#define VARB_mid27_cfg 0x0320 /* width RMuint32 */
+#define VARB_mid28_cfg 0x0324 /* width RMuint32 */
+#define VARB_mid29_cfg 0x0328 /* width RMuint32 */
+#define VARB_mid2A_cfg 0x032c /* width RMuint32 */
+#define VARB_mid10_cfg 0x0330 /* width RMuint32 */
+#define VARB_mid30_cfg 0x0334 /* width RMuint32 */
+#define VARB_mid31_cfg 0x0338 /* width RMuint32 */
+#define VARB_mid03_cfg 0x033c /* width RMuint32 */
+#define IARB_mid01_cfg 0x0400 /* width RMuint32 */
+#define IARB_mid02_cfg 0x0404 /* width RMuint32 */
+#define SYS_gpio_dir 0x0500 /* width RMuint32 */
+#define SYS_gpio_data 0x0504 /* width RMuint32 */
+#define SYS_gpio_int 0x0508 /* width RMuint32 */
+#define SYS_gpio15_pwm 0x0510 /* width RMuint32 */
+#define SYS_gpio14_pwm 0x0514 /* width RMuint32 */
+#define REG_BASE_dram_controller_0 0x00030000 /* width RMuint32 */
+#define REG_BASE_dram_controller_1 0x00040000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_0_alias 0x10000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_0 0x80000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_1_alias 0x20000000 /* width RMuint32 */
+#define MEM_BASE_dram_controller_1 0xc0000000 /* width RMuint32 */
+#define DRAM_dunit_cfg 0x0000 /* width RMuint32 */
+#define DRAM_dunit_delay0_ctrl 0x0004 /* width RMuint32 */
+#define DRAM_dunit_delay1_ctrl 0x0008 /* width RMuint32 */
+#define DRAM_dunit_auto_delay 0x000c /* width RMuint32 */
+#define DRAM_dunit_fall_delay0 0x0010 /* width RMuint32 */
+#define DRAM_dunit_fall_delay1 0x0014 /* width RMuint32 */
+#define DRAM_dunit_bw_lobound 0x0018 /* width RMuint32 */
+#define DRAM_dunit_bw_hibound 0x001c /* width RMuint32 */
+#define DRAM_dunit_bw_probe_cfg 0x0020 /* width RMuint32 */
+#define DRAM_dunit_bw_probe_cnt 0x0024 /* width RMuint32 */
+#define DRAM_dunit_bw_cntall 0x0028 /* width RMuint32 */
+#define DRAM_dunit_calibration_delay 0x0030 /* width RMuint32 */
+#define DRAM_dunit_calibration_rise_err 0x0034 /* width RMuint32 */
+#define DRAM_dunit_calibration_fall_err 0x0038 /* width RMuint32 */
+#define DRAM_dunit_calibration_page 0x0088 /* width RMuint32 */
+#define DRAM_dunit_flush_buffer 0x0104 /* width RMuint32 */
+#define REG_BASE_host_interface 0x00020000 /* width RMuint32 */
+#define MEM_BASE_host_interface 0x40000000 /* width RMuint32 */
+#define IDE_data 0x0000 /* width RMuint32 */
+#define IDE_error 0x0004 /* width RMuint32 */
+#define IDE_count 0x0008 /* width RMuint32 */
+#define IDE_start_sector 0x000c /* width RMuint32 */
+#define IDE_cylinder_lo 0x0010 /* width RMuint32 */
+#define IDE_cylinder_hi 0x0014 /* width RMuint32 */
+#define IDE_head_device 0x0018 /* width RMuint32 */
+#define IDE_cmd_stat 0x001c /* width RMuint32 */
+#define IDE_irq_stat 0x0218 /* width RMuint32 */
+#define IDE_cmd_stat__ 0x021c /* width RMuint32 */
+#define PB_timing0 0x0800 /* width RMuint32 */
+#define PB_timing1 0x0804 /* width RMuint32 */
+#define PB_timing2 0x0808 /* width RMuint32 */
+#define PB_timing3 0x080c /* width RMuint32 */
+#define PB_timing4 0x0810 /* width RMuint32 */
+#define PB_timing5 0x0814 /* width RMuint32 */
+#define PB_default_timing 0x0818 /* width RMuint32 */
+#define PB_use_timing0 0x081c /* width RMuint32 */
+#define PB_use_timing1 0x0820 /* width RMuint32 */
+#define PB_use_timing2 0x0824 /* width RMuint32 */
+#define PB_use_timing3 0x0828 /* width RMuint32 */
+#define PB_use_timing4 0x082c /* width RMuint32 */
+#define PB_use_timing5 0x0830 /* width RMuint32 */
+#define PB_CS_config 0x0834 /* width RMuint32 */
+#define PB_automode_start_address 0x0840 /* width RMuint32 */
+#define PB_automode_control 0x0844 /* width RMuint32 */
+#define EMHWLIB_IS_HOST 0xe000 /* width RMuint32 */
+#define HOST_REG1 0xfed0 /* width RMuint32 */
+#define HOST_REG2 0xfed4 /* width RMuint32 */
+#define READ_ADDRESS 0xfec0 /* width RMuint32 */
+#define READ_COUNTER 0xfec4 /* width RMuint32 */
+#define READ_ENABLE 0xfec8 /* width RMuint32 */
+#define REV_ORDER 0xfecc /* width RMuint32 */
+#define WRITE_ADDRESS 0xfed8 /* width RMuint32 */
+#define WRITE_COUNTER 0xfedc /* width RMuint32 */
+#define WRITE_ENABLE 0xfee0 /* width RMuint32 */
+#define BURST 0xfee4 /* width RMuint32 */
+#define PCI_TIMEOUT 0x8000 /* width RMuint32 */
+#define PCI_TIMEOUT_STATUS 0x8004 /* width RMuint32 */
+#define PCI_TIMER 0x8008 /* width RMuint32 */
+#define PCI_TIMER_TEST 0x800c /* width RMuint32 */
+#define PCI_WAKEUP 0x8010 /* width RMuint32 */
+#define PCI_REGION_0_BASE 0x9000 /* width RMuint32 */
+#define PCI_REGION_1_BASE 0x9004 /* width RMuint32 */
+#define PCI_REGION_2_BASE 0x9008 /* width RMuint32 */
+#define PCI_REGION_3_BASE 0x900c /* width RMuint32 */
+#define PCI_REGION_4_BASE 0x9010 /* width RMuint32 */
+#define PCI_REGION_5_BASE 0x9014 /* width RMuint32 */
+#define PCI_REGION_6_BASE 0x9018 /* width RMuint32 */
+#define PCI_REGION_7_BASE 0x901c /* width RMuint32 */
+#define PCI_irq_status 0x9020 /* width RMuint32 */
+#define PCI_irq_set 0x9024 /* width RMuint32 */
+#define PCI_irq_clear 0x9028 /* width RMuint32 */
+#define SBOX_FIFO_RESET 0x90a0 /* width RMuint32 */
+#define SBOX_FIFO_RESET2 0x90a4 /* width RMuint32 */
+#define SBOX_ROUTE 0x90a8 /* width RMuint32 */
+#define SBOX_ROUTE2 0x90ac /* width RMuint32 */
+#define output_SBOX_MBUS_W0 0x9080 /* width RMuint32 */
+#define output_SBOX_MBUS_W1 0x9084 /* width RMuint32 */
+#define output_SBOX_PCI_MASTER 0x9088 /* width RMuint32 */
+#define output_SBOX_PCI_SLAVE 0x908c /* width RMuint32 */
+#define output_SBOX_SATA 0x9090 /* width RMuint32 */
+#define output_SBOX_IDE_ISA 0x9094 /* width RMuint32 */
+#define output_SBOX_IDE_DVD 0x9098 /* width RMuint32 */
+#define output_SBOX_SATA2 0x909c /* width RMuint32 */
+#define output_SBOX_MBUS_W2 0x90b0 /* width RMuint32 */
+#define input_keep_SBOX 0 /* width RMuint32 */
+#define input_MBUS_R0_SBOX 1 /* width RMuint32 */
+#define input_MBUS_R1_SBOX 2 /* width RMuint32 */
+#define input_PCI_MASTER_SBOX 3 /* width RMuint32 */
+#define input_PCI_SLAVE_SBOX 4 /* width RMuint32 */
+#define input_SATA_SBOX 5 /* width RMuint32 */
+#define input_IDE_ISA_SBOX 6 /* width RMuint32 */
+#define input_IDE_DVD_SBOX 7 /* width RMuint32 */
+#define input_SATA2_SBOX 8 /* width RMuint32 */
+#define input_MBUS_R2_SBOX 9 /* width RMuint32 */
+#define input_unconnected_SBOX 0xf /* width RMuint32 */
+#define host_mutex0 0x9040 /* width RMuint32 */
+#define host_mutex1 0x9044 /* width RMuint32 */
+#define host_mutex2 0x9048 /* width RMuint32 */
+#define host_mutex3 0x904c /* width RMuint32 */
+#define host_mutex4 0x9050 /* width RMuint32 */
+#define host_mutex5 0x9054 /* width RMuint32 */
+#define host_mutex6 0x9058 /* width RMuint32 */
+#define host_mutex7 0x905c /* width RMuint32 */
+#define host_mutex8 0x9060 /* width RMuint32 */
+#define host_mutex9 0x9064 /* width RMuint32 */
+#define host_mutex10 0x9068 /* width RMuint32 */
+#define host_mutex11 0x906c /* width RMuint32 */
+#define host_mutex12 0x9070 /* width RMuint32 */
+#define host_mutex13 0x9074 /* width RMuint32 */
+#define host_mutex14 0x9078 /* width RMuint32 */
+#define host_mutex15 0x907c /* width RMuint32 */
+#define PCI_host_reg5 0xfe94 /* width RMuint32 */
+#define PCI_chip_is_host 0xfe90 /* width RMuint32 */
+#define IDECTRL_idesrc 0x20d0 /* width RMuint32 */
+#define IDECTRL_pri_drv1udmatim1 0x20e0 /* width RMuint32 */
+#define IDECTRL_pri_drv1udmatim2 0x20f0 /* width RMuint32 */
+#define IDECTRL_pri_idectl 0x2100 /* width RMuint32 */
+#define IDECTRL_pri_drv0tim 0x2110 /* width RMuint32 */
+#define IDECTRL_pri_drv1tim 0x2120 /* width RMuint32 */
+#define IDECTRL_idemisc 0x2130 /* width RMuint32 */
+#define IDECTRL_idestatus 0x2140 /* width RMuint32 */
+#define IDECTRL_udmactl 0x2150 /* width RMuint32 */
+#define IDECTRL_pri_drv0udmatim1 0x2160 /* width RMuint32 */
+#define IDECTRL_pri_drv0udmatim2 0x2170 /* width RMuint32 */
+#define IDECTRL_pref_st 0x2310 /* width RMuint32 */
+#define IDECTRL_pri_ctrlblock 0x2398 /* width RMuint32 */
+#define IDECTRL_pri_cmdblock 0x23c0 /* width RMuint32 */
+#define IDECTRL_bmic 0x2400 /* width RMuint32 */
+#define IDECTRL_bmis 0x2410 /* width RMuint32 */
+#define IDECTRL_bmidtp 0x2420 /* width RMuint32 */
+#define IDECTRL_ide_dmaptr 0x2780 /* width RMuint32 */
+#define IDECTRL_ide_dmalen 0x2790 /* width RMuint32 */
+#define IDECTRL_pio_prefetch_data 0x27c0 /* width RMuint32 */
+#define MEM_BASE_pfla 0x40000000 /* width RMuint32 */
+#define PB_CS0_OFFSET 0x00000000 /* width RMuint32 */
+#define PB_CS1_OFFSET 0x04000000 /* width RMuint32 */
+#define PB_CS2_OFFSET 0x08000000 /* width RMuint32 */
+#define PB_CS3_OFFSET 0x0c000000 /* width RMuint32 */
+#define ETH_gpio_dir1 0x7100 /* width RMuint32 */
+#define ETH_gpio_data1 0x7104 /* width RMuint32 */
+#define ETH_gpio_mask1 0x7108 /* width RMuint32 */
+#define ETH_gpio_dir2 0x710c /* width RMuint32 */
+#define ETH_gpio_data2 0x7110 /* width RMuint32 */
+#define PB_CS_config1 0x0838 /* width RMuint32 */
+#define PB_CS_ctrl 0x083c /* width RMuint32 */
+#define PB_strap_ctrl 0x0880 /* width RMuint32 */
+#define PB_strap0 0x0884 /* width RMuint32 */
+#define PB_strap1 0x0888 /* width RMuint32 */
+#define PB_ECC_code0 0x08c0 /* width RMuint32 */
+#define PB_ECC_code1 0x08c4 /* width RMuint32 */
+#define PB_ECC_code2 0x08c8 /* width RMuint32 */
+#define PB_ECC_code3 0x08cc /* width RMuint32 */
+#define PB_ECC_clear 0x08d0 /* width RMuint32 */
+#define MIF_W2_ADD 0xb100 /* width RMuint32 */
+#define MIF_W2_CNT 0xb104 /* width RMuint32 */
+#define MIF_W2_SKIP 0xb108 /* width RMuint32 */
+#define MIF_W2_CMD 0xb10c /* width RMuint32 */
+#define MIF_R2_ADD 0xb140 /* width RMuint32 */
+#define MIF_R2_CNT 0xb144 /* width RMuint32 */
+#define MIF_R2_SKIP 0xb148 /* width RMuint32 */
+#define MIF_R2_CMD 0xb14c /* width RMuint32 */
+#define PCI_host_reg1 0xfed0 /* width RMuint32 */
+#define PCI_host_reg2 0xfed4 /* width RMuint32 */
+#define PCI_host_reg3 0xfe80 /* width RMuint32 */
+#define PCI_host_reg4 0xfe84 /* width RMuint32 */
+#define PCI_pcictrl_reg1 0xfe88 /* width RMuint32 */
+#define PCI_pcictrl_reg2 0xfe8c /* width RMuint32 */
+#define PCI_pcictrl_reg3 0xfefc /* width RMuint32 */
+#define PCI_REG0 0xfee8 /* width RMuint32 */
+#define PCI_REG1 0xfeec /* width RMuint32 */
+#define PCI_REG2 0xfef0 /* width RMuint32 */
+#define PCI_REG3 0xfef4 /* width RMuint32 */
+#define PCI_CONFIG 0xfef8 /* width RMuint32 */
+#define MIF_W0_ADD 0xb000 /* width RMuint32 */
+#define MIF_W0_CNT 0xb004 /* width RMuint32 */
+#define MIF_W0_SKIP 0xb008 /* width RMuint32 */
+#define MIF_W0_CMD 0xb00c /* width RMuint32 */
+#define MIF_W1_ADD 0xb040 /* width RMuint32 */
+#define MIF_W1_CNT 0xb044 /* width RMuint32 */
+#define MIF_W1_SKIP 0xb048 /* width RMuint32 */
+#define MIF_W1_CMD 0xb04c /* width RMuint32 */
+#define MIF_R0_ADD 0xb080 /* width RMuint32 */
+#define MIF_R0_CNT 0xb084 /* width RMuint32 */
+#define MIF_R0_SKIP 0xb088 /* width RMuint32 */
+#define MIF_R0_CMD 0xb08c /* width RMuint32 */
+#define MIF_R1_ADD 0xb0c0 /* width RMuint32 */
+#define MIF_R1_CNT 0xb0c4 /* width RMuint32 */
+#define MIF_R1_SKIP 0xb0c8 /* width RMuint32 */
+#define MIF_R1_CMD 0xb0cc /* width RMuint32 */
+#define MBUS_IDLE 0 /* width RMuint32 */
+#define MBUS_LINEAR 1 /* width RMuint32 */
+#define MBUS_DOUBLE 2 /* width RMuint32 */
+#define MBUS_RECTANGLE 3 /* width RMuint32 */
+#define MBUS_VOID 4 /* width RMuint32 */
+#define MBUS_LINEAR_VOID 5 /* width RMuint32 */
+#define MBUS_DOUBLE_VOID 6 /* width RMuint32 */
+#define MBUS_RECTANGLE_VOID 7 /* width RMuint32 */
+#define MBUS_TILED 8 /* width RMuint32 */
+#define GBUS_MUTEX_XPU 0x14 /* width RMuint32 */
+#define GBUS_MUTEX_PT110 0x16 /* width RMuint32 */
+#define GBUS_MUTEX_TDMX 0x19 /* width RMuint32 */
+#define GBUS_MUTEX_AUDIO_0 0x1b /* width RMuint32 */
+#define GBUS_MUTEX_AUDIO_1 0x1c /* width RMuint32 */
+#define GBUS_MUTEX_MPEG_0 0x1d /* width RMuint32 */
+#define GBUS_MUTEX_MPEG_1 0x1e /* width RMuint32 */
+#define GBUS_MUTEX_HOST 0x1f /* width RMuint32 */
+#define GBUS_MUTEX_LOCAL 0x10 /* width RMuint32 */
+/* SystemBlock registers done */
+
+/* CPUBlock registers */
+#define REG_BASE_cpu_block 0x00060000 /* width RMuint32 */
+#define CPU_time0_load 0xc500 /* width RMuint32 */
+#define CPU_time0_value 0xc504 /* width RMuint32 */
+#define CPU_time0_ctrl 0xc508 /* width RMuint32 */
+#define CPU_time0_clr 0xc50c /* width RMuint32 */
+#define CPU_time1_load 0xc600 /* width RMuint32 */
+#define CPU_time1_value 0xc604 /* width RMuint32 */
+#define CPU_time1_ctrl 0xc608 /* width RMuint32 */
+#define CPU_time1_clr 0xc60c /* width RMuint32 */
+#define CPU_rtc_data 0xc800 /* width RMuint32 */
+#define CPU_rtc_match 0xc804 /* width RMuint32 */
+#define CPU_rtc_stat 0xc808 /* width RMuint32 */
+#define CPU_rtc_load 0xc80c /* width RMuint32 */
+#define CPU_rtc_ctrl 0xc810 /* width RMuint32 */
+#define CPU_irq_status 0xe000 /* width RMuint32 */
+#define CPU_irq_rawstat 0xe004 /* width RMuint32 */
+#define CPU_irq_enableset 0xe008 /* width RMuint32 */
+#define CPU_irq_enableclr 0xe00c /* width RMuint32 */
+#define CPU_irq_softset 0xe010 /* width RMuint32 */
+#define CPU_irq_softclr 0xe014 /* width RMuint32 */
+#define CPU_fiq_status 0xe100 /* width RMuint32 */
+#define CPU_fiq_rawstat 0xe104 /* width RMuint32 */
+#define CPU_fiq_enableset 0xe108 /* width RMuint32 */
+#define CPU_fiq_enableclr 0xe10c /* width RMuint32 */
+#define CPU_fiq_softset 0xe110 /* width RMuint32 */
+#define CPU_fiq_softclr 0xe114 /* width RMuint32 */
+#define CPU_edge_status 0xe200 /* width RMuint32 */
+#define CPU_edge_rawstat 0xe204 /* width RMuint32 */
+#define CPU_edge_config_rise 0xe208 /* width RMuint32 */
+#define CPU_edge_config_fall 0xe20c /* width RMuint32 */
+#define CPU_SOFT_INT 0x00000001 /* width RMuint32 */
+#define CPU_UART0_INT 0x00000002 /* width RMuint32 */
+#define CPU_UART1_INT 0x00000004 /* width RMuint32 */
+#define CPU_TIMER0_INT 0x00000020 /* width RMuint32 */
+#define CPU_TIMER1_INT 0x00000040 /* width RMuint32 */
+#define CPU_HOST_MBUS_W0_INT 0x00000200 /* width RMuint32 */
+#define CPU_HOST_MBUS_W1_INT 0x00000400 /* width RMuint32 */
+#define CPU_HOST_MBUS_R0_INT 0x00000800 /* width RMuint32 */
+#define CPU_HOST_MBUS_R1_INT 0x00001000 /* width RMuint32 */
+#define CPU_PCI_INTA 0x00002000 /* width RMuint32 */
+#define CPU_PCI_INTB 0x00004000 /* width RMuint32 */
+#define CPU_PCI_INTC 0x00008000 /* width RMuint32 */
+#define CPU_PCI_INTD 0x00010000 /* width RMuint32 */
+#define CPU_PCI_FAULT_INT 0x00100000 /* width RMuint32 */
+#define CPU_INFRARED_INT 0x00200000 /* width RMuint32 */
+#define CPU_SFLA_INT 0x00000010 /* width RMuint32 */
+#define CPU_DVD_INT 0x00000080 /* width RMuint32 */
+#define CPU_ETH_INT 0x00000100 /* width RMuint32 */
+#define CPU_DMAIDE_INT 0x00020000 /* width RMuint32 */
+#define CPU_IDE_INT 0x00040000 /* width RMuint32 */
+#define CPU_FRONTPANEL_INT 0x00080000 /* width RMuint32 */
+#define CPU_I2C_INT 0x00400000 /* width RMuint32 */
+#define CPU_GFX_ACCEL_INT 0x00800000 /* width RMuint32 */
+#define CPU_VSYNC0_INT 0x01000000 /* width RMuint32 */
+#define CPU_VSYNC1_INT 0x02000000 /* width RMuint32 */
+#define CPU_VSYNC2_INT 0x04000000 /* width RMuint32 */
+#define CPU_VSYNC3_INT 0x08000000 /* width RMuint32 */
+#define CPU_VSYNC4_INT 0x10000000 /* width RMuint32 */
+#define CPU_VSYNC4BKEND_INT 0x20000000 /* width RMuint32 */
+#define CPU_VSYNC5_INT 0x40000000 /* width RMuint32 */
+#define CPU_VSYNC5BKEND_INT 0x80000000 /* width RMuint32 */
+#define CPU_SMARTCARD_HI_INT 0x00000001 /* width RMuint32 */
+#define CPU_HDMI_HI_INT 0x00000002 /* width RMuint32 */
+#define CPU_HDMI_I2C_HI_INT 0x00000004 /* width RMuint32 */
+#define CPU_VBUS_W0_HI_INT 0x00000008 /* width RMuint32 */
+#define CPU_VBUS_W3_HI_INT 0x00000010 /* width RMuint32 */
+#define CPU_ETH_PHY_HI_INT 0x00000020 /* width RMuint32 */
+#define CPU_ETH_MAC_HI_INT 0x00000040 /* width RMuint32 */
+#define CPU_USB_OHCI_MAC_HI_INT 0x00000080 /* width RMuint32 */
+#define CPU_USB_EHCI_MAC_HI_INT 0x00000100 /* width RMuint32 */
+#define LOG2_CPU_SOFT_INT 0 /* width RMuint32 */
+#define LOG2_CPU_UART0_INT 1 /* width RMuint32 */
+#define LOG2_CPU_UART1_INT 2 /* width RMuint32 */
+#define LOG2_CPU_TIMER0_INT 5 /* width RMuint32 */
+#define LOG2_CPU_TIMER1_INT 6 /* width RMuint32 */
+#define LOG2_CPU_DVD_INT 7 /* width RMuint32 */
+#define LOG2_CPU_RTC_INT 8 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_W0_INT 9 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_W1_INT 10 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_R0_INT 11 /* width RMuint32 */
+#define LOG2_CPU_HOST_MBUS_R1_INT 12 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTA 13 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTB 14 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTC 15 /* width RMuint32 */
+#define LOG2_CPU_PCI_INTD 16 /* width RMuint32 */
+#define LOG2_CPU_DMAIDE_INT 17 /* width RMuint32 */
+#define LOG2_CPU_IDE_INT 18 /* width RMuint32 */
+#define LOG2_CPU_FRONTPANEL_INT 19 /* width RMuint32 */
+#define LOG2_CPU_PCI_FAULT_INT 20 /* width RMuint32 */
+#define LOG2_CPU_INFRARED_INT 21 /* width RMuint32 */
+#define LOG2_CPU_I2C_INT 22 /* width RMuint32 */
+#define LOG2_CPU_GFX_ACCEL_INT 23 /* width RMuint32 */
+#define LOG2_CPU_VSYNC0_INT 24 /* width RMuint32 */
+#define LOG2_CPU_VSYNC1_INT 25 /* width RMuint32 */
+#define LOG2_CPU_VSYNC2_INT 26 /* width RMuint32 */
+#define LOG2_CPU_VSYNC3_INT 27 /* width RMuint32 */
+#define LOG2_CPU_VSYNC4_INT 28 /* width RMuint32 */
+#define LOG2_CPU_VSYNC4BKEND_INT 29 /* width RMuint32 */
+#define LOG2_CPU_VSYNC5_INT 30 /* width RMuint32 */
+#define LOG2_CPU_VSYNC5BKEND_INT 31 /* width RMuint32 */
+#define LOG2_CPU_SMARTCARD_INT 32 /* width RMuint32 */
+#define LOG2_CPU_HDMI_INT 33 /* width RMuint32 */
+#define LOG2_CPU_HDMI_I2C_INT 34 /* width RMuint32 */
+#define LOG2_CPU_VBUS_W0_INT 35 /* width RMuint32 */
+#define LOG2_CPU_VBUS_W3_INT 36 /* width RMuint32 */
+#define LOG2_CPU_ETH_PHY_INT 37 /* width RMuint32 */
+#define LOG2_CPU_ETH_MAC_INT 38 /* width RMuint32 */
+#define LOG2_CPU_USB_OHCI_INT 39 /* width RMuint32 */
+#define LOG2_CPU_USB_EHCI_INT 40 /* width RMuint32 */
+#define LOG2_CPU_SATA_INT 41 /* width RMuint32 */
+#define LOG2_CPU_DMASATA_INT 42 /* width RMuint32 */
+#define LOG2_XPU_W0_INT 43 /* width RMuint32 */
+#define LOG2_XPU_R0_INT 44 /* width RMuint32 */
+#define LOG2_XPU_W_SP_INT 45 /* width RMuint32 */
+#define LOG2_XPU_R_SP_INT 46 /* width RMuint32 */
+#define LOG2_CPU_GPIO24_INT 47 /* width RMuint32 */
+#define LOG2_CPU_GPIO25_INT 48 /* width RMuint32 */
+#define LOG2_CPU_GPIO26_INT 49 /* width RMuint32 */
+#define LOG2_CPU_GPIO27_INT 50 /* width RMuint32 */
+#define LOG2_CPU_VBUS_W4_INT 51 /* width RMuint32 */
+#define LOG2_CPU_SMARTCARD1_INT 52 /* width RMuint32 */
+#define LOG2_CPU_HDMI_CEC_INT 53 /* width RMuint32 */
+#define CPU_edge_status_hi 0xe220 /* width RMuint32 */
+#define CPU_edge_rawstat_hi 0xe224 /* width RMuint32 */
+#define CPU_edge_config_rise_hi 0xe228 /* width RMuint32 */
+#define CPU_edge_config_fall_hi 0xe22c /* width RMuint32 */
+#define CPU_irq_status_hi 0xe018 /* width RMuint32 */
+#define CPU_irq_rawstat_hi 0xe01c /* width RMuint32 */
+#define CPU_irq_enableset_hi 0xe020 /* width RMuint32 */
+#define CPU_irq_enableclr_hi 0xe024 /* width RMuint32 */
+#define CPU_fiq_status_hi 0xe118 /* width RMuint32 */
+#define CPU_fiq_rawstat_hi 0xe11c /* width RMuint32 */
+#define CPU_fiq_enableset_hi 0xe120 /* width RMuint32 */
+#define CPU_fiq_enableclr_hi 0xe124 /* width RMuint32 */
+#define CPU_iiq_status 0xe300 /* width RMuint32 */
+#define CPU_iiq_rawstat 0xe304 /* width RMuint32 */
+#define CPU_iiq_enableset 0xe308 /* width RMuint32 */
+#define CPU_iiq_enableclr 0xe30c /* width RMuint32 */
+#define CPU_iiq_softset 0xe310 /* width RMuint32 */
+#define CPU_iiq_softclr 0xe314 /* width RMuint32 */
+#define CPU_iiq_status_hi 0xe318 /* width RMuint32 */
+#define CPU_iiq_rawstat_hi 0xe31c /* width RMuint32 */
+#define CPU_iiq_enableset_hi 0xe320 /* width RMuint32 */
+#define CPU_iiq_enableclr_hi 0xe324 /* width RMuint32 */
+#define CPU_UART_GPIOMODE 0x38 /* width RMuint32 */
+#define CPU_UART_GPIODIR 0x30 /* width RMuint32 */
+#define CPU_UART_GPIODATA 0x34 /* width RMuint32 */
+#define CPU_edge_config_rise_set 0xe210 /* width RMuint32 */
+#define CPU_edge_config_rise_clr 0xe214 /* width RMuint32 */
+#define CPU_edge_config_fall_set 0xe218 /* width RMuint32 */
+#define CPU_edge_config_fall_clr 0xe21c /* width RMuint32 */
+#define CPU_edge_config_rise_set_hi 0xe230 /* width RMuint32 */
+#define CPU_edge_config_rise_clr_hi 0xe234 /* width RMuint32 */
+#define CPU_edge_config_fall_set_hi 0xe238 /* width RMuint32 */
+#define CPU_edge_config_fall_clr_hi 0xe23c /* width RMuint32 */
+#define intentionaldiff_em 0xeee0 /* width RMuint32 */
+#define CPU_pm_select_0 0xc900 /* width RMuint32 */
+#define CPU_pm_counter_0 0xc904 /* width RMuint32 */
+#define CPU_pm_select_1 0xc908 /* width RMuint32 */
+#define CPU_pm_counter_1 0xc90c /* width RMuint32 */
+#define CPU_remap 0xf000 /* width RMuint32 */
+#define CPU_remap1 0xf004 /* width RMuint32 */
+#define CPU_remap2 0xf008 /* width RMuint32 */
+#define CPU_remap3 0xf00c /* width RMuint32 */
+#define CPU_remap4 0xf010 /* width RMuint32 */
+#define CPU_remap5 0xf014 /* width RMuint32 */
+#define CPU_remap6 0xf018 /* width RMuint32 */
+#define CPU_remap7 0xf01c /* width RMuint32 */
+#define CPU_remap_address 0x1fc00000 /* width RMuint32 */
+#define CPU_remap1_address 0 /* width RMuint32 */
+#define CPU_remap2_address 0x04000000 /* width RMuint32 */
+#define CPU_remap3_address 0x08000000 /* width RMuint32 */
+#define CPU_remap4_address 0x0c000000 /* width RMuint32 */
+#define CPU_remap5_address 0x10000000 /* width RMuint32 */
+#define CPU_remap6_address 0x14000000 /* width RMuint32 */
+#define CPU_remap7_address 0x18000000 /* width RMuint32 */
+#define REG_BASE_irq_handler_block 0xf0000 /* width RMuint32 */
+#define G2L_BIST_BUSY 0xffe0 /* width RMuint32 */
+#define G2L_BIST_PASS 0xffe4 /* width RMuint32 */
+#define G2L_BIST_MASK 0xffe8 /* width RMuint32 */
+#define G2L_RESET_CONTROL 0xfffc /* width RMuint32 */
+#define CPU_UART0_base 0xc100 /* width RMuint32 */
+#define CPU_UART1_base 0xc200 /* width RMuint32 */
+#define CPU_UART_RBR 0x00 /* width RMuint32 */
+#define CPU_UART_THR 0x04 /* width RMuint32 */
+#define CPU_UART_IER 0x08 /* width RMuint32 */
+#define CPU_UART_IIR 0x0c /* width RMuint32 */
+#define CPU_UART_FCR 0x10 /* width RMuint32 */
+#define CPU_UART_LCR 0x14 /* width RMuint32 */
+#define CPU_UART_MCR 0x18 /* width RMuint32 */
+#define CPU_UART_LSR 0x1c /* width RMuint32 */
+#define CPU_UART_MSR 0x20 /* width RMuint32 */
+#define CPU_UART_SCR 0x24 /* width RMuint32 */
+#define CPU_UART_CLKDIV 0x28 /* width RMuint32 */
+#define CPU_UART_CLKSEL 0x2c /* width RMuint32 */
+/* CPUBlock registers done */
+
+/* XPUBlock registers */
+#define REG_BASE_xpu_block 0x000e0000 /* width RMuint32 */
+/* XPUBlock registers done */
+
+/* IPUBlock registers */
+#define REG_BASE_ipu_block 0x000f0000 /* width RMuint32 */
+/* IPUBlock registers done */
+
+/* DisplayBlock registers */
+#define REG_BASE_display_block 0x00070000 /* width RMuint32 */
+#define PMEM_BASE_display_block 0x00300000 /* width RMuint32 */
+#define VIF_w0 0x4000 /* width RMuint32 */
+#define VIF_w1 0x4100 /* width RMuint32 */
+#define VIF_w2 0x4200 /* width RMuint32 */
+#define VIF_w3 0x4F00 /* width RMuint32 */
+#define VIF_r0 0x4300 /* width RMuint32 */
+#define VIF_r1 0x4400 /* width RMuint32 */
+#define VIF_r2 0x4500 /* width RMuint32 */
+#define VIF_r3 0x4600 /* width RMuint32 */
+#define VIF_r4 0x4700 /* width RMuint32 */
+#define VIF_r5 0x4800 /* width RMuint32 */
+#define VIF_r6 0x4900 /* width RMuint32 */
+#define VIF_r7 0x4A00 /* width RMuint32 */
+#define VIF_r8 0x4B00 /* width RMuint32 */
+#define VIF_r9 0x4C00 /* width RMuint32 */
+#define VIF_r10 0x4D00 /* width RMuint32 */
+#define VIF_r11 0x4E00 /* width RMuint32 */
+#define VIF_offs 0x0100 /* width RMuint32 */
+#define VIF_add 0x0000 /* width RMuint32 */
+#define VIF_cnt 0x0004 /* width RMuint32 */
+#define VIF_skip 0x0008 /* width RMuint32 */
+#define VIF_cmd 0x000c /* width RMuint32 */
+#define VIF_addB 0x0010 /* width RMuint32 */
+#define VIF_cntB 0x0014 /* width RMuint32 */
+#define VIF_skipB 0x0018 /* width RMuint32 */
+#define VBUS_IDLE 0x0 /* width RMuint32 */
+#define VBUS_LINEAR 0x1 /* width RMuint32 */
+#define VBUS_DOUBLE 0x2 /* width RMuint32 */
+#define VBUS_RECTANGLE 0x3 /* width RMuint32 */
+#define VBUS_DOUBLE_FIELD 0x4 /* width RMuint32 */
+#define VBUS_DOUBLE_RECTANGLE 0x5 /* width RMuint32 */
+#define VBUS_8BYTE_COLUMN 0x6 /* width RMuint32 */
+#define VBUS_VOID 0x8 /* width RMuint32 */
+#define VBUS_LINEAR_VOID 0x9 /* width RMuint32 */
+#define VBUS_DOUBLE_VOID 0xa /* width RMuint32 */
+#define VBUS_RECTANGLE_VOID 0xb /* width RMuint32 */
+#define VBUS_DOUBLE_FIELD_VOID 0xc /* width RMuint32 */
+#define VBUS_DOUBLE_RECTANGLE_VOID 0xd /* width RMuint32 */
+#define VBUS_8BYTE_COLUMN_VOID 0xe /* width RMuint32 */
+/* DisplayBlock registers done */
+
+/* DemuxEngine registers */
+#define REG_BASE_demux_engine 0x000A0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine 0x00140000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine 0x00140000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine 0x00150000 /* width RMuint32 */
+#define REG_BASE_demux_engine_0 0x000A0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine_0 0x00140000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine_0 0x00140000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine_0 0x00150000 /* width RMuint32 */
+#define REG_BASE_demux_engine_1 0x000b0000 /* width RMuint32 */
+#define MEM_BASE_demux_engine_1 0x00160000 /* width RMuint32 */
+#define PMEM_BASE_demux_engine_1 0x00160000 /* width RMuint32 */
+#define DMEM_BASE_demux_engine_1 0x00170000 /* width RMuint32 */
+#define TDMX_gpio_data 0x2e0c /* width RMuint32 */
+#define TDMX_gpio_dir 0x2e0d /* width RMuint32 */
+/* DemuxEngine registers done */
+
+/* MpegEngine registers */
+#define REG_BASE_mpeg_engine_0 0x00080000 /* width RMuint32 */
+#define MEM_BASE_mpeg_engine_0 0x00100000 /* width RMuint32 */
+#define PMEM_BASE_mpeg_engine_0 0x00100000 /* width RMuint32 */
+#define DMEM_BASE_mpeg_engine_0 0x00110000 /* width RMuint32 */
+#define REG_BASE_mpeg_engine_1 0x00090000 /* width RMuint32 */
+#define MEM_BASE_mpeg_engine_1 0x00120000 /* width RMuint32 */
+#define PMEM_BASE_mpeg_engine_1 0x00120000 /* width RMuint32 */
+#define DMEM_BASE_mpeg_engine_1 0x00130000 /* width RMuint32 */
+#define RBUS_offset 0x4000 /* width RMuint32 */
+/* MpegEngine registers done */
+
+/* VideoDecoder registers */
+/* VideoDecoder registers done */
+
+/* AudioEngine registers */
+#define REG_BASE_audio_engine_0 0x000c0000 /* width RMuint32 */
+#define MEM_BASE_audio_engine_0 0x00180000 /* width RMuint32 */
+#define PMEM_BASE_audio_engine_0 0x00180000 /* width RMuint32 */
+#define DMEM_BASE_audio_engine_0 0x00190000 /* width RMuint32 */
+#define REG_BASE_audio_engine_1 0x000d0000 /* width RMuint32 */
+#define MEM_BASE_audio_engine_1 0x001a0000 /* width RMuint32 */
+#define PMEM_BASE_audio_engine_1 0x001a0000 /* width RMuint32 */
+#define DMEM_BASE_audio_engine_1 0x001b0000 /* width RMuint32 */
+#define audio_mutex0 0x3e90 /* width RMuint32 */
+#define audio_mutex1 0x3e91 /* width RMuint32 */
+#define audio_mutex2 0x3e92 /* width RMuint32 */
+#define audio_mutex3 0x3e93 /* width RMuint32 */
+#define audio_mutex4 0x3e94 /* width RMuint32 */
+#define audio_mutex5 0x3e95 /* width RMuint32 */
+#define audio_mutex6 0x3e96 /* width RMuint32 */
+#define audio_mutex7 0x3e97 /* width RMuint32 */
+/* AudioEngine registers done */
+
+/* AudioDecoder registers */
+/* AudioDecoder registers done */
+
+/* AudioCapture registers */
+/* AudioCapture registers done */
+
+/* VoipCodec registers */
+/* VoipCodec registers done */
+
+/* CRCDecoder registers */
+/* CRCDecoder registers done */
+
+/* XCRCDecoder registers */
+/* XCRCDecoder registers done */
+
+/* StreamCapture registers */
+/* StreamCapture registers done */
+
+/* RawDataTransfer registers */
+/* RawDataTransfer registers done */
+
+/* I2C registers */
+#define I2C_MASTER_CONFIG 0x80 /* width RMuint32 */
+#define I2C_MASTER_CLK_DIV 0x84 /* width RMuint32 */
+#define I2C_MASTER_DEV_ADDR 0x88 /* width RMuint32 */
+#define I2C_MASTER_ADDR 0x8c /* width RMuint32 */
+#define I2C_MASTER_DATA_OUT 0x90 /* width RMuint32 */
+#define I2C_MASTER_DATA_IN 0x94 /* width RMuint32 */
+#define I2C_MASTER_STATUS 0x98 /* width RMuint32 */
+#define I2C_MASTER_STARTXFER 0x9c /* width RMuint32 */
+#define I2C_MASTER_BYTE_CNT 0xa0 /* width RMuint32 */
+#define I2C_MASTER_INTEN 0xa4 /* width RMuint32 */
+#define I2C_MASTER_INT 0xa8 /* width RMuint32 */
+#define I2C_SLAVE_ADDR_REG 0xC0 /* width RMuint32 */
+#define I2C_SLAVE_DATAOUT 0xC4 /* width RMuint32 */
+#define I2C_SLAVE_DATAIN 0xC8 /* width RMuint32 */
+#define I2C_SLAVE_STATUS 0xCC /* width RMuint32 */
+#define I2C_SLAVE_INTEN 0xD0 /* width RMuint32 */
+#define I2C_SLAVE_INT 0xD4 /* width RMuint32 */
+#define I2C_SLAVE_BUS_HOLD 0xD8 /* width RMuint32 */
+/* I2C registers done */
+
+/* MM registers */
+/* MM registers done */
+
+/* SpuDecoder registers */
+/* SpuDecoder registers done */
+
+/* PictureTransform registers */
+/* PictureTransform registers done */
+
+/* ClosedCaptionDecoder registers */
+/* ClosedCaptionDecoder registers done */
+
+/* RTC registers */
+/* RTC registers done */
+
+/* Cipher registers */
+/* Cipher registers done */
+
+/* STC registers */
+/* STC registers done */
+
+/* PLL registers */
+/* PLL registers done */
+
+/* DemuxCipher registers */
+/* DemuxCipher registers done */
+
+/* DemuxTask registers */
+/* DemuxTask registers done */
+
+/* DemuxOutput registers */
+/* DemuxOutput registers done */
+
+/* CCFifo registers */
+/* CCFifo registers done */
+
+/* Sha1Sum registers */
+/* Sha1Sum registers done */
+
+/* XTask registers */
+/* XTask registers done */
+
+/* TTXFifo registers */
+/* TTXFifo registers done */
+
+/* VCXO registers */
+/* VCXO registers done */
+
+/* PPF registers */
+/* PPF registers done */
+
+#endif /* __EMHWLIB_REGISTERS_TANGO3_H__ */
+
+/* End of generated file ../emhwlib_hal/include/tango3/emhwlib_registers_tango3.h */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_registers_tango3.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_registers_tango3.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_registers_tango3.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_registers_tango3.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,609 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/tango3/emhwlib_registers_tango3.inc (generated from emhwlib_hal/include/tango3/emhwlib_registers_tango3.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+REG_BASE_system_block=0x10000
+SYS_clkgen0_pll=0x0
+SYS_clkgen0_div=0x4
+SYS_clkgen1_pll=0x8
+SYS_clkgen1_div=0xc
+SYS_clkgen2_pll=0x10
+SYS_clkgen2_div=0x14
+SYS_clkgen3_pll=0x18
+SYS_clkgen3_div=0x1c
+SYS_avclk_mux=0x38
+SYS_sysclk_mux=0x3c
+SYS_clk_cnt=0x40
+SYS_xtal_in_cnt=0x48
+DRAM_vbus_w0_cfg=0x300
+DRAM_vbus_w1_cfg=0x304
+DRAM_vbus_w2_cfg=0x308
+DRAM_vbus_w3_cfg=0x30c
+DRAM_vbus_r0_cfg=0x340
+DRAM_vbus_r1_cfg=0x344
+DRAM_vbus_r2_cfg=0x348
+DRAM_vbus_r3_cfg=0x34c
+DRAM_vbus_r4_cfg=0x350
+DRAM_vbus_r5_cfg=0x354
+DRAM_vbus_r6_cfg=0x358
+DRAM_vbus_r7_cfg=0x35c
+DRAM_vbus_r8_cfg=0x360
+DRAM_vbus_r9_cfg=0x364
+DRAM_vbus_r10_cfg=0x368
+DRAM_vbus_r11_cfg=0x36c
+DRAM_mbus_w0_cfg=0x200
+DRAM_mbus_w1_cfg=0x204
+DRAM_mbus_w2_cfg=0x208
+DRAM_mbus_w3_cfg=0x20c
+DRAM_mbus_w4_cfg=0x210
+DRAM_mbus_w5_cfg=0x214
+DRAM_mbus_w6_cfg=0x218
+DRAM_mbus_w7_cfg=0x21c
+DRAM_mbus_w8_cfg=0x220
+DRAM_mbus_w9_cfg=0x224
+DRAM_mbus_w10_cfg=0x228
+DRAM_mbus_r0_cfg=0x240
+DRAM_mbus_r1_cfg=0x244
+DRAM_mbus_r2_cfg=0x248
+DRAM_mbus_r3_cfg=0x24c
+DRAM_mbus_r4_cfg=0x250
+DRAM_mbus_r5_cfg=0x254
+DRAM_mbus_r6_cfg=0x258
+DRAM_mbus_r7_cfg=0x25c
+DRAM_mbus_r8_cfg=0x260
+DRAM_mbus_r9_cfg=0x264
+DRAM_mbus_r10_cfg=0x268
+SYS_hostclk_mux=0x30
+SYS_sysclk_premux=0x34
+SYS_rnd_cnt=0x44
+SYS_cnt_cfg=0x4c
+SYS_cfg_cnt0=0x50
+SYS_cfg_cnt1=0x54
+SYS_cfg_cnt2=0x58
+SYS_cfg_cnt3=0x5c
+SYS_cfg_cnt4=0x60
+SYS_cleandiv0_div=0x80
+SYS_cleandiv1_div=0x88
+SYS_cleandiv2_div=0x90
+SYS_cleandiv3_div=0x98
+SYS_cleandiv4_div=0xa0
+SYS_cleandiv5_div=0xa8
+SYS_cleandiv6_div=0xb0
+SYS_cleandiv7_div=0xb8
+SYS_cleandiv8_div=0xc0
+SYS_cleandiv9_div=0xc8
+SYS_cleandiv10_div=0xd0
+MARB_mid01_cfg=0x200
+MARB_mid21_cfg=0x204
+MARB_mid02_cfg=0x208
+MARB_mid22_cfg=0x20c
+MARB_mid04_cfg=0x210
+MARB_mid24_cfg=0x214
+MARB_mid25_cfg=0x218
+MARB_mid08_cfg=0x21c
+MARB_mid28_cfg=0x220
+MARB_mid29_cfg=0x224
+MARB_mid0C_cfg=0x228
+MARB_mid2C_cfg=0x22c
+MARB_mid10_cfg=0x230
+MARB_mid30_cfg=0x234
+MARB_mid31_cfg=0x238
+MARB_mid12_cfg=0x23c
+MARB_mid32_cfg=0x240
+VARB_mid01_cfg=0x300
+VARB_mid02_cfg=0x304
+VARB_mid21_cfg=0x308
+VARB_mid22_cfg=0x30c
+VARB_mid23_cfg=0x310
+VARB_mid24_cfg=0x314
+VARB_mid25_cfg=0x318
+VARB_mid26_cfg=0x31c
+VARB_mid27_cfg=0x320
+VARB_mid28_cfg=0x324
+VARB_mid29_cfg=0x328
+VARB_mid2A_cfg=0x32c
+VARB_mid10_cfg=0x330
+VARB_mid30_cfg=0x334
+VARB_mid31_cfg=0x338
+VARB_mid03_cfg=0x33c
+IARB_mid01_cfg=0x400
+IARB_mid02_cfg=0x404
+SYS_gpio_dir=0x500
+SYS_gpio_data=0x504
+SYS_gpio_int=0x508
+SYS_gpio15_pwm=0x510
+SYS_gpio14_pwm=0x514
+REG_BASE_dram_controller_0=0x30000
+REG_BASE_dram_controller_1=0x40000
+MEM_BASE_dram_controller_0=0x80000000
+MEM_BASE_dram_controller_1=0xc0000000
+MEM_BASE_dram_controller_0_alias=0x10000000
+MEM_BASE_dram_controller_1_alias=0x20000000 
+DRAM_dunit_cfg=0x0
+DRAM_dunit_delay0_ctrl=0x4
+DRAM_dunit_delay1_ctrl=0x8
+DRAM_dunit_auto_delay=0xc
+DRAM_dunit_fall_delay0=0x10
+DRAM_dunit_fall_delay1=0x14
+DRAM_dunit_bw_lobound=0x18
+DRAM_dunit_bw_hibound=0x1c
+DRAM_dunit_bw_probe_cfg=0x20
+DRAM_dunit_bw_probe_cnt=0x24
+DRAM_dunit_bw_cntall=0x28
+DRAM_dunit_calibration_delay=0x30
+DRAM_dunit_calibration_rise_err=0x34
+DRAM_dunit_calibration_fall_err=0x38
+DRAM_dunit_calibration_page=0x88
+DRAM_dunit_flush_buffer=0x104
+REG_BASE_host_interface=0x20000
+MEM_BASE_host_interface=0x40000000
+IDE_data=0x0
+IDE_error=0x4
+IDE_count=0x8
+IDE_start_sector=0xc
+IDE_cylinder_lo=0x10
+IDE_cylinder_hi=0x14
+IDE_head_device=0x18
+IDE_cmd_stat=0x1c
+IDE_irq_stat=0x218
+IDE_cmd_stat__=0x21c
+PB_timing0=0x800
+PB_timing1=0x804
+PB_timing2=0x808
+PB_timing3=0x80c
+PB_timing4=0x810
+PB_timing5=0x814
+PB_default_timing=0x818
+PB_use_timing0=0x81c
+PB_use_timing1=0x820
+PB_use_timing2=0x824
+PB_use_timing3=0x828
+PB_use_timing4=0x82c
+PB_use_timing5=0x830
+PB_CS_config=0x834
+PB_automode_start_address=0x840
+PB_automode_control=0x844
+EMHWLIB_IS_HOST=0xe000
+HOST_REG1=0xfed0
+HOST_REG2=0xfed4
+READ_ADDRESS=0xfec0
+READ_COUNTER=0xfec4
+READ_ENABLE=0xfec8
+REV_ORDER=0xfecc
+WRITE_ADDRESS=0xfed8
+WRITE_COUNTER=0xfedc
+WRITE_ENABLE=0xfee0
+BURST=0xfee4
+PCI_TIMEOUT=0x8000
+PCI_TIMEOUT_STATUS=0x8004
+PCI_TIMER=0x8008
+PCI_TIMER_TEST=0x800c
+PCI_WAKEUP=0x8010
+PCI_REGION_0_BASE=0x9000
+PCI_REGION_1_BASE=0x9004
+PCI_REGION_2_BASE=0x9008
+PCI_REGION_3_BASE=0x900c
+PCI_REGION_4_BASE=0x9010
+PCI_REGION_5_BASE=0x9014
+PCI_REGION_6_BASE=0x9018
+PCI_REGION_7_BASE=0x901c
+PCI_irq_status=0x9020
+PCI_irq_set=0x9024
+PCI_irq_clear=0x9028
+SBOX_FIFO_RESET=0x90a0
+SBOX_ROUTE=0x90a8
+output_SBOX_MBUS_W0=0x9080
+output_SBOX_MBUS_W1=0x9084
+output_SBOX_PCI_MASTER=0x9088
+output_SBOX_PCI_SLAVE=0x908c
+output_SBOX_CIPHER=0x9090
+output_SBOX_IDE_ISA=0x9094
+output_SBOX_IDE_DVD=0x9098
+input_keep_SBOX=0x0
+input_MBUS_R0_SBOX=0x1
+input_MBUS_R1_SBOX=0x2
+input_PCI_MASTER_SBOX=0x3
+input_PCI_SLAVE_SBOX=0x4
+input_CIPHER_SBOX=0x5
+input_IDE_DVD_SBOX=0x6
+input_IDE_ISA_SBOX=0x7
+input_SFLA_SBOX=0x8
+input_unconnected_SBOX=0xf
+host_mutex0=0x9040
+host_mutex1=0x9044
+host_mutex2=0x9048
+host_mutex3=0x904c
+host_mutex4=0x9050
+host_mutex5=0x9054
+host_mutex6=0x9058
+host_mutex7=0x905c
+host_mutex8=0x9060
+host_mutex9=0x9064
+host_mutex10=0x9068
+host_mutex11=0x906c
+host_mutex12=0x9070
+host_mutex13=0x9074
+host_mutex14=0x9078
+host_mutex15=0x907c
+PCI_host_reg5=0xfe94
+PCI_chip_is_host=0xfe90
+IDECTRL_idesrc=0x20d0
+IDECTRL_pri_drv1udmatim1=0x20e0
+IDECTRL_pri_drv1udmatim2=0x20f0
+IDECTRL_pri_idectl=0x2100
+IDECTRL_pri_drv0tim=0x2110
+IDECTRL_pri_drv1tim=0x2120
+IDECTRL_idemisc=0x2130
+IDECTRL_idestatus=0x2140
+IDECTRL_udmactl=0x2150
+IDECTRL_pri_drv0udmatim1=0x2160
+IDECTRL_pri_drv0udmatim2=0x2170
+IDECTRL_pref_st=0x2310
+IDECTRL_pri_ctrlblock=0x2398
+IDECTRL_pri_cmdblock=0x23c0
+IDECTRL_bmic=0x2400
+IDECTRL_bmis=0x2410
+IDECTRL_bmidtp=0x2420
+IDECTRL_ide_dmaptr=0x2780
+IDECTRL_ide_dmalen=0x2790
+IDECTRL_pio_prefetch_data=0x27c0
+MEM_BASE_pfla=0x40000000
+PB_CS0_OFFSET=0x0
+PB_CS1_OFFSET=0x4000000
+PB_CS2_OFFSET=0x8000000
+PB_CS3_OFFSET=0xc000000
+ETH_gpio_dir1=0x7100
+ETH_gpio_data1=0x7104
+ETH_gpio_mask1=0x7108
+ETH_gpio_dir2=0x710c
+ETH_gpio_data2=0x7110
+PCI_host_reg1=0xfed0
+PCI_host_reg2=0xfed4
+PCI_host_reg3=0xfe80
+PCI_host_reg4=0xfe84
+PCI_pcictrl_reg1=0xfe88
+PCI_pcictrl_reg2=0xfe8c
+PCI_pcictrl_reg3=0xfefc
+PCI_REG0=0xfee8
+PCI_REG1=0xfeec
+PCI_REG2=0xfef0
+PCI_REG3=0xfef4
+PCI_CONFIG=0xfef8
+MIF_W0_ADD=0xb000
+MIF_W0_CNT=0xb004
+MIF_W0_SKIP=0xb008
+MIF_W0_CMD=0xb00c
+MIF_W1_ADD=0xb040
+MIF_W1_CNT=0xb044
+MIF_W1_SKIP=0xb048
+MIF_W1_CMD=0xb04c
+MIF_R0_ADD=0xb080
+MIF_R0_CNT=0xb084
+MIF_R0_SKIP=0xb088
+MIF_R0_CMD=0xb08c
+MIF_R1_ADD=0xb0c0
+MIF_R1_CNT=0xb0c4
+MIF_R1_SKIP=0xb0c8
+MIF_R1_CMD=0xb0cc
+MBUS_IDLE=0x0
+MBUS_LINEAR=0x1
+MBUS_DOUBLE=0x2
+MBUS_RECTANGLE=0x3
+MBUS_VOID=0x4
+MBUS_LINEAR_VOID=0x5
+MBUS_DOUBLE_VOID=0x6
+MBUS_RECTANGLE_VOID=0x7
+MBUS_TILED=0x8
+GBUS_MUTEX_XPU=0x14
+GBUS_MUTEX_PT110=0x16
+GBUS_MUTEX_TDMX=0x19
+GBUS_MUTEX_AUDIO_0=0x1b
+GBUS_MUTEX_AUDIO_1=0x1c
+GBUS_MUTEX_MPEG_0=0x1d
+GBUS_MUTEX_MPEG_1=0x1e
+GBUS_MUTEX_HOST=0x1f
+GBUS_MUTEX_LOCAL=0x10
+REG_BASE_cpu_block=0x60000
+CPU_time0_load=0xc500
+CPU_time0_value=0xc504
+CPU_time0_ctrl=0xc508
+CPU_time0_clr=0xc50c
+CPU_time1_load=0xc600
+CPU_time1_value=0xc604
+CPU_time1_ctrl=0xc608
+CPU_time1_clr=0xc60c
+CPU_rtc_data=0xc800
+CPU_rtc_match=0xc804
+CPU_rtc_stat=0xc808
+CPU_rtc_load=0xc80c
+CPU_rtc_ctrl=0xc810
+CPU_irq_status=0xe000
+CPU_irq_rawstat=0xe004
+CPU_irq_enableset=0xe008
+CPU_irq_enableclr=0xe00c
+CPU_irq_softset=0xe010
+CPU_irq_softclr=0xe014
+CPU_fiq_status=0xe100
+CPU_fiq_rawstat=0xe104
+CPU_fiq_enableset=0xe108
+CPU_fiq_enableclr=0xe10c
+CPU_fiq_softset=0xe110
+CPU_fiq_softclr=0xe114
+CPU_edge_status=0xe200
+CPU_edge_rawstat=0xe204
+CPU_edge_config_rise=0xe208
+CPU_edge_config_fall=0xe20c
+CPU_SOFT_INT=0x1
+CPU_UART0_INT=0x2
+CPU_UART1_INT=0x4
+CPU_TIMER0_INT=0x20
+CPU_TIMER1_INT=0x40
+CPU_HOST_MBUS_W0_INT=0x200
+CPU_HOST_MBUS_W1_INT=0x400
+CPU_HOST_MBUS_R0_INT=0x800
+CPU_HOST_MBUS_R1_INT=0x1000
+CPU_PCI_INTA=0x2000
+CPU_PCI_INTB=0x4000
+CPU_PCI_INTC=0x8000
+CPU_PCI_INTD=0x10000
+CPU_PCI_FAULT_INT=0x100000
+CPU_INFRARED_INT=0x200000
+CPU_SFLA_INT=0x10
+CPU_DVD_INT=0x80
+CPU_ETH_INT=0x100
+CPU_DMAIDE_INT=0x20000
+CPU_IDE_INT=0x40000
+CPU_FRONTPANEL_INT=0x80000
+CPU_I2C_INT=0x400000
+CPU_GFX_ACCEL_INT=0x800000
+CPU_VSYNC0_INT=0x1000000
+CPU_VSYNC1_INT=0x2000000
+CPU_VSYNC2_INT=0x4000000
+CPU_VSYNC3_INT=0x8000000
+CPU_VSYNC4_INT=0x10000000
+CPU_VSYNC4BKEND_INT=0x20000000
+CPU_VSYNC5_INT=0x40000000
+CPU_VSYNC5BKEND_INT=0x80000000
+CPU_SMARTCARD_HI_INT=0x1
+CPU_HDMI_HI_INT=0x2
+CPU_HDMI_I2C_HI_INT=0x4
+CPU_VBUS_W0_HI_INT=0x8
+CPU_VBUS_W3_HI_INT=0x10
+CPU_ETH_PHY_HI_INT=0x20
+CPU_ETH_MAC_HI_INT=0x40
+CPU_USB_OHCI_MAC_HI_INT=0x80
+CPU_USB_EHCI_MAC_HI_INT=0x100
+LOG2_CPU_SOFT_INT=0x0
+LOG2_CPU_UART0_INT=0x1
+LOG2_CPU_UART1_INT=0x2
+LOG2_CPU_TIMER0_INT=0x5
+LOG2_CPU_TIMER1_INT=0x6
+LOG2_CPU_DVD_INT=0x7
+LOG2_CPU_RTC_INT=0x8
+LOG2_CPU_HOST_MBUS_W0_INT=0x9
+LOG2_CPU_HOST_MBUS_W1_INT=0xa
+LOG2_CPU_HOST_MBUS_R0_INT=0xb
+LOG2_CPU_HOST_MBUS_R1_INT=0xc
+LOG2_CPU_PCI_INTA=0xd
+LOG2_CPU_PCI_INTB=0xe
+LOG2_CPU_PCI_INTC=0xf
+LOG2_CPU_PCI_INTD=0x10
+LOG2_CPU_DMAIDE_INT=0x11
+LOG2_CPU_IDE_INT=0x12
+LOG2_CPU_FRONTPANEL_INT=0x13
+LOG2_CPU_PCI_FAULT_INT=0x14
+LOG2_CPU_INFRARED_INT=0x15
+LOG2_CPU_I2C_INT=0x16
+LOG2_CPU_GFX_ACCEL_INT=0x17
+LOG2_CPU_VSYNC0_INT=0x18
+LOG2_CPU_VSYNC1_INT=0x19
+LOG2_CPU_VSYNC2_INT=0x1a
+LOG2_CPU_VSYNC3_INT=0x1b
+LOG2_CPU_VSYNC4_INT=0x1c
+LOG2_CPU_VSYNC4BKEND_INT=0x1d
+LOG2_CPU_VSYNC5_INT=0x1e
+LOG2_CPU_VSYNC5BKEND_INT=0x1f
+LOG2_CPU_SMARTCARD_INT=0x20
+LOG2_CPU_HDMI_INT=0x21
+LOG2_CPU_HDMI_I2C_INT=0x22
+LOG2_CPU_VBUS_W0_INT=0x23
+LOG2_CPU_VBUS_W3_INT=0x24
+LOG2_CPU_ETH_PHY_INT=0x25
+LOG2_CPU_ETH_MAC_INT=0x26
+LOG2_CPU_USB_OHCI_INT=0x27
+LOG2_CPU_USB_EHCI_INT=0x28
+LOG2_CPU_SATA_INT=0x29
+LOG2_CPU_DMASATA_INT=0x2a
+LOG2_XPU_W0_INT=0x2b
+LOG2_XPU_R0_INT=0x2c
+LOG2_XPU_W_SP_INT=0x2d
+LOG2_XPU_R_SP_INT=0x2e
+LOG2_CPU_GPIO24_INT=0x2f
+LOG2_CPU_GPIO25_INT=0x30
+LOG2_CPU_GPIO26_INT=0x31
+LOG2_CPU_GPIO27_INT=0x32
+LOG2_CPU_VBUS_W4_INT=0x33
+LOG2_CPU_SMARTCARD2_INT=0x34
+LOG2_CPU_HDMI_CEC_INT=0x35
+CPU_edge_status_hi=0xe220
+CPU_edge_rawstat_hi=0xe224
+CPU_edge_config_rise_hi=0xe228
+CPU_edge_config_fall_hi=0xe22c
+CPU_irq_status_hi=0xe018
+CPU_irq_rawstat_hi=0xe01c
+CPU_irq_enableset_hi=0xe020
+CPU_irq_enableclr_hi=0xe024
+CPU_fiq_status_hi=0xe118
+CPU_fiq_rawstat_hi=0xe11c
+CPU_fiq_enableset_hi=0xe120
+CPU_fiq_enableclr_hi=0xe124
+CPU_iiq_status=0xe300
+CPU_iiq_rawstat=0xe304
+CPU_iiq_enableset=0xe308
+CPU_iiq_enableclr=0xe30c
+CPU_iiq_softset=0xe310
+CPU_iiq_softclr=0xe314
+CPU_iiq_status_hi=0xe318
+CPU_iiq_rawstat_hi=0xe31c
+CPU_iiq_enableset_hi=0xe320
+CPU_iiq_enableclr_hi=0xe324
+CPU_UART_GPIOMODE=0x38
+CPU_UART_GPIODIR=0x30
+CPU_UART_GPIODATA=0x34
+CPU_edge_config_rise_set=0xe210
+CPU_edge_config_rise_clr=0xe214
+CPU_edge_config_fall_set=0xe218
+CPU_edge_config_fall_clr=0xe21c
+CPU_edge_config_rise_set_hi=0xe230
+CPU_edge_config_rise_clr_hi=0xe234
+CPU_edge_config_fall_set_hi=0xe238
+CPU_edge_config_fall_clr_hi=0xe23c
+intentionaldiff_em=0xeee0
+CPU_pm_select_0=0xc900
+CPU_pm_counter_0=0xc904
+CPU_pm_select_1=0xc908
+CPU_pm_counter_1=0xc90c
+CPU_remap=0xf000
+CPU_remap1=0xf004
+CPU_remap2=0xf008
+CPU_remap3=0xf00c
+CPU_remap4=0xf010
+CPU_remap5=0xf014
+CPU_remap6=0xf018
+CPU_remap7=0xf01c
+CPU_remap_address=0x1fc00000
+CPU_remap1_address=0x0
+CPU_remap2_address=0x4000000
+CPU_remap3_address=0x8000000
+CPU_remap4_address=0xc000000
+CPU_remap5_address=0x10000000
+CPU_remap6_address=0x14000000
+CPU_remap7_address=0x18000000
+REG_BASE_irq_handler_block=0xf0000
+G2L_BIST_BUSY=0xffe0
+G2L_BIST_PASS=0xffe4
+G2L_BIST_MASK=0xffe8
+G2L_RESET_CONTROL=0xfffc
+CPU_UART0_base=0xc100
+CPU_UART1_base=0xc200
+CPU_UART_RBR=0x0
+CPU_UART_THR=0x4
+CPU_UART_IER=0x8
+CPU_UART_IIR=0xc
+CPU_UART_FCR=0x10
+CPU_UART_LCR=0x14
+CPU_UART_MCR=0x18
+CPU_UART_LSR=0x1c
+CPU_UART_MSR=0x20
+CPU_UART_SCR=0x24
+CPU_UART_CLKDIV=0x28
+CPU_UART_CLKSEL=0x2c
+REG_BASE_xpu_block=0xe0000
+REG_BASE_ipu_block=0xf0000
+REG_BASE_display_block=0x70000
+PMEM_BASE_display_block=0x300000
+VIF_w0=0x4000
+VIF_w1=0x4100
+VIF_w2=0x4200
+VIF_w3=0x4f00
+VIF_r0=0x4300
+VIF_r1=0x4400
+VIF_r2=0x4500
+VIF_r3=0x4600
+VIF_r4=0x4700
+VIF_r5=0x4800
+VIF_r6=0x4900
+VIF_r7=0x4a00
+VIF_r8=0x4b00
+VIF_r9=0x4c00
+VIF_r10=0x4d00
+VIF_r11=0x4e00
+VIF_offs=0x100
+VIF_add=0x0
+VIF_cnt=0x4
+VIF_skip=0x8
+VIF_cmd=0xc
+VIF_addB=0x10
+VIF_cntB=0x14
+VIF_skipB=0x18
+VBUS_IDLE=0x0
+VBUS_LINEAR=0x1
+VBUS_DOUBLE=0x2
+VBUS_RECTANGLE=0x3
+VBUS_DOUBLE_FIELD=0x4
+VBUS_DOUBLE_RECTANGLE=0x5
+VBUS_8BYTE_COLUMN=0x6
+VBUS_VOID=0x8
+VBUS_LINEAR_VOID=0x9
+VBUS_DOUBLE_VOID=0xa
+VBUS_RECTANGLE_VOID=0xb
+VBUS_DOUBLE_FIELD_VOID=0xc
+VBUS_DOUBLE_RECTANGLE_VOID=0xd
+VBUS_8BYTE_COLUMN_VOID=0xe
+REG_BASE_demux_engine=0xa0000
+MEM_BASE_demux_engine=0x140000
+PMEM_BASE_demux_engine=0x140000
+DMEM_BASE_demux_engine=0x150000
+REG_BASE_demux_engine_0=0xa0000
+MEM_BASE_demux_engine_0=0x140000
+PMEM_BASE_demux_engine_0=0x140000
+DMEM_BASE_demux_engine_0=0x150000
+REG_BASE_demux_engine_1=0xb0000
+MEM_BASE_demux_engine_1=0x160000
+PMEM_BASE_demux_engine_1=0x160000
+DMEM_BASE_demux_engine_1=0x170000
+TDMX_gpio_data=0x2e0c
+TDMX_gpio_dir=0x2e0d
+REG_BASE_mpeg_engine_0=0x80000
+MEM_BASE_mpeg_engine_0=0x100000
+PMEM_BASE_mpeg_engine_0=0x100000
+DMEM_BASE_mpeg_engine_0=0x110000
+REG_BASE_mpeg_engine_1=0x90000
+MEM_BASE_mpeg_engine_1=0x120000
+PMEM_BASE_mpeg_engine_1=0x120000
+DMEM_BASE_mpeg_engine_1=0x130000
+RBUS_offset=0x4000
+REG_BASE_audio_engine_0=0xc0000
+MEM_BASE_audio_engine_0=0x180000
+PMEM_BASE_audio_engine_0=0x180000
+DMEM_BASE_audio_engine_0=0x190000
+REG_BASE_audio_engine_1=0xd0000
+MEM_BASE_audio_engine_1=0x1a0000
+PMEM_BASE_audio_engine_1=0x1a0000
+DMEM_BASE_audio_engine_1=0x1b0000
+audio_mutex0=0x3e90
+audio_mutex1=0x3e91
+audio_mutex2=0x3e92
+audio_mutex3=0x3e93
+audio_mutex4=0x3e94
+audio_mutex5=0x3e95
+audio_mutex6=0x3e96
+audio_mutex7=0x3e97
+I2C_MASTER_CONFIG=0x80
+I2C_MASTER_CLK_DIV=0x84
+I2C_MASTER_DEV_ADDR=0x88
+I2C_MASTER_ADDR=0x8c
+I2C_MASTER_DATA_OUT=0x90
+I2C_MASTER_DATA_IN=0x94
+I2C_MASTER_STATUS=0x98
+I2C_MASTER_STARTXFER=0x9c
+I2C_MASTER_BYTE_CNT=0xa0
+I2C_MASTER_INTEN=0xa4
+I2C_MASTER_INT=0xa8
+I2C_SLAVE_ADDR_REG=0xc0
+I2C_SLAVE_DATAOUT=0xc4
+I2C_SLAVE_DATAIN=0xc8
+I2C_SLAVE_STATUS=0xcc
+I2C_SLAVE_INTEN=0xd0
+I2C_SLAVE_INT=0xd4
+I2C_SLAVE_BUS_HOLD=0xd8
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_shared.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_shared.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_shared.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_shared.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,114 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_resources_shared.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2005-03-22
+*/
+
+#ifndef __EMHWLIB_RESOURCES_SHARED_H__
+#define __EMHWLIB_RESOURCES_SHARED_H__
+
+#define VIDEO_0_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_0  + 4 * mpeg_mutex1))
+#define VIDEO_1_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_1  + 4 * mpeg_mutex1))
+#define AUDIO_0_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_0 + 4 * audio_mutex1))
+#define DEMUX_RPC_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex3))
+
+// pt110 local ram map
+#define UCLINUX_CURRENT_PROCESS (REG_BASE_cpu_block + 0x0000)
+
+#define RESET_VECTOR   (REG_BASE_cpu_block + 0x0000)
+#define UNDEF_VECTOR   (REG_BASE_cpu_block + 0x0004)
+#define SWI_VECTOR     (REG_BASE_cpu_block + 0x0008)
+#define I_ABORT_VECTOR (REG_BASE_cpu_block + 0x000c)
+#define D_ABORT_VECTOR (REG_BASE_cpu_block + 0x0010)
+#define RSV_VECTOR     (REG_BASE_cpu_block + 0x0014)
+#define IRQ_VECTOR     (REG_BASE_cpu_block + 0x0018)
+#define FIQ_VECTOR     (REG_BASE_cpu_block + 0x001c)
+
+#define RESET_JUMP     (REG_BASE_cpu_block + 0x0020)
+#define UNDEF_JUMP     (REG_BASE_cpu_block + 0x0024)
+#define SWI_JUMP       (REG_BASE_cpu_block + 0x0028)
+#define I_ABORT_JUMP   (REG_BASE_cpu_block + 0x002c)
+#define D_ABORT_JUMP   (REG_BASE_cpu_block + 0x0030)
+#define RSV_JUMP       (REG_BASE_cpu_block + 0x0034)
+#define IRQ_JUMP       (REG_BASE_cpu_block + 0x0038)
+#define FIQ_JUMP       (REG_BASE_cpu_block + 0x003c)
+
+#define INFINITE_LOOP  (REG_BASE_cpu_block + 0x0040)
+
+/* where to store uclinux interrupt handler */
+#define UCLINUX_RESET_VECTOR   (REG_BASE_cpu_block + 0x0044)
+#define UCLINUX_UNDEF_VECTOR   (REG_BASE_cpu_block + 0x0048)
+#define UCLINUX_SWI_VECTOR     (REG_BASE_cpu_block + 0x004c)
+#define UCLINUX_I_ABORT_VECTOR (REG_BASE_cpu_block + 0x0050)
+#define UCLINUX_D_ABORT_VECTOR (REG_BASE_cpu_block + 0x0054)
+#define UCLINUX_RSV_VECTOR     (REG_BASE_cpu_block + 0x0058)
+#define UCLINUX_IRQ_VECTOR     (REG_BASE_cpu_block + 0x005c)
+#define UCLINUX_FIQ_VECTOR     (REG_BASE_cpu_block + 0x0060)
+
+/* where to store fiq/irq enable values */
+#define UCLINUX_IRQ_ENABLE      (REG_BASE_cpu_block + 0x0064)
+#define UCLINUX_FIQ_ENABLE      (REG_BASE_cpu_block + 0x0068)
+
+/* we use this in uClinux to handshake llad with the hardware library. llad will 
+   initialize the value to 0. As long as this value is 0, llad will mask the
+   triggered interrupt. When the CPUBlock is done loading the IRQ handler, it
+   will set this value to all the IRQ that are now being handled by itself. Next
+   time llad receives an IRQ, it will read this value and if set to the proper
+   interrupt value, it will return without masking the interrupt.
+   This value is a mask of all the IRQs handled by the IRQ handler (see em8xxx
+   hardware IRQ register).
+
+   *** IMPORTANT *** This value must be update in llad.c if changed.
+*/
+#define UCLINUX_LLAD_IRQHANDLER_HANDSHAKE    (REG_BASE_cpu_block + 0x006C)
+
+/* these symbols are used to store the entry point of the irqhandler
+   loaded by the bootloader.  when uclinux boots it overwrites the
+   interrupt vector, and when we load emhwlib we must restore the RUA
+   entry point in the vector. Since the current version of the emhwlib
+   loaded may not match the irqhandler loaded by bootloader, the entry
+   points should not be determined at compilation time, but rather at
+   runtime.
+*/
+#define IRQHANDLER_ENTRY   (REG_BASE_cpu_block + 0x0070) 
+#define FIQHANDLER_ENTRY   (REG_BASE_cpu_block + 0x0074) 
+#define UNDEFHANDLER_ENTRY (REG_BASE_cpu_block + 0x0078) 
+#define JUMPTABLE_ADDRESS  (REG_BASE_cpu_block + 0x007c)
+
+/* address of linux General exeption handler */
+#define LINUX_GE (REG_BASE_cpu_block + 0x0080)
+
+// random seeds (refer to gbuslib/include/gbus_random.h)
+#define RANDOM0              (REG_BASE_cpu_block + LR_RANDOM_SEED + 0)
+#define RANDOM1              (REG_BASE_cpu_block + LR_RANDOM_SEED + 4)
+
+#define PCI_INTERRUPT_ENABLE    (REG_BASE_cpu_block + LR_PCI_INTERRUPT_ENABLE)
+#define HOST_INTERRUPT_STATUS   (REG_BASE_cpu_block + LR_HOST_INTERRUPT_STATUS)
+
+// next 8 dword locations are for local debug, they are reset to 0 at vsync_init time.
+// Please do not affect them in cvs source.
+#define DEBUG_PROBE0                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x00)
+#define DEBUG_PROBE1                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x04)
+#define DEBUG_PROBE2                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x08)
+#define DEBUG_PROBE3                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x0c)
+#define DEBUG_PROBE4                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x10)
+#define DEBUG_PROBE5                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x14)
+#define DEBUG_PROBE6                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x18)
+#define DEBUG_PROBE7                  (REG_BASE_cpu_block + LR_LOCAL_DEBUG_PROBE + 0x1c)
+
+// uses 8 entries, up to 0x1EF0
+#define PARAM_VSYNC_PERIOD_DEC0        (REG_BASE_cpu_block + LR_VSYNC_PERIOD)  // video decoder 0
+
+#endif // __EMHWLIB_RESOURCES_SHARED_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_shared.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_shared.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_shared.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_shared.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,14 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/emhwlib_resources_shared.inc (generated from emhwlib/include/emhwlib_resources_shared.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_tango3.h linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,48 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   emhwlib_resources_tango2.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2004-01-28y
+*/
+
+#ifndef __EMHWLIB_RESOURCES_TANGO3_H__
+#define __EMHWLIB_RESOURCES_TANGO3_H__
+
+#define VSYNC_PARAM_MUTEX   ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex2))
+#define PCI_IRQ_MUTEX       ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex3))
+#define GFX_MUTEX           ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex4))
+#define HOST_MBUS_MUTEX     ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex5))
+#define SOFT_IRQ_MUTEX_TASK ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex6))
+#define SOFT_IRQ_MUTEX_IRQ  ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex7))
+#define SOFT_IRQ_MUTEX_FIQ  ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex8))
+#define RTC_IRQ_MUTEX       ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex9))
+#define XRPC_MUTEX          ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex10))
+#define XTASK_MUTEX         ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex11))
+#define IDMA_MUTEX          ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex12)) /* keep same as tango15 */
+#define TIMER_IRQ_MUTEX     ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex13)) 
+#define SSD_MUTEX           ((struct gbus_mutex *)(REG_BASE_host_interface  + host_mutex14)) 
+
+#define AUDIO_0_IRQ_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_audio_engine_0 + 4 * audio_mutex0))
+#define AUDIO_1_IRQ_MUTEX   ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex0))
+#define VIDEO_0_FIFO_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_0  + 4 * mpeg_mutex0))
+#define VIDEO_1_FIFO_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_mpeg_engine_1  + 4 * mpeg_mutex0))
+#define DEMUX_IRQ_MUTEX     ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex0))
+#define DEMUX_EMHWLIB_MUTEX ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex4))
+#define TIMER_UPDATE_MUTEX  ((struct gbus_mutex *)(DMEM_BASE_demux_engine   + 4 * demux_mutex5))
+
+#define AUDIO_1_RPC_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex1))
+#define AUDIO_1_ENET_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex2))
+#define AUDIO_1_INTSTATUS_MUTEX ((struct gbus_mutex *)(DMEM_BASE_audio_engine_1 + 4 * audio_mutex3))
+
+#endif // __EMHWLIB_RESOURCES_TANGO3_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_tango3.inc linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_tango3.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/emhwlib_resources_tango3.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/emhwlib_resources_tango3.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,14 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib/include/tango3/emhwlib_resources_tango3.inc (generated from emhwlib/include/tango3/emhwlib_resources_tango3.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/hardware.h linux-2.6.30-test/arch/mips/include/asm/tango3/hardware.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/hardware.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/hardware.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,114 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+#ifndef __HARDWARE_H
+#define __HARDWARE_H
+
+#include <linux/version.h>
+#include <asm/tango3/emhwlib_registers_tango3.h>
+#include <asm/tango3/tango3_gbus.h>
+
+// UART0
+#define CPU_uart0_gpio_dir	    (CPU_UART0_base + CPU_UART_GPIODIR)
+#define CPU_uart0_gpio_data	    (CPU_UART0_base + CPU_UART_GPIODATA)
+#define CPU_uart0_gpio_mode	    (CPU_UART0_base + CPU_UART_GPIOMODE)
+
+// UART0
+#define CPU_uart1_gpio_dir	    (CPU_UART1_base + CPU_UART_GPIODIR)
+#define CPU_uart1_gpio_data	    (CPU_UART1_base + CPU_UART_GPIODATA)
+#define CPU_uart1_gpio_mode	    (CPU_UART1_base + CPU_UART_GPIOMODE)
+
+#define MIPS_CPU_IRQ_BASE 0
+
+#if defined(CONFIG_TANGO3_SMP865X)
+#define IRQ_CONTROLLER_IRQ_BASE 8
+#define FIQ_CONTROLLER_IRQ_BASE 72
+#define IIQ_CONTROLLER_IRQ_BASE 136 // bit31 of iiq is linux irq 199
+#define IRQ_COUNT               64  // 64 interrupt sources
+#else
+#error "Unsupported Tango3 chip."
+#endif
+
+#define IRQ_SOFTINT                     (IRQ_CONTROLLER_IRQ_BASE+0)   // gnet compatibility
+// IDE interrupts
+#define IRQ_IDECTRL_IDEDMA	(LOG2_CPU_DMAIDE_INT + IRQ_CONTROLLER_IRQ_BASE)
+#define IRQ_IDECTRL_IDE		(LOG2_CPU_IDE_INT + IRQ_CONTROLLER_IRQ_BASE)
+
+// MBUS interface
+#define MIF_add_offset		    0x0
+#define MIF_cnt_offset              (MIF_W0_CNT - MIF_W0_ADD) //0x04
+#define MIF_add2_skip_offset        (MIF_W0_SKIP - MIF_W0_ADD) //0x08
+#define MIF_cmd_offset              (MIF_W0_CMD - MIF_W0_ADD) //0x0c
+
+// GPIO
+#define GPIO_DIR_INPUT(gpio)        ((1 << (16 + (gpio))))
+#define GPIO_DIR_OUTPUT(gpio)       ((1 << (16 + (gpio))) | (1 << (gpio)))
+#define GPIO_DATA_SET(gpio)         ((1 << (16 + (gpio))) | (1 << (gpio)))
+#define GPIO_DATA_CLEAR(gpio)       ((1 << (16 + (gpio))))
+
+// UART GPIO
+#define UART_GPIO_DIR_INPUT(gpio)        ((1 << (8 + (gpio))))
+#define UART_GPIO_DIR_OUTPUT(gpio)       ((1 << (8 + (gpio))) | (1 << (gpio)))
+#define UART_GPIO_DATA_SET(gpio)         ((1 << (8 + (gpio))) | (1 << (gpio)))
+#define UART_GPIO_DATA_CLEAR(gpio)       ((1 << (8 + (gpio))))
+
+/* PCI Memories */
+#define MEMORY_BASE_PCI_CONFIG      0x50000000UL  /* PCI configuration */
+#define MEMORY_BASE_PCI_IO          0x58000000UL  /* PCI I/O space */
+#define MEMORY_BASE_PCI_MEMORY      0x60000000UL  /* PCI Memory Base */
+
+#define MAX_LOG2_PCIMEM_MAP  	7   	/* 2^(7+3) = 1024MB */
+#define MAX_PCIMEM_MAP_SIZE  	(((1<<(MAX_LOG2_PCIMEM_MAP+3))*7)>>3)	/* Max ~896MB */
+
+#define PCIBIOS_MIN_MEM_EM86XX  (MEMORY_BASE_PCI_MEMORY + 0x40000000UL)   /* base address of EM86xx PCI slave */
+
+// Peripheral bus Registers
+#define HOST_pb0_base               0x0000
+#define HOST_pb_base_cs(n)          (HOST_pb0_base + (0x0200 * (n)))
+
+#define PB_timing_slot(n)	    (PB_timing0 + (0x04 * (n)))
+
+// Bus Master IDE
+#define REG_BASE_host_interface_BMIDE         (REG_BASE_host_interface + IDECTRL_pri_cmdblock)
+
+#define REG_BASE_host_interface_ISAIDE(x)  (REG_BASE_host_interface + HOST_pb_base_cs(x))
+
+#ifndef __ASSEMBLY__
+
+// Physical address mapping
+static inline unsigned long tangox_dma_address(unsigned long physaddr)
+{
+	extern unsigned long phy_remap, max_remap_size;
+
+	/* for Tango3, another remap takes place */
+	if ((physaddr >= CPU_REMAP_SPACE) && (physaddr < (CPU_REMAP_SPACE + max_remap_size)))
+		return(phy_remap + (physaddr - CPU_REMAP_SPACE));
+	else {
+		printk(KERN_ERR "dma_address conversion failure (0x%08lx in range 0x%08x-0x%08lx)\n",
+			physaddr, CPU_REMAP_SPACE, CPU_REMAP_SPACE + max_remap_size);
+		return(physaddr); /* use whatever is specified */
+	}
+}
+
+// Inverted physical address mapping
+static inline unsigned long tangox_inv_dma_address(unsigned long mapaddr)
+{
+	extern unsigned long phy_remap, max_remap_size;
+
+	if ((mapaddr >= phy_remap) && (mapaddr < (phy_remap + max_remap_size)))
+		return(CPU_REMAP_SPACE + (mapaddr - phy_remap));
+	else {
+		printk(KERN_ERR "dma_address inversion failure (0x%08lx in range 0x%08lx-0x%08lx)\n",
+			mapaddr, phy_remap, phy_remap + max_remap_size);
+		return(mapaddr); /* use whatever is specified */
+	}
+}
+#endif
+
+#endif //__HARDWARE_H
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/ir.h linux-2.6.30-test/arch/mips/include/asm/tango3/ir.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/ir.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/ir.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,34 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+                                                                                
+/*
+ * IR related definitions, and function prototypes.
+ */
+#ifndef _IR_H_
+#define _IR_H_
+                                                                                
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/ioctl.h>
+#elif !defined(BOOTLOADER)
+#include <sys/ioctl.h>
+#endif /* __KERNEL__ */
+
+#if defined(__KERNEL__) || !defined(BOOTLOADER)
+/* ioctl commands for user level applications*/
+#define IR_IOC_MAGIC           'I'
+#define IR_IOCSETREPEATKEYS	_IO(IR_IOC_MAGIC, 0)
+#define IR_IOCGETREPEATKEYS	_IO(IR_IOC_MAGIC, 1)
+#define IR_IOCSETWAITPERIOD	_IO(IR_IOC_MAGIC, 2)
+#define IR_IOCGETWAITPERIOD	_IO(IR_IOC_MAGIC, 3)
+#endif /* __KERNEL__ || !BOOTLOADER */
+                                                                                
+#endif /* _IR_H_ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/memcfg.h linux-2.6.30-test/arch/mips/include/asm/tango3/memcfg.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/memcfg.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/memcfg.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,45 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/* For more memcfg operations */
+
+#ifndef _MEMCFG_H_
+#define _MEMCFG_H_
+
+#include <linux/config.h>
+#include <asm/tango3/tango3.h>
+#include <asm/tango3/rmem86xxid.h>
+#include <asm/tango3/emhwlib_lram.h>
+#include <asm/tango3/emhwlib_dram.h>
+
+static inline int is_valid_memcfg(memcfg_t *memcfg_ptr)
+{
+	unsigned int sum, i, *ptr;
+
+	if ((memcfg_ptr->signature) != MEMCFG_SIGNATURE)
+		return(0);
+	for (sum = i = 0, ptr = (unsigned int *)memcfg_ptr;
+		i < (sizeof(memcfg_t) / sizeof(unsigned int)); i++, ptr++)
+		sum += (*ptr);
+	return((sum == 0) ? 1 : 0);
+}
+
+static inline void gen_memcfg_checksum(memcfg_t *memcfg_ptr)
+{
+	unsigned int sum, i, *ptr;
+
+	memcfg_ptr->checksum = 0;
+	for (sum = i = 0, ptr = (unsigned int *)memcfg_ptr;
+		i < (sizeof(memcfg_t) / sizeof(unsigned int)); i++, ptr++)
+		sum += (*ptr);
+	memcfg_ptr->checksum = ~sum + 1;
+}
+
+#endif /* _MEMCFG_H_ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/rmdefs.h linux-2.6.30-test/arch/mips/include/asm/tango3/rmdefs.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/rmdefs.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/rmdefs.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,11 @@
+
+#ifndef __RMDEFS_H
+#define __RMDEFS_H
+
+typedef unsigned long RMuint32;
+typedef unsigned short RMuint16;
+typedef unsigned char RMuint8;
+typedef char RMascii;
+typedef int RMstatus;
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/rmem86xxid.h linux-2.6.30-test/arch/mips/include/asm/tango3/rmem86xxid.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/rmem86xxid.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/rmem86xxid.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,203 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   rmem86xxid.h
+  @brief  
+
+  long description
+
+  @author Emmanuel Michon
+  @date   2004-09-22
+*/
+
+#ifndef __RMEM86XXID_H__
+#define __RMEM86XXID_H__
+
+/*
+  the main chip ids 
+  
+  tango3 is for asic development (should be tango\infty)
+
+  Usually, users do not set by hand, but thru `rmcflags' helper
+*/
+#define EM86XX_CHIPID_MAMBO      1000
+#define EM86XX_CHIPID_MAMBOLIGHT 2000
+#define EM86XX_CHIPID_TANGO      3000
+#define EM86XX_CHIPID_TANGOLIGHT 4000
+#define EM86XX_CHIPID_TANGO15    4500
+#define EM86XX_CHIPID_TANGO2     5000
+#define EM86XX_CHIPID_TANGO3    10000
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_MAMBO)
+#define S_EM86XX_CHIPID "mambo"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_MAMBOLIGHT)
+#define S_EM86XX_CHIPID "mambolight"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGOLIGHT)
+#define S_EM86XX_CHIPID "tangolight"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO15)
+#define S_EM86XX_CHIPID "tango15"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO2)
+#define S_EM86XX_CHIPID "tango2"
+#elif (EM86XX_CHIP==EM86XX_CHIPID_TANGO3)
+#define S_EM86XX_CHIPID "tango3"
+#else
+#error EM86XX_CHIP is not set
+#endif
+
+/* 
+  revisions...
+  
+  Referring to whatever is written at the surface of the BGA,
+  not the PCI revid / subid / etc. This detail is important for some chips
+  are ambiguous software wise.
+  
+  1: ES1
+  2: ES2
+  3: ES3
+  4: ES4 
+  5: ES5 
+  6: ES6 
+  65: revA
+  66: revB
+  67: revC
+  
+  No ID, but numbers. For a 8630ES2 for instance: build with
+  RMCFLAGS="... -DEM86XX_CHIP=EM86XX_CHIPID_TANGO2 -DEM86XX_REVISION=2 ..."
+
+  --------------------------------------------------------------------------
+  package writing          ES1  ES2  ES3  ES4     ES5     ES6  ES7  ES8  ES9 revA revB revC
+
+  EM86XX_REVISION            1    2    3    4       5       6    7    8    9  'A'  'B'  'C'
+
+  8600 `mambo' series                                                           1    2    3
+
+  8620 `tangolight' series                                                    (a)  (b) 0x82
+  8622 `tango15' series   0x81                (d)0x81                   0x82
+                                                                           ^this is the PCI revID
+
+  863x `tango2' series (c)0x81 0x81 0x81 0x82 (e)0x82 (f)0x83 0x84 0x85 0x86                
+
+  (a) don't remember
+  (b) no such chip
+  (c) 8630: FibbedES1 ES1 ES2 ES3 are the same chip
+  (d) 8622: ES1 and revA cannot be distinguished from revID. Software test impossible in practice
+  (e) 8630: ES4 and ES5 cannot be distinguished from revID. Software test with 0x6c900 bit12
+  (f) 8634: ES6 and RevA have the same revID (just different bonding option)
+      8634: ES7 and RevB have the same revID (just different bonding option)
+      8634: ES9 and RevC have the same revID (just different bonding option)
+  --------------------------------------------------------------------------
+
+  Usually, users do not set by hand, but thru `rmcflags' helper
+*/
+#ifndef EM86XX_REVISION
+#error EM86XX_REVISION is not set
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='A') 
+#error inconsistent: 863x revA is actually -DWITH_PROD=1 -DEM86XX_REVISION=6
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='B') 
+#error inconsistent: 863x revB is actually -DWITH_PROD=1 -DEM86XX_REVISION=7
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (EM86XX_REVISION=='C') 
+#error inconsistent: 863x revC is actually -DWITH_PROD=1 -DEM86XX_REVISION=9
+#endif
+
+#if (EM86XX_REVISION==1)
+#define S_EM86XX_REVISION "ES1"
+#elif (EM86XX_REVISION==2)
+#define S_EM86XX_REVISION "ES2"
+#elif (EM86XX_REVISION==3)
+#define S_EM86XX_REVISION "ES3"
+#elif (EM86XX_REVISION==4)
+#define S_EM86XX_REVISION "ES4"
+#elif (EM86XX_REVISION==5)
+#define S_EM86XX_REVISION "ES5"
+#elif (EM86XX_REVISION==6)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revA"
+#else
+#define S_EM86XX_REVISION "ES6"
+#endif
+#elif (EM86XX_REVISION==7)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revB"
+#else
+#define S_EM86XX_REVISION "ES7"
+#endif
+#elif (EM86XX_REVISION==8)
+#define S_EM86XX_REVISION "ES8"
+#elif (EM86XX_REVISION==9)
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2) && (defined(WITH_PROD) || defined(WITH_FACSPROD))
+#define S_EM86XX_REVISION "revC"
+#else
+#define S_EM86XX_REVISION "ES9"
+#endif
+
+#elif (EM86XX_REVISION=='A')
+#define S_EM86XX_REVISION "revA"
+#elif (EM86XX_REVISION=='B')
+#define S_EM86XX_REVISION "revB"
+#elif (EM86XX_REVISION=='C')
+#define S_EM86XX_REVISION "revC"
+#else
+#error complete revision strings
+#endif
+
+/* the compilation modes */
+#define EM86XX_MODEID_WITHHOST   1000
+#define EM86XX_MODEID_STANDALONE 2000
+
+/* the dsps */
+#define EM86XX_ENGINEID_MPEG0 10
+#define EM86XX_ENGINEID_MPEG1 11
+#define EM86XX_ENGINEID_AUDIO0 20
+#define EM86XX_ENGINEID_AUDIO1 21
+#define EM86XX_ENGINEID_DEMUX 30
+
+/* user does not have to set an engine id. This makes sense for mu only */
+#ifdef EM86XX_ENGINE
+#if (EM86XX_ENGINE==EM86XX_ENGINEID_MPEG0)
+#define SENG "mpeg0"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_MPEG1)
+#define SENG "mpeg1"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_AUDIO0)
+#define SENG "audio0"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_AUDIO1)
+#define SENG "audio1"
+#elif (EM86XX_ENGINE==EM86XX_ENGINEID_DEMUX)
+#define SENG "demux"
+#else
+#endif // end of engine dependent stuff
+#endif
+
+#if (EM86XX_CHIP==EM86XX_CHIPID_TANGO2)
+/*
+#if (defined(WITH_PROD) || defined(WITH_FACSPROD)) && !defined WITH_XLOADED_UCODE
+#error inconsistent flag combination.
+#endif
+
+#if (defined(WITH_PROD) || defined(WITH_FACSPROD)) && !defined WITH_IRQHANDLER_BOOTLOADER
+#error inconsistent flag combination.
+#endif
+*/
+#ifdef WITH_UCODE_BOOTLOADER
+#error inconsistent flag combination. You probably want WITH_XLOADED_UCODE
+#endif
+
+#endif
+
+/* the microcode debug mode */
+
+#define EM86XX_DEBUG_CHIP	1000
+#define EM86XX_DEBUG_SIMU	2000
+
+#endif // __RMEM86XXID_H__
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/sigblock.h linux-2.6.30-test/arch/mips/include/asm/tango3/sigblock.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/sigblock.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/sigblock.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,261 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __SIG_BLOCK_H__
+#define __SIG_BLOCK_H__
+
+#define DEFAULT_IRQ_ROUTE1	0x55555555 /* All PCI IRQs route to LOG2_CPU_PCI_INTB */
+#define DEFAULT_IRQ_ROUTE2	0x00030000 /* ISA IDE uses LOG2_CPU_PCU_INTD, Timing slot 0 */
+#define DEFAULT_IRQ_RISE_EDGE_LO	0xff284a00 /* IRQ14 active low level, IRQ19/21 active riseedge */
+#define DEFAULT_IRQ_RISE_EDGE_HI	0x00000000 /* IRQ14 active low level, IRQ19/21 active rise edge */
+#define DEFAULT_IRQ_FALL_EDGE_LO	0x00004000
+#define DEFAULT_IRQ_FALL_EDGE_HI	0x00000000
+#define DEFAULT_IRQ_GPIO_MAP	0x0607080d /* ISA IDE/GPIO 6, PCI/GPIO 8 */
+#define DEFAULT_DEV_ENABLED	0x00003cf7 /* ISAIDE/BMIDE/PCIHOST/IR/FIP/I2CM/I2CS/PCI1-4 enabled */
+#define DEFAULT_PB_DEF_TIMING	0x01090008
+#define DEFAULT_PB_CS_CONFIG	0x00001044
+#define DEFAULT_PB_TIMING0	0x01090008
+#define DEFAULT_PB_USE_TIMING0	0x000001f4
+#define DEFAULT_PB_TIMING1	0x00110101
+#define DEFAULT_PB_USE_TIMING1	0x000003f3
+#define DEFAULT_PB_TIMING2	0
+#define DEFAULT_PB_USE_TIMING2	0
+#define DEFAULT_PB_TIMING3	0
+#define DEFAULT_PB_USE_TIMING3	0
+#define DEFAULT_PB_TIMING4	0
+#define DEFAULT_PB_USE_TIMING4	0
+#define DEFAULT_PB_TIMING5	0
+#define DEFAULT_PB_USE_TIMING5	0
+
+#define DEFAULT_SYSCLK_PLL	0x0 /* Set by XOS */
+#define DEFAULT_SYSCLK_DIV	0x0 /* Not changed */
+
+#define DEFAULT_ETH_MAC_HI	0x00000000 /* MAC address */
+#define DEFAULT_ETH_MAC_LO	0x00000000
+
+/* This list of devices in the enable list field (irq_route2) */
+#define ISAIDE_SHIFT		0
+#define BMIDE_SHIFT		1
+#define PCIHOST_SHIFT		2
+#define ETHERNET_SHIFT		3
+#define IR_SHIFT		4
+#define FIP_SHIFT		5	
+#define I2CM_SHIFT		6
+#define I2CS_SHIFT		7
+#define SDIO_SHIFT		8
+#define USB_SHIFT		9
+#define PCI1_SHIFT		10
+#define PCI2_SHIFT		11
+#define PCI3_SHIFT		12
+#define PCI4_SHIFT		13
+#define PCI5_SHIFT		14
+#define PCI6_SHIFT		15
+#define SATA_SHIFT		16
+#define SCARD_SHIFT		17
+#define GNET_SHIFT		18
+/*				19-32: undefined */
+
+#ifndef __ASSEMBLY__
+
+struct hwinfo {
+	unsigned long sysclk_pll; /* The setting for the PLL */
+	unsigned long sysclk_div;
+
+	/* Only 4 IRQs can be used for PCI devices (LOG2_CPU_PCI_INTA-D,
+	   so we can encode it in 2 bits. Each device can have 4 IRQ
+	   routing and as as result we can use one byte to represent
+	   the IRQ route for a given device (IDSELx). Bu using 8 bytes,
+	   we can represent the PCI devices (IDSEL1-6, 5-6 reserved) as
+	   well as ISA IDE information and device enabling list*/
+	unsigned long irq_route1;	/* PCI dev 1-4 */
+
+	/* PCI dev 5-6, ISA IDE information, device enabling list */
+	unsigned long irq_route2;	/* PCI dev 5-6: bit 0-15 */
+					/* ISA IDE: bit 16-17: IRQ offset */
+
+	unsigned long irq_rise_edge_hi; /* Rising edge config */
+	unsigned long irq_rise_edge_lo; /* Rising edge config */
+	unsigned long irq_fall_edge_hi; /* Falling edge config */
+	unsigned long irq_fall_edge_lo; /* Falling edge config */
+
+	unsigned long gpio_irq_map; /* GPIO pins hook to IRQ13..16 */
+	unsigned long dev_enabled;  /* Device enabling list*/
+
+	unsigned long pb_def_timing;
+	unsigned long pb_cs_config;
+	unsigned long pb_timing0;
+	unsigned long pb_use_timing0;
+	unsigned long pb_timing1;
+	unsigned long pb_use_timing1;
+	unsigned long pb_timing2;
+	unsigned long pb_use_timing2;
+	unsigned long pb_timing3;
+	unsigned long pb_use_timing3;
+	unsigned long pb_timing4;
+	unsigned long pb_use_timing4;
+	unsigned long pb_timing5;
+	unsigned long pb_use_timing5;
+
+	unsigned long mac_hi;	/* Ethernet MAC address */
+	unsigned long mac_lo;
+};
+
+/* Definition of signature block (192bytes), which should start at 0xbfc00000 */
+/* There'll be 20bytes sha1sum afterward (0xbfc000c0-0xbfc000d3) */
+struct signature_block {
+	unsigned long opcodes[2];  /* For opcodes, fixed value 0x10000034/0x00000000 */
+	struct hwinfo hwinfo;
+	/* 
+	   zboot or such specific extensions 
+
+	   Note that YAMON requires extension[2]=0x1105e0 (product ID `thirdparty')
+	 */
+	unsigned long extension[20];	
+};
+
+//RMmustBeEqual(sizeof(struct signature_block),3*64,seed0);
+
+#ifdef __EMHWLIB_REGISTERS_TANGO2_H__
+static inline int isaide_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> ISAIDE_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int bmide_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> BMIDE_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int sata_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SATA_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int scard_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SCARD_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int gnet_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> GNET_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int pci_host_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> PCIHOST_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int ethernet_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> ETHERNET_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int ir_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> IR_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int fip_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> FIP_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int i2cm_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> I2CM_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int i2cs_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> I2CS_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int sdio_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> SDIO_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int usb_enabled(const struct signature_block *sigptr)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> USB_SHIFT) & 1) != 0) ? 1 : 0);
+}
+
+static inline int pcidev_enabled(const struct signature_block *sigptr, int pci_idsel)
+{
+	return(((((sigptr->hwinfo.dev_enabled) >> (pci_idsel - 1 + PCI1_SHIFT)) & 1) != 0) ? 1 : 0);
+}
+
+/* Given PCI device idsel number and INT number, returning the IRQ number
+   for it */
+static inline int pcidev_intr_num(const struct signature_block *sigptr,
+				const int pci_idsel, const int int_num)
+{
+	unsigned long route;
+	int irq;
+
+	if (pcidev_enabled(sigptr, pci_idsel) == 0)
+		return(-1);
+	else if ((pci_idsel >= 1) && (pci_idsel <= 4)) {
+		/* Get the routing information for specific device */
+		route = ((sigptr->hwinfo.irq_route1) >> ((pci_idsel - 1) * 8)) & 0xff;
+		irq = (int)((route >> (int_num * 2)) & 0x3); /* int_num: 0-3 = INTA-D */
+	} else if ((pci_idsel >= 5) && (pci_idsel <= 6)) {
+		/* Get the routing information for specific device */
+		route = ((sigptr->hwinfo.irq_route2) >> ((pci_idsel - 5) * 8)) & 0xff;
+		irq = (int)((route >> (int_num * 2)) & 0x3); /* int_num: 0-3 = INTA-D */
+	} else 
+		return(-1);
+
+	return(LOG2_CPU_PCI_INTA + irq);
+}
+ 
+/* Find out the CS# used by ISA IDE */
+static inline int isaide_cs_select(const struct signature_block *sigptr)
+{
+	unsigned long cs_config = (sigptr->hwinfo.pb_cs_config >> 12) & 0xf;
+	int i;
+
+	if (isaide_enabled(sigptr) == 0)
+		return(-1);
+
+	for (i = 0; i < 4; i++) {
+		if ((cs_config & 0x1) != 0) 
+			return(i);
+		else
+			cs_config >>= 1;
+	}
+	return(-1);
+}
+
+/* Return the IRQ number for ISA IDE */
+static inline int isaide_intr_num(const struct signature_block *sigptr)
+{
+	int irq;
+
+	if (isaide_enabled(sigptr) == 0)
+		return(-1);
+	else
+		irq = (int)(((sigptr->hwinfo.irq_route2) >> 16) & 0x3);
+	return(LOG2_CPU_PCI_INTA + irq);
+}
+
+static inline int isaide_timing_slot(const struct signature_block *sigptr)
+{
+	unsigned long slot;
+
+	slot = ((sigptr->hwinfo.irq_route2) >> 18) & 0x7;
+	return((int)slot);
+}
+#endif /* __EMHWLIB_REGISTERS_TANGO2_H__ */
+
+#endif /* !__ASSEMBLY__ */
+
+#endif /* !__SIG_BLOCK_H__ */
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/sigblock.inc linux-2.6.30-test/arch/mips/include/asm/tango3/sigblock.inc
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/sigblock.inc	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/sigblock.inc	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,59 @@
+#
+#******************************************************
+#* This file is generated automatically, DO NOT EDIT! *
+#******************************************************
+#*
+#* destined to be included by a shell script or a Makefile (keep syntax adapted to both)
+#*
+#* emhwlib_hal/include/sigblock.inc (generated from emhwlib_hal/include/sigblock.h)
+#*
+#* Copyright (C) Sigma Designs, Inc. 2007. All rights reserved.
+#*
+i386=0x1
+linux=0x1
+unix=0x1
+DEFAULT_IRQ_ROUTE1=0x55555555
+DEFAULT_IRQ_ROUTE2=0x30000
+DEFAULT_IRQ_RISE_EDGE_LO=0xff284a00
+DEFAULT_IRQ_RISE_EDGE_HI=0x0
+DEFAULT_IRQ_FALL_EDGE_LO=0x4000
+DEFAULT_IRQ_FALL_EDGE_HI=0x0
+DEFAULT_IRQ_GPIO_MAP=0x607080d
+DEFAULT_DEV_ENABLED=0x3cf7
+DEFAULT_PB_DEF_TIMING=0x1090008
+DEFAULT_PB_CS_CONFIG=0x1044
+DEFAULT_PB_TIMING0=0x1090008
+DEFAULT_PB_USE_TIMING0=0x1f4
+DEFAULT_PB_TIMING1=0x110101
+DEFAULT_PB_USE_TIMING1=0x3f3
+DEFAULT_PB_TIMING2=0x0
+DEFAULT_PB_USE_TIMING2=0x0
+DEFAULT_PB_TIMING3=0x0
+DEFAULT_PB_USE_TIMING3=0x0
+DEFAULT_PB_TIMING4=0x0
+DEFAULT_PB_USE_TIMING4=0x0
+DEFAULT_PB_TIMING5=0x0
+DEFAULT_PB_USE_TIMING5=0x0
+DEFAULT_SYSCLK_PLL=0x0
+DEFAULT_SYSCLK_DIV=0x0
+DEFAULT_ETH_MAC_HI=0x0
+DEFAULT_ETH_MAC_LO=0x0
+ISAIDE_SHIFT=0x0
+BMIDE_SHIFT=0x1
+PCIHOST_SHIFT=0x2
+ETHERNET_SHIFT=0x3
+IR_SHIFT=0x4
+FIP_SHIFT=0x5
+I2CM_SHIFT=0x6
+I2CS_SHIFT=0x7
+SDIO_SHIFT=0x8
+USB_SHIFT=0x9
+PCI1_SHIFT=0xa
+PCI2_SHIFT=0xb
+PCI3_SHIFT=0xc
+PCI4_SHIFT=0xd
+PCI5_SHIFT=0xe
+PCI6_SHIFT=0xf
+SATA_SHIFT=0x10
+SCARD_SHIFT=0x11
+GNET_SHIFT=0x12
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3.h linux-2.6.30-test/arch/mips/include/asm/tango3/tango3.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/tango3.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,62 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   tango3.h
+  @brief  
+
+  <long description>
+
+  @author Emmanuel Michon
+  @date   2004-05-10
+*/
+
+#ifndef __TANGO3_H__
+#define __TANGO3_H__
+#include <linux/config.h>
+#include <asm/tango3/hardware.h>
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO3
+#include <asm/tango3/rmem86xxid.h>
+#include <asm/tango3/emhwlib_lram.h>
+#include <asm/tango3/emhwlib_resources_tango3.h>
+#ifndef CONFIG_TANGOX_BASE_FREQUENCY
+#define TANGOX_BASE_FREQUENCY	27000000 
+#endif
+/* Baudrate setting */
+#if defined(CONFIG_TANGO3_SMP865X)
+#ifndef CONFIG_TANGOX_BASE_BAUD
+#define TANGOX_BASE_BAUD 38400
+#else
+#define TANGOX_BASE_BAUD CONFIG_TANGOX_BASE_BAUD
+#endif
+//#define TANGOX_CPU_FREQUENCY 333000000
+#else
+#error "Unsupported platform"
+#endif /* CONFIG_TANGOX_SMP865X */
+
+/* Memory size used by Linux */
+#ifndef CONFIG_TANGOX_MEMSIZE
+#if defined(CONFIG_TANGO3_SMP865X)
+#define  TANGOX_SYSTEMRAM_ACTUALSIZE   (32*1024*1024)
+#else
+#error "Unsupported platform"
+#endif /* CONFIG_TANGOX_SMP865X */
+#else
+#define TANGOX_SYSTEMRAM_ACTUALSIZE    CONFIG_TANGOX_MEMSIZE
+#endif /* !CONFIG_TANGOX_MEMSIZE */
+
+#define TANGOX_CTRLIRQ 0
+#define TANGOX_CTRLFIQ 1
+#define TANGOX_CTRLIIQ 2
+
+#if defined(CONFIG_TANGO3_SMP865X)
+#define SYS_clkgen_pll        SYS_clkgen3_pll
+#endif
+
+#endif // __TANGO3_H__
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3_gbus.h linux-2.6.30-test/arch/mips/include/asm/tango3/tango3_gbus.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3_gbus.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/tango3_gbus.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,146 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+  Refer to bug #3644.
+
+  TLB-based implementation works on the ranges:
+  [0x00000000..0x20000000[ access thru kseg1
+  [0x20000000..0x2xxxxxxx (size  of dram1, a  parameter of ioremap())[
+  access thru tlb. Outside: unpredictable/oops.
+
+  Remap-based implementation does:
+  00xy b27b26..b0 to 101y(b27|x)b26..b0.
+  and works  everywhere excepted ranges:  [0x18000000..0x20000000[ and
+  [0x28000000..0xffffffff]
+
+  Test with
+  {
+	volatile int q=gbus_read_uint32(pGBus,0x1020212c); // correct
+	q=gbus_read_uint32(pGBus,0x1f20212c);              // incorrect
+	q=gbus_read_uint32(pGBus,0x2020212c);              // correct
+	q=gbus_read_uint32(pGBus,0x2720212c);              // correct
+	q=gbus_read_uint32(pGBus,0x2820212c);              // incorrect
+	q=gbus_read_uint32(pGBus,0x2f20212c);              // incorrect
+  }
+*/
+
+#ifndef __TANGO3_GBUS_H
+#define __TANGO3_GBUS_H
+
+#include <linux/config.h>
+
+#ifndef __ASSEMBLY__
+
+#include "rmdefs.h"
+
+#include <asm/addrspace.h>
+
+struct gbus;
+#define pGBus ((struct gbus *)1)
+
+#ifdef CONFIG_TANGO3_USE_TLB_REMAP_DRAM1
+
+__asm__ (
+	"	.macro gbus_swizzle_addr res tmp addr			\n"
+	"	ext	\\res, \\addr, 29, 1				\n"
+	"	bnez	\\res, 1f					\n"
+	"	lui	\\tmp, 0xa000					\n"
+	"	or	\\res, \\tmp, \\addr				\n"
+	"	j	2f						\n"
+	"	nop							\n"
+	"1:								\n"
+	"	lui	\\tmp, 0x2000					\n"
+	"	sub	\\res, \\addr, \\tmp				\n"
+	"	lw	\\tmp, em86xx_tlb_dram1_map_base		\n"
+	"	add	\\res, \\tmp					\n"
+	"2:								\n"
+	"	.endm");
+
+#else
+
+__asm__ (
+	"	.macro gbus_swizzle_addr res tmp addr			\n"
+	"	rotr	\\res, \\addr, 29				\n"
+	"	ins	\\res, \\res, 30, 1				\n"
+	"	or	\\res, 5					\n"
+	"	rotr	\\res, 3					\n"
+	"	.endm");
+#endif
+
+
+/*
+ * we just want to set kseg1 bit, most of the time address is known at
+ * compile time, so this will usually be reduced to 2 instructions
+ */
+
+#define BUILD_GBUS_READ(size)						\
+static inline RMuint32 gbus_read_dram_uint##size(struct gbus *pgbus,	\
+					    RMuint32 byte_address)	\
+{									\
+	if (__builtin_constant_p(byte_address)) {			\
+		if ((byte_address & 0x70000000) == 0x20000000) {	\
+			byte_address &= ~0x20000000;			\
+			byte_address |= 0x08000000;			\
+		}							\
+		return *((volatile RMuint##size *)KSEG1ADDR(byte_address)); \
+	} else {							\
+		RMuint32 res, tmp;					\
+									\
+		__asm__ __volatile(					\
+			"gbus_swizzle_addr\t%0 %1 %2\n"			\
+			: "=&r" (res), "=&r" (tmp) : "r" (byte_address)); \
+		return *((volatile RMuint##size *)res);			\
+	}								\
+}
+
+BUILD_GBUS_READ(8);
+BUILD_GBUS_READ(16);
+BUILD_GBUS_READ(32);
+
+#define BUILD_GBUS_WRITE(size)						\
+static inline void gbus_write_dram_uint##size(struct gbus *pgbus,	\
+				     RMuint32 byte_address,		\
+				     RMuint##size data)			\
+{									\
+	if (__builtin_constant_p(byte_address)) {			\
+		if ((byte_address & 0x70000000) == 0x20000000) {	\
+			byte_address &= ~0x20000000;			\
+			byte_address |= 0x08000000;			\
+		}							\
+		*((volatile RMuint##size *)KSEG1ADDR(byte_address)) = data; \
+	} else {							\
+		RMuint32 res, tmp;					\
+									\
+		__asm__ __volatile(					\
+			"gbus_swizzle_addr\t%0 %1 %2\n"			\
+			: "=&r" (res), "=&r" (tmp) : "r" (byte_address)); \
+		*((volatile RMuint##size *)res) = data;			\
+	}								\
+}
+
+BUILD_GBUS_WRITE(8);
+BUILD_GBUS_WRITE(16);
+BUILD_GBUS_WRITE(32);
+
+RMuint32 gbus_read_uint32(struct gbus *pgbus, RMuint32 byte_address);
+RMuint16 gbus_read_uint16(struct gbus *pgbus, RMuint32 byte_address);
+RMuint8 gbus_read_uint8(struct gbus *pgbus, RMuint32 byte_address);
+void gbus_write_uint32(struct gbus *pgbus, RMuint32 byte_address, RMuint32 data);
+void gbus_write_uint16(struct gbus *pgbus, RMuint32 byte_address, RMuint16 data);
+void gbus_write_uint8(struct gbus *pgbus, RMuint32 byte_address, RMuint8 data);
+
+#define gbus_readl(r)		gbus_read_uint32(pGBus, (r))
+#define gbus_writel(r, v)	gbus_write_uint32(pGBus, (r), (v))
+#define gbus_readw(r)		gbus_read_uint16(pGBus, (r))
+#define gbus_writew(r, v)	gbus_write_uint16(pGBus, (r), (v))
+#define gbus_readb(r)		gbus_read_uint8(pGBus, (r))
+#define gbus_writeb(r, v)	gbus_write_uint8(pGBus, (r), (v))
+
+#endif /* !__ASSEMBLY__ */
+#endif /* __TANGO3_GBUS_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3_usb.h linux-2.6.30-test/arch/mips/include/asm/tango3/tango3_usb.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3_usb.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/tango3_usb.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,38 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __TANGO3_USB_H
+#define __TANGO3_USB_H
+
+#include <asm/tango3/hardware.h>
+#include <asm/tango3/tango3_gbus.h>
+
+#define TANGOX_EHCI_IRQ	(IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_EHCI_INT)
+#define TANGOX_OHCI_IRQ	(IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_OHCI_INT)
+
+#define TANGOX_EHCI_BASE_ADDR		(REG_BASE_host_interface + 0x1400)
+#define TANGOX_OHCI_BASE_ADDR		(REG_BASE_host_interface + 0x1500)
+#define TANGOX_USB_CTL_STATUS_REG_BASE	(REG_BASE_host_interface + 0x1700)
+
+/*
+ * helpers to access USB registers
+ */
+#define RD_OHCI_REG32(r)	\
+		gbus_readl(TANGOX_OHCI_BASE_ADDR + (r))
+
+#define WR_OHCI_REG32(r, v)	\
+		gbus_writel(TANGOX_OHCI_BASE_ADDR + (r), (v))
+
+#define RD_USB_REG32(r)	\
+		gbus_readl(TANGOX_USB_CTL_STATUS_REG_BASE + (r))
+
+#define WR_USB_REG32(r, v)	\
+		gbus_writel(TANGOX_USB_CTL_STATUS_REG_BASE + (r), (v))
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3api.h linux-2.6.30-test/arch/mips/include/asm/tango3/tango3api.h
--- linux-2.6.30-ori/arch/mips/include/asm/tango3/tango3api.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/tango3/tango3api.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,118 @@
+/*
+ * arch/mips/include/asm/tango3/tango3api.h
+ *
+ * Copyright 2002-2007, Sigma Designs, Inc 
+ *
+ * This file contains SMP86XX controling functions
+ *
+ */
+
+#ifndef __ASM_ARCH_EM86XX_H
+#define __ASM_ARCH_EM86XX_H
+#include <asm/tango3/hardware.h>
+//
+// global variables
+// 
+
+//
+// from arch/arm/arch-em86xx/irq.c
+//
+
+// irq
+void em86xx_mask_irq(unsigned int irq);
+void em86xx_unmask_irq(unsigned int irq);
+void em86xx_wait_irq(unsigned int irq);
+
+// fiq
+void em86xx_mask_fiq(unsigned int fiq);
+void em86xx_unmask_fiq(unsigned int fiq);
+
+// software interrupt
+int em86xx_softirq_isset(int irq);
+void em86xx_softirq_set(int irq);
+void em86xx_softirq_clr(int irq);
+void em86xx_irq_clr(int irq);
+
+//
+// from arch/arm/arch-em86xx/em86xxapi.c
+//
+
+// Cache
+// clean : write dirty buffer (D cache only)
+// invalidate : invalidate the contents of cache (I & D cache)
+// flush : clean + invalidate
+void em86xx_get_cache_state(int *picache, int *pdcache, int *pwriteback);
+void em86xx_enable_cache(int icache, int dcache, int writeback);
+void em86xx_clean_cache_data(void);
+void em86xx_clean_cache_data_region(unsigned int from, unsigned int to);
+void em86xx_invalidate_cache_instruction(void);
+void em86xx_invalidate_cache_instruction_region(unsigned int from, unsigned int to);
+void em86xx_invalidate_cache_data(void);
+void em86xx_invalidate_cache_data_region(unsigned int from, unsigned int to);
+
+void em86xx_flush_cache_all(void);
+void em86xx_flush_cache_data(void);
+void em86xx_flush_cache_data_region(unsigned int from, unsigned int to);
+
+// memory
+unsigned int em86xx_get_pciregionsize(void);
+unsigned int em86xx_get_dmamemorysize(void);
+
+// switchbox (Host interface)
+enum { 
+	SBOX_MBUS_W0 = 0, SBOX_MBUS_W1, SBOX_PCIMASTER, SBOX_PCISLAVE, 
+	SBOX_SATA1, SBOX_IDEFLASH, SBOX_IDEDVD, SBOX_SATA2, SBOX_MBUS_W2, SBOX_MAX
+};
+
+int em86xx_sbox_init(void);
+#if 0
+void em86xx_sbox_reset(void);
+int em86xx_sbox_setup(void);
+int em86xx_sbox_connect(int iface);
+void em86xx_sbox_disconnect(int port);
+#endif
+
+// MBUS DMA 
+typedef void (*mbus_irq_handler_t)(int irq, void *arg);
+
+int em86xx_mbus_init(void);
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any);
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox);
+
+int em86xx_mbus_setup_dma_common(unsigned int regbase, unsigned int addr, unsigned int count, mbus_irq_handler_t handler, void *arg, unsigned int flags);
+void em86xx_mbus_setup_dma_linear(unsigned int regbase, unsigned int addr, unsigned int count, unsigned int flags);
+void em86xx_mbus_setup_dma_double(unsigned int regbase, unsigned int addr, unsigned int count, unsigned int addr2, unsigned int count2, unsigned int flags);
+void em86xx_mbus_setup_dma_rectangle(unsigned int regbase, unsigned int addr, unsigned int horiz, unsigned int lines, int skip, unsigned int flags);
+void em86xx_mbus_setup_dma_void(unsigned int regbase);
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr, unsigned int count, mbus_irq_handler_t handler, void *arg, unsigned int flags);
+int em86xx_mbus_inuse(unsigned int regbase);
+int em86xx_mbus_wait(unsigned int regbase, int sbox);
+int mbus_memcpy(unsigned int regbase, unsigned int src, unsigned int dst, unsigned int size);
+
+// PCI master
+void em86xx_pcimaster_setup_read(unsigned int addr, unsigned int count);
+void em86xx_pcimaster_start_read(int start);
+void em86xx_pcimaster_setup_write(unsigned int addr, unsigned int count);
+void em86xx_pcimaster_start_write(int start);
+
+// GPIO
+#define GPIO_INPUT		0
+#define GPIO_OUTPUT		1
+
+int em86xx_gpio_read(int gpio);
+void em86xx_gpio_write(int gpio, int data);
+void em86xx_gpio_setdirection(int gpio, int dir);
+
+#if defined(CONFIG_EM86XX_UART0_AS_GPIO_FULL) || defined(CONFIG_EM86XX_UART0_AS_GPIO_PARTIAL)
+int em86xx_uart0_gpio_read(int gpio);
+void em86xx_uart0_gpio_write(int gpio, int data);
+void em86xx_uart0_gpio_setdirection(int gpio, int dir);
+#endif
+#if defined(CONFIG_EM86XX_UART1_AS_GPIO_FULL) || defined(CONFIG_EM86XX_UART1_AS_GPIO_PARTIAL)
+int em86xx_uart1_gpio_read(int gpio);
+void em86xx_uart1_gpio_write(int gpio, int data);
+void em86xx_uart1_gpio_setdirection(int gpio, int dir);
+#endif
+
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/thread_info.h linux-2.6.30-test/arch/mips/include/asm/thread_info.h
--- linux-2.6.30-ori/arch/mips/include/asm/thread_info.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/thread_info.h	2009-06-12 18:32:43.000000000 -0400
@@ -128,6 +128,7 @@
 #define TIF_32BIT_ADDR		23	/* 32-bit address space (o32/n32) */
 #define TIF_FPUBOUND		24	/* thread bound to FPU-full CPU set */
 #define TIF_LOAD_WATCH		25	/* If set, load watch registers */
+#define TIF_DMA		26	/* thread is doing kernel-userspace dma */
 #define TIF_SYSCALL_TRACE	31	/* syscall trace active */
 
 #ifdef CONFIG_MIPS32_O32
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/thread_info.h.orig linux-2.6.30-test/arch/mips/include/asm/thread_info.h.orig
--- linux-2.6.30-ori/arch/mips/include/asm/thread_info.h.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/thread_info.h.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,162 @@
+/* thread_info.h: MIPS low-level thread information
+ *
+ * Copyright (C) 2002  David Howells (dhowells@redhat.com)
+ * - Incorporating suggestions made by Linus Torvalds and Dave Miller
+ */
+
+#ifndef _ASM_THREAD_INFO_H
+#define _ASM_THREAD_INFO_H
+
+#ifdef __KERNEL__
+
+
+#ifndef __ASSEMBLY__
+
+#include <asm/processor.h>
+
+/*
+ * low level task data that entry.S needs immediate access to
+ * - this struct should fit entirely inside of one cache line
+ * - this struct shares the supervisor stack pages
+ * - if the contents of this structure are changed, the assembly constants
+ *   must also be changed
+ */
+struct thread_info {
+	struct task_struct	*task;		/* main task structure */
+	struct exec_domain	*exec_domain;	/* execution domain */
+	unsigned long		flags;		/* low level flags */
+	unsigned long		tp_value;	/* thread pointer */
+	__u32			cpu;		/* current CPU */
+	int			preempt_count;	/* 0 => preemptable, <0 => BUG */
+
+	mm_segment_t		addr_limit;	/* thread address space:
+						   0-0xBFFFFFFF for user-thead
+						   0-0xFFFFFFFF for kernel-thread
+						*/
+	struct restart_block	restart_block;
+	struct pt_regs		*regs;
+};
+
+/*
+ * macros/functions for gaining access to the thread information structure
+ *
+ * preempt_count needs to be 1 initially, until the scheduler is functional.
+ */
+#define INIT_THREAD_INFO(tsk)			\
+{						\
+	.task		= &tsk,			\
+	.exec_domain	= &default_exec_domain,	\
+	.flags		= _TIF_FIXADE,		\
+	.cpu		= 0,			\
+	.preempt_count	= 1,			\
+	.addr_limit	= KERNEL_DS,		\
+	.restart_block	= {			\
+		.fn = do_no_restart_syscall,	\
+	},					\
+}
+
+#define init_thread_info	(init_thread_union.thread_info)
+#define init_stack		(init_thread_union.stack)
+
+/* How to get the thread information struct from C.  */
+register struct thread_info *__current_thread_info __asm__("$28");
+#define current_thread_info()  __current_thread_info
+
+/* thread information allocation */
+#if defined(CONFIG_PAGE_SIZE_4KB) && defined(CONFIG_32BIT)
+#define THREAD_SIZE_ORDER (1)
+#endif
+#if defined(CONFIG_PAGE_SIZE_4KB) && defined(CONFIG_64BIT)
+#define THREAD_SIZE_ORDER (2)
+#endif
+#ifdef CONFIG_PAGE_SIZE_8KB
+#define THREAD_SIZE_ORDER (1)
+#endif
+#ifdef CONFIG_PAGE_SIZE_16KB
+#define THREAD_SIZE_ORDER (0)
+#endif
+#ifdef CONFIG_PAGE_SIZE_32KB
+#define THREAD_SIZE_ORDER (0)
+#endif
+#ifdef CONFIG_PAGE_SIZE_64KB
+#define THREAD_SIZE_ORDER (0)
+#endif
+
+#define THREAD_SIZE (PAGE_SIZE << THREAD_SIZE_ORDER)
+#define THREAD_MASK (THREAD_SIZE - 1UL)
+
+#define __HAVE_ARCH_THREAD_INFO_ALLOCATOR
+
+#ifdef CONFIG_DEBUG_STACK_USAGE
+#define alloc_thread_info(tsk)					\
+({								\
+	struct thread_info *ret;				\
+								\
+	ret = kzalloc(THREAD_SIZE, GFP_KERNEL);			\
+								\
+	ret;							\
+})
+#else
+#define alloc_thread_info(tsk) kmalloc(THREAD_SIZE, GFP_KERNEL)
+#endif
+
+#define free_thread_info(info) kfree(info)
+
+#endif /* !__ASSEMBLY__ */
+
+#define PREEMPT_ACTIVE		0x10000000
+
+/*
+ * thread information flags
+ * - these are process state flags that various assembly files may need to
+ *   access
+ * - pending work-to-be-done flags are in LSW
+ * - other flags in MSW
+ */
+#define TIF_SIGPENDING		1	/* signal pending */
+#define TIF_NEED_RESCHED	2	/* rescheduling necessary */
+#define TIF_SYSCALL_AUDIT	3	/* syscall auditing active */
+#define TIF_SECCOMP		4	/* secure computing */
+#define TIF_RESTORE_SIGMASK	9	/* restore signal mask in do_signal() */
+#define TIF_USEDFPU		16	/* FPU was used by this task this quantum (SMP) */
+#define TIF_POLLING_NRFLAG	17	/* true if poll_idle() is polling TIF_NEED_RESCHED */
+#define TIF_MEMDIE		18
+#define TIF_FREEZE		19
+#define TIF_FIXADE		20	/* Fix address errors in software */
+#define TIF_LOGADE		21	/* Log address errors to syslog */
+#define TIF_32BIT_REGS		22	/* also implies 16/32 fprs */
+#define TIF_32BIT_ADDR		23	/* 32-bit address space (o32/n32) */
+#define TIF_FPUBOUND		24	/* thread bound to FPU-full CPU set */
+#define TIF_LOAD_WATCH		25	/* If set, load watch registers */
+#define TIF_SYSCALL_TRACE	31	/* syscall trace active */
+
+#ifdef CONFIG_MIPS32_O32
+#define TIF_32BIT TIF_32BIT_REGS
+#elif defined(CONFIG_MIPS32_N32)
+#define TIF_32BIT _TIF_32BIT_ADDR
+#endif /* CONFIG_MIPS32_O32 */
+
+#define _TIF_SYSCALL_TRACE	(1<<TIF_SYSCALL_TRACE)
+#define _TIF_SIGPENDING		(1<<TIF_SIGPENDING)
+#define _TIF_NEED_RESCHED	(1<<TIF_NEED_RESCHED)
+#define _TIF_SYSCALL_AUDIT	(1<<TIF_SYSCALL_AUDIT)
+#define _TIF_SECCOMP		(1<<TIF_SECCOMP)
+#define _TIF_RESTORE_SIGMASK	(1<<TIF_RESTORE_SIGMASK)
+#define _TIF_USEDFPU		(1<<TIF_USEDFPU)
+#define _TIF_POLLING_NRFLAG	(1<<TIF_POLLING_NRFLAG)
+#define _TIF_FREEZE		(1<<TIF_FREEZE)
+#define _TIF_FIXADE		(1<<TIF_FIXADE)
+#define _TIF_LOGADE		(1<<TIF_LOGADE)
+#define _TIF_32BIT_REGS		(1<<TIF_32BIT_REGS)
+#define _TIF_32BIT_ADDR		(1<<TIF_32BIT_ADDR)
+#define _TIF_FPUBOUND		(1<<TIF_FPUBOUND)
+#define _TIF_LOAD_WATCH		(1<<TIF_LOAD_WATCH)
+
+/* work to do on interrupt/exception return */
+#define _TIF_WORK_MASK		(0x0000ffef & ~_TIF_SECCOMP)
+/* work to do on any return to u-space */
+#define _TIF_ALLWORK_MASK	(0x8000ffff & ~_TIF_SECCOMP)
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_THREAD_INFO_H */
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/uaccess.h linux-2.6.30-test/arch/mips/include/asm/uaccess.h
--- linux-2.6.30-ori/arch/mips/include/asm/uaccess.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/include/asm/uaccess.h	2009-06-15 11:31:21.000000000 -0400
@@ -714,12 +714,16 @@
 	__cu_from = (from);						\
 	__cu_len = (n);							\
 	might_fault();							\
-	__cu_len = __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);	\
+	__cu_len = __invoke_copy_to_user_dma(__cu_to, __cu_from, __cu_len);	\
 	__cu_len;							\
 })
 
 extern size_t __copy_user_inatomic(void *__to, const void *__from, size_t __n);
 
+extern size_t __invoke_copy_to_user_dma(void __user * __cu_to, const void * __cu_from, long __cu_len);
+extern size_t __invoke_copy_from_user_dma(void * __cu_to, const void __user * __cu_from, long __cu_len);
+
+
 #define __copy_to_user_inatomic(to, from, n)				\
 ({									\
 	void __user *__cu_to;						\
@@ -729,7 +733,7 @@
 	__cu_to = (to);							\
 	__cu_from = (from);						\
 	__cu_len = (n);							\
-	__cu_len = __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);	\
+	__cu_len = __invoke_copy_to_user_dma(__cu_to, __cu_from, __cu_len);	\
 	__cu_len;							\
 })
 
@@ -747,6 +751,8 @@
 	__cu_len;							\
 })
 
+extern long long em86_stats[20];
+
 /*
  * copy_to_user: - Copy a block of data into user space.
  * @to:   Destination address, in user space.
@@ -771,7 +777,7 @@
 	__cu_len = (n);							\
 	if (access_ok(VERIFY_WRITE, __cu_to, __cu_len)) {		\
 		might_fault();						\
-		__cu_len = __invoke_copy_to_user(__cu_to, __cu_from,	\
+		__cu_len = __invoke_copy_to_user_dma(__cu_to, __cu_from,	\
 		                                 __cu_len);		\
 	}								\
 	__cu_len;							\
@@ -783,6 +789,7 @@
 	register const void __user *__cu_from_r __asm__("$5");		\
 	register long __cu_len_r __asm__("$6");				\
 									\
+	em86_stats[4]+=(n); \
 	__cu_to_r = (to);						\
 	__cu_from_r = (from);						\
 	__cu_len_r = (n);						\
@@ -806,6 +813,7 @@
 	register const void __user *__cu_from_r __asm__("$5");		\
 	register long __cu_len_r __asm__("$6");				\
 									\
+	em86_stats[6]+=(n); \
 	__cu_to_r = (to);						\
 	__cu_from_r = (from);						\
 	__cu_len_r = (n);						\
@@ -850,7 +858,7 @@
 	__cu_from = (from);						\
 	__cu_len = (n);							\
 	might_fault();							\
-	__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,		\
+	__cu_len = __invoke_copy_from_user_dma(__cu_to, __cu_from,		\
 	                                   __cu_len);			\
 	__cu_len;							\
 })
@@ -882,7 +890,7 @@
 	__cu_len = (n);							\
 	if (access_ok(VERIFY_READ, __cu_from, __cu_len)) {		\
 		might_fault();						\
-		__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,	\
+		__cu_len = __invoke_copy_from_user_dma(__cu_to, __cu_from,	\
 		                                   __cu_len);		\
 	}								\
 	__cu_len;							\
@@ -937,6 +945,7 @@
 {
 	__kernel_size_t res;
 
+    em86_stats[8]+=(size);
 	might_fault();
 	__asm__ __volatile__(
 		"move\t$4, %1\n\t"
diff -Naur linux-2.6.30-ori/arch/mips/include/asm/uaccess.h~ linux-2.6.30-test/arch/mips/include/asm/uaccess.h~
--- linux-2.6.30-ori/arch/mips/include/asm/uaccess.h~	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/include/asm/uaccess.h~	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1148 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1996, 1997, 1998, 1999, 2000, 03, 04 by Ralf Baechle
+ * Copyright (C) 1999, 2000 Silicon Graphics, Inc.
+ * Copyright (C) 2007  Maciej W. Rozycki
+ */
+#ifndef _ASM_UACCESS_H
+#define _ASM_UACCESS_H
+
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/thread_info.h>
+
+/*
+ * The fs value determines whether argument validity checking should be
+ * performed or not.  If get_fs() == USER_DS, checking is performed, with
+ * get_fs() == KERNEL_DS, checking is bypassed.
+ *
+ * For historical reasons, these macros are grossly misnamed.
+ */
+#ifdef CONFIG_32BIT
+
+#define __UA_LIMIT	0x80000000UL
+
+#define __UA_ADDR	".word"
+#define __UA_LA		"la"
+#define __UA_ADDU	"addu"
+#define __UA_t0		"$8"
+#define __UA_t1		"$9"
+
+#endif /* CONFIG_32BIT */
+
+#ifdef CONFIG_64BIT
+
+#define __UA_LIMIT	(- TASK_SIZE)
+
+#define __UA_ADDR	".dword"
+#define __UA_LA		"dla"
+#define __UA_ADDU	"daddu"
+#define __UA_t0		"$12"
+#define __UA_t1		"$13"
+
+#endif /* CONFIG_64BIT */
+
+/*
+ * USER_DS is a bitmask that has the bits set that may not be set in a valid
+ * userspace address.  Note that we limit 32-bit userspace to 0x7fff8000 but
+ * the arithmetic we're doing only works if the limit is a power of two, so
+ * we use 0x80000000 here on 32-bit kernels.  If a process passes an invalid
+ * address in this range it's the process's problem, not ours :-)
+ */
+
+#define KERNEL_DS	((mm_segment_t) { 0UL })
+#define USER_DS		((mm_segment_t) { __UA_LIMIT })
+
+#define VERIFY_READ    0
+#define VERIFY_WRITE   1
+
+#define get_ds()	(KERNEL_DS)
+#define get_fs()	(current_thread_info()->addr_limit)
+#define set_fs(x)	(current_thread_info()->addr_limit = (x))
+
+#define segment_eq(a, b)	((a).seg == (b).seg)
+
+
+/*
+ * Is a address valid? This does a straighforward calculation rather
+ * than tests.
+ *
+ * Address valid if:
+ *  - "addr" doesn't have any high-bits set
+ *  - AND "size" doesn't have any high-bits set
+ *  - AND "addr+size" doesn't have any high-bits set
+ *  - OR we are in kernel mode.
+ *
+ * __ua_size() is a trick to avoid runtime checking of positive constant
+ * sizes; for those we already know at compile time that the size is ok.
+ */
+#define __ua_size(size)							\
+	((__builtin_constant_p(size) && (signed long) (size) > 0) ? 0 : (size))
+
+/*
+ * access_ok: - Checks if a user space pointer is valid
+ * @type: Type of access: %VERIFY_READ or %VERIFY_WRITE.  Note that
+ *        %VERIFY_WRITE is a superset of %VERIFY_READ - if it is safe
+ *        to write to a block, it is always safe to read from it.
+ * @addr: User space pointer to start of block to check
+ * @size: Size of block to check
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Checks if a pointer to a block of memory in user space is valid.
+ *
+ * Returns true (nonzero) if the memory block may be valid, false (zero)
+ * if it is definitely invalid.
+ *
+ * Note that, depending on architecture, this function probably just
+ * checks that the pointer is in the user space range - after calling
+ * this function, memory access functions may still return -EFAULT.
+ */
+
+#define __access_mask get_fs().seg
+
+#define __access_ok(addr, size, mask)					\
+({									\
+	unsigned long __addr = (unsigned long) (addr);			\
+	unsigned long __size = size;					\
+	unsigned long __mask = mask;					\
+	unsigned long __ok;						\
+									\
+	__chk_user_ptr(addr);						\
+	__ok = (signed long)(__mask & (__addr | (__addr + __size) |	\
+		__ua_size(__size)));					\
+	__ok == 0;							\
+})
+
+#define access_ok(type, addr, size)					\
+	likely(__access_ok((addr), (size), __access_mask))
+
+/*
+ * put_user: - Write a simple value into user space.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define put_user(x,ptr)	\
+	__put_user_check((x), (ptr), sizeof(*(ptr)))
+
+/*
+ * get_user: - Get a simple variable from user space.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define get_user(x,ptr) \
+	__get_user_check((x), (ptr), sizeof(*(ptr)))
+
+/*
+ * __put_user: - Write a simple value into user space, with less checking.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define __put_user(x,ptr) \
+	__put_user_nocheck((x), (ptr), sizeof(*(ptr)))
+
+/*
+ * __get_user: - Get a simple variable from user space, with less checking.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define __get_user(x,ptr) \
+	__get_user_nocheck((x), (ptr), sizeof(*(ptr)))
+
+struct __large_struct { unsigned long buf[100]; };
+#define __m(x) (*(struct __large_struct __user *)(x))
+
+/*
+ * Yuck.  We need two variants, one for 64bit operation and one
+ * for 32 bit mode and old iron.
+ */
+#ifdef CONFIG_32BIT
+#define __GET_USER_DW(val, ptr) __get_user_asm_ll32(val, ptr)
+#endif
+#ifdef CONFIG_64BIT
+#define __GET_USER_DW(val, ptr) __get_user_asm(val, "ld", ptr)
+#endif
+
+extern void __get_user_unknown(void);
+
+#define __get_user_common(val, size, ptr)				\
+do {									\
+	switch (size) {							\
+	case 1: __get_user_asm(val, "lb", ptr); break;			\
+	case 2: __get_user_asm(val, "lh", ptr); break;			\
+	case 4: __get_user_asm(val, "lw", ptr); break;			\
+	case 8: __GET_USER_DW(val, ptr); break;				\
+	default: __get_user_unknown(); break;				\
+	}								\
+} while (0)
+
+#define __get_user_nocheck(x, ptr, size)				\
+({									\
+	int __gu_err;							\
+									\
+	__chk_user_ptr(ptr);						\
+	__get_user_common((x), size, ptr);				\
+	__gu_err;							\
+})
+
+#define __get_user_check(x, ptr, size)					\
+({									\
+	int __gu_err = -EFAULT;						\
+	const __typeof__(*(ptr)) __user * __gu_ptr = (ptr);		\
+									\
+	might_fault();							\
+	if (likely(access_ok(VERIFY_READ,  __gu_ptr, size)))		\
+		__get_user_common((x), size, __gu_ptr);			\
+									\
+	__gu_err;							\
+})
+
+#define __get_user_asm(val, insn, addr)					\
+{									\
+	long __gu_tmp;							\
+									\
+	__asm__ __volatile__(						\
+	"1:	" insn "	%1, %3				\n"	\
+	"2:							\n"	\
+	"	.section .fixup,\"ax\"				\n"	\
+	"3:	li	%0, %4					\n"	\
+	"	j	2b					\n"	\
+	"	.previous					\n"	\
+	"	.section __ex_table,\"a\"			\n"	\
+	"	"__UA_ADDR "\t1b, 3b				\n"	\
+	"	.previous					\n"	\
+	: "=r" (__gu_err), "=r" (__gu_tmp)				\
+	: "0" (0), "o" (__m(addr)), "i" (-EFAULT));			\
+									\
+	(val) = (__typeof__(*(addr))) __gu_tmp;				\
+}
+
+/*
+ * Get a long long 64 using 32 bit registers.
+ */
+#define __get_user_asm_ll32(val, addr)					\
+{									\
+	union {								\
+		unsigned long long	l;				\
+		__typeof__(*(addr))	t;				\
+	} __gu_tmp;							\
+									\
+	__asm__ __volatile__(						\
+	"1:	lw	%1, (%3)				\n"	\
+	"2:	lw	%D1, 4(%3)				\n"	\
+	"3:	.section	.fixup,\"ax\"			\n"	\
+	"4:	li	%0, %4					\n"	\
+	"	move	%1, $0					\n"	\
+	"	move	%D1, $0					\n"	\
+	"	j	3b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 4b				\n"	\
+	"	" __UA_ADDR "	2b, 4b				\n"	\
+	"	.previous					\n"	\
+	: "=r" (__gu_err), "=&r" (__gu_tmp.l)				\
+	: "0" (0), "r" (addr), "i" (-EFAULT));				\
+									\
+	(val) = __gu_tmp.t;						\
+}
+
+/*
+ * Yuck.  We need two variants, one for 64bit operation and one
+ * for 32 bit mode and old iron.
+ */
+#ifdef CONFIG_32BIT
+#define __PUT_USER_DW(ptr) __put_user_asm_ll32(ptr)
+#endif
+#ifdef CONFIG_64BIT
+#define __PUT_USER_DW(ptr) __put_user_asm("sd", ptr)
+#endif
+
+#define __put_user_nocheck(x, ptr, size)				\
+({									\
+	__typeof__(*(ptr)) __pu_val;					\
+	int __pu_err = 0;						\
+									\
+	__chk_user_ptr(ptr);						\
+	__pu_val = (x);							\
+	switch (size) {							\
+	case 1: __put_user_asm("sb", ptr); break;			\
+	case 2: __put_user_asm("sh", ptr); break;			\
+	case 4: __put_user_asm("sw", ptr); break;			\
+	case 8: __PUT_USER_DW(ptr); break;				\
+	default: __put_user_unknown(); break;				\
+	}								\
+	__pu_err;							\
+})
+
+#define __put_user_check(x, ptr, size)					\
+({									\
+	__typeof__(*(ptr)) __user *__pu_addr = (ptr);			\
+	__typeof__(*(ptr)) __pu_val = (x);				\
+	int __pu_err = -EFAULT;						\
+									\
+	might_fault();							\
+	if (likely(access_ok(VERIFY_WRITE,  __pu_addr, size))) {	\
+		switch (size) {						\
+		case 1: __put_user_asm("sb", __pu_addr); break;		\
+		case 2: __put_user_asm("sh", __pu_addr); break;		\
+		case 4: __put_user_asm("sw", __pu_addr); break;		\
+		case 8: __PUT_USER_DW(__pu_addr); break;		\
+		default: __put_user_unknown(); break;			\
+		}							\
+	}								\
+	__pu_err;							\
+})
+
+#define __put_user_asm(insn, ptr)					\
+{									\
+	__asm__ __volatile__(						\
+	"1:	" insn "	%z2, %3		# __put_user_asm\n"	\
+	"2:							\n"	\
+	"	.section	.fixup,\"ax\"			\n"	\
+	"3:	li	%0, %4					\n"	\
+	"	j	2b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 3b				\n"	\
+	"	.previous					\n"	\
+	: "=r" (__pu_err)						\
+	: "0" (0), "Jr" (__pu_val), "o" (__m(ptr)),			\
+	  "i" (-EFAULT));						\
+}
+
+#define __put_user_asm_ll32(ptr)					\
+{									\
+	__asm__ __volatile__(						\
+	"1:	sw	%2, (%3)	# __put_user_asm_ll32	\n"	\
+	"2:	sw	%D2, 4(%3)				\n"	\
+	"3:							\n"	\
+	"	.section	.fixup,\"ax\"			\n"	\
+	"4:	li	%0, %4					\n"	\
+	"	j	3b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 4b				\n"	\
+	"	" __UA_ADDR "	2b, 4b				\n"	\
+	"	.previous"						\
+	: "=r" (__pu_err)						\
+	: "0" (0), "r" (__pu_val), "r" (ptr),				\
+	  "i" (-EFAULT));						\
+}
+
+extern void __put_user_unknown(void);
+
+/*
+ * put_user_unaligned: - Write a simple value into user space.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define put_user_unaligned(x,ptr)	\
+	__put_user_unaligned_check((x),(ptr),sizeof(*(ptr)))
+
+/*
+ * get_user_unaligned: - Get a simple variable from user space.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define get_user_unaligned(x,ptr) \
+	__get_user_unaligned_check((x),(ptr),sizeof(*(ptr)))
+
+/*
+ * __put_user_unaligned: - Write a simple value into user space, with less checking.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define __put_user_unaligned(x,ptr) \
+	__put_user_unaligned_nocheck((x),(ptr),sizeof(*(ptr)))
+
+/*
+ * __get_user_unaligned: - Get a simple variable from user space, with less checking.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Caller must check the pointer with access_ok() before calling this
+ * function.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define __get_user_unaligned(x,ptr) \
+	__get_user__unalignednocheck((x),(ptr),sizeof(*(ptr)))
+
+/*
+ * Yuck.  We need two variants, one for 64bit operation and one
+ * for 32 bit mode and old iron.
+ */
+#ifdef CONFIG_32BIT
+#define __GET_USER_UNALIGNED_DW(val, ptr)				\
+	__get_user_unaligned_asm_ll32(val, ptr)
+#endif
+#ifdef CONFIG_64BIT
+#define __GET_USER_UNALIGNED_DW(val, ptr)				\
+	__get_user_unaligned_asm(val, "uld", ptr)
+#endif
+
+extern void __get_user_unaligned_unknown(void);
+
+#define __get_user_unaligned_common(val, size, ptr)			\
+do {									\
+	switch (size) {							\
+	case 1: __get_user_asm(val, "lb", ptr); break;			\
+	case 2: __get_user_unaligned_asm(val, "ulh", ptr); break;	\
+	case 4: __get_user_unaligned_asm(val, "ulw", ptr); break;	\
+	case 8: __GET_USER_UNALIGNED_DW(val, ptr); break;		\
+	default: __get_user_unaligned_unknown(); break;			\
+	}								\
+} while (0)
+
+#define __get_user_unaligned_nocheck(x,ptr,size)			\
+({									\
+	int __gu_err;							\
+									\
+	__get_user_unaligned_common((x), size, ptr);			\
+	__gu_err;							\
+})
+
+#define __get_user_unaligned_check(x,ptr,size)				\
+({									\
+	int __gu_err = -EFAULT;						\
+	const __typeof__(*(ptr)) __user * __gu_ptr = (ptr);		\
+									\
+	if (likely(access_ok(VERIFY_READ,  __gu_ptr, size)))		\
+		__get_user_unaligned_common((x), size, __gu_ptr);	\
+									\
+	__gu_err;							\
+})
+
+#define __get_user_unaligned_asm(val, insn, addr)			\
+{									\
+	long __gu_tmp;							\
+									\
+	__asm__ __volatile__(						\
+	"1:	" insn "	%1, %3				\n"	\
+	"2:							\n"	\
+	"	.section .fixup,\"ax\"				\n"	\
+	"3:	li	%0, %4					\n"	\
+	"	j	2b					\n"	\
+	"	.previous					\n"	\
+	"	.section __ex_table,\"a\"			\n"	\
+	"	"__UA_ADDR "\t1b, 3b				\n"	\
+	"	"__UA_ADDR "\t1b + 4, 3b			\n"	\
+	"	.previous					\n"	\
+	: "=r" (__gu_err), "=r" (__gu_tmp)				\
+	: "0" (0), "o" (__m(addr)), "i" (-EFAULT));			\
+									\
+	(val) = (__typeof__(*(addr))) __gu_tmp;				\
+}
+
+/*
+ * Get a long long 64 using 32 bit registers.
+ */
+#define __get_user_unaligned_asm_ll32(val, addr)			\
+{									\
+        unsigned long long __gu_tmp;					\
+									\
+	__asm__ __volatile__(						\
+	"1:	ulw	%1, (%3)				\n"	\
+	"2:	ulw	%D1, 4(%3)				\n"	\
+	"	move	%0, $0					\n"	\
+	"3:	.section	.fixup,\"ax\"			\n"	\
+	"4:	li	%0, %4					\n"	\
+	"	move	%1, $0					\n"	\
+	"	move	%D1, $0					\n"	\
+	"	j	3b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 4b				\n"	\
+	"	" __UA_ADDR "	1b + 4, 4b			\n"	\
+	"	" __UA_ADDR "	2b, 4b				\n"	\
+	"	" __UA_ADDR "	2b + 4, 4b			\n"	\
+	"	.previous					\n"	\
+	: "=r" (__gu_err), "=&r" (__gu_tmp)				\
+	: "0" (0), "r" (addr), "i" (-EFAULT));				\
+	(val) = (__typeof__(*(addr))) __gu_tmp;				\
+}
+
+/*
+ * Yuck.  We need two variants, one for 64bit operation and one
+ * for 32 bit mode and old iron.
+ */
+#ifdef CONFIG_32BIT
+#define __PUT_USER_UNALIGNED_DW(ptr) __put_user_unaligned_asm_ll32(ptr)
+#endif
+#ifdef CONFIG_64BIT
+#define __PUT_USER_UNALIGNED_DW(ptr) __put_user_unaligned_asm("usd", ptr)
+#endif
+
+#define __put_user_unaligned_nocheck(x,ptr,size)			\
+({									\
+	__typeof__(*(ptr)) __pu_val;					\
+	int __pu_err = 0;						\
+									\
+	__pu_val = (x);							\
+	switch (size) {							\
+	case 1: __put_user_asm("sb", ptr); break;			\
+	case 2: __put_user_unaligned_asm("ush", ptr); break;		\
+	case 4: __put_user_unaligned_asm("usw", ptr); break;		\
+	case 8: __PUT_USER_UNALIGNED_DW(ptr); break;			\
+	default: __put_user_unaligned_unknown(); break;			\
+	}								\
+	__pu_err;							\
+})
+
+#define __put_user_unaligned_check(x,ptr,size)				\
+({									\
+	__typeof__(*(ptr)) __user *__pu_addr = (ptr);			\
+	__typeof__(*(ptr)) __pu_val = (x);				\
+	int __pu_err = -EFAULT;						\
+									\
+	if (likely(access_ok(VERIFY_WRITE,  __pu_addr, size))) {	\
+		switch (size) {						\
+		case 1: __put_user_asm("sb", __pu_addr); break;		\
+		case 2: __put_user_unaligned_asm("ush", __pu_addr); break; \
+		case 4: __put_user_unaligned_asm("usw", __pu_addr); break; \
+		case 8: __PUT_USER_UNALGINED_DW(__pu_addr); break;	\
+		default: __put_user_unaligned_unknown(); break;		\
+		}							\
+	}								\
+	__pu_err;							\
+})
+
+#define __put_user_unaligned_asm(insn, ptr)				\
+{									\
+	__asm__ __volatile__(						\
+	"1:	" insn "	%z2, %3		# __put_user_unaligned_asm\n" \
+	"2:							\n"	\
+	"	.section	.fixup,\"ax\"			\n"	\
+	"3:	li	%0, %4					\n"	\
+	"	j	2b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 3b				\n"	\
+	"	.previous					\n"	\
+	: "=r" (__pu_err)						\
+	: "0" (0), "Jr" (__pu_val), "o" (__m(ptr)),			\
+	  "i" (-EFAULT));						\
+}
+
+#define __put_user_unaligned_asm_ll32(ptr)				\
+{									\
+	__asm__ __volatile__(						\
+	"1:	sw	%2, (%3)	# __put_user_unaligned_asm_ll32	\n" \
+	"2:	sw	%D2, 4(%3)				\n"	\
+	"3:							\n"	\
+	"	.section	.fixup,\"ax\"			\n"	\
+	"4:	li	%0, %4					\n"	\
+	"	j	3b					\n"	\
+	"	.previous					\n"	\
+	"	.section	__ex_table,\"a\"		\n"	\
+	"	" __UA_ADDR "	1b, 4b				\n"	\
+	"	" __UA_ADDR "	1b + 4, 4b			\n"	\
+	"	" __UA_ADDR "	2b, 4b				\n"	\
+	"	" __UA_ADDR "	2b + 4, 4b			\n"	\
+	"	.previous"						\
+	: "=r" (__pu_err)						\
+	: "0" (0), "r" (__pu_val), "r" (ptr),				\
+	  "i" (-EFAULT));						\
+}
+
+extern void __put_user_unaligned_unknown(void);
+
+/*
+ * We're generating jump to subroutines which will be outside the range of
+ * jump instructions
+ */
+#ifdef MODULE
+#define __MODULE_JAL(destination)					\
+	".set\tnoat\n\t"						\
+	__UA_LA "\t$1, " #destination "\n\t" 				\
+	"jalr\t$1\n\t"							\
+	".set\tat\n\t"
+#else
+#define __MODULE_JAL(destination)					\
+	"jal\t" #destination "\n\t"
+#endif
+
+#ifndef CONFIG_CPU_DADDI_WORKAROUNDS
+#define DADDI_SCRATCH "$0"
+#else
+#define DADDI_SCRATCH "$3"
+#endif
+
+extern size_t __copy_user(void *__to, const void *__from, size_t __n);
+
+#define __invoke_copy_to_user(to, from, n)				\
+({									\
+	register void __user *__cu_to_r __asm__("$4");			\
+	register const void *__cu_from_r __asm__("$5");			\
+	register long __cu_len_r __asm__("$6");				\
+									\
+	__cu_to_r = (to);						\
+	__cu_from_r = (from);						\
+	__cu_len_r = (n);						\
+	__asm__ __volatile__(						\
+	__MODULE_JAL(__copy_user)					\
+	: "+r" (__cu_to_r), "+r" (__cu_from_r), "+r" (__cu_len_r)	\
+	:								\
+	: "$8", "$9", "$10", "$11", "$12", "$15", "$24", "$31",		\
+	  DADDI_SCRATCH, "memory");					\
+	__cu_len_r;							\
+})
+
+/*
+ * __copy_to_user: - Copy a block of data into user space, with less checking.
+ * @to:   Destination address, in user space.
+ * @from: Source address, in kernel space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from kernel space to user space.  Caller must check
+ * the specified block with access_ok() before calling this function.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ */
+#define __copy_to_user(to, from, n)					\
+({									\
+	void __user *__cu_to;						\
+	const void *__cu_from;						\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	might_fault();							\
+	__cu_len = __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);	\
+	__cu_len;							\
+})
+
+extern size_t __copy_user_inatomic(void *__to, const void *__from, size_t __n);
+
+#define __copy_to_user_inatomic(to, from, n)				\
+({									\
+	void __user *__cu_to;						\
+	const void *__cu_from;						\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	__cu_len = __invoke_copy_to_user_dma(__cu_to, __cu_from, __cu_len);	\
+	__cu_len;							\
+})
+
+#define __copy_from_user_inatomic(to, from, n)				\
+({									\
+	void *__cu_to;							\
+	const void __user *__cu_from;					\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	__cu_len = __invoke_copy_from_user_inatomic(__cu_to, __cu_from,	\
+	                                            __cu_len);		\
+	__cu_len;							\
+})
+
+extern long long em86_stats[20];
+
+/*
+ * copy_to_user: - Copy a block of data into user space.
+ * @to:   Destination address, in user space.
+ * @from: Source address, in kernel space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from kernel space to user space.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ */
+#define copy_to_user(to, from, n)					\
+({									\
+	void __user *__cu_to;						\
+	const void *__cu_from;						\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	if (access_ok(VERIFY_WRITE, __cu_to, __cu_len)) {		\
+		might_fault();						\
+		__cu_len = __invoke_copy_to_user(__cu_to, __cu_from,	\
+		                                 __cu_len);		\
+	}								\
+	__cu_len;							\
+})
+
+#define __invoke_copy_from_user(to, from, n)				\
+({									\
+	register void *__cu_to_r __asm__("$4");				\
+	register const void __user *__cu_from_r __asm__("$5");		\
+	register long __cu_len_r __asm__("$6");				\
+									\
+	em86_stats[4]+=(n); \
+	__cu_to_r = (to);						\
+	__cu_from_r = (from);						\
+	__cu_len_r = (n);						\
+	__asm__ __volatile__(						\
+	".set\tnoreorder\n\t"						\
+	__MODULE_JAL(__copy_user)					\
+	".set\tnoat\n\t"						\
+	__UA_ADDU "\t$1, %1, %2\n\t"					\
+	".set\tat\n\t"							\
+	".set\treorder"							\
+	: "+r" (__cu_to_r), "+r" (__cu_from_r), "+r" (__cu_len_r)	\
+	:								\
+	: "$8", "$9", "$10", "$11", "$12", "$15", "$24", "$31",		\
+	  DADDI_SCRATCH, "memory");					\
+	__cu_len_r;							\
+})
+
+#define __invoke_copy_from_user_inatomic(to, from, n)			\
+({									\
+	register void *__cu_to_r __asm__("$4");				\
+	register const void __user *__cu_from_r __asm__("$5");		\
+	register long __cu_len_r __asm__("$6");				\
+									\
+	em86_stats[6]+=(n); \
+	__cu_to_r = (to);						\
+	__cu_from_r = (from);						\
+	__cu_len_r = (n);						\
+	__asm__ __volatile__(						\
+	".set\tnoreorder\n\t"						\
+	__MODULE_JAL(__copy_user_inatomic)				\
+	".set\tnoat\n\t"						\
+	__UA_ADDU "\t$1, %1, %2\n\t"					\
+	".set\tat\n\t"							\
+	".set\treorder"							\
+	: "+r" (__cu_to_r), "+r" (__cu_from_r), "+r" (__cu_len_r)	\
+	:								\
+	: "$8", "$9", "$10", "$11", "$12", "$15", "$24", "$31",		\
+	  DADDI_SCRATCH, "memory");					\
+	__cu_len_r;							\
+})
+
+/*
+ * __copy_from_user: - Copy a block of data from user space, with less checking.
+ * @to:   Destination address, in kernel space.
+ * @from: Source address, in user space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from user space to kernel space.  Caller must check
+ * the specified block with access_ok() before calling this function.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ *
+ * If some data could not be copied, this function will pad the copied
+ * data to the requested size using zero bytes.
+ */
+#define __copy_from_user(to, from, n)					\
+({									\
+	void *__cu_to;							\
+	const void __user *__cu_from;					\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	might_fault();							\
+	__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,		\
+	                                   __cu_len);			\
+	__cu_len;							\
+})
+
+/*
+ * copy_from_user: - Copy a block of data from user space.
+ * @to:   Destination address, in kernel space.
+ * @from: Source address, in user space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from user space to kernel space.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ *
+ * If some data could not be copied, this function will pad the copied
+ * data to the requested size using zero bytes.
+ */
+#define copy_from_user(to, from, n)					\
+({									\
+	void *__cu_to;							\
+	const void __user *__cu_from;					\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	if (access_ok(VERIFY_READ, __cu_from, __cu_len)) {		\
+		might_fault();						\
+		__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,	\
+		                                   __cu_len);		\
+	}								\
+	__cu_len;							\
+})
+
+#define __copy_in_user(to, from, n)					\
+({									\
+	void __user *__cu_to;						\
+	const void __user *__cu_from;					\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	might_fault();							\
+	__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,		\
+	                                   __cu_len);			\
+	__cu_len;							\
+})
+
+#define copy_in_user(to, from, n)					\
+({									\
+	void __user *__cu_to;						\
+	const void __user *__cu_from;					\
+	long __cu_len;							\
+									\
+	__cu_to = (to);							\
+	__cu_from = (from);						\
+	__cu_len = (n);							\
+	if (likely(access_ok(VERIFY_READ, __cu_from, __cu_len) &&	\
+	           access_ok(VERIFY_WRITE, __cu_to, __cu_len))) {	\
+		might_fault();						\
+		__cu_len = __invoke_copy_from_user(__cu_to, __cu_from,	\
+		                                   __cu_len);		\
+	}								\
+	__cu_len;							\
+})
+
+/*
+ * __clear_user: - Zero a block of memory in user space, with less checking.
+ * @to:   Destination address, in user space.
+ * @n:    Number of bytes to zero.
+ *
+ * Zero a block of memory in user space.  Caller must check
+ * the specified block with access_ok() before calling this function.
+ *
+ * Returns number of bytes that could not be cleared.
+ * On success, this will be zero.
+ */
+static inline __kernel_size_t
+__clear_user(void __user *addr, __kernel_size_t size)
+{
+	__kernel_size_t res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		"move\t$5, $0\n\t"
+		"move\t$6, %2\n\t"
+		__MODULE_JAL(__bzero)
+		"move\t%0, $6"
+		: "=r" (res)
+		: "r" (addr), "r" (size)
+		: "$4", "$5", "$6", __UA_t0, __UA_t1, "$31");
+
+	return res;
+}
+
+#define clear_user(addr,n)						\
+({									\
+	void __user * __cl_addr = (addr);				\
+	unsigned long __cl_size = (n);					\
+	if (__cl_size && access_ok(VERIFY_WRITE,			\
+					__cl_addr, __cl_size))		\
+		__cl_size = __clear_user(__cl_addr, __cl_size);		\
+	__cl_size;							\
+})
+
+/*
+ * __strncpy_from_user: - Copy a NUL terminated string from userspace, with less checking.
+ * @dst:   Destination address, in kernel space.  This buffer must be at
+ *         least @count bytes long.
+ * @src:   Source address, in user space.
+ * @count: Maximum number of bytes to copy, including the trailing NUL.
+ *
+ * Copies a NUL-terminated string from userspace to kernel space.
+ * Caller must check the specified block with access_ok() before calling
+ * this function.
+ *
+ * On success, returns the length of the string (not including the trailing
+ * NUL).
+ *
+ * If access to userspace fails, returns -EFAULT (some data may have been
+ * copied).
+ *
+ * If @count is smaller than the length of the string, copies @count bytes
+ * and returns @count.
+ */
+static inline long
+__strncpy_from_user(char *__to, const char __user *__from, long __len)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		"move\t$5, %2\n\t"
+		"move\t$6, %3\n\t"
+		__MODULE_JAL(__strncpy_from_user_nocheck_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (__to), "r" (__from), "r" (__len)
+		: "$2", "$3", "$4", "$5", "$6", __UA_t0, "$31", "memory");
+
+	return res;
+}
+
+/*
+ * strncpy_from_user: - Copy a NUL terminated string from userspace.
+ * @dst:   Destination address, in kernel space.  This buffer must be at
+ *         least @count bytes long.
+ * @src:   Source address, in user space.
+ * @count: Maximum number of bytes to copy, including the trailing NUL.
+ *
+ * Copies a NUL-terminated string from userspace to kernel space.
+ *
+ * On success, returns the length of the string (not including the trailing
+ * NUL).
+ *
+ * If access to userspace fails, returns -EFAULT (some data may have been
+ * copied).
+ *
+ * If @count is smaller than the length of the string, copies @count bytes
+ * and returns @count.
+ */
+static inline long
+strncpy_from_user(char *__to, const char __user *__from, long __len)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		"move\t$5, %2\n\t"
+		"move\t$6, %3\n\t"
+		__MODULE_JAL(__strncpy_from_user_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (__to), "r" (__from), "r" (__len)
+		: "$2", "$3", "$4", "$5", "$6", __UA_t0, "$31", "memory");
+
+	return res;
+}
+
+/* Returns: 0 if bad, string length+1 (memory size) of string if ok */
+static inline long __strlen_user(const char __user *s)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		__MODULE_JAL(__strlen_user_nocheck_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (s)
+		: "$2", "$4", __UA_t0, "$31");
+
+	return res;
+}
+
+/*
+ * strlen_user: - Get the size of a string in user space.
+ * @str: The string to measure.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Get the size of a NUL-terminated string in user space.
+ *
+ * Returns the size of the string INCLUDING the terminating NUL.
+ * On exception, returns 0.
+ *
+ * If there is a limit on the length of a valid string, you may wish to
+ * consider using strnlen_user() instead.
+ */
+static inline long strlen_user(const char __user *s)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		__MODULE_JAL(__strlen_user_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (s)
+		: "$2", "$4", __UA_t0, "$31");
+
+	return res;
+}
+
+/* Returns: 0 if bad, string length+1 (memory size) of string if ok */
+static inline long __strnlen_user(const char __user *s, long n)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		"move\t$5, %2\n\t"
+		__MODULE_JAL(__strnlen_user_nocheck_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (s), "r" (n)
+		: "$2", "$4", "$5", __UA_t0, "$31");
+
+	return res;
+}
+
+/*
+ * strlen_user: - Get the size of a string in user space.
+ * @str: The string to measure.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Get the size of a NUL-terminated string in user space.
+ *
+ * Returns the size of the string INCLUDING the terminating NUL.
+ * On exception, returns 0.
+ *
+ * If there is a limit on the length of a valid string, you may wish to
+ * consider using strnlen_user() instead.
+ */
+static inline long strnlen_user(const char __user *s, long n)
+{
+	long res;
+
+	might_fault();
+	__asm__ __volatile__(
+		"move\t$4, %1\n\t"
+		"move\t$5, %2\n\t"
+		__MODULE_JAL(__strnlen_user_asm)
+		"move\t%0, $2"
+		: "=r" (res)
+		: "r" (s), "r" (n)
+		: "$2", "$4", "$5", __UA_t0, "$31");
+
+	return res;
+}
+
+struct exception_table_entry
+{
+	unsigned long insn;
+	unsigned long nextinsn;
+};
+
+extern int fixup_exception(struct pt_regs *regs);
+
+#endif /* _ASM_UACCESS_H */
diff -Naur linux-2.6.30-ori/arch/mips/kernel/cpu-probe.c linux-2.6.30-test/arch/mips/kernel/cpu-probe.c
--- linux-2.6.30-ori/arch/mips/kernel/cpu-probe.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/kernel/cpu-probe.c	2009-06-12 18:32:43.000000000 -0400
@@ -645,7 +645,9 @@
 	if (config1 & MIPS_CONF1_EP)
 		c->options |= MIPS_CPU_EJTAG;
 	if (config1 & MIPS_CONF1_FP) {
+#ifndef CONFIG_TANGO3_DISABLE_HWFPU
 		c->options |= MIPS_CPU_FPU;
+#endif
 		c->options |= MIPS_CPU_32FPR;
 	}
 	if (cpu_has_tlb)
diff -Naur linux-2.6.30-ori/arch/mips/kernel/head.S linux-2.6.30-test/arch/mips/kernel/head.S
--- linux-2.6.30-ori/arch/mips/kernel/head.S	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/kernel/head.S	2009-06-12 18:32:43.000000000 -0400
@@ -131,7 +131,7 @@
 
 EXPORT(_stext)
 
-#ifdef CONFIG_BOOT_RAW
+#if defined(CONFIG_BOOT_RAW) || defined (CONFIG_TANGOX)
 	/*
 	 * Give us a fighting chance of running if execution beings at the
 	 * kernel load address.  This is needed because this platform does
diff -Naur linux-2.6.30-ori/arch/mips/kernel/mips_ksyms.c linux-2.6.30-test/arch/mips/kernel/mips_ksyms.c
--- linux-2.6.30-ori/arch/mips/kernel/mips_ksyms.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/kernel/mips_ksyms.c	2009-06-12 18:32:43.000000000 -0400
@@ -28,7 +28,7 @@
  * String functions
  */
 EXPORT_SYMBOL(memset);
-EXPORT_SYMBOL(memcpy);
+//EXPORT_SYMBOL(memcpy);
 EXPORT_SYMBOL(memmove);
 
 EXPORT_SYMBOL(kernel_thread);
diff -Naur linux-2.6.30-ori/arch/mips/kernel/setup.c linux-2.6.30-test/arch/mips/kernel/setup.c
--- linux-2.6.30-ori/arch/mips/kernel/setup.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/kernel/setup.c	2009-06-12 18:32:43.000000000 -0400
@@ -32,6 +32,21 @@
 #include <asm/smp-ops.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/rmdefs.h>
+#include <asm/tango2/memcfg.h>
+#include <asm/tango2/tango2.h>
+#include <asm/tango2/hardware.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/rmdefs.h>
+#include <asm/tango3/memcfg.h>
+#include <asm/tango3/tango3.h>
+#include <asm/tango3/hardware.h>
+
+#include "../tangox/xenv.h"
+#include "../tangox/xenvkeys.h"
+#endif
+
 struct cpuinfo_mips cpu_data[NR_CPUS] __read_mostly;
 
 EXPORT_SYMBOL(cpu_data);
@@ -442,6 +457,13 @@
  */
 
 static int usermem __initdata = 0;
+#ifdef CONFIG_TANGOX
+	extern unsigned long em8xxx_kmem_start;
+	extern unsigned long em8xxx_kmem_size;
+#ifdef CONFIG_TANGO3
+	extern unsigned long max_remap_size;
+#endif
+#endif
 
 static int __init early_parse_mem(char *p)
 {
@@ -456,12 +478,46 @@
 		boot_mem_map.nr_map = 0;
 		usermem = 1;
  	}
+#ifdef CONFIG_TANGOX
+	start = CPHYSADDR(em8xxx_kmem_start);
+#else
 	start = 0;
+#endif
 	size = memparse(p, &p);
 	if (*p == '@')
 		start = memparse(p + 1, &p);
 
+#ifdef CONFIG_TANGOX
+	if (start == CPHYSADDR(em8xxx_kmem_start)) {
+		unsigned long em8xxx_kmem_end;
+#ifdef CONFIG_TANGO3
+		em8xxx_kmem_size = ((mem_size + em8xxx_kmem_start) & 0xfff00000) - em8xxx_kmem_start;
+
+		if (em8xxx_kmem_size > max_remap_size)
+			em8xxx_kmem_size = max_remap_size;
+
+		add_memory_region(start, em8xxx_kmem_size, BOOT_MEM_RAM);
+		em8xxx_kmem_end = KSEG1ADDR(em8xxx_kmem_start + em8xxx_kmem_size) - KSEG1ADDR(CPU_REMAP_SPACE);
+
+		/* Update information into LR_XENV2_RW */
+		xenv_set((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_KERNEL_END, &em8xxx_kmem_end, 0, sizeof(em8xxx_kmem_end)); 
+#else
+		memcfg_t *m = (memcfg_t *)KSEG1ADDR(MEM_BASE_dram_controller_0_alias + FM_MEMCFG);
+
+		em8xxx_kmem_size = ((size + em8xxx_kmem_start) & 0xfff00000) - em8xxx_kmem_start;
+		add_memory_region(start, em8xxx_kmem_size, BOOT_MEM_RAM);
+
+		em8xxx_kmem_end = KSEG1ADDR(em8xxx_kmem_start + em8xxx_kmem_size) - KSEG1ADDR(MEM_BASE_dram_controller_0_alias);
+		m->kernel_end = em8xxx_kmem_end;
+		gen_memcfg_checksum(m);
+#endif
+	} else {
+		/* We just add this blindly as the alignment can be wrong, use it as own risk */
+		add_memory_region(start, size, BOOT_MEM_RAM);
+	}
+#else
 	add_memory_region(start, size, BOOT_MEM_RAM);
+#endif
 	return 0;
 }
 early_param("mem", early_parse_mem);
diff -Naur linux-2.6.30-ori/arch/mips/kernel/traps.c linux-2.6.30-test/arch/mips/kernel/traps.c
--- linux-2.6.30-ori/arch/mips/kernel/traps.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/kernel/traps.c	2009-06-12 18:32:43.000000000 -0400
@@ -49,6 +49,17 @@
 #include <asm/stacktrace.h>
 #include <asm/irq.h>
 
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/emhwlib_registers_tango2.h>
+#include <asm/tango2/emhwlib_dram_tango2.h>
+#include <asm/tango2/hardware.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/emhwlib_registers_tango3.h>
+#include <asm/tango3/emhwlib_dram_tango3.h>
+#include <asm/tango3/hardware.h>
+#endif
+
+
 extern void check_wait(void);
 extern asmlinkage void r4k_wait(void);
 extern asmlinkage void rollback_handle_int(void);
@@ -1501,6 +1512,15 @@
 	change_c0_status(ST0_CU|ST0_MX|ST0_RE|ST0_FR|ST0_BEV|ST0_TS|ST0_KX|ST0_SX|ST0_UX,
 			 status_set);
 
+#ifdef CONFIG_TANGOX
+#ifdef CONFIG_TANGO3
+	ebase = KSEG0ADDR(CPU_REMAP_SPACE);
+#else
+	ebase = KSEG0ADDR(MEM_BASE_dram_controller_0_alias + FM_RESERVED);
+#endif
+	write_c0_ebase(ebase);
+#endif
+
 	if (cpu_has_mips_r2) {
 		unsigned int enable = 0x0000000f;
 
@@ -1549,7 +1569,10 @@
 		cp0_compare_irq = CP0_LEGACY_COMPARE_IRQ;
 		cp0_perfcount_irq = -1;
 	}
-
+    printk("cp0_compare : %d cp0_perf : %d intctl : %08X\n",cp0_compare_irq, cp0_perfcount_irq, read_c0_intctl());
+#ifdef CONFIG_TANGOX
+	cp0_compare_irq = 7;
+#endif
 #ifdef CONFIG_MIPS_MT_SMTC
 	}
 #endif /* CONFIG_MIPS_MT_SMTC */
@@ -1748,6 +1771,7 @@
 
 	set_except_vector(26, handle_dsp);
 
+#ifdef CONFIG_TANGOX
 	if (cpu_has_vce)
 		/* Special exception: R4[04]00 uses also the divec space. */
 		memcpy((void *)(ebase + 0x180), &except_vec3_r4000, 0x100);
@@ -1755,6 +1779,15 @@
 		memcpy((void *)(ebase + 0x180), &except_vec3_generic, 0x80);
 	else
 		memcpy((void *)(ebase + 0x080), &except_vec3_generic, 0x80);
+#else
+	if (cpu_has_vce)
+		/* Special exception: R4[04]00 uses also the divec space. */
+		memcpy((void *)(ebase + 0x180), &except_vec3_r4000, 0x100);
+	else if (cpu_has_4kex)
+		memcpy((void *)(ebase + 0x180), &except_vec3_generic, 0x80);
+	else
+		memcpy((void *)(ebase + 0x080), &except_vec3_generic, 0x80);
+#endif
 
 	signal_init();
 #ifdef CONFIG_MIPS32_COMPAT
diff -Naur linux-2.6.30-ori/arch/mips/lib/delay.c linux-2.6.30-test/arch/mips/lib/delay.c
--- linux-2.6.30-ori/arch/mips/lib/delay.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/lib/delay.c	2009-06-15 12:00:10.000000000 -0400
@@ -43,7 +43,7 @@
 {
 	unsigned int lpj = current_cpu_data.udelay_val;
 
-	__delay((us * 0x000010c7 * HZ * lpj) >> 32);
+	__delay((us * 0x000010c7ull * HZ * lpj) >> 32);
 }
 EXPORT_SYMBOL(__udelay);
 
@@ -51,6 +51,6 @@
 {
 	unsigned int lpj = current_cpu_data.udelay_val;
 
-	__delay((us * 0x00000005 * HZ * lpj) >> 32);
+	__delay((ns * 0x00000005ull * HZ * lpj) >> 32);
 }
 EXPORT_SYMBOL(__ndelay);
diff -Naur linux-2.6.30-ori/arch/mips/lib/memcpy.S linux-2.6.30-test/arch/mips/lib/memcpy.S
--- linux-2.6.30-ori/arch/mips/lib/memcpy.S	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/arch/mips/lib/memcpy.S	2009-06-12 18:32:43.000000000 -0400
@@ -189,7 +189,7 @@
  * memcpy sets v0 to dst.
  */
 	.align	5
-LEAF(memcpy)					/* a0=dst a1=src a2=len */
+LEAF(memcpy2)					/* a0=dst a1=src a2=len */
 	move	v0, dst				/* return value */
 .L__memcpy:
 FEXPORT(__copy_user)
@@ -428,7 +428,7 @@
 .Ldone:
 	jr	ra
 	 nop
-	END(memcpy)
+	END(memcpy2)
 
 .Ll_exc_copy:
 	/*
diff -Naur linux-2.6.30-ori/arch/mips/tangox/Kconfig linux-2.6.30-test/arch/mips/tangox/Kconfig
--- linux-2.6.30-ori/arch/mips/tangox/Kconfig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,296 @@
+
+#
+# environnent selection
+#
+
+config TANGO2_SMP863X
+	bool
+
+config TANGO3_SMP865X
+	bool
+
+#
+# chip revision selection
+#
+choice
+	prompt "SMP863x chip revision"
+	depends on TANGO2_SMP863X
+	default TANGO2_ES6
+
+config TANGO2_ES1
+	bool "ES1"
+
+config TANGO2_ES2
+	bool "ES2"
+
+config TANGO2_ES3
+	bool "ES3"
+
+config TANGO2_ES4
+	bool "ES4"
+
+config TANGO2_ES5
+	bool "ES5"
+
+config TANGO2_ES6
+	bool "ES6+"
+
+config TANGO2_SD
+	bool "SD revision (SMP8632/SMP8710)"
+
+endchoice
+
+choice
+	prompt "SMP865x chip revision"
+	depends on TANGO3_SMP865X
+	default TANGO3_ES1
+
+config TANGO3_ES1
+	bool "ES1"
+
+config TANGO3_ES2
+	bool "ES2"
+
+config TANGO3_ES3
+	bool "ES3"
+
+endchoice
+
+config TANGO3_DISABLE_HWFPU
+	bool "Disable HW FPU"
+	depends on TANGO3_SMP865X && TANGO3
+	default n
+	help
+	 Disable HW FPU, and use SW FPU emulation.
+
+config TANGOX_HZ_VALUE
+	int "customized HZ value"
+	depends on TANGOX
+	default 100 if TANGO2_SD || TANGO3
+	default 1000 if !(TANGO2_SD || TANGO3)
+	help
+	 For TangoX, the HZ value can be customized, normally it's between 100-1000.
+
+config TANGOX_SYSTEMRAM_ACTUALSIZE
+	int "System RAM size (in MB)"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default 64
+	help
+	 This is the default amount of RAM available to the Linux kernel. It can be
+	 override with "mem=" command line option.
+
+
+config TANGOX_IGNORE_CMDLINE
+	bool "Ignore YAMON, XENV & memcfg command line"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default n
+	help
+	 If you say  yes, boot command line from  YAMON, XENV & memcfg
+	 will be ignored. You can then use CONFIG_CMDLINE to force the
+	 kernel command line.
+
+
+config TANGOX_PROM_CONSOLE
+	bool "Register an early console"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default n
+	help
+	 If you say yes, an light console will be available very early
+	 in the  boot process,  this is useful  if the  kernel crashes
+	 before reaching  the main console  code. The console  will be
+	 automatically replaced by the normal one after.
+	 ### NOTE: This console can only do output ###
+
+config TANGOX_FIXED_FREQUENCIES
+	bool "Specified fixed frequencies"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default n if TANGO2_SMP863X
+	default y if TANGO3_SMP865X
+	help
+	 To specify, statically, the frequencies for CPU, System, and Base.
+	 Normally this is only used in experimental purpose where PLL may be
+	 set differently (typical for simulation or FPGA).
+
+config TANGOX_BASE_FREQUENCY
+	int "Base Frequency"
+	depends on TANGOX_FIXED_FREQUENCIES
+	default 27000000
+	help
+	 Base frequency (corresponding to XTAL in).
+
+config TANGOX_CPU_FREQUENCY
+	int "CPU Frequency"
+	depends on TANGOX_FIXED_FREQUENCIES
+	default 300000000
+	help
+	 CPU frequency.
+
+config TANGOX_SYS_FREQUENCY
+	int "System Frequency"
+	depends on TANGOX_FIXED_FREQUENCIES
+	default 200000000
+	help
+	 System frequency.
+
+config TANGOX_USE_CPU_CLOCK
+	bool "Use internal cpu clock for system timer"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default y
+	help
+	 If you say  yes here, the mips timer  interrupt (IP7) will be
+	 used as the  Linux timer interrupt. Timer0 can  be used as an
+	 alternative.
+
+config TANGOX_UART_USE_SYSCLK
+	bool "Use system clock for UART"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	default y
+	help
+	 If you  say yes here, the UART  clock will be  derivated from the
+	 board  system clock. If  you say  no, the  CPU clock  is used
+	 instead.
+
+config TANGOX_USE_TLB_REMAP_DRAM1
+	bool "Use TLB to access DRAM1"
+	depends on TANGO2_SMP863X 
+	default n
+	help
+	 If  you say yes  here, kernel  access to  DRAM1 will  be done
+	 using TLB implementation. gbus() funcs will use an ioremapped
+	 address to access this area of memory. If you say no, special
+	 CPU remap registers are used instead.
+
+#
+# XENV stuffs
+#
+
+config TANGOX_XENV_READ
+	bool "Read config from XENV"
+	depends on TANGO2_SMP863X || TANGO3_SMP865X
+	help
+	 If you  say yes  here, board configuration  (enabled devices,
+	 pci irq routing,  ...) will be read from  xenv space.
+
+config TANGOX_XENV_DUMP
+	bool "Dump XENV content at boot"
+	depends on TANGOX_XENV_READ
+	default n
+
+config TANGOX_XENV_READ_SAFE
+	bool "Don't boot if XENV invalid"
+	depends on TANGOX_XENV_READ
+	help
+	 If you say yes here and XENV content is invalid, linux wont boot.
+
+menu "XENV failsafe/override values"
+	depends on (TANGO2_SMP863X || TANGO3_SMP865X) && (!TANGOX_XENV_READ_SAFE)
+
+config TANGOX_XENV_DEF_CS0_SIZE
+	hex "CS0 size (flash0)"
+	default 0x0
+
+config TANGOX_XENV_DEF_CS1_SIZE
+	hex "CS1 size (flash1)"
+	default 0x0
+
+config TANGOX_XENV_DEF_CS2_SIZE
+	hex "CS2 size (flash2)"
+	default 0x400000
+
+config TANGOX_XENV_DEF_CS3_SIZE
+	hex "CS3 size (flash3)"
+	default 0x0
+
+config TANGOX_XENV_DEF_UART0
+	bool "UART0 enabled"
+	default y
+
+config TANGOX_XENV_DEF_UART1
+	bool "UART1 enabled"
+	default y
+
+config TANGOX_XENV_DEF_BAUDRATE
+	int "Default baudrate"
+	default 115200
+
+config TANGOX_XENV_DEF_CONSOLE_UART_PORT
+	int "Console UART port"
+	default 0
+
+config TANGOX_XENV_DEF_ENET
+	bool "Ethernet enabled"
+	default n
+
+config TANGOX_XENV_DEF_FIP
+	bool "FIP enabled"
+	default n
+
+config TANGOX_XENV_DEF_I2CM
+	bool "I2CM enabled"
+	default n
+
+config TANGOX_XENV_DEF_I2CS
+	bool "I2CS enabled"
+	default n
+
+config TANGOX_XENV_DEF_BMIDE
+	bool "BM IDE controller enabled"
+	default n
+
+config TANGOX_XENV_DEF_ISAIDE
+	bool "ISA IDE controller enabled"
+	default n
+
+config TANGOX_XENV_DEF_IR
+	bool "IR enabled"
+	default n
+
+config TANGOX_XENV_DEF_PCIHOST
+	bool "PCI Host enabled"
+	default n
+
+config TANGOX_XENV_DEF_PCI_ID1
+	bool "PCI device 1 enabled"
+	depends on TANGOX_XENV_DEF_PCIHOST
+	default n
+
+config TANGOX_XENV_DEF_PCI_ID1_IRQ
+	hex "PCI device 1 IRQ route"
+	depends on TANGOX_XENV_DEF_PCIHOST && TANGOX_XENV_DEF_PCI_ID1
+	default 0x0
+
+config TANGOX_XENV_DEF_PCI_ID2
+	bool "PCI device 2 enabled"
+	depends on TANGOX_XENV_DEF_PCIHOST
+	default n
+
+config TANGOX_XENV_DEF_PCI_ID2_IRQ
+	hex "PCI device 2 IRQ route"
+	depends on TANGOX_XENV_DEF_PCIHOST && TANGOX_XENV_DEF_PCI_ID2
+	default 0x0
+
+config TANGOX_XENV_DEF_PCI_ID3
+	bool "PCI device 3 enabled"
+	depends on TANGOX_XENV_DEF_PCIHOST
+	default n
+
+config TANGOX_XENV_DEF_PCI_ID3_IRQ
+	hex "PCI device 3 IRQ route"
+	depends on TANGOX_XENV_DEF_PCIHOST && TANGOX_XENV_DEF_PCI_ID3
+	default 0x0
+
+config TANGOX_XENV_DEF_PCI_ID4
+	bool "PCI device 4 enabled"
+	depends on TANGOX_XENV_DEF_PCIHOST
+	default n
+
+config TANGOX_XENV_DEF_PCI_ID4_IRQ
+	hex "PCI device 4 IRQ route"
+	depends on TANGOX_XENV_DEF_PCIHOST && TANGOX_XENV_DEF_PCI_ID4
+	default 0x0
+
+config TANGOX_XENV_DEF_USB
+	bool "USB enabled"
+	default n
+
+endmenu
diff -Naur linux-2.6.30-ori/arch/mips/tangox/Makefile linux-2.6.30-test/arch/mips/tangox/Makefile
--- linux-2.6.30-ori/arch/mips/tangox/Makefile	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,16 @@
+#
+# Makefile for SigmaDesigns Tango2/Tango3 board
+#
+# Note! Dependencies are done automagically by 'make dep', which also
+# removes any old dependencies. DON'T put your own dependencies here
+# unless it's something special (ie not a .c file).
+#
+
+obj-y += irq.o setup.o prom.o gbus.o xenv_config.o delay.o platform.o
+
+obj-$(CONFIG_TANGOX_PROM_CONSOLE) += console.o
+
+obj-$(CONFIG_TANGOX_XENV_READ) += sha.o xenv.o
+
+obj-y += mbus.o
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/console.c linux-2.6.30-test/arch/mips/tangox/console.c
--- linux-2.6.30-ori/arch/mips/tangox/console.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/console.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,114 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ * simple  uart support for  tango2/tango3 board,  register an  early console
+ * that make boot problem easier to debug.
+ *
+ * this uart init code comes from zboot
+ */
+
+#include <linux/init.h>
+#include <linux/console.h>
+
+
+
+#include "setup.h"
+
+extern int tangox_uart_console_port(void);
+
+/*
+ * helpers to access uart0/uart1 register
+ */
+#define RD_UART_REG32(r)	\
+	(tangox_uart_console_port() ? \
+		gbus_readl(REG_BASE_cpu_block + CPU_UART1_base + (r)) : \
+		gbus_readl(REG_BASE_cpu_block + CPU_UART0_base + (r)))
+
+#define WR_UART_REG32(r, v)	\
+	(tangox_uart_console_port() ? \
+		gbus_writel(REG_BASE_cpu_block + CPU_UART1_base + (r), (v)) : \
+		gbus_writel(REG_BASE_cpu_block + CPU_UART0_base + (r), (v)))
+
+/*
+ * print given char to uart0/uart1
+ */
+static void __init prom_putc(char c)
+{
+	/* if '\n', then print '\r' also */
+	if (c == '\n') {
+		prom_putc('\r');
+	}
+
+	while ((RD_UART_REG32(CPU_UART_LSR) & 0x20) == 0);
+	WR_UART_REG32(CPU_UART_THR, (unsigned long)c);
+	while ((RD_UART_REG32(CPU_UART_LSR) & 0x20) == 0);
+}
+
+/*
+ * print given string to uart0/uart1
+ */
+void __init prom_puts(const char *s)
+{
+	while (*s)
+		prom_putc(*s++);
+}
+
+/*
+ * initialize uart0/uart1 with given parameters
+ */
+static void __init uart_init(int baud, int fifo)
+{
+	WR_UART_REG32(CPU_UART_IER, 0x0);
+	WR_UART_REG32(CPU_UART_FCR, (fifo ? 0x1f : 0x0));
+	WR_UART_REG32(CPU_UART_LCR, 0x3);
+
+#ifdef CONFIG_TANGOX_UART_USE_SYSCLK
+	WR_UART_REG32(CPU_UART_CLKSEL, 0x0);
+	WR_UART_REG32(CPU_UART_CLKDIV, ((tangox_get_sysclock() / baud) >> 4) + 1);
+#else
+	WR_UART_REG32(CPU_UART_CLKSEL, 0x1);
+	WR_UART_REG32(CPU_UART_CLKDIV, ((TANGOX_BASE_FREQUENCY / baud) >> 4) + 1);
+#endif
+}
+
+/*
+ * kernel console write callback
+ */
+static void __init prom_console_write(struct console *con, const char *s,
+				      unsigned int c)
+{
+	while(c>0)
+	{
+		prom_putc(*s++);
+		c--;
+	}
+}
+
+static struct console promcons __initdata = {
+	.name   = "prom",
+	.write  = prom_console_write,
+	.flags  = CON_PRINTBUFFER | CON_BOOT,
+	.index  = -1,
+};
+
+/*
+ * init uart0/uart1 and register a console that will use our prom console
+ * callbacks
+ */
+extern int tangox_uart_baudrate(int uart);
+
+void __init prom_console_register(void)
+{
+	uart_init(tangox_uart_baudrate(tangox_uart_console_port()), 0);
+	register_console(&promcons);
+
+	/* hello world ! */
+	printk(KERN_INFO "prom console registered\n");
+}
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/delay.c linux-2.6.30-test/arch/mips/tangox/delay.c
--- linux-2.6.30-ori/arch/mips/tangox/delay.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/delay.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,57 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ * arch/mips/tangox/delay.c
+ *
+ * Copyright (C) 2003-2007 Sigma Designs, Inc.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <asm/io.h>
+#include <linux/irq.h>
+#include <linux/sched.h>
+
+#include "setup.h"
+
+static inline unsigned long tangox_getxtal(void)
+{
+	return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+/* This is the replacement of Linux's udelay. */
+void tangox_udelay(unsigned usec)
+{
+	/* SYS_xtal_in_cnt is a counter running off 27MHz, so 1 usec
+           is roughly equivalent to 27 increase of count */
+	unsigned long start = tangox_getxtal();
+	unsigned long end = start + (usec * 27);
+
+    if (end > start)
+        while (tangox_getxtal() < end && tangox_getxtal() > start);
+    else {
+    /* Handle overflow condition */
+        while (! (tangox_getxtal() > end && tangox_getxtal() < start));
+    }
+}
+
+void tangox_syncwith_xtal(unsigned long *mark, unsigned usec)
+{
+	unsigned long end = *mark + (usec * 27);
+	if (end > *mark)
+		/* Handle overflow condition */
+		while (tangox_getxtal() > *mark);
+	while (tangox_getxtal() < end);
+	*mark = end;
+}
+
+EXPORT_SYMBOL(tangox_udelay);
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/gbus.c linux-2.6.30-test/arch/mips/tangox/gbus.c
--- linux-2.6.30-ori/arch/mips/tangox/gbus.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/gbus.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,280 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ * export gbus symbol to modules
+ */
+
+#include <linux/module.h>
+#include <asm/system.h>
+
+#include "setup.h"
+
+#define TMP_REMAPPED_REG   CPU_remap1
+#define TMP_REMAPPED_BASE  CPU_remap1_address
+#define TMP_REMAPPED_SIZE  0x00010000
+#define TMP_REMAPPED_MASK  ~(TMP_REMAPPED_SIZE-1)
+
+#if defined(CONFIG_TANGO2) && defined(CONFIG_TANGOX_USE_TLB_REMAP_DRAM1)
+unsigned long em86xx_tlb_dram1_map_base;
+unsigned long em86xx_tlb_dram1_map_size;
+#endif
+
+static RMuint32 set_remap(RMuint32 remap_reg, RMuint32 value)
+{
+	RMuint32 orig = *((volatile RMuint32 *)KSEG1ADDR(REG_BASE_cpu_block + remap_reg));
+	if (orig != value) {
+		*((volatile RMuint32 *)KSEG1ADDR(REG_BASE_cpu_block + remap_reg)) = value;
+		iob();
+	}
+	return(orig);
+}
+
+#ifdef CONFIG_TANGO3
+
+#define BUILD_GBUS_READ_OP(size)									\
+RMuint##size gbus_read_uint##size(struct gbus *pgbus, RMuint32 byte_address) 				\
+{													\
+	RMuint32 remap;											\
+	RMuint##size tmp;										\
+	extern unsigned long phy_remap, max_remap_size;							\
+	if (byte_address < CPU_remap2_address)								\
+		return *((volatile RMuint##size *)KSEG1ADDR(byte_address)); 				\
+	else if ((byte_address >= phy_remap) && (byte_address < (phy_remap + max_remap_size)))		\
+		return *((volatile RMuint##size *)KSEG1ADDR(CPU_REMAP_SPACE + (byte_address - phy_remap))); 	\
+	else {												\
+		unsigned long flags;									\
+		local_irq_save(flags); /* Ensure remap won't be changed */				\
+		/* Use CPU_remapx to temporarily map the address */					\
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);			\
+		tmp = *((volatile RMuint##size *)KSEG1ADDR(TMP_REMAPPED_BASE + 				\
+								(byte_address & (TMP_REMAPPED_SIZE-1))));	\
+		set_remap(TMP_REMAPPED_REG, remap);							\
+		local_irq_restore(flags);								\
+		return(tmp);										\
+	}												\
+}
+
+BUILD_GBUS_READ_OP(32);
+BUILD_GBUS_READ_OP(16);
+BUILD_GBUS_READ_OP(8);
+
+#define BUILD_GBUS_WRITE_OP(size)									\
+void gbus_write_uint##size(struct gbus *pgbus, RMuint32 byte_address, RMuint##size data)		\
+{													\
+	RMuint32 remap;											\
+	extern unsigned long phy_remap, max_remap_size;							\
+	if (byte_address < CPU_remap2_address)								\
+		*((volatile RMuint##size *)KSEG1ADDR(byte_address)) = data;				\
+	else if ((byte_address >= phy_remap) && (byte_address < (phy_remap + max_remap_size)))		\
+		*((volatile RMuint##size *)KSEG1ADDR(CPU_REMAP_SPACE + (byte_address - phy_remap))) = data;	\
+	else {												\
+		unsigned long flags;									\
+		local_irq_save(flags); /* Ensure remap won't be changed */				\
+		/* Use CPU_remapx to temporarily map the address */					\
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);			\
+		*((volatile RMuint##size *)KSEG1ADDR(TMP_REMAPPED_BASE + 				\
+							(byte_address & (TMP_REMAPPED_SIZE-1)))) = data;	\
+		__sync();										\
+		set_remap(TMP_REMAPPED_REG, remap);							\
+		local_irq_restore(flags);								\
+	}												\
+	iob();												\
+}
+
+BUILD_GBUS_WRITE_OP(32);
+BUILD_GBUS_WRITE_OP(16);
+BUILD_GBUS_WRITE_OP(8);
+
+#else /* CONFIG_TANGO3 */
+
+RMuint32 gbus_read_uint32(struct gbus *pgbus, RMuint32 byte_address)
+{
+	RMuint32 remap;
+	RMuint32 tmp;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		return gbus_read_dram_uint32(pgbus, byte_address);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			return gbus_read_dram_uint32(pgbus, byte_address);
+		else {
+			printk("accessing non-existed DRAM1 area 0x%08lx\n", byte_address);
+			return(0);
+		}
+#else
+		return gbus_read_dram_uint32(pgbus, byte_address);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		tmp = *((volatile RMuint32 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1))));
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+		return(tmp);
+	}
+}
+
+RMuint16 gbus_read_uint16(struct gbus *pgbus, RMuint32 byte_address)
+{
+	RMuint32 remap;
+	RMuint16 tmp;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		return gbus_read_dram_uint16(pgbus, byte_address);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			return gbus_read_dram_uint16(pgbus, byte_address);
+		else {
+			printk("accessing non-existed DRAM1 area 0x%08lx\n", byte_address);
+			return(0);
+		}
+#else
+		return gbus_read_dram_uint16(pgbus, byte_address);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		tmp = *((volatile RMuint16 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1))));
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+		return(tmp & 0xffff);
+	}
+}
+
+RMuint8 gbus_read_uint8(struct gbus *pgbus, RMuint32 byte_address)
+{
+	RMuint32 remap;
+	RMuint8 tmp;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		return gbus_read_dram_uint8(pgbus, byte_address);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			return gbus_read_dram_uint8(pgbus, byte_address);
+		else {
+			printk("accessing non-existed DRAM1 area 0x%08lx\n", byte_address);
+			return(0);
+		}
+#else
+		return gbus_read_dram_uint8(pgbus, byte_address);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		tmp = *((volatile RMuint8 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1))));
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+		return(tmp & 0xff);
+	}
+}
+
+void gbus_write_uint32(struct gbus *pgbus, RMuint32 byte_address, RMuint32 data)
+{
+	RMuint32 remap;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		gbus_write_dram_uint32(pgbus, byte_address, data);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			gbus_write_dram_uint32(pgbus, byte_address, data);
+		else 
+			printk("accessing non-existed DRAM1 area 0x%08lx.\n", byte_address);
+#else
+		gbus_write_dram_uint32(pgbus, byte_address, data);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		*((volatile RMuint32 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1)))) = data;
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+	}
+	__sync();
+}
+
+void gbus_write_uint16(struct gbus *pgbus, RMuint32 byte_address, RMuint16 data)
+{
+	RMuint32 remap;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		gbus_write_dram_uint16(pgbus, byte_address, data);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			gbus_write_dram_uint16(pgbus, byte_address, data);
+		else 
+			printk("accessing non-existed DRAM1 area 0x%08lx.\n", byte_address);
+#else
+		gbus_write_dram_uint16(pgbus, byte_address, data);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		*((volatile RMuint16 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1)))) = (data & 0xffff);
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+	}
+	__sync();
+}
+
+void gbus_write_uint8(struct gbus *pgbus, RMuint32 byte_address, RMuint8 data)
+{
+	RMuint32 remap;
+
+	if (byte_address < (MEM_BASE_dram_controller_0_alias + 0x10000000))
+		gbus_write_dram_uint8(pgbus, byte_address, data);
+	else if (byte_address < (MEM_BASE_dram_controller_1 + 0x10000000))
+#ifdef CONFIG_TANGOX_USE_TLB_REMAP_DRAM1
+		if (byte_address < (MEM_BASE_dram_controller_1 + em86xx_tlb_dram1_map_size))
+			gbus_write_dram_uint8(pgbus, byte_address, data);
+		else 
+			printk("accessing non-existed DRAM1 area 0x%08lx.\n", byte_address);
+#else
+		gbus_write_dram_uint8(pgbus, byte_address, data);
+#endif
+	else {
+		unsigned long flags;
+		local_irq_save(flags); // Ensure remap won't be changed 
+		// Use CPU_remapx to temporarily map the address
+		remap = set_remap(TMP_REMAPPED_REG, byte_address & TMP_REMAPPED_MASK);
+		*((volatile RMuint8 *)KSEG1ADDR(TMP_REMAPPED_BASE + (byte_address & (TMP_REMAPPED_SIZE-1)))) = (data & 0xff);
+		set_remap(TMP_REMAPPED_REG, remap);
+		local_irq_restore(flags);
+	}
+	__sync();
+}
+
+#endif /* CONFIG_TANGO3 */
+
+EXPORT_SYMBOL(gbus_read_uint32);
+EXPORT_SYMBOL(gbus_write_uint32);
+EXPORT_SYMBOL(gbus_read_uint16);
+EXPORT_SYMBOL(gbus_write_uint16);
+EXPORT_SYMBOL(gbus_read_uint8);
+EXPORT_SYMBOL(gbus_write_uint8);
+
+#if defined(CONFIG_TANGO2) && defined(CONFIG_TANGOX_USE_TLB_REMAP_DRAM1)
+EXPORT_SYMBOL(em86xx_tlb_dram1_map_base);
+EXPORT_SYMBOL(em86xx_tlb_dram1_map_size);
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/irq.c linux-2.6.30-test/arch/mips/tangox/irq.c
--- linux-2.6.30-ori/arch/mips/tangox/irq.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/irq.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,490 @@
+/*
+ * Copyright (C) 2007 Sigma Designs, inc.
+ * Copyright 2001 MontaVista Software Inc.
+ * Author: Jun Sun, jsun@mvista.com or jsun@junsun.net
+ *
+ * arch_init_irq for tango2/tango3.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <asm/irq_cpu.h>
+
+#include "setup.h"
+
+/*
+ * helpers to access cpu block registers
+ */
+#define RD_CPU_REG32(r)	\
+		gbus_readl(REG_BASE_cpu_block + (r))
+
+#define WR_CPU_REG32(r, v)	\
+		gbus_writel(REG_BASE_cpu_block + (r), (v))
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+static inline u64 get_irq_status(void)
+{
+	return((((u64)RD_CPU_REG32(CPU_irq_status_hi))<<32ULL) | ((u64)RD_CPU_REG32(CPU_irq_status)));
+}
+static inline u64 get_fiq_status(void)
+{
+	return((((u64)RD_CPU_REG32(CPU_fiq_status_hi))<<32ULL) | ((u64)RD_CPU_REG32(CPU_fiq_status)));
+}
+static inline u64 get_iiq_status(void)
+{
+	return((((u64)RD_CPU_REG32(CPU_iiq_status_hi))<<32ULL) | ((u64)RD_CPU_REG32(CPU_iiq_status)));
+}
+#else
+static inline u32 get_irq_status(void)
+{
+	return((u32)RD_CPU_REG32(CPU_irq_status));
+}
+static inline u32 get_fiq_status(void)
+{
+	return((u32)RD_CPU_REG32(CPU_fiq_status));
+}
+static inline u32 get_iiq_status(void)
+{
+	return((u32)RD_CPU_REG32(CPU_iiq_status));
+}
+#endif
+
+/*
+ * dispatch routine called from tangoxIRQ.S
+ */
+extern void spurious_interrupt(void);
+void tangox_dispatch(int ipline)
+{
+	int x;
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	u64 status;
+#else
+	u32 status;
+#endif
+
+	switch (ipline) {
+	case 2:
+		if ((status = get_irq_status()) == 0) {
+			spurious_interrupt();
+			return;
+		} else {
+			do {
+				for (x = 0; status != 0; x++, status >>= 1) {
+					if ((status & 0x1) != 0) {
+						do_IRQ(IRQ_CONTROLLER_IRQ_BASE + x);
+						break;
+					}
+				}
+			} while ((status = get_irq_status()) != 0);
+		}
+		break;
+
+	case 3:
+		if ((status = get_fiq_status()) == 0) {
+			spurious_interrupt();
+			return;
+		} else {
+			/* We need to mask out irq, fiq > irq */
+			u32 sr_old = read_c0_status();
+			u32 sr_new = sr_old & (~STATUSF_IP2);
+
+			write_c0_status(sr_new);
+			do {
+				for (x = 0; status != 0; x++, status >>= 1) {
+					if ((status & 0x1) != 0) {
+						do_IRQ(FIQ_CONTROLLER_IRQ_BASE + x);
+						break;
+					}
+				}
+			} while ((status = get_fiq_status()) != 0);
+			write_c0_status(sr_old);
+		}
+		break;
+
+	case 4:
+		if ((status = get_iiq_status()) == 0) {
+			spurious_interrupt();
+			return;
+		} else {
+			/* We need to mask out fiq/irq, iiq > fiq > irq */
+			u32 sr_old = read_c0_status();
+			u32 sr_new = sr_old & (~(STATUSF_IP2|STATUSF_IP3));
+
+			write_c0_status(sr_new);
+			do {
+				for (x = 0; status != 0; x++, status >>= 1) {
+					if ((status & 0x1) != 0) {
+						do_IRQ(IIQ_CONTROLLER_IRQ_BASE + x);
+						break;
+					}
+				}
+			} while ((status = get_iiq_status()) != 0);
+			write_c0_status(sr_old);
+		}
+		break;
+
+	case 7:
+		do_IRQ(7);
+		return;
+
+	default:
+		printk("spurious irq: ipline: %d\n", ipline);
+		spurious_interrupt();
+		return;
+	}
+}
+
+/*
+ * our hw_irq_controller cb
+ */
+static inline void tangox_irq_enable(unsigned int x)
+{
+	int bit = x - IRQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_irq_enableset_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_irq_enableset, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static inline void tangox_fiq_enable(unsigned int x)
+{
+	int bit = x - FIQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_fiq_enableset_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_fiq_enableset, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static inline void tangox_iiq_enable(unsigned int x)
+{
+	int bit = x - IIQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_iiq_enableset_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_iiq_enableset, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static inline void tangox_irq_disable(unsigned int x)
+{
+	int bit = x - IRQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_irq_enableclr_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_irq_enableclr, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static inline void tangox_fiq_disable(unsigned int x)
+{
+	int bit = x - FIQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_fiq_enableclr_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_fiq_enableclr, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static inline void tangox_iiq_disable(unsigned int x)
+{
+	int bit = x - IIQ_CONTROLLER_IRQ_BASE;
+	unsigned long flags;
+
+	local_irq_save(flags);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_iiq_enableclr_hi, 1 << (bit - 32));
+		local_irq_restore(flags);
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_iiq_enableclr, 1 << bit);
+	local_irq_restore(flags);
+}
+
+static unsigned int tangox_irq_startup(unsigned int x)
+{
+	int bit = x - IRQ_CONTROLLER_IRQ_BASE;
+
+	/* clear any pending interrupt before enabling it */
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		tangox_irq_enable(x);
+		return 0;
+	}
+#endif
+
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+
+	tangox_irq_enable(x);
+
+	return 0;
+}
+
+static unsigned int tangox_fiq_startup(unsigned int x)
+{
+	int bit = x - FIQ_CONTROLLER_IRQ_BASE;
+
+	/* clear any pending interrupt before enabling it */
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		tangox_fiq_enable(x);
+		return 0;
+	}
+#endif
+
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+
+	tangox_fiq_enable(x);
+
+	return 0;
+}
+
+static unsigned int tangox_iiq_startup(unsigned int x)
+{
+	int bit = x - IIQ_CONTROLLER_IRQ_BASE;
+
+	/* clear any pending interrupt before enabling it */
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		tangox_iiq_enable(x);
+		return 0;
+	}
+#endif
+
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+
+	tangox_iiq_enable(x);
+
+	return 0;
+}
+
+#define	tangox_irq_shutdown tangox_irq_disable
+#define	tangox_fiq_shutdown tangox_fiq_disable
+#define	tangox_iiq_shutdown tangox_iiq_disable
+
+static void tangox_irq_ack(unsigned int x)
+{
+	int bit = x - IRQ_CONTROLLER_IRQ_BASE;
+
+	tangox_irq_disable(x);
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+}
+
+static void tangox_fiq_ack(unsigned int x)
+{
+	int bit = x - FIQ_CONTROLLER_IRQ_BASE;
+
+	tangox_fiq_disable(x);
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+}
+
+static void tangox_iiq_ack(unsigned int x)
+{
+	int bit = x - IIQ_CONTROLLER_IRQ_BASE;
+
+	tangox_iiq_disable(x);
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	if (bit >= 32) {
+		WR_CPU_REG32(CPU_edge_rawstat_hi, 1 << (bit - 32));
+		return;
+	}
+#endif
+	WR_CPU_REG32(CPU_edge_rawstat, 1 << bit);
+}
+
+static void tangox_irq_end(unsigned int x)
+{
+	if (!(irq_desc[x].status & (IRQ_DISABLED | IRQ_INPROGRESS)))
+		tangox_irq_enable(x);
+}
+
+static void tangox_fiq_end(unsigned int x)
+{
+	if (!(irq_desc[x].status & (IRQ_DISABLED | IRQ_INPROGRESS)))
+		tangox_fiq_enable(x);
+}
+
+static void tangox_iiq_end(unsigned int x)
+{
+	if (!(irq_desc[x].status & (IRQ_DISABLED | IRQ_INPROGRESS)))
+		tangox_iiq_enable(x);
+}
+
+/*
+ * our hw_irq_controller
+ */
+static struct irq_chip tangox_irq_controller = {
+	.typename = "tangox_irq",
+	.ack = tangox_irq_ack,
+	.mask = tangox_irq_disable,
+	.mask_ack = tangox_irq_ack,
+	.unmask = tangox_irq_enable,
+	.end = tangox_irq_end,
+};
+
+static struct irq_chip tangox_fiq_controller = {
+	.typename = "tangox_fiq",
+	.ack = tangox_fiq_ack,
+	.mask = tangox_fiq_disable,
+	.mask_ack = tangox_fiq_ack,
+	.unmask = tangox_fiq_enable,
+	.end = tangox_fiq_end,
+};
+
+static struct irq_chip tangox_iiq_controller = {
+	.typename = "tangox_iiq",
+	.ack = tangox_iiq_ack,
+	.mask = tangox_iiq_disable,
+	.mask_ack = tangox_iiq_ack,
+	.unmask = tangox_iiq_enable,
+	.end = tangox_iiq_end,
+};
+
+static struct irqaction irq_cascade = {
+	no_action, 0, { { 0, } }, "cascade", NULL, NULL
+};
+
+void __init arch_init_irq(void)
+{
+	unsigned long x;
+	unsigned long rise = 0;
+	unsigned long fall = 0;
+	unsigned long edge_trig = 0;
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	unsigned long rise_hi = 0;
+	unsigned long fall_hi = 0;
+	unsigned long edge_trig_hi = 0;
+#endif
+
+	/* this hooks except_vec0 to tangox assembly routine */
+	//set_except_vector(0, tangoxIRQ);
+
+	/* irq_desc entries 0..7 */
+	mips_cpu_irq_init();
+
+	for (x = IRQ_CONTROLLER_IRQ_BASE; x < IRQ_CONTROLLER_IRQ_BASE + IRQ_COUNT; x++) {
+		set_irq_chip_and_handler(x, &tangox_irq_controller, handle_level_irq);
+	}
+
+	for (x = FIQ_CONTROLLER_IRQ_BASE; x < FIQ_CONTROLLER_IRQ_BASE + IRQ_COUNT; x++) {
+		set_irq_chip_and_handler(x, &tangox_fiq_controller, handle_level_irq);
+	}
+
+	for (x = IIQ_CONTROLLER_IRQ_BASE; x < IIQ_CONTROLLER_IRQ_BASE + IRQ_COUNT; x++) {
+		set_irq_chip_and_handler(x, &tangox_iiq_controller, handle_level_irq);
+	}
+
+	setup_irq(MIPS_CPU_IRQ_BASE + 2, &irq_cascade);
+	setup_irq(MIPS_CPU_IRQ_BASE + 3, &irq_cascade);
+	setup_irq(MIPS_CPU_IRQ_BASE + 4, &irq_cascade);
+
+	WR_CPU_REG32(CPU_irq_enableclr, 0xffffffff);
+	WR_CPU_REG32(CPU_fiq_enableclr, 0xffffffff);
+	WR_CPU_REG32(CPU_iiq_enableclr, 0xffffffff);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	WR_CPU_REG32(CPU_irq_enableclr_hi, 0xffffffff);
+	WR_CPU_REG32(CPU_fiq_enableclr_hi, 0xffffffff);
+	WR_CPU_REG32(CPU_iiq_enableclr_hi, 0xffffffff);
+#endif
+
+	rise = RD_CPU_REG32(CPU_edge_config_rise);
+	fall = RD_CPU_REG32(CPU_edge_config_fall);
+	edge_trig = rise ^ fall;
+	WR_CPU_REG32(CPU_edge_rawstat, edge_trig);
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	rise_hi = RD_CPU_REG32(CPU_edge_config_rise_hi);
+	fall_hi = RD_CPU_REG32(CPU_edge_config_fall_hi);
+	edge_trig_hi = rise_hi ^ fall_hi;
+	WR_CPU_REG32(CPU_edge_rawstat_hi, edge_trig_hi);
+#endif
+
+	return;
+}
+
+asmlinkage void plat_irq_dispatch(void)
+{
+	unsigned int pending = read_c0_status() & read_c0_cause();
+	if (pending & STATUSF_IP7)			/* cpu timer */
+		do_IRQ(7);
+	else if (pending & STATUSF_IP6)			/* cpu timer */
+		tangox_dispatch(6);
+	else if (pending & STATUSF_IP5)			/* cpu timer */
+		tangox_dispatch(5);
+	else if (pending & STATUSF_IP4)			/* cpu timer */
+		tangox_dispatch(4);
+	else if (pending & STATUSF_IP3)			/* cpu timer */
+		tangox_dispatch(3);
+	else if (pending & STATUSF_IP2)			/* cpu timer */
+		tangox_dispatch(2);
+	else if (pending & STATUSF_IP1)			/* cpu timer */
+		tangox_dispatch(1);
+	else if (pending & STATUSF_IP0)			/* cpu timer */
+		tangox_dispatch(0);
+	else
+		spurious_interrupt();
+}
diff -Naur linux-2.6.30-ori/arch/mips/tangox/mbus.c linux-2.6.30-test/arch/mips/tangox/mbus.c
--- linux-2.6.30-ori/arch/mips/tangox/mbus.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/mbus.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1376 @@
+/*********************************************************************
+ Copyright (C) 2001-2008
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+/* Modified version by Jean-Francois Thibert <jeanfrancois@sagetv.com>
+- Added copy from userspace optimisations using mbus
+- Added copy to userspace optimisations using mbus
+*/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <asm/uaccess.h>
+#include <asm/r4kcache.h>
+#include <linux/pagemap.h>
+#include <linux/dma-mapping.h>
+
+#include "setup.h"
+
+#if !defined(CONFIG_TANGO2) && !defined(CONFIG_TANGO3)
+#error Undefined Sigma's chip!!!
+#endif
+
+#ifdef CONFIG_TANGO3
+#warning TANGO3 TODO IRQ assignment for W2/R2!!
+/* Temporary as no W2/R2 IRQ assigned yet. */
+#define LOG2_CPU_HOST_MBUS_W2_INT	62
+#define LOG2_CPU_HOST_MBUS_R2_INT	63
+
+/* Uncomment this only if W1/R1 can be used (typically not) */
+// #define WITH_MBUS_W1R1
+
+#endif /* CONFIG_TANGO3 */
+
+/*
+ * computed in prom.c
+ */
+extern unsigned long em8xxx_kmem_start;
+extern unsigned long em8xxx_kmem_size;
+
+long long em86_stats[20] = {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0};
+
+static int usedma=0;
+
+/*
+ * switchbox stuffs
+ *
+ * We keep  track of  current mapping using  this globals  rather than
+ * reading hardware registers each time.
+ */
+static unsigned int g_sbox_map[SBOX_MAX];
+
+static inline void sbox_update_route(void)
+{
+	int i;
+#ifdef CONFIG_TANGO3
+	u64 data = 0; /* to cover two 32 bits registers */
+#else
+	unsigned int data = 0;
+#endif
+
+	for (i = SBOX_MAX - 1; i >= 0; --i)
+		data = (data << 4) | g_sbox_map[i];
+
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data & 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, (data >> 32) & 0xffffffff);
+#else
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data);
+#endif
+}
+
+static void sbox_reset(void)
+{
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xff00ff00);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfdfdfdfd);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfd00fd00);
+#endif
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01010101);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01000100);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d7d7d7d);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d007d00);
+#endif
+}
+
+static void sbox_setup(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* W0 initially disconnected */
+	g_sbox_map[SBOX_MBUS_W0] = 0xf;
+
+#if defined(CONFIG_TANGO3) && defined(WITH_MBUS_W1R1)
+	g_sbox_map[SBOX_MBUS_W1] = 0xf;
+#else
+	/* Leave W1 alone */
+	g_sbox_map[SBOX_MBUS_W1] = 0;
+#endif
+
+	g_sbox_map[SBOX_PCIMASTER] = 0xf;
+	g_sbox_map[SBOX_PCISLAVE] = SBOX_PCISLAVE + 1; /* Loopback */
+	g_sbox_map[SBOX_SATA1] = 0xf;
+	g_sbox_map[SBOX_IDEDVD] = 0xf;
+	g_sbox_map[SBOX_IDEFLASH] = 0xf;
+#ifdef CONFIG_TANGO3
+	g_sbox_map[SBOX_SATA2] = 0xf;
+	g_sbox_map[SBOX_MBUS_W2] = 0xf;
+#else
+	g_sbox_map[SBOX_UNUSED1] = 0xf;
+#endif
+
+	sbox_update_route();
+	wmb();
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Connect given interface to R?/W? channel
+ */
+#ifdef CONFIG_TANGO3
+static int sbox_connect(int iface, int *channel, int any)
+#else
+static int sbox_connect(int iface)
+#endif
+{
+	unsigned long flags;
+	int res = 0;
+#ifdef CONFIG_TANGO3
+	int chan = 0;
+#endif
+
+	local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) {
+		*channel = 0; /* connected to W0/R0 */
+		goto done;
+#ifdef WITH_MBUS_W1R1
+	} else if (g_sbox_map[SBOX_MBUS_W1] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W1 + 1)) {
+		*channel = 1; /* connected to W1/R1 */
+		goto done;
+#endif
+	} else if (g_sbox_map[SBOX_MBUS_W2] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W2 + 1)) {
+		*channel = 2; /* connected to W2/R2 */
+		goto done;
+	}
+
+	if (g_sbox_map[iface] != 0xf) { /* connect to something else already */
+		res = 1;
+		goto done;
+	}
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf) {
+		chan++; /* try next */
+#ifdef WITH_MBUS_W1R1
+		if (g_sbox_map[SBOX_MBUS_W1] != 0xf) {
+#endif
+			if (any == 0) {
+#warning TO BE FIX in TANGO3 H/W!! (W2/R2 allocation)
+				res = 1; /* TANGO3 TODO: allocate W2/R2 once IRQ is available */
+				goto done;
+			}
+			chan++; /* try next */
+			if (g_sbox_map[SBOX_MBUS_W2] != 0xf)  {
+				res = 1; /* Both W0/W2 not available, and optional (W1 as well) */
+				goto done;
+			}
+#ifdef WITH_MBUS_W1R1
+		}
+#endif
+	}
+#else
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) 
+		goto done;
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf || g_sbox_map[iface] != 0xf) {
+		res = 1;
+		goto done;
+	}
+#endif /* CONFIG_TANGO3 */
+
+#ifdef CONFIG_TANGO3
+	switch(chan) {
+		case 0: g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W0 + 1; /* W0/R0 */
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: g_sbox_map[SBOX_MBUS_W1] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W1 + 1; /* W1/R1 */
+			break;
+#endif
+		case 2: g_sbox_map[SBOX_MBUS_W2] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W2 + 1; /* W2/R2 */
+			break;
+
+		default: BUG();
+			break;
+	}
+	*channel = chan;
+#else
+	g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+	g_sbox_map[iface] = SBOX_MBUS_W0 + 1;
+#endif
+	sbox_update_route();
+	wmb();
+
+done:
+	local_irq_restore(flags);
+
+	return res;
+}
+
+#ifdef CONFIG_TANGO3
+static void sbox_disconnect(int iface, int channel)
+#else
+static void sbox_disconnect(int iface)
+#endif
+{
+	unsigned long flags;
+
+	if (iface >= 0) {
+		local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+		switch(channel) {
+			case 0: g_sbox_map[SBOX_MBUS_W0] = 0xf;
+				break;
+#ifdef WITH_MBUS_W1R1
+			case 1: g_sbox_map[SBOX_MBUS_W1] = 0xf;
+				break;
+#endif
+			case 2: g_sbox_map[SBOX_MBUS_W2] = 0xf;
+				break;
+
+			default: BUG();
+				break;
+		}
+#else
+		g_sbox_map[SBOX_MBUS_W0] = 0xf;
+#endif
+		g_sbox_map[iface] = 0xf;
+		sbox_update_route();
+		wmb();
+
+		local_irq_restore(flags);
+	}
+}
+
+static void sbox_init(void)
+{
+	sbox_setup();
+	sbox_reset();
+	// JFT, I wish we had more information on how those registers stuff work...
+	// Note :Is this early enough for all cases or we need a special enable flag?
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fe4, 0x0700); // Unreset dbk channels
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3dcc, 0x8000); // dbk loopback
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fdc, 0x0003); // switchbox->WMV9
+    usedma=1;
+}
+
+
+/*
+ * mbus stuffs
+ *
+ * to  avoid   requesting/freeing  irq   each  time,  we   keep  given
+ * handler/args  for each  dma  request and  call  it in  our own  irq
+ * handler.
+ */
+#define MBUS_LINEAR_MAX		(0x2000 - 1)
+
+#ifdef CONFIG_TANGO3
+static mbus_irq_handler_t g_mbus_intr_handler[6];
+static void *g_mbus_intr_handler_arg[6];
+#else
+static mbus_irq_handler_t g_mbus_intr_handler[4];
+static void *g_mbus_intr_handler_arg[4];
+#endif
+
+/*
+ * alloc_dma, need to be called before setup, will try to connect
+ * needed sbox.
+ */
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any)
+{
+	int x;
+
+#ifdef CONFIG_TANGO3
+	int channel = 0;
+
+	if (sbox_connect(sbox, &channel, any) != 0)
+		return -1;
+
+	switch(channel) {
+		case 0: { 	/* Using W0/R0 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W0_ADD + (x * 0x40);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: { 	/* Using W1/R1 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W1_ADD + (x * 0x40);
+			}
+			break;
+#endif
+		case 2: { 	/* Using W2/R2 pair */
+				x = (fromdev ? 0 : 1);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W2_ADD + (x * 0x40);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	if (sbox_connect(sbox) != 0)
+		return -1;
+
+	x = (fromdev ? 0 : 2);
+	if (pirq)
+		*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+	if (pregbase)
+		*pregbase = REG_BASE_host_interface + MIF_W0_ADD + x * 0x40;
+#endif
+
+	return 0;
+}
+
+#ifdef CONFIG_TANGO3
+/* Convert MBUS register address to channel index */
+static inline int mbus_idx2channel(unsigned int regbase)
+{
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	static const int channel[6] = { 0, 1, 0, 1, 2, 2 };
+	return(channel[idx]);
+}
+#endif
+
+/*
+ * free_dma,  need to  be called  after  transfer is  done to  release
+ * switchbox.
+ */
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox)
+{
+	unsigned long flags;
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	local_irq_save(flags);
+	g_mbus_intr_handler[idx] = NULL;
+	wmb();
+	local_irq_restore(flags);
+
+#ifdef CONFIG_TANGO3
+	sbox_disconnect(sbox, mbus_idx2channel(regbase)); 
+#else
+	sbox_disconnect(sbox);
+#endif
+}
+
+/*
+ * irq handler for mbus interrupt
+ */
+static irqreturn_t mbus_intr(int irq, void *devinfo)
+{
+	int idx = irq - (LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE);
+
+#ifdef CONFIG_TANGO3
+	if (idx >= 4)
+		idx = irq - (LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE) + 4;
+#endif
+	if (g_mbus_intr_handler[idx]) {
+		mbus_irq_handler_t f;
+
+		f = g_mbus_intr_handler[idx];
+		g_mbus_intr_handler[idx] = NULL;
+		wmb();
+		f(irq, g_mbus_intr_handler_arg[idx]);
+	}
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * check if mbus is in use for given regbase
+ */
+static inline int mbus_inuse(unsigned int regbase)
+{
+	return (gbus_readl(regbase + MIF_cmd_offset) & 0x7) != 0;
+}
+
+/*
+ * setup mbus  register to start  a linear transfer (count  bytes from
+ * addr, where count < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_linear(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (linear): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, count);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x1);
+}
+
+/*
+ * setup mbus  register to start  a double transfer (count  bytes from
+ * addr and count2 bytes from addr2, where count < MBUS_LINEAR_MAX and
+ * count2 < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_double(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int addr2,
+					 unsigned int count2,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address 0x%08x\n", addr);
+	if ((addr2 < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr2 >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address2 0x%08x\n", addr2);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (count2 << 16) | count);
+	gbus_writel(regbase + MIF_add2_skip_offset, addr2);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x2);
+}
+
+/*
+ * setup mbus  register to start  a rectangle transfer (horiz  * lines
+ * bytes  from  addr,  where  horiz  <  MBUS_LINEAR_MAX  and  lines  <
+ * MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_rectangle(unsigned int regbase,
+					    unsigned int addr,
+					    unsigned int horiz,
+					    unsigned int lines,
+					    unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (rectangle): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (lines << 16) | horiz);
+	gbus_writel(regbase + MIF_add2_skip_offset, horiz);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x3);
+}
+
+/*
+ * register mbus interrupt if not done
+ */
+#ifdef CONFIG_TANGO3
+static inline void mbus_register_intr(int channel)
+#else
+static inline void mbus_register_intr(void)
+#endif
+{
+#ifdef CONFIG_TANGO3
+	static int done[3] = { 0, 0, 0 };
+
+	switch(channel) {
+		case 0: {	/* Use W0/R0 then */
+				if (done[0])
+					return;
+				done[0] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: {	/* Use W1/R1 instead */
+				if (done[1])
+					return;
+				done[1] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r1", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w1", NULL);
+			}
+			break;
+#endif
+		case 2: {	/* Use W2/R2 instead */
+				if (done[2])
+					return;
+				done[2] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r2", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w2", NULL);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	static int done = 0;
+
+	if (done)
+		return;
+	done = 1;
+	/*
+	 * register irq handler for R0/W0 only (R1/W1 are not used for
+	 * the moment)
+	 */
+	request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+
+	request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+
+#endif
+}
+
+/*
+ * setup void transaction 
+ */
+void em86xx_mbus_setup_dma_void(unsigned int regbase)
+{
+	while (mbus_inuse(regbase) != 0)
+		;
+	gbus_writel(regbase + MIF_cmd_offset, 4);
+}
+
+/*
+ * start  a   mbus  dma,   use  this  after   a  sucessfull   call  to
+ * em86xx_mbus_alloc_dma
+ */
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr,
+			  unsigned int count, mbus_irq_handler_t handler,
+			  void *arg, unsigned int tflags)
+{
+	unsigned long flags;
+	unsigned int horiz, lines, sz;
+	unsigned int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	/*
+	 * make sure no one uses the mbus before
+	 */
+	if (unlikely(mbus_inuse(regbase))) {
+		printk(KERN_ERR "MBUS: error previous command is pending\n");
+		return 1;
+	}
+
+	/*
+	 * "register" given handler if any
+	 */
+	if (handler) {
+#ifdef CONFIG_TANGO3
+		mbus_register_intr(mbus_idx2channel(regbase));
+#else
+		mbus_register_intr();
+#endif
+		local_irq_save(flags);
+		g_mbus_intr_handler[idx] = handler;
+		g_mbus_intr_handler_arg[idx] = arg;
+		wmb();
+		local_irq_restore(flags);
+	}
+
+	/*
+	 * decide which dma function to use depending on count
+	 */
+	if (count <= MBUS_LINEAR_MAX) {
+		mbus_setup_dma_linear(regbase, addr, count, tflags);
+		return 0;
+	}
+
+	if (count <= (MBUS_LINEAR_MAX * 2)) {
+		mbus_setup_dma_double(regbase, addr, MBUS_LINEAR_MAX,
+				      addr + MBUS_LINEAR_MAX,
+				      count - MBUS_LINEAR_MAX, tflags);
+		return 0;
+	}
+
+	/*
+	 * we need to use rectangle, compute  horiz & lines
+	 * values to use
+	 */
+	for (idx = 0, horiz = 1, sz = count; (idx < 10) && ((sz & 0x01) == 0); ++idx, horiz <<= 1, sz >>= 1)
+		;
+	lines = count >> idx;
+	if ((horiz > MBUS_LINEAR_MAX) || (lines > MBUS_LINEAR_MAX)) {
+		printk(KERN_ERR "MBUS: can't handle rectangle transfer "
+		       "of %d bytes (h: %d, v: %d)\n", count, horiz, lines);
+		BUG();
+	}
+	mbus_setup_dma_rectangle(regbase, addr, horiz, lines, tflags);
+
+	return 0;
+}
+
+/*
+ * Bit 0/8: MBUS_R0_SBOX
+ * Bit 1/9: MBUS_R1_SBOX
+ * Bit 2/10: PCI_MASTER_SBOX
+ * Bit 3/11: PCI_SLAVE_SBOX
+ * Bit 4/12: SATA1_SBOX
+ * Bit 5/13: IDE_ISA_SBOX
+ * Bit 6/14: IDE_DVD_SBOX
+ * Bit 7/15: SATA2_SBOX (Tango3)
+ * Bit 16/24: SBOX_MBUS_W0
+ * Bit 17/25: SBOX_MBUS_W1
+ * Bit 18/26: SBOX_PCI_MASTER
+ * Bit 19/27: SBOX_PCI_SLAVE
+ * Bit 20/28: SBOX_SATA1
+ * Bit 21/29: SBOX_ISA
+ * Bit 22/30: SBOX_DVD
+ * Bit 23/31: SBOX_SATA2 (Tango3)
+ *
+ * Bit 32/40: MBUS_R2_SBOX (Tango3)
+ * Bit 48/50: SBOX_MBUS_W2 (Tango3)
+ */
+#ifdef CONFIG_TANGO3
+static const u64 sbox_reset_vals[4][6] = {
+	{ 0x0000000001011010ULL, 0x0000000002021010ULL, 0x0000000010100101ULL, 0x0000000010100202ULL, 0x0101000000001010ULL, 0x0000010110100000ULL },
+	{ 0x0000000001012020ULL, 0x0000000002022020ULL, 0x0000000020200101ULL, 0x0000000020200202ULL, 0x0101000000002020ULL, 0x0000010120200000ULL },
+	{ 0x0000000001014040ULL, 0x0000000002024040ULL, 0x0000000040400101ULL, 0x0000000040400202ULL, 0x0101000000004040ULL, 0x0000010140400000ULL },
+	{ 0x0000000001018080ULL, 0x0000000002028080ULL, 0x0000000080800101ULL, 0x0000000080800202ULL, 0x0101000000008080ULL, 0x0000010180800000ULL },
+};
+#else
+static const unsigned int sbox_reset_vals[2][4] = {
+	{ 0x01012020, 0x02022020, 0x20200101, 0x20200202 },
+	{ 0x01014040, 0x02024040, 0x40400101, 0x40400202 }
+};
+#endif
+
+/*
+ * clear MBUS transaction for given regbase/sbox
+ */
+static void mbus_reset(unsigned int regbase, int sbox)
+{
+	int midx;
+	int sidx;
+
+#ifdef CONFIG_TANGO3
+	unsigned int rl, rh;
+
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_SATA1;
+
+	if (((midx < 0) || (midx > 5)) || ((sidx < 0) || (sidx > 3))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+	rl = sbox_reset_vals[sidx][midx] & 0xffffffff;
+	rh = (sbox_reset_vals[sidx][midx] >> 32) & 0xffffffff;
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh);
+	iob();
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl & 0xff00ff00);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh & 0xff00ff00);
+	iob();
+#else
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_IDEFLASH;
+
+	if (((midx < 0) || (midx > 3)) || ((sidx < 0) || (sidx > 2))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx]);
+	iob();
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx] & 0xff00ff00);
+	iob();
+#endif
+}
+
+/* Fancy version of memcpy, both dst and src need to be physical address */
+/* The channels have to be allocated already */
+int mbus_memcpy(unsigned int regbase, unsigned int dst, unsigned int src, unsigned int size)
+{
+	/* Save the old SBOX route */
+	unsigned int sbox_route;
+	unsigned int w_base;
+	unsigned int r_base;
+	int channel = 0;
+/* 
+ * TRANSFER defines 4 bits, bit 0: followed by void (1) or not (0),
+ * bit 1: tiled buffer or not (tango3 only).
+ * bit 3-2: 0 = 8 bit, 1 = 16 bit, 2 = 32 bit (tango3 only).
+ */
+#ifdef CONFIG_TANGO3
+#define TRANSFER    0x1 /* or 0x9 for 32 bit transfer */
+#else
+#define TRANSFER    0x1
+#endif
+
+#ifdef CONFIG_TANGO3
+	channel = mbus_idx2channel(regbase);
+
+	if (channel == 0) /* W0/R0 channels are used */
+#endif
+	{
+		w_base = REG_BASE_host_interface + MIF_W0_ADD;
+		r_base = REG_BASE_host_interface + MIF_R0_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xffffff0f;
+
+		/* Hook up W0/R0 and left W1/R1 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff01);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W0 */
+			printk("MBUS: need to reset W0 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	else if (channel == 1) { /* W1/R1 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W1_ADD;
+		r_base = REG_BASE_host_interface + MIF_R1_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xfffffff0;
+
+		/* Hook up W1/R1 and left W0/R0 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff20);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W1 */
+			printk("MBUS: need to reset W1 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#endif
+	else { /* channel == 2: W2/R2 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W2_ADD;
+		r_base = REG_BASE_host_interface + MIF_R2_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE2);
+
+		/* Hook up W2/R2 */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, 0xfffffff9);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W2 */
+			printk("MBUS: need to reset W2 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+	}
+#endif
+
+	return(size);
+}
+
+/*
+ * busy wait  for current mbus transfer  to finish, will  not wait for
+ * more than 20 ms. 0 is ok, 1 timeout, 2 for timeout + reset error.
+ */
+#define MBUS_TIMEOUT	20000
+
+int em86xx_mbus_wait(unsigned int regbase, int sbox)
+{
+	int timeout;
+
+	/* wait for mbus to be released */
+	timeout = 0;
+	do {
+		if (!mbus_inuse(regbase))
+			break;
+		udelay(1);
+		timeout++;
+	} while (timeout < MBUS_TIMEOUT);
+
+	if (timeout < MBUS_TIMEOUT ) {
+		/* ok */
+		if (sbox == SBOX_IDEFLASH){
+                        int i;
+			unsigned int pb_count = 0;
+
+			pb_count = gbus_readl(REG_BASE_host_interface + 
+					       PB_automode_control) & 0xffff;
+
+                        for (i = 0; pb_count && (i < MBUS_TIMEOUT); i++){
+                                udelay(1);
+				pb_count = gbus_readl(REG_BASE_host_interface +
+					       PB_automode_control) & 0xffff;
+			}
+
+                        if (i < MBUS_TIMEOUT) 
+				return 0;
+
+		} else
+			return 0;
+	}
+
+	/* timeout, let's dump some registers ! */
+        if (sbox == SBOX_IDEFLASH) {
+  		printk("MBUS timeout : MBUS CMD = %ld, PB Automode = %08x\n",
+                	(unsigned long)gbus_readl(regbase + MIF_cmd_offset) & 0x7,
+                	(unsigned int)gbus_readl(REG_BASE_host_interface + PB_automode_control));
+        } else {
+		printk("MBUS timeout : MBUS CMD = %08lx\n",
+			gbus_readl(regbase + MIF_cmd_offset) & 0x7);
+	}
+
+	printk("MBUS registers : %08lx %08lx %08lx %08lx\n",
+	       gbus_readl(regbase + MIF_add_offset),
+	       gbus_readl(regbase + MIF_cnt_offset),
+	       gbus_readl(regbase + MIF_add2_skip_offset),
+	       gbus_readl(regbase + MIF_cmd_offset));
+
+	printk(KERN_ERR "MBUS fails, resetting %d ..\n", sbox);
+	mbus_reset(regbase, sbox);
+
+	/* If not able to reset, return  1, so the DMA can be disabled
+	   accordingly  */
+	return mbus_inuse(regbase) ? 0 : 1;
+}
+
+int em86xx_mbus_init(void)
+{
+	static int done = 0;
+
+	if (done)
+		return 0;
+	done = 1;
+
+	/* reset sbox to default values */
+	sbox_init();
+
+	/* Give better MBUS bandwidth for Wx/Rx channel */
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_system_block + MARB_mid01_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid21_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid03_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid23_cfg, 0x12005);
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x12005);
+#endif
+#else
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x11f1f);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x11f1f);
+#endif
+
+	return 0;
+}
+
+// JFT, *** WARNING ***  CODE BELOW IS ONLY VALID IN SPECIFIC CASES
+
+#define offset_into_page(x) ((x) & (PAGE_SIZE - 1))
+
+static inline unsigned long tangox_getxtal(void)
+{
+	return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+// Reduce gbus usage
+static int wait_mpegdma()
+{
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0)
+    {
+        __asm__ __volatile__("nop;nop;nop;nop");
+        __asm__ __volatile__("nop;nop;nop;nop");
+        __asm__ __volatile__("nop;nop;nop;nop");
+        __asm__ __volatile__("nop;nop;nop;nop");
+    }
+}
+
+// At this point the memory copy is linear in physical space
+static int mpeg_dma_transfer_to_user(unsigned int dma_to, unsigned int virt_to, unsigned int dma_from, int len)
+{
+        int byte=0;
+        while(len>0)
+        {
+            int blockcount = len>0x1FFF ? 1 : 1;
+            int curlen=len>0x1FFF ? (blockcount*0x1FFF) : len;
+            // if(len>=16384) curlen=16384;
+
+            // printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, curlen);
+            blast_dcache_range(dma_from+byte, dma_from+byte+curlen);
+            blast_inv_dcache_range(virt_to+byte, virt_to+byte+curlen);
+
+            wait_mpegdma();
+
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0x3fff0000) >> 16);
+            if(curlen>0x1FFF)
+            {
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, 0x1FFF);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, blockcount);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad0, 0x1FFF);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad4, 0);
+                if((len-curlen)==0)
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x7);
+                else
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x3);
+            }
+            else
+            {
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, len>0x1FFF ? 0x1FFF : len);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+
+                if((len-curlen)==0)
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+                else
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x1);
+            }
+            // Start VDEC0_MBUS_R2 
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from+byte) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from+byte) & 0x3fff0000) >> 16);
+            if(curlen>0x1FFF)
+            {
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, 0x1FFF);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, blockcount);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b10, 0x1FFF);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b14, 0);
+                if((len-curlen)==0)
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x7);
+                else
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x3);
+            }
+            else
+            {
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, len>0x1FFF ? 0x1FFF : len);
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+                if((len-curlen)==0)
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+                else
+                    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x1);
+            }
+            dma_to += curlen;
+            byte += curlen;
+            len-= curlen;
+        }
+        return byte;
+}
+
+extern void *memcpy2(void *__to, __const__ void *__from, size_t __n);
+void *memcpy(void *__to, __const__ void *__from, size_t __n)
+{
+    unsigned long virt_to = (unsigned long) __to;
+    unsigned long virt_from = (unsigned long) __from;
+    dma_addr_t dma_from;
+    dma_addr_t dma_to;
+    int len=__n;
+    int flag;
+    unsigned long t1,t2;
+
+
+    // JFT, We could probably handle more cases
+    if(__n<512 || !usedma || virt_from < 0x90000000 || virt_to < 0x90000000 ||
+        virt_from>=0xA0000000 || virt_to >=0xA0000000)
+    {
+        em86_stats[10]+=__n;
+        return memcpy2(__to, __from, __n);
+    }
+
+    t1=tangox_getxtal();
+
+
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // JFT, If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__n)&0xF) flush_dcache_line((virt_to+__n)&~0xF);
+
+    dma_from=virt_from;
+    dma_to=virt_to;
+
+    raw_local_irq_save(flag);
+    while(len>0)
+    {
+        int curlen= len>0x1FFF ? 0x1FFF : len;
+        blast_dcache_range(dma_from, dma_from+curlen);
+        blast_inv_dcache_range(dma_to, dma_to+curlen);
+        wait_mpegdma();
+
+//            printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, len>0x1FFF ? 0x1FFF : len);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+        if((len-curlen)==0)
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+        else
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x1);
+        // Start VDEC0_MBUS_R2 
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+        if((len-curlen)==0)
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+        else
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x1);
+        dma_to += curlen;
+        dma_from += curlen;
+        len-= curlen;
+    }
+    wait_mpegdma();
+    t2=tangox_getxtal();
+    em86_stats[12]+=__n;
+    em86_stats[13]+=(t2-t1);
+    raw_local_irq_restore(flag);
+    return __to;
+}
+
+size_t __invoke_copy_to_user_dma(void __user * __cu_to, const void * __cu_from, long __cu_len)
+{
+    unsigned long virt_to = (unsigned long) __cu_to;
+    unsigned long virt_from = (unsigned long) __cu_from;
+    dma_addr_t dma_from;
+    int byte;
+    unsigned long _n;
+    int flag;
+    unsigned long t1,t2;
+
+    // JFT, note: this is very common case so make it first
+    if(__cu_len<512)
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+
+    if(virt_to >= 0x80000000)
+    {
+        memcpy(__cu_to, __cu_from, __cu_len);
+        return 0;
+    }
+
+    em86_stats[3]+=__cu_len;
+
+    if(__cu_len<512 || !usedma || virt_from >= 0xC0000000 || virt_to >= 0x80000000)
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    if(!(virt_addr_valid(__cu_from)) ||
+        !(virt_addr_valid(__cu_from + __cu_len)))
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    t1=tangox_getxtal();
+
+    // Verify all pages exist
+    for(byte = 0; byte < __cu_len; byte+=PAGE_SIZE)
+    {
+        __put_user_check(0, (unsigned char *) (virt_to+byte), 1);
+    }
+    __put_user_check(0, (unsigned char *) (virt_to+__cu_len-1), 1);
+
+    // If the virt_to is not aligned we need to flush the data before it
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__cu_len)&0xF) flush_dcache_line((virt_to+__cu_len)&~0xF);
+
+    dma_from = virt_from;
+
+    // printk(KERN_ERR "dma transfer %X to %x len %X\n", __cu_from, __cu_to , __cu_len);
+
+    raw_local_irq_save(flag);
+
+    for (byte = 0, _n = __cu_len; byte < __cu_len;) 
+    {
+        int len = min(PAGE_SIZE - offset_into_page(virt_to + byte), _n);
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+        unsigned long pg_addr;
+        unsigned long dma_to;
+
+        pg_addr = (virt_to+byte) & PAGE_MASK; /* address of start page */
+
+        if (pg_addr > TASK_SIZE)
+            pgd = pgd_offset_k(pg_addr);
+        else
+            pgd = pgd_offset_gate(current->mm, pg_addr);
+        BUG_ON(pgd_none(*pgd));
+        pud = pud_offset(pgd, pg_addr);
+        BUG_ON(pud_none(*pud));
+        pmd = pmd_offset(pud, pg_addr);
+        if (pmd_none(*pmd)) 
+        {
+            printk(KERN_ERR "pmd_none\n");
+            wait_mpegdma();
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        pte = pte_offset_map(pmd, pg_addr);
+        if (pte_none(*pte)) {
+            pte_unmap(pte);
+            printk(KERN_ERR "pte_none\n");
+            wait_mpegdma();
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        dma_to= (pte_val(*pte) & PAGE_MASK) + offset_into_page(virt_to + byte);
+        pte_unmap(pte);
+
+
+        if(dma_to<0x10000000 || dma_to>=0x30000000)
+        {
+            wait_mpegdma();
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            printk(KERN_ERR "invalid copy to user %08X\n",dma_to);
+            goto unpin;
+        }
+        _n -= len;
+
+        byte+=mpeg_dma_transfer_to_user(dma_to, virt_to+byte, dma_from+byte, len);
+    }
+    wait_mpegdma();
+//	do_gettimeofday(&tv);
+//	t2=tv.tv_sec*1000000LL+tv.tv_usec;
+    raw_local_irq_restore(flag);
+//    em86dma_time+=(t2-t1);
+//    em86dma_csum_time+=(t2-t3);
+    em86_stats[0]+=__cu_len;
+    em86_stats[2]+=1;
+    t2=tangox_getxtal();
+    em86_stats[1]+=(t2-t1);
+unpin:
+    return _n;
+}
+
+size_t __invoke_copy_from_user_dma(void * __cu_to, const void __user * __cu_from, long __cu_len)
+{
+    unsigned long virt_to = (unsigned long) __cu_to;
+    unsigned long virt_from = (unsigned long) __cu_from;
+    dma_addr_t dma_to;
+    int byte;
+    unsigned long _n;
+    int flag;
+    unsigned long t1,t2;
+    unsigned char val;
+
+
+    // JFT, this is very common case so make it first
+    if(__cu_len<512) 
+        return __invoke_copy_from_user(__cu_to, __cu_from, __cu_len);
+
+    // printk(KERN_ERR "dma transfer %X to %x len %X\n", __cu_from, __cu_to , __cu_len);
+
+    if(virt_from >= 0x80000000)
+    {
+        memcpy(__cu_to, __cu_from, __cu_len);
+        return 0;
+    }
+
+    if(__cu_len<512 || !usedma || virt_to >= 0xC0000000)
+    {
+        em86_stats[16]+=__cu_len;
+        return __invoke_copy_from_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    if(!(virt_addr_valid(__cu_to)) ||
+        !(virt_addr_valid(__cu_to + __cu_len)))
+    {
+        em86_stats[16]+=__cu_len;
+        return __invoke_copy_from_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    // Verify all pages exist
+    for(byte = 0; byte < __cu_len; byte+=PAGE_SIZE)
+    {
+        __get_user_check(val, (unsigned char *) (virt_from+byte), 1);
+    }
+    __get_user_check(val, (unsigned char *) (virt_from+__cu_len-1), 1);
+
+    t1=tangox_getxtal();
+
+    // If the virt_to is not aligned we need to flush the data before it
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__cu_len)&0xF) flush_dcache_line((virt_to+__cu_len)&~0xF);
+
+    dma_to = virt_to;
+
+
+    raw_local_irq_save(flag);
+
+    for (byte = 0, _n = __cu_len; byte < __cu_len;) 
+    {
+        int len = min(PAGE_SIZE - offset_into_page(virt_from + byte), _n);
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+        unsigned long pg_addr;
+        unsigned long dma_from;
+
+        pg_addr = (virt_from+byte) & PAGE_MASK; /* address of start page */
+
+        if (pg_addr > TASK_SIZE)
+            pgd = pgd_offset_k(pg_addr);
+        else
+            pgd = pgd_offset_gate(current->mm, pg_addr);
+        BUG_ON(pgd_none(*pgd));
+        pud = pud_offset(pgd, pg_addr);
+        BUG_ON(pud_none(*pud));
+        pmd = pmd_offset(pud, pg_addr);
+        if (pmd_none(*pmd)) 
+        {
+            printk(KERN_ERR "pmd_none\n");
+            wait_mpegdma();
+            em86_stats[16]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        pte = pte_offset_map(pmd, pg_addr);
+        if (pte_none(*pte)) {
+            pte_unmap(pte);
+            printk(KERN_ERR "pte_none\n");
+            wait_mpegdma();
+            em86_stats[16]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        dma_from= (pte_val(*pte) & PAGE_MASK) + offset_into_page(virt_from + byte);
+        pte_unmap(pte);
+
+
+        if(dma_from<0x10000000 || dma_from>=0x30000000)
+        {
+            wait_mpegdma();
+            em86_stats[16]+=__cu_len;
+            raw_local_irq_restore(flag);
+            printk(KERN_ERR "invalid copy from user %08X\n",dma_from);
+            goto unpin;
+        }
+        _n -= len;
+
+        while(len>0)
+        {
+            int curlen=len>0x1FFF ? 0x1FFF : len;
+
+            // printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, curlen);
+            
+            blast_dcache_range(virt_from+byte, virt_from+byte+curlen);
+            blast_inv_dcache_range(dma_to+byte, dma_to+byte+curlen);
+
+            wait_mpegdma();
+    
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to+byte) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to+byte) & 0x3fff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+            if((curlen-len)==0)
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+            else
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x1);
+            // Start VDEC0_MBUS_R2 
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from) & 0x3fff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+            if((curlen-len)==0)
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+            else
+                gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x1);
+            dma_from += curlen;
+            byte += curlen;
+            len-= curlen;
+        }
+    }
+    wait_mpegdma();
+//	do_gettimeofday(&tv);
+//	t2=tv.tv_sec*1000000LL+tv.tv_usec;
+    raw_local_irq_restore(flag);
+//    em86dma_time+=(t2-t1);
+//    em86dma_csum_time+=(t2-t3);
+    em86_stats[18]+=__cu_len;
+//    em86_stats[2]+=1;
+    t2=tangox_getxtal();
+    em86_stats[19]+=(t2-t1);
+unpin:
+    return _n;
+}
+
+EXPORT_SYMBOL(em86xx_mbus_alloc_dma);
+EXPORT_SYMBOL(em86xx_mbus_free_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma_void);
+EXPORT_SYMBOL(em86xx_mbus_wait);
+EXPORT_SYMBOL(em86xx_mbus_init);
+EXPORT_SYMBOL(mbus_setup_dma_linear);
+EXPORT_SYMBOL(mbus_setup_dma_double);
+EXPORT_SYMBOL(mbus_setup_dma_rectangle);
+EXPORT_SYMBOL(mbus_memcpy);
+
+EXPORT_SYMBOL(em86_stats);
+EXPORT_SYMBOL(memcpy);
+EXPORT_SYMBOL(__invoke_copy_to_user_dma);
+EXPORT_SYMBOL(__invoke_copy_from_user_dma);
diff -Naur linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma1 linux-2.6.30-test/arch/mips/tangox/mbus.c.dma1
--- linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma1	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/mbus.c.dma1	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1058 @@
+/*********************************************************************
+ Copyright (C) 2001-2008
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <asm/uaccess.h>
+#include <asm/r4kcache.h>
+#include <linux/pagemap.h>
+#include <linux/dma-mapping.h>
+
+#include "setup.h"
+
+#if !defined(CONFIG_TANGO2) && !defined(CONFIG_TANGO3)
+#error Undefined Sigma's chip!!!
+#endif
+
+#ifdef CONFIG_TANGO3
+#warning TANGO3 TODO IRQ assignment for W2/R2!!
+/* Temporary as no W2/R2 IRQ assigned yet. */
+#define LOG2_CPU_HOST_MBUS_W2_INT	62
+#define LOG2_CPU_HOST_MBUS_R2_INT	63
+
+/* Uncomment this only if W1/R1 can be used (typically not) */
+// #define WITH_MBUS_W1R1
+
+#endif /* CONFIG_TANGO3 */
+
+/*
+ * computed in prom.c
+ */
+extern unsigned long em8xxx_kmem_start;
+extern unsigned long em8xxx_kmem_size;
+
+long long em86dma_notdma_bytes=0;
+long long em86dma_bytes=0;
+long long em86dma_time=0;
+long long em86dma_csum_bytes=0;
+long long em86dma_csum_time=0;
+
+static int usedma=0;
+
+/*
+ * switchbox stuffs
+ *
+ * We keep  track of  current mapping using  this globals  rather than
+ * reading hardware registers each time.
+ */
+static unsigned int g_sbox_map[SBOX_MAX];
+
+static inline void sbox_update_route(void)
+{
+	int i;
+#ifdef CONFIG_TANGO3
+	u64 data = 0; /* to cover two 32 bits registers */
+#else
+	unsigned int data = 0;
+#endif
+
+	for (i = SBOX_MAX - 1; i >= 0; --i)
+		data = (data << 4) | g_sbox_map[i];
+
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data & 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, (data >> 32) & 0xffffffff);
+#else
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data);
+#endif
+}
+
+static void sbox_reset(void)
+{
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xff00ff00);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfdfdfdfd);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfd00fd00);
+#endif
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01010101);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01000100);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d7d7d7d);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d007d00);
+#endif
+}
+
+static void sbox_setup(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* W0 initially disconnected */
+	g_sbox_map[SBOX_MBUS_W0] = 0xf;
+
+#if defined(CONFIG_TANGO3) && defined(WITH_MBUS_W1R1)
+	g_sbox_map[SBOX_MBUS_W1] = 0xf;
+#else
+	/* Leave W1 alone */
+	g_sbox_map[SBOX_MBUS_W1] = 0;
+#endif
+
+	g_sbox_map[SBOX_PCIMASTER] = 0xf;
+	g_sbox_map[SBOX_PCISLAVE] = SBOX_PCISLAVE + 1; /* Loopback */
+	g_sbox_map[SBOX_SATA1] = 0xf;
+	g_sbox_map[SBOX_IDEDVD] = 0xf;
+	g_sbox_map[SBOX_IDEFLASH] = 0xf;
+#ifdef CONFIG_TANGO3
+	g_sbox_map[SBOX_SATA2] = 0xf;
+	g_sbox_map[SBOX_MBUS_W2] = 0xf;
+#else
+	g_sbox_map[SBOX_UNUSED1] = 0xf;
+#endif
+
+	sbox_update_route();
+	wmb();
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Connect given interface to R?/W? channel
+ */
+#ifdef CONFIG_TANGO3
+static int sbox_connect(int iface, int *channel, int any)
+#else
+static int sbox_connect(int iface)
+#endif
+{
+	unsigned long flags;
+	int res = 0;
+#ifdef CONFIG_TANGO3
+	int chan = 0;
+#endif
+
+	local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) {
+		*channel = 0; /* connected to W0/R0 */
+		goto done;
+#ifdef WITH_MBUS_W1R1
+	} else if (g_sbox_map[SBOX_MBUS_W1] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W1 + 1)) {
+		*channel = 1; /* connected to W1/R1 */
+		goto done;
+#endif
+	} else if (g_sbox_map[SBOX_MBUS_W2] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W2 + 1)) {
+		*channel = 2; /* connected to W2/R2 */
+		goto done;
+	}
+
+	if (g_sbox_map[iface] != 0xf) { /* connect to something else already */
+		res = 1;
+		goto done;
+	}
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf) {
+		chan++; /* try next */
+#ifdef WITH_MBUS_W1R1
+		if (g_sbox_map[SBOX_MBUS_W1] != 0xf) {
+#endif
+			if (any == 0) {
+#warning TO BE FIX in TANGO3 H/W!! (W2/R2 allocation)
+				res = 1; /* TANGO3 TODO: allocate W2/R2 once IRQ is available */
+				goto done;
+			}
+			chan++; /* try next */
+			if (g_sbox_map[SBOX_MBUS_W2] != 0xf)  {
+				res = 1; /* Both W0/W2 not available, and optional (W1 as well) */
+				goto done;
+			}
+#ifdef WITH_MBUS_W1R1
+		}
+#endif
+	}
+#else
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) 
+		goto done;
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf || g_sbox_map[iface] != 0xf) {
+		res = 1;
+		goto done;
+	}
+#endif /* CONFIG_TANGO3 */
+
+#ifdef CONFIG_TANGO3
+	switch(chan) {
+		case 0: g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W0 + 1; /* W0/R0 */
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: g_sbox_map[SBOX_MBUS_W1] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W1 + 1; /* W1/R1 */
+			break;
+#endif
+		case 2: g_sbox_map[SBOX_MBUS_W2] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W2 + 1; /* W2/R2 */
+			break;
+
+		default: BUG();
+			break;
+	}
+	*channel = chan;
+#else
+	g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+	g_sbox_map[iface] = SBOX_MBUS_W0 + 1;
+#endif
+	sbox_update_route();
+	wmb();
+
+done:
+	local_irq_restore(flags);
+
+	return res;
+}
+
+#ifdef CONFIG_TANGO3
+static void sbox_disconnect(int iface, int channel)
+#else
+static void sbox_disconnect(int iface)
+#endif
+{
+	unsigned long flags;
+
+	if (iface >= 0) {
+		local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+		switch(channel) {
+			case 0: g_sbox_map[SBOX_MBUS_W0] = 0xf;
+				break;
+#ifdef WITH_MBUS_W1R1
+			case 1: g_sbox_map[SBOX_MBUS_W1] = 0xf;
+				break;
+#endif
+			case 2: g_sbox_map[SBOX_MBUS_W2] = 0xf;
+				break;
+
+			default: BUG();
+				break;
+		}
+#else
+		g_sbox_map[SBOX_MBUS_W0] = 0xf;
+#endif
+		g_sbox_map[iface] = 0xf;
+		sbox_update_route();
+		wmb();
+
+		local_irq_restore(flags);
+	}
+}
+
+static void sbox_init(void)
+{
+	sbox_setup();
+	sbox_reset();
+	// Is this early enough?
+    gbus_writel(REG_BASE_system_block + 0x240, 0x11f1f); // write
+    gbus_writel(REG_BASE_system_block + 0x244, 0x11f1f); // read
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fe4, 0x0700); // Unreset dbk channels
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3dcc, 0x8000); // dbk loopback
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fdc, 0x0003); // switchbox->WMV9
+    usedma=1;
+}
+
+
+/*
+ * mbus stuffs
+ *
+ * to  avoid   requesting/freeing  irq   each  time,  we   keep  given
+ * handler/args  for each  dma  request and  call  it in  our own  irq
+ * handler.
+ */
+#define MBUS_LINEAR_MAX		(0x2000 - 1)
+
+#ifdef CONFIG_TANGO3
+static mbus_irq_handler_t g_mbus_intr_handler[6];
+static void *g_mbus_intr_handler_arg[6];
+#else
+static mbus_irq_handler_t g_mbus_intr_handler[4];
+static void *g_mbus_intr_handler_arg[4];
+#endif
+
+/*
+ * alloc_dma, need to be called before setup, will try to connect
+ * needed sbox.
+ */
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any)
+{
+	int x;
+
+#ifdef CONFIG_TANGO3
+	int channel = 0;
+
+	if (sbox_connect(sbox, &channel, any) != 0)
+		return -1;
+
+	switch(channel) {
+		case 0: { 	/* Using W0/R0 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W0_ADD + (x * 0x40);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: { 	/* Using W1/R1 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W1_ADD + (x * 0x40);
+			}
+			break;
+#endif
+		case 2: { 	/* Using W2/R2 pair */
+				x = (fromdev ? 0 : 1);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W2_ADD + (x * 0x40);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	if (sbox_connect(sbox) != 0)
+		return -1;
+
+	x = (fromdev ? 0 : 2);
+	if (pirq)
+		*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+	if (pregbase)
+		*pregbase = REG_BASE_host_interface + MIF_W0_ADD + x * 0x40;
+#endif
+
+	return 0;
+}
+
+#ifdef CONFIG_TANGO3
+/* Convert MBUS register address to channel index */
+static inline int mbus_idx2channel(unsigned int regbase)
+{
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	static const int channel[6] = { 0, 1, 0, 1, 2, 2 };
+	return(channel[idx]);
+}
+#endif
+
+/*
+ * free_dma,  need to  be called  after  transfer is  done to  release
+ * switchbox.
+ */
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox)
+{
+	unsigned long flags;
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	local_irq_save(flags);
+	g_mbus_intr_handler[idx] = NULL;
+	wmb();
+	local_irq_restore(flags);
+
+#ifdef CONFIG_TANGO3
+	sbox_disconnect(sbox, mbus_idx2channel(regbase)); 
+#else
+	sbox_disconnect(sbox);
+#endif
+}
+
+/*
+ * irq handler for mbus interrupt
+ */
+static irqreturn_t mbus_intr(int irq, void *devinfo)
+{
+	int idx = irq - (LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE);
+
+#ifdef CONFIG_TANGO3
+	if (idx >= 4)
+		idx = irq - (LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE) + 4;
+#endif
+	if (g_mbus_intr_handler[idx]) {
+		mbus_irq_handler_t f;
+
+		f = g_mbus_intr_handler[idx];
+		g_mbus_intr_handler[idx] = NULL;
+		wmb();
+		f(irq, g_mbus_intr_handler_arg[idx]);
+	}
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * check if mbus is in use for given regbase
+ */
+static inline int mbus_inuse(unsigned int regbase)
+{
+	return (gbus_readl(regbase + MIF_cmd_offset) & 0x7) != 0;
+}
+
+/*
+ * setup mbus  register to start  a linear transfer (count  bytes from
+ * addr, where count < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_linear(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (linear): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, count);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x1);
+}
+
+/*
+ * setup mbus  register to start  a double transfer (count  bytes from
+ * addr and count2 bytes from addr2, where count < MBUS_LINEAR_MAX and
+ * count2 < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_double(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int addr2,
+					 unsigned int count2,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address 0x%08x\n", addr);
+	if ((addr2 < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr2 >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address2 0x%08x\n", addr2);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (count2 << 16) | count);
+	gbus_writel(regbase + MIF_add2_skip_offset, addr2);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x2);
+}
+
+/*
+ * setup mbus  register to start  a rectangle transfer (horiz  * lines
+ * bytes  from  addr,  where  horiz  <  MBUS_LINEAR_MAX  and  lines  <
+ * MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_rectangle(unsigned int regbase,
+					    unsigned int addr,
+					    unsigned int horiz,
+					    unsigned int lines,
+					    unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (rectangle): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (lines << 16) | horiz);
+	gbus_writel(regbase + MIF_add2_skip_offset, horiz);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x3);
+}
+
+/*
+ * register mbus interrupt if not done
+ */
+#ifdef CONFIG_TANGO3
+static inline void mbus_register_intr(int channel)
+#else
+static inline void mbus_register_intr(void)
+#endif
+{
+#ifdef CONFIG_TANGO3
+	static int done[3] = { 0, 0, 0 };
+
+	switch(channel) {
+		case 0: {	/* Use W0/R0 then */
+				if (done[0])
+					return;
+				done[0] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: {	/* Use W1/R1 instead */
+				if (done[1])
+					return;
+				done[1] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r1", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w1", NULL);
+			}
+			break;
+#endif
+		case 2: {	/* Use W2/R2 instead */
+				if (done[2])
+					return;
+				done[2] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r2", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w2", NULL);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	static int done = 0;
+
+	if (done)
+		return;
+	done = 1;
+	/*
+	 * register irq handler for R0/W0 only (R1/W1 are not used for
+	 * the moment)
+	 */
+	request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+
+	request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+
+#endif
+}
+
+/*
+ * setup void transaction 
+ */
+void em86xx_mbus_setup_dma_void(unsigned int regbase)
+{
+	while (mbus_inuse(regbase) != 0)
+		;
+	gbus_writel(regbase + MIF_cmd_offset, 4);
+}
+
+/*
+ * start  a   mbus  dma,   use  this  after   a  sucessfull   call  to
+ * em86xx_mbus_alloc_dma
+ */
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr,
+			  unsigned int count, mbus_irq_handler_t handler,
+			  void *arg, unsigned int tflags)
+{
+	unsigned long flags;
+	unsigned int horiz, lines, sz;
+	unsigned int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	/*
+	 * make sure no one uses the mbus before
+	 */
+	if (unlikely(mbus_inuse(regbase))) {
+		printk(KERN_ERR "MBUS: error previous command is pending\n");
+		return 1;
+	}
+
+	/*
+	 * "register" given handler if any
+	 */
+	if (handler) {
+#ifdef CONFIG_TANGO3
+		mbus_register_intr(mbus_idx2channel(regbase));
+#else
+		mbus_register_intr();
+#endif
+		local_irq_save(flags);
+		g_mbus_intr_handler[idx] = handler;
+		g_mbus_intr_handler_arg[idx] = arg;
+		wmb();
+		local_irq_restore(flags);
+	}
+
+	/*
+	 * decide which dma function to use depending on count
+	 */
+	if (count <= MBUS_LINEAR_MAX) {
+		mbus_setup_dma_linear(regbase, addr, count, tflags);
+		return 0;
+	}
+
+	if (count <= (MBUS_LINEAR_MAX * 2)) {
+		mbus_setup_dma_double(regbase, addr, MBUS_LINEAR_MAX,
+				      addr + MBUS_LINEAR_MAX,
+				      count - MBUS_LINEAR_MAX, tflags);
+		return 0;
+	}
+
+	/*
+	 * we need to use rectangle, compute  horiz & lines
+	 * values to use
+	 */
+	for (idx = 0, horiz = 1, sz = count; (idx < 10) && ((sz & 0x01) == 0); ++idx, horiz <<= 1, sz >>= 1)
+		;
+	lines = count >> idx;
+	if ((horiz > MBUS_LINEAR_MAX) || (lines > MBUS_LINEAR_MAX)) {
+		printk(KERN_ERR "MBUS: can't handle rectangle transfer "
+		       "of %d bytes (h: %d, v: %d)\n", count, horiz, lines);
+		BUG();
+	}
+	mbus_setup_dma_rectangle(regbase, addr, horiz, lines, tflags);
+
+	return 0;
+}
+
+/*
+ * Bit 0/8: MBUS_R0_SBOX
+ * Bit 1/9: MBUS_R1_SBOX
+ * Bit 2/10: PCI_MASTER_SBOX
+ * Bit 3/11: PCI_SLAVE_SBOX
+ * Bit 4/12: SATA1_SBOX
+ * Bit 5/13: IDE_ISA_SBOX
+ * Bit 6/14: IDE_DVD_SBOX
+ * Bit 7/15: SATA2_SBOX (Tango3)
+ * Bit 16/24: SBOX_MBUS_W0
+ * Bit 17/25: SBOX_MBUS_W1
+ * Bit 18/26: SBOX_PCI_MASTER
+ * Bit 19/27: SBOX_PCI_SLAVE
+ * Bit 20/28: SBOX_SATA1
+ * Bit 21/29: SBOX_ISA
+ * Bit 22/30: SBOX_DVD
+ * Bit 23/31: SBOX_SATA2 (Tango3)
+ *
+ * Bit 32/40: MBUS_R2_SBOX (Tango3)
+ * Bit 48/50: SBOX_MBUS_W2 (Tango3)
+ */
+#ifdef CONFIG_TANGO3
+static const u64 sbox_reset_vals[4][6] = {
+	{ 0x0000000001011010ULL, 0x0000000002021010ULL, 0x0000000010100101ULL, 0x0000000010100202ULL, 0x0101000000001010ULL, 0x0000010110100000ULL },
+	{ 0x0000000001012020ULL, 0x0000000002022020ULL, 0x0000000020200101ULL, 0x0000000020200202ULL, 0x0101000000002020ULL, 0x0000010120200000ULL },
+	{ 0x0000000001014040ULL, 0x0000000002024040ULL, 0x0000000040400101ULL, 0x0000000040400202ULL, 0x0101000000004040ULL, 0x0000010140400000ULL },
+	{ 0x0000000001018080ULL, 0x0000000002028080ULL, 0x0000000080800101ULL, 0x0000000080800202ULL, 0x0101000000008080ULL, 0x0000010180800000ULL },
+};
+#else
+static const unsigned int sbox_reset_vals[2][4] = {
+	{ 0x01012020, 0x02022020, 0x20200101, 0x20200202 },
+	{ 0x01014040, 0x02024040, 0x40400101, 0x40400202 }
+};
+#endif
+
+/*
+ * clear MBUS transaction for given regbase/sbox
+ */
+static void mbus_reset(unsigned int regbase, int sbox)
+{
+	int midx;
+	int sidx;
+
+#ifdef CONFIG_TANGO3
+	unsigned int rl, rh;
+
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_SATA1;
+
+	if (((midx < 0) || (midx > 5)) || ((sidx < 0) || (sidx > 3))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+	rl = sbox_reset_vals[sidx][midx] & 0xffffffff;
+	rh = (sbox_reset_vals[sidx][midx] >> 32) & 0xffffffff;
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh);
+	iob();
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl & 0xff00ff00);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh & 0xff00ff00);
+	iob();
+#else
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_IDEFLASH;
+
+	if (((midx < 0) || (midx > 3)) || ((sidx < 0) || (sidx > 2))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx]);
+	iob();
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx] & 0xff00ff00);
+	iob();
+#endif
+}
+
+/* Fancy version of memcpy, both dst and src need to be physical address */
+/* The channels have to be allocated already */
+int mbus_memcpy(unsigned int regbase, unsigned int dst, unsigned int src, unsigned int size)
+{
+	/* Save the old SBOX route */
+	unsigned int sbox_route;
+	unsigned int w_base;
+	unsigned int r_base;
+	int channel = 0;
+/* 
+ * TRANSFER defines 4 bits, bit 0: followed by void (1) or not (0),
+ * bit 1: tiled buffer or not (tango3 only).
+ * bit 3-2: 0 = 8 bit, 1 = 16 bit, 2 = 32 bit (tango3 only).
+ */
+#ifdef CONFIG_TANGO3
+#define TRANSFER    0x1 /* or 0x9 for 32 bit transfer */
+#else
+#define TRANSFER    0x1
+#endif
+
+#ifdef CONFIG_TANGO3
+	channel = mbus_idx2channel(regbase);
+
+	if (channel == 0) /* W0/R0 channels are used */
+#endif
+	{
+		w_base = REG_BASE_host_interface + MIF_W0_ADD;
+		r_base = REG_BASE_host_interface + MIF_R0_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xffffff0f;
+
+		/* Hook up W0/R0 and left W1/R1 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff01);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W0 */
+			printk("MBUS: need to reset W0 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	else if (channel == 1) { /* W1/R1 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W1_ADD;
+		r_base = REG_BASE_host_interface + MIF_R1_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xfffffff0;
+
+		/* Hook up W1/R1 and left W0/R0 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff20);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W1 */
+			printk("MBUS: need to reset W1 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#endif
+	else { /* channel == 2: W2/R2 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W2_ADD;
+		r_base = REG_BASE_host_interface + MIF_R2_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE2);
+
+		/* Hook up W2/R2 */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, 0xfffffff9);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W2 */
+			printk("MBUS: need to reset W2 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+	}
+#endif
+
+	return(size);
+}
+
+/*
+ * busy wait  for current mbus transfer  to finish, will  not wait for
+ * more than 20 ms. 0 is ok, 1 timeout, 2 for timeout + reset error.
+ */
+#define MBUS_TIMEOUT	20000
+
+int em86xx_mbus_wait(unsigned int regbase, int sbox)
+{
+	int timeout;
+
+	/* wait for mbus to be released */
+	timeout = 0;
+	do {
+		if (!mbus_inuse(regbase))
+			break;
+		udelay(1);
+		timeout++;
+	} while (timeout < MBUS_TIMEOUT);
+
+	if (timeout < MBUS_TIMEOUT ) {
+		/* ok */
+		if (sbox == SBOX_IDEFLASH){
+                        int i;
+			unsigned int pb_count = 0;
+
+			pb_count = gbus_readl(REG_BASE_host_interface + 
+					       PB_automode_control) & 0xffff;
+
+                        for (i = 0; pb_count && (i < MBUS_TIMEOUT); i++){
+                                udelay(1);
+				pb_count = gbus_readl(REG_BASE_host_interface +
+					       PB_automode_control) & 0xffff;
+			}
+
+                        if (i < MBUS_TIMEOUT) 
+				return 0;
+
+		} else
+			return 0;
+	}
+
+	/* timeout, let's dump some registers ! */
+        if (sbox == SBOX_IDEFLASH) {
+  		printk("MBUS timeout : MBUS CMD = %ld, PB Automode = %08x\n",
+                	(unsigned long)gbus_readl(regbase + MIF_cmd_offset) & 0x7,
+                	(unsigned int)gbus_readl(REG_BASE_host_interface + PB_automode_control));
+        } else {
+		printk("MBUS timeout : MBUS CMD = %08lx\n",
+			gbus_readl(regbase + MIF_cmd_offset) & 0x7);
+	}
+
+	printk("MBUS registers : %08lx %08lx %08lx %08lx\n",
+	       gbus_readl(regbase + MIF_add_offset),
+	       gbus_readl(regbase + MIF_cnt_offset),
+	       gbus_readl(regbase + MIF_add2_skip_offset),
+	       gbus_readl(regbase + MIF_cmd_offset));
+
+	printk(KERN_ERR "MBUS fails, resetting %d ..\n", sbox);
+	mbus_reset(regbase, sbox);
+
+	/* If not able to reset, return  1, so the DMA can be disabled
+	   accordingly  */
+	return mbus_inuse(regbase) ? 0 : 1;
+}
+
+int em86xx_mbus_init(void)
+{
+	static int done = 0;
+
+	if (done)
+		return 0;
+	done = 1;
+
+	/* reset sbox to default values */
+	sbox_init();
+
+	/* Give better MBUS bandwidth for Wx/Rx channel */
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_system_block + MARB_mid01_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid21_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid03_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid23_cfg, 0x12005);
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x12005);
+#endif
+#else
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x11f1f);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x11f1f);
+#endif
+
+	return 0;
+}
+
+#define offset_into_page(x) ((x) & (PAGE_SIZE - 1))
+
+size_t __invoke_copy_to_user_dma(void __user * __cu_to, const void * __cu_from, long __cu_len)
+{
+    unsigned long virt_to = (unsigned long) __cu_to;
+    unsigned long virt_from = (unsigned long) __cu_from;
+    int nr_pages = 1 + ((__cu_len - 1 + offset_into_page(virt_to)) / PAGE_SIZE);
+    struct page *pages[nr_pages];
+    dma_addr_t dma_from;
+    int nr_unmap;
+    size_t ret = 0;
+    int byte;
+    unsigned long _n;
+    int flag;
+    long long t1,t2,t3;
+	struct timeval tv;
+
+    if(__cu_len<1024 || !usedma || virt_from >= 0xC0000000)
+    {
+        em86dma_notdma_bytes+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    if(!(virt_addr_valid(__cu_from)) ||
+        !(virt_addr_valid(__cu_from + __cu_len)))
+    {
+        em86dma_notdma_bytes+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+
+	do_gettimeofday(&tv);
+	t1=tv.tv_sec*1000000LL+tv.tv_usec;
+
+    set_thread_flag(TIF_DMA);
+    down_read(&current->mm->mmap_sem);
+    nr_unmap = get_user_pages(
+        current,
+        current->mm,
+        virt_to,
+        nr_pages,
+        1,	/* write */
+        0,	/* force */
+        pages,
+        NULL);
+    up_read(&current->mm->mmap_sem);
+    if (nr_unmap != nr_pages) {
+        em86dma_notdma_bytes+=__cu_len;
+        _n = __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+        goto unpin;
+    }
+    // If the virt_to is not aligned we need to flush the data before it
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__cu_len)&0xF) flush_dcache_line((virt_to+__cu_len)&~0xF);
+    blast_inv_dcache_range(virt_to, virt_to+__cu_len);
+    dma_from = dma_map_single(NULL, (void *) virt_from, __cu_len, DMA_TO_DEVICE);
+
+    raw_local_irq_save(flag);
+	do_gettimeofday(&tv);
+	t3=tv.tv_sec*1000000LL+tv.tv_usec;
+
+    for (byte = 0, _n = __cu_len; byte < __cu_len;) {
+        int len = min(PAGE_SIZE - offset_into_page(virt_to + byte), _n);
+        int idx = (byte + offset_into_page(virt_to)) >> PAGE_SHIFT;
+        dma_addr_t dma_to = dma_map_page(NULL, pages[idx],
+                        offset_into_page(virt_to + byte),
+                        len, DMA_FROM_DEVICE);
+
+        if(dma_to<0x10000000 || dma_to>=0x30000000 ||
+            dma_from<0x10000000 || dma_from>=0x30000000)
+        {
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            //em86dma_csum_bytes+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        _n -= len;
+        
+        while(len>0)
+        {
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+    
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0xffff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+            // Start VDEC0_MBUS_R2 
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from+byte) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from+byte) & 0xffff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+            byte += len>0x1FFF ? 0x1FFF : len;;
+            len-= len>0x1FFF ? 0x1FFF : len;
+        }
+    }
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+	do_gettimeofday(&tv);
+	t2=tv.tv_sec*1000000LL+tv.tv_usec;
+    raw_local_irq_restore(flag);
+    em86dma_time+=(t2-t1);
+    em86dma_csum_time+=(t2-t3);
+    em86dma_bytes+=__cu_len;
+    em86dma_csum_bytes+=1;
+unpin:
+    while (nr_unmap--) {
+        set_page_dirty_lock(pages[nr_unmap]);
+        page_cache_release(pages[nr_unmap]);
+    }
+    clear_thread_flag(TIF_DMA);
+    return _n;
+}
+
+EXPORT_SYMBOL(em86xx_mbus_alloc_dma);
+EXPORT_SYMBOL(em86xx_mbus_free_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma_void);
+EXPORT_SYMBOL(em86xx_mbus_wait);
+EXPORT_SYMBOL(em86xx_mbus_init);
+EXPORT_SYMBOL(mbus_setup_dma_linear);
+EXPORT_SYMBOL(mbus_setup_dma_double);
+EXPORT_SYMBOL(mbus_setup_dma_rectangle);
+EXPORT_SYMBOL(mbus_memcpy);
+
+EXPORT_SYMBOL(em86dma_bytes);
+EXPORT_SYMBOL(em86dma_notdma_bytes);
+EXPORT_SYMBOL(em86dma_csum_bytes);
+EXPORT_SYMBOL(em86dma_csum_time);
+EXPORT_SYMBOL(em86dma_time);
diff -Naur linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma2 linux-2.6.30-test/arch/mips/tangox/mbus.c.dma2
--- linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma2	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/mbus.c.dma2	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1136 @@
+/*********************************************************************
+ Copyright (C) 2001-2008
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <asm/uaccess.h>
+#include <asm/r4kcache.h>
+#include <linux/pagemap.h>
+#include <linux/dma-mapping.h>
+
+#include "setup.h"
+
+#if !defined(CONFIG_TANGO2) && !defined(CONFIG_TANGO3)
+#error Undefined Sigma's chip!!!
+#endif
+
+#ifdef CONFIG_TANGO3
+#warning TANGO3 TODO IRQ assignment for W2/R2!!
+/* Temporary as no W2/R2 IRQ assigned yet. */
+#define LOG2_CPU_HOST_MBUS_W2_INT	62
+#define LOG2_CPU_HOST_MBUS_R2_INT	63
+
+/* Uncomment this only if W1/R1 can be used (typically not) */
+// #define WITH_MBUS_W1R1
+
+#endif /* CONFIG_TANGO3 */
+
+/*
+ * computed in prom.c
+ */
+extern unsigned long em8xxx_kmem_start;
+extern unsigned long em8xxx_kmem_size;
+
+long long em86_stats[16] = {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0};
+
+static int usedma=0;
+
+/*
+ * switchbox stuffs
+ *
+ * We keep  track of  current mapping using  this globals  rather than
+ * reading hardware registers each time.
+ */
+static unsigned int g_sbox_map[SBOX_MAX];
+
+static inline void sbox_update_route(void)
+{
+	int i;
+#ifdef CONFIG_TANGO3
+	u64 data = 0; /* to cover two 32 bits registers */
+#else
+	unsigned int data = 0;
+#endif
+
+	for (i = SBOX_MAX - 1; i >= 0; --i)
+		data = (data << 4) | g_sbox_map[i];
+
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data & 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, (data >> 32) & 0xffffffff);
+#else
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data);
+#endif
+}
+
+static void sbox_reset(void)
+{
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xff00ff00);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfdfdfdfd);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfd00fd00);
+#endif
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01010101);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01000100);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d7d7d7d);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d007d00);
+#endif
+}
+
+static void sbox_setup(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* W0 initially disconnected */
+	g_sbox_map[SBOX_MBUS_W0] = 0xf;
+
+#if defined(CONFIG_TANGO3) && defined(WITH_MBUS_W1R1)
+	g_sbox_map[SBOX_MBUS_W1] = 0xf;
+#else
+	/* Leave W1 alone */
+	g_sbox_map[SBOX_MBUS_W1] = 0;
+#endif
+
+	g_sbox_map[SBOX_PCIMASTER] = 0xf;
+	g_sbox_map[SBOX_PCISLAVE] = SBOX_PCISLAVE + 1; /* Loopback */
+	g_sbox_map[SBOX_SATA1] = 0xf;
+	g_sbox_map[SBOX_IDEDVD] = 0xf;
+	g_sbox_map[SBOX_IDEFLASH] = 0xf;
+#ifdef CONFIG_TANGO3
+	g_sbox_map[SBOX_SATA2] = 0xf;
+	g_sbox_map[SBOX_MBUS_W2] = 0xf;
+#else
+	g_sbox_map[SBOX_UNUSED1] = 0xf;
+#endif
+
+	sbox_update_route();
+	wmb();
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Connect given interface to R?/W? channel
+ */
+#ifdef CONFIG_TANGO3
+static int sbox_connect(int iface, int *channel, int any)
+#else
+static int sbox_connect(int iface)
+#endif
+{
+	unsigned long flags;
+	int res = 0;
+#ifdef CONFIG_TANGO3
+	int chan = 0;
+#endif
+
+	local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) {
+		*channel = 0; /* connected to W0/R0 */
+		goto done;
+#ifdef WITH_MBUS_W1R1
+	} else if (g_sbox_map[SBOX_MBUS_W1] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W1 + 1)) {
+		*channel = 1; /* connected to W1/R1 */
+		goto done;
+#endif
+	} else if (g_sbox_map[SBOX_MBUS_W2] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W2 + 1)) {
+		*channel = 2; /* connected to W2/R2 */
+		goto done;
+	}
+
+	if (g_sbox_map[iface] != 0xf) { /* connect to something else already */
+		res = 1;
+		goto done;
+	}
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf) {
+		chan++; /* try next */
+#ifdef WITH_MBUS_W1R1
+		if (g_sbox_map[SBOX_MBUS_W1] != 0xf) {
+#endif
+			if (any == 0) {
+#warning TO BE FIX in TANGO3 H/W!! (W2/R2 allocation)
+				res = 1; /* TANGO3 TODO: allocate W2/R2 once IRQ is available */
+				goto done;
+			}
+			chan++; /* try next */
+			if (g_sbox_map[SBOX_MBUS_W2] != 0xf)  {
+				res = 1; /* Both W0/W2 not available, and optional (W1 as well) */
+				goto done;
+			}
+#ifdef WITH_MBUS_W1R1
+		}
+#endif
+	}
+#else
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) 
+		goto done;
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf || g_sbox_map[iface] != 0xf) {
+		res = 1;
+		goto done;
+	}
+#endif /* CONFIG_TANGO3 */
+
+#ifdef CONFIG_TANGO3
+	switch(chan) {
+		case 0: g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W0 + 1; /* W0/R0 */
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: g_sbox_map[SBOX_MBUS_W1] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W1 + 1; /* W1/R1 */
+			break;
+#endif
+		case 2: g_sbox_map[SBOX_MBUS_W2] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W2 + 1; /* W2/R2 */
+			break;
+
+		default: BUG();
+			break;
+	}
+	*channel = chan;
+#else
+	g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+	g_sbox_map[iface] = SBOX_MBUS_W0 + 1;
+#endif
+	sbox_update_route();
+	wmb();
+
+done:
+	local_irq_restore(flags);
+
+	return res;
+}
+
+#ifdef CONFIG_TANGO3
+static void sbox_disconnect(int iface, int channel)
+#else
+static void sbox_disconnect(int iface)
+#endif
+{
+	unsigned long flags;
+
+	if (iface >= 0) {
+		local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+		switch(channel) {
+			case 0: g_sbox_map[SBOX_MBUS_W0] = 0xf;
+				break;
+#ifdef WITH_MBUS_W1R1
+			case 1: g_sbox_map[SBOX_MBUS_W1] = 0xf;
+				break;
+#endif
+			case 2: g_sbox_map[SBOX_MBUS_W2] = 0xf;
+				break;
+
+			default: BUG();
+				break;
+		}
+#else
+		g_sbox_map[SBOX_MBUS_W0] = 0xf;
+#endif
+		g_sbox_map[iface] = 0xf;
+		sbox_update_route();
+		wmb();
+
+		local_irq_restore(flags);
+	}
+}
+
+static void sbox_init(void)
+{
+	sbox_setup();
+	sbox_reset();
+	// Is this early enough?
+    gbus_writel(REG_BASE_system_block + 0x240, 0x11f1f); // write
+    gbus_writel(REG_BASE_system_block + 0x244, 0x11f1f); // read
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fe4, 0x0700); // Unreset dbk channels
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3dcc, 0x8000); // dbk loopback
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fdc, 0x0003); // switchbox->WMV9
+    usedma=1;
+}
+
+
+/*
+ * mbus stuffs
+ *
+ * to  avoid   requesting/freeing  irq   each  time,  we   keep  given
+ * handler/args  for each  dma  request and  call  it in  our own  irq
+ * handler.
+ */
+#define MBUS_LINEAR_MAX		(0x2000 - 1)
+
+#ifdef CONFIG_TANGO3
+static mbus_irq_handler_t g_mbus_intr_handler[6];
+static void *g_mbus_intr_handler_arg[6];
+#else
+static mbus_irq_handler_t g_mbus_intr_handler[4];
+static void *g_mbus_intr_handler_arg[4];
+#endif
+
+/*
+ * alloc_dma, need to be called before setup, will try to connect
+ * needed sbox.
+ */
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any)
+{
+	int x;
+
+#ifdef CONFIG_TANGO3
+	int channel = 0;
+
+	if (sbox_connect(sbox, &channel, any) != 0)
+		return -1;
+
+	switch(channel) {
+		case 0: { 	/* Using W0/R0 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W0_ADD + (x * 0x40);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: { 	/* Using W1/R1 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W1_ADD + (x * 0x40);
+			}
+			break;
+#endif
+		case 2: { 	/* Using W2/R2 pair */
+				x = (fromdev ? 0 : 1);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W2_ADD + (x * 0x40);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	if (sbox_connect(sbox) != 0)
+		return -1;
+
+	x = (fromdev ? 0 : 2);
+	if (pirq)
+		*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+	if (pregbase)
+		*pregbase = REG_BASE_host_interface + MIF_W0_ADD + x * 0x40;
+#endif
+
+	return 0;
+}
+
+#ifdef CONFIG_TANGO3
+/* Convert MBUS register address to channel index */
+static inline int mbus_idx2channel(unsigned int regbase)
+{
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	static const int channel[6] = { 0, 1, 0, 1, 2, 2 };
+	return(channel[idx]);
+}
+#endif
+
+/*
+ * free_dma,  need to  be called  after  transfer is  done to  release
+ * switchbox.
+ */
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox)
+{
+	unsigned long flags;
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	local_irq_save(flags);
+	g_mbus_intr_handler[idx] = NULL;
+	wmb();
+	local_irq_restore(flags);
+
+#ifdef CONFIG_TANGO3
+	sbox_disconnect(sbox, mbus_idx2channel(regbase)); 
+#else
+	sbox_disconnect(sbox);
+#endif
+}
+
+/*
+ * irq handler for mbus interrupt
+ */
+static irqreturn_t mbus_intr(int irq, void *devinfo)
+{
+	int idx = irq - (LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE);
+
+#ifdef CONFIG_TANGO3
+	if (idx >= 4)
+		idx = irq - (LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE) + 4;
+#endif
+	if (g_mbus_intr_handler[idx]) {
+		mbus_irq_handler_t f;
+
+		f = g_mbus_intr_handler[idx];
+		g_mbus_intr_handler[idx] = NULL;
+		wmb();
+		f(irq, g_mbus_intr_handler_arg[idx]);
+	}
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * check if mbus is in use for given regbase
+ */
+static inline int mbus_inuse(unsigned int regbase)
+{
+	return (gbus_readl(regbase + MIF_cmd_offset) & 0x7) != 0;
+}
+
+/*
+ * setup mbus  register to start  a linear transfer (count  bytes from
+ * addr, where count < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_linear(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (linear): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, count);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x1);
+}
+
+/*
+ * setup mbus  register to start  a double transfer (count  bytes from
+ * addr and count2 bytes from addr2, where count < MBUS_LINEAR_MAX and
+ * count2 < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_double(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int addr2,
+					 unsigned int count2,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address 0x%08x\n", addr);
+	if ((addr2 < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr2 >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address2 0x%08x\n", addr2);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (count2 << 16) | count);
+	gbus_writel(regbase + MIF_add2_skip_offset, addr2);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x2);
+}
+
+/*
+ * setup mbus  register to start  a rectangle transfer (horiz  * lines
+ * bytes  from  addr,  where  horiz  <  MBUS_LINEAR_MAX  and  lines  <
+ * MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_rectangle(unsigned int regbase,
+					    unsigned int addr,
+					    unsigned int horiz,
+					    unsigned int lines,
+					    unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (rectangle): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (lines << 16) | horiz);
+	gbus_writel(regbase + MIF_add2_skip_offset, horiz);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x3);
+}
+
+/*
+ * register mbus interrupt if not done
+ */
+#ifdef CONFIG_TANGO3
+static inline void mbus_register_intr(int channel)
+#else
+static inline void mbus_register_intr(void)
+#endif
+{
+#ifdef CONFIG_TANGO3
+	static int done[3] = { 0, 0, 0 };
+
+	switch(channel) {
+		case 0: {	/* Use W0/R0 then */
+				if (done[0])
+					return;
+				done[0] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: {	/* Use W1/R1 instead */
+				if (done[1])
+					return;
+				done[1] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r1", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w1", NULL);
+			}
+			break;
+#endif
+		case 2: {	/* Use W2/R2 instead */
+				if (done[2])
+					return;
+				done[2] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r2", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w2", NULL);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	static int done = 0;
+
+	if (done)
+		return;
+	done = 1;
+	/*
+	 * register irq handler for R0/W0 only (R1/W1 are not used for
+	 * the moment)
+	 */
+	request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+
+	request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+
+#endif
+}
+
+/*
+ * setup void transaction 
+ */
+void em86xx_mbus_setup_dma_void(unsigned int regbase)
+{
+	while (mbus_inuse(regbase) != 0)
+		;
+	gbus_writel(regbase + MIF_cmd_offset, 4);
+}
+
+/*
+ * start  a   mbus  dma,   use  this  after   a  sucessfull   call  to
+ * em86xx_mbus_alloc_dma
+ */
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr,
+			  unsigned int count, mbus_irq_handler_t handler,
+			  void *arg, unsigned int tflags)
+{
+	unsigned long flags;
+	unsigned int horiz, lines, sz;
+	unsigned int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	/*
+	 * make sure no one uses the mbus before
+	 */
+	if (unlikely(mbus_inuse(regbase))) {
+		printk(KERN_ERR "MBUS: error previous command is pending\n");
+		return 1;
+	}
+
+	/*
+	 * "register" given handler if any
+	 */
+	if (handler) {
+#ifdef CONFIG_TANGO3
+		mbus_register_intr(mbus_idx2channel(regbase));
+#else
+		mbus_register_intr();
+#endif
+		local_irq_save(flags);
+		g_mbus_intr_handler[idx] = handler;
+		g_mbus_intr_handler_arg[idx] = arg;
+		wmb();
+		local_irq_restore(flags);
+	}
+
+	/*
+	 * decide which dma function to use depending on count
+	 */
+	if (count <= MBUS_LINEAR_MAX) {
+		mbus_setup_dma_linear(regbase, addr, count, tflags);
+		return 0;
+	}
+
+	if (count <= (MBUS_LINEAR_MAX * 2)) {
+		mbus_setup_dma_double(regbase, addr, MBUS_LINEAR_MAX,
+				      addr + MBUS_LINEAR_MAX,
+				      count - MBUS_LINEAR_MAX, tflags);
+		return 0;
+	}
+
+	/*
+	 * we need to use rectangle, compute  horiz & lines
+	 * values to use
+	 */
+	for (idx = 0, horiz = 1, sz = count; (idx < 10) && ((sz & 0x01) == 0); ++idx, horiz <<= 1, sz >>= 1)
+		;
+	lines = count >> idx;
+	if ((horiz > MBUS_LINEAR_MAX) || (lines > MBUS_LINEAR_MAX)) {
+		printk(KERN_ERR "MBUS: can't handle rectangle transfer "
+		       "of %d bytes (h: %d, v: %d)\n", count, horiz, lines);
+		BUG();
+	}
+	mbus_setup_dma_rectangle(regbase, addr, horiz, lines, tflags);
+
+	return 0;
+}
+
+/*
+ * Bit 0/8: MBUS_R0_SBOX
+ * Bit 1/9: MBUS_R1_SBOX
+ * Bit 2/10: PCI_MASTER_SBOX
+ * Bit 3/11: PCI_SLAVE_SBOX
+ * Bit 4/12: SATA1_SBOX
+ * Bit 5/13: IDE_ISA_SBOX
+ * Bit 6/14: IDE_DVD_SBOX
+ * Bit 7/15: SATA2_SBOX (Tango3)
+ * Bit 16/24: SBOX_MBUS_W0
+ * Bit 17/25: SBOX_MBUS_W1
+ * Bit 18/26: SBOX_PCI_MASTER
+ * Bit 19/27: SBOX_PCI_SLAVE
+ * Bit 20/28: SBOX_SATA1
+ * Bit 21/29: SBOX_ISA
+ * Bit 22/30: SBOX_DVD
+ * Bit 23/31: SBOX_SATA2 (Tango3)
+ *
+ * Bit 32/40: MBUS_R2_SBOX (Tango3)
+ * Bit 48/50: SBOX_MBUS_W2 (Tango3)
+ */
+#ifdef CONFIG_TANGO3
+static const u64 sbox_reset_vals[4][6] = {
+	{ 0x0000000001011010ULL, 0x0000000002021010ULL, 0x0000000010100101ULL, 0x0000000010100202ULL, 0x0101000000001010ULL, 0x0000010110100000ULL },
+	{ 0x0000000001012020ULL, 0x0000000002022020ULL, 0x0000000020200101ULL, 0x0000000020200202ULL, 0x0101000000002020ULL, 0x0000010120200000ULL },
+	{ 0x0000000001014040ULL, 0x0000000002024040ULL, 0x0000000040400101ULL, 0x0000000040400202ULL, 0x0101000000004040ULL, 0x0000010140400000ULL },
+	{ 0x0000000001018080ULL, 0x0000000002028080ULL, 0x0000000080800101ULL, 0x0000000080800202ULL, 0x0101000000008080ULL, 0x0000010180800000ULL },
+};
+#else
+static const unsigned int sbox_reset_vals[2][4] = {
+	{ 0x01012020, 0x02022020, 0x20200101, 0x20200202 },
+	{ 0x01014040, 0x02024040, 0x40400101, 0x40400202 }
+};
+#endif
+
+/*
+ * clear MBUS transaction for given regbase/sbox
+ */
+static void mbus_reset(unsigned int regbase, int sbox)
+{
+	int midx;
+	int sidx;
+
+#ifdef CONFIG_TANGO3
+	unsigned int rl, rh;
+
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_SATA1;
+
+	if (((midx < 0) || (midx > 5)) || ((sidx < 0) || (sidx > 3))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+	rl = sbox_reset_vals[sidx][midx] & 0xffffffff;
+	rh = (sbox_reset_vals[sidx][midx] >> 32) & 0xffffffff;
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh);
+	iob();
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl & 0xff00ff00);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh & 0xff00ff00);
+	iob();
+#else
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_IDEFLASH;
+
+	if (((midx < 0) || (midx > 3)) || ((sidx < 0) || (sidx > 2))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx]);
+	iob();
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx] & 0xff00ff00);
+	iob();
+#endif
+}
+
+/* Fancy version of memcpy, both dst and src need to be physical address */
+/* The channels have to be allocated already */
+int mbus_memcpy(unsigned int regbase, unsigned int dst, unsigned int src, unsigned int size)
+{
+	/* Save the old SBOX route */
+	unsigned int sbox_route;
+	unsigned int w_base;
+	unsigned int r_base;
+	int channel = 0;
+/* 
+ * TRANSFER defines 4 bits, bit 0: followed by void (1) or not (0),
+ * bit 1: tiled buffer or not (tango3 only).
+ * bit 3-2: 0 = 8 bit, 1 = 16 bit, 2 = 32 bit (tango3 only).
+ */
+#ifdef CONFIG_TANGO3
+#define TRANSFER    0x1 /* or 0x9 for 32 bit transfer */
+#else
+#define TRANSFER    0x1
+#endif
+
+#ifdef CONFIG_TANGO3
+	channel = mbus_idx2channel(regbase);
+
+	if (channel == 0) /* W0/R0 channels are used */
+#endif
+	{
+		w_base = REG_BASE_host_interface + MIF_W0_ADD;
+		r_base = REG_BASE_host_interface + MIF_R0_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xffffff0f;
+
+		/* Hook up W0/R0 and left W1/R1 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff01);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W0 */
+			printk("MBUS: need to reset W0 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	else if (channel == 1) { /* W1/R1 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W1_ADD;
+		r_base = REG_BASE_host_interface + MIF_R1_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xfffffff0;
+
+		/* Hook up W1/R1 and left W0/R0 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff20);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W1 */
+			printk("MBUS: need to reset W1 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#endif
+	else { /* channel == 2: W2/R2 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W2_ADD;
+		r_base = REG_BASE_host_interface + MIF_R2_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE2);
+
+		/* Hook up W2/R2 */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, 0xfffffff9);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W2 */
+			printk("MBUS: need to reset W2 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+	}
+#endif
+
+	return(size);
+}
+
+/*
+ * busy wait  for current mbus transfer  to finish, will  not wait for
+ * more than 20 ms. 0 is ok, 1 timeout, 2 for timeout + reset error.
+ */
+#define MBUS_TIMEOUT	20000
+
+int em86xx_mbus_wait(unsigned int regbase, int sbox)
+{
+	int timeout;
+
+	/* wait for mbus to be released */
+	timeout = 0;
+	do {
+		if (!mbus_inuse(regbase))
+			break;
+		udelay(1);
+		timeout++;
+	} while (timeout < MBUS_TIMEOUT);
+
+	if (timeout < MBUS_TIMEOUT ) {
+		/* ok */
+		if (sbox == SBOX_IDEFLASH){
+                        int i;
+			unsigned int pb_count = 0;
+
+			pb_count = gbus_readl(REG_BASE_host_interface + 
+					       PB_automode_control) & 0xffff;
+
+                        for (i = 0; pb_count && (i < MBUS_TIMEOUT); i++){
+                                udelay(1);
+				pb_count = gbus_readl(REG_BASE_host_interface +
+					       PB_automode_control) & 0xffff;
+			}
+
+                        if (i < MBUS_TIMEOUT) 
+				return 0;
+
+		} else
+			return 0;
+	}
+
+	/* timeout, let's dump some registers ! */
+        if (sbox == SBOX_IDEFLASH) {
+  		printk("MBUS timeout : MBUS CMD = %ld, PB Automode = %08x\n",
+                	(unsigned long)gbus_readl(regbase + MIF_cmd_offset) & 0x7,
+                	(unsigned int)gbus_readl(REG_BASE_host_interface + PB_automode_control));
+        } else {
+		printk("MBUS timeout : MBUS CMD = %08lx\n",
+			gbus_readl(regbase + MIF_cmd_offset) & 0x7);
+	}
+
+	printk("MBUS registers : %08lx %08lx %08lx %08lx\n",
+	       gbus_readl(regbase + MIF_add_offset),
+	       gbus_readl(regbase + MIF_cnt_offset),
+	       gbus_readl(regbase + MIF_add2_skip_offset),
+	       gbus_readl(regbase + MIF_cmd_offset));
+
+	printk(KERN_ERR "MBUS fails, resetting %d ..\n", sbox);
+	mbus_reset(regbase, sbox);
+
+	/* If not able to reset, return  1, so the DMA can be disabled
+	   accordingly  */
+	return mbus_inuse(regbase) ? 0 : 1;
+}
+
+int em86xx_mbus_init(void)
+{
+	static int done = 0;
+
+	if (done)
+		return 0;
+	done = 1;
+
+	/* reset sbox to default values */
+	sbox_init();
+
+	/* Give better MBUS bandwidth for Wx/Rx channel */
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_system_block + MARB_mid01_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid21_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid03_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid23_cfg, 0x12005);
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x12005);
+#endif
+#else
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x11f1f);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x11f1f);
+#endif
+
+	return 0;
+}
+
+#define offset_into_page(x) ((x) & (PAGE_SIZE - 1))
+
+static inline unsigned long tangox_getxtal(void)
+{
+	return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+extern void *memcpy2(void *__to, __const__ void *__from, size_t __n);
+void *memcpy(void *__to, __const__ void *__from, size_t __n)
+{
+    unsigned long virt_to = (unsigned long) __to;
+    unsigned long virt_from = (unsigned long) __from;
+    dma_addr_t dma_from;
+    dma_addr_t dma_to;
+    int len=__n;
+    int flag;
+    unsigned long t1,t2;
+
+
+    if(__n<512 || !usedma || virt_from < 0x90000000 || virt_to < 0x90000000 ||
+        virt_from>=0xA0000000 || virt_to >=0xA0000000)
+    {
+        em86_stats[10]+=__n;
+        return memcpy2(__to, __from, __n);
+    }
+
+    t1=tangox_getxtal();
+
+
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__n)&0xF) flush_dcache_line((virt_to+__n)&~0xF);
+
+    dma_from=virt_from;
+    dma_to=virt_to;
+
+    raw_local_irq_save(flag);
+    while(len>0)
+    {
+        int curlen= len>0x1FFF ? 0x1FFF : len;
+        blast_dcache_range(dma_from, dma_from+curlen);
+        blast_inv_dcache_range(dma_to, dma_to+curlen);
+        while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+
+//            printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, len>0x1FFF ? 0x1FFF : len);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+        // Start VDEC0_MBUS_R2 
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+        dma_to += curlen;
+        dma_from += curlen;
+        len-= curlen;
+    }
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+    t2=tangox_getxtal();
+    em86_stats[12]+=__n;
+    em86_stats[13]+=(t2-t1);
+    raw_local_irq_restore(flag);
+    return __to;
+}
+
+size_t __invoke_copy_to_user_dma(void __user * __cu_to, const void * __cu_from, long __cu_len)
+{
+    unsigned long virt_to = (unsigned long) __cu_to;
+    unsigned long virt_from = (unsigned long) __cu_from;
+    dma_addr_t dma_from;
+    int byte;
+    unsigned long _n;
+    int flag;
+//    long long t1,t2,t3;
+//	struct timeval tv;
+
+    if(__cu_len<512 || !usedma || virt_from >= 0xC0000000 || virt_to >= 0x80000000)
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    if(!(virt_addr_valid(__cu_from)) ||
+        !(virt_addr_valid(__cu_from + __cu_len)))
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    // Verify all pages exist
+    for(byte = 0; byte < __cu_len; byte+=PAGE_SIZE)
+    {
+        __put_user_check(0, (unsigned char *) (virt_to+byte), 1);
+    }
+    __put_user_check(0, (unsigned char *) (virt_to+__cu_len-1), 1);
+
+//	do_gettimeofday(&tv);
+//	t1=tv.tv_sec*1000000LL+tv.tv_usec;
+
+    // If the virt_to is not aligned we need to flush the data before it
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__cu_len)&0xF) flush_dcache_line((virt_to+__cu_len)&~0xF);
+    blast_inv_dcache_range(virt_to, virt_to+__cu_len);
+    dma_from = dma_map_single(NULL, (void *) virt_from, __cu_len, DMA_TO_DEVICE);
+
+//    printk(KERN_ERR "dma transfer %X to %x len %X\n", __cu_from, __cu_to , __cu_len);
+
+    raw_local_irq_save(flag);
+//	do_gettimeofday(&tv);
+//	t3=tv.tv_sec*1000000LL+tv.tv_usec;
+
+    for (byte = 0, _n = __cu_len; byte < __cu_len;) 
+    {
+        int len = min(PAGE_SIZE - offset_into_page(virt_to + byte), _n);
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+        unsigned long pg_addr;
+        unsigned long dma_to;
+
+        pg_addr = (virt_to+byte) & PAGE_MASK; /* address of start page */
+
+        if (pg_addr > TASK_SIZE)
+            pgd = pgd_offset_k(pg_addr);
+        else
+            pgd = pgd_offset_gate(current->mm, pg_addr);
+        BUG_ON(pgd_none(*pgd));
+        pud = pud_offset(pgd, pg_addr);
+        BUG_ON(pud_none(*pud));
+        pmd = pmd_offset(pud, pg_addr);
+        if (pmd_none(*pmd)) 
+        {
+            printk(KERN_ERR "pmd_none\n");
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        pte = pte_offset_map(pmd, pg_addr);
+        if (pte_none(*pte)) {
+            pte_unmap(pte);
+            printk(KERN_ERR "pte_none\n");
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        dma_to= (pte_val(*pte) & PAGE_MASK) + offset_into_page(virt_to + byte);
+        pte_unmap(pte);
+
+
+        if(dma_to<0x10000000 || dma_to>=0x30000000 ||
+            dma_from<0x10000000 || dma_from>=0x30000000)
+        {
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        _n -= len;
+
+        while(len>0)
+        {
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+    
+//            printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0xffff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+            // Start VDEC0_MBUS_R2 
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from+byte) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from+byte) & 0xffff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+            dma_to += len>0x1FFF ? 0x1FFF : len;
+            byte += len>0x1FFF ? 0x1FFF : len;
+            len-= len>0x1FFF ? 0x1FFF : len;
+        }
+    }
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+//	do_gettimeofday(&tv);
+//	t2=tv.tv_sec*1000000LL+tv.tv_usec;
+    raw_local_irq_restore(flag);
+//    em86dma_time+=(t2-t1);
+//    em86dma_csum_time+=(t2-t3);
+    em86_stats[0]+=__cu_len;
+    em86_stats[2]+=1;
+unpin:
+    return _n;
+}
+
+EXPORT_SYMBOL(em86xx_mbus_alloc_dma);
+EXPORT_SYMBOL(em86xx_mbus_free_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma_void);
+EXPORT_SYMBOL(em86xx_mbus_wait);
+EXPORT_SYMBOL(em86xx_mbus_init);
+EXPORT_SYMBOL(mbus_setup_dma_linear);
+EXPORT_SYMBOL(mbus_setup_dma_double);
+EXPORT_SYMBOL(mbus_setup_dma_rectangle);
+EXPORT_SYMBOL(mbus_memcpy);
+
+EXPORT_SYMBOL(em86_stats);
+EXPORT_SYMBOL(memcpy);
+EXPORT_SYMBOL(__invoke_copy_to_user_dma);
diff -Naur linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma3 linux-2.6.30-test/arch/mips/tangox/mbus.c.dma3
--- linux-2.6.30-ori/arch/mips/tangox/mbus.c.dma3	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/mbus.c.dma3	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1146 @@
+/*********************************************************************
+ Copyright (C) 2001-2008
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <asm/uaccess.h>
+#include <asm/r4kcache.h>
+#include <linux/pagemap.h>
+#include <linux/dma-mapping.h>
+
+#include "setup.h"
+
+#if !defined(CONFIG_TANGO2) && !defined(CONFIG_TANGO3)
+#error Undefined Sigma's chip!!!
+#endif
+
+#ifdef CONFIG_TANGO3
+#warning TANGO3 TODO IRQ assignment for W2/R2!!
+/* Temporary as no W2/R2 IRQ assigned yet. */
+#define LOG2_CPU_HOST_MBUS_W2_INT	62
+#define LOG2_CPU_HOST_MBUS_R2_INT	63
+
+/* Uncomment this only if W1/R1 can be used (typically not) */
+// #define WITH_MBUS_W1R1
+
+#endif /* CONFIG_TANGO3 */
+
+/*
+ * computed in prom.c
+ */
+extern unsigned long em8xxx_kmem_start;
+extern unsigned long em8xxx_kmem_size;
+
+long long em86_stats[16] = {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0};
+
+static int usedma=0;
+
+/*
+ * switchbox stuffs
+ *
+ * We keep  track of  current mapping using  this globals  rather than
+ * reading hardware registers each time.
+ */
+static unsigned int g_sbox_map[SBOX_MAX];
+
+static inline void sbox_update_route(void)
+{
+	int i;
+#ifdef CONFIG_TANGO3
+	u64 data = 0; /* to cover two 32 bits registers */
+#else
+	unsigned int data = 0;
+#endif
+
+	for (i = SBOX_MAX - 1; i >= 0; --i)
+		data = (data << 4) | g_sbox_map[i];
+
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data & 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, (data >> 32) & 0xffffffff);
+#else
+	gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, data);
+#endif
+}
+
+static void sbox_reset(void)
+{
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xffffffff);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xff00ff00);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfdfdfdfd);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0xfd00fd00);
+#endif
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01010101);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, 0x01000100);
+#else
+	/* Leave W1/R1 alone. */
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d7d7d7d);
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, 0x7d007d00);
+#endif
+}
+
+static void sbox_setup(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* W0 initially disconnected */
+	g_sbox_map[SBOX_MBUS_W0] = 0xf;
+
+#if defined(CONFIG_TANGO3) && defined(WITH_MBUS_W1R1)
+	g_sbox_map[SBOX_MBUS_W1] = 0xf;
+#else
+	/* Leave W1 alone */
+	g_sbox_map[SBOX_MBUS_W1] = 0;
+#endif
+
+	g_sbox_map[SBOX_PCIMASTER] = 0xf;
+	g_sbox_map[SBOX_PCISLAVE] = SBOX_PCISLAVE + 1; /* Loopback */
+	g_sbox_map[SBOX_SATA1] = 0xf;
+	g_sbox_map[SBOX_IDEDVD] = 0xf;
+	g_sbox_map[SBOX_IDEFLASH] = 0xf;
+#ifdef CONFIG_TANGO3
+	g_sbox_map[SBOX_SATA2] = 0xf;
+	g_sbox_map[SBOX_MBUS_W2] = 0xf;
+#else
+	g_sbox_map[SBOX_UNUSED1] = 0xf;
+#endif
+
+	sbox_update_route();
+	wmb();
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Connect given interface to R?/W? channel
+ */
+#ifdef CONFIG_TANGO3
+static int sbox_connect(int iface, int *channel, int any)
+#else
+static int sbox_connect(int iface)
+#endif
+{
+	unsigned long flags;
+	int res = 0;
+#ifdef CONFIG_TANGO3
+	int chan = 0;
+#endif
+
+	local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) {
+		*channel = 0; /* connected to W0/R0 */
+		goto done;
+#ifdef WITH_MBUS_W1R1
+	} else if (g_sbox_map[SBOX_MBUS_W1] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W1 + 1)) {
+		*channel = 1; /* connected to W1/R1 */
+		goto done;
+#endif
+	} else if (g_sbox_map[SBOX_MBUS_W2] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W2 + 1)) {
+		*channel = 2; /* connected to W2/R2 */
+		goto done;
+	}
+
+	if (g_sbox_map[iface] != 0xf) { /* connect to something else already */
+		res = 1;
+		goto done;
+	}
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf) {
+		chan++; /* try next */
+#ifdef WITH_MBUS_W1R1
+		if (g_sbox_map[SBOX_MBUS_W1] != 0xf) {
+#endif
+			if (any == 0) {
+#warning TO BE FIX in TANGO3 H/W!! (W2/R2 allocation)
+				res = 1; /* TANGO3 TODO: allocate W2/R2 once IRQ is available */
+				goto done;
+			}
+			chan++; /* try next */
+			if (g_sbox_map[SBOX_MBUS_W2] != 0xf)  {
+				res = 1; /* Both W0/W2 not available, and optional (W1 as well) */
+				goto done;
+			}
+#ifdef WITH_MBUS_W1R1
+		}
+#endif
+	}
+#else
+	/* Already connected? */
+	if (g_sbox_map[SBOX_MBUS_W0] == (iface + 1) && g_sbox_map[iface] == (SBOX_MBUS_W0 + 1)) 
+		goto done;
+
+	/* In use ? */
+	if (g_sbox_map[SBOX_MBUS_W0] != 0xf || g_sbox_map[iface] != 0xf) {
+		res = 1;
+		goto done;
+	}
+#endif /* CONFIG_TANGO3 */
+
+#ifdef CONFIG_TANGO3
+	switch(chan) {
+		case 0: g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W0 + 1; /* W0/R0 */
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: g_sbox_map[SBOX_MBUS_W1] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W1 + 1; /* W1/R1 */
+			break;
+#endif
+		case 2: g_sbox_map[SBOX_MBUS_W2] = iface + 1;
+			g_sbox_map[iface] = SBOX_MBUS_W2 + 1; /* W2/R2 */
+			break;
+
+		default: BUG();
+			break;
+	}
+	*channel = chan;
+#else
+	g_sbox_map[SBOX_MBUS_W0] = iface + 1;
+	g_sbox_map[iface] = SBOX_MBUS_W0 + 1;
+#endif
+	sbox_update_route();
+	wmb();
+
+done:
+	local_irq_restore(flags);
+
+	return res;
+}
+
+#ifdef CONFIG_TANGO3
+static void sbox_disconnect(int iface, int channel)
+#else
+static void sbox_disconnect(int iface)
+#endif
+{
+	unsigned long flags;
+
+	if (iface >= 0) {
+		local_irq_save(flags);
+
+#ifdef CONFIG_TANGO3
+		switch(channel) {
+			case 0: g_sbox_map[SBOX_MBUS_W0] = 0xf;
+				break;
+#ifdef WITH_MBUS_W1R1
+			case 1: g_sbox_map[SBOX_MBUS_W1] = 0xf;
+				break;
+#endif
+			case 2: g_sbox_map[SBOX_MBUS_W2] = 0xf;
+				break;
+
+			default: BUG();
+				break;
+		}
+#else
+		g_sbox_map[SBOX_MBUS_W0] = 0xf;
+#endif
+		g_sbox_map[iface] = 0xf;
+		sbox_update_route();
+		wmb();
+
+		local_irq_restore(flags);
+	}
+}
+
+static void sbox_init(void)
+{
+	sbox_setup();
+	sbox_reset();
+	// Is this early enough?
+    gbus_writel(REG_BASE_system_block + 0x240, 0x11f1f); // write
+    gbus_writel(REG_BASE_system_block + 0x244, 0x11f1f); // read
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fe4, 0x0700); // Unreset dbk channels
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3dcc, 0x8000); // dbk loopback
+    gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3fdc, 0x0003); // switchbox->WMV9
+    usedma=1;
+}
+
+
+/*
+ * mbus stuffs
+ *
+ * to  avoid   requesting/freeing  irq   each  time,  we   keep  given
+ * handler/args  for each  dma  request and  call  it in  our own  irq
+ * handler.
+ */
+#define MBUS_LINEAR_MAX		(0x2000 - 1)
+
+#ifdef CONFIG_TANGO3
+static mbus_irq_handler_t g_mbus_intr_handler[6];
+static void *g_mbus_intr_handler_arg[6];
+#else
+static mbus_irq_handler_t g_mbus_intr_handler[4];
+static void *g_mbus_intr_handler_arg[4];
+#endif
+
+/*
+ * alloc_dma, need to be called before setup, will try to connect
+ * needed sbox.
+ */
+int em86xx_mbus_alloc_dma(int sbox, int fromdev, unsigned long *pregbase, int *pirq, int any)
+{
+	int x;
+
+#ifdef CONFIG_TANGO3
+	int channel = 0;
+
+	if (sbox_connect(sbox, &channel, any) != 0)
+		return -1;
+
+	switch(channel) {
+		case 0: { 	/* Using W0/R0 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W0_ADD + (x * 0x40);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: { 	/* Using W1/R1 pair */
+				x = (fromdev ? 0 : 2);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W1_ADD + (x * 0x40);
+			}
+			break;
+#endif
+		case 2: { 	/* Using W2/R2 pair */
+				x = (fromdev ? 0 : 1);
+				if (pirq)
+					*pirq = LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+				if (pregbase)
+					*pregbase = REG_BASE_host_interface + MIF_W2_ADD + (x * 0x40);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	if (sbox_connect(sbox) != 0)
+		return -1;
+
+	x = (fromdev ? 0 : 2);
+	if (pirq)
+		*pirq = LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE + x;
+	if (pregbase)
+		*pregbase = REG_BASE_host_interface + MIF_W0_ADD + x * 0x40;
+#endif
+
+	return 0;
+}
+
+#ifdef CONFIG_TANGO3
+/* Convert MBUS register address to channel index */
+static inline int mbus_idx2channel(unsigned int regbase)
+{
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	static const int channel[6] = { 0, 1, 0, 1, 2, 2 };
+	return(channel[idx]);
+}
+#endif
+
+/*
+ * free_dma,  need to  be called  after  transfer is  done to  release
+ * switchbox.
+ */
+void em86xx_mbus_free_dma(unsigned long regbase, int sbox)
+{
+	unsigned long flags;
+	int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	local_irq_save(flags);
+	g_mbus_intr_handler[idx] = NULL;
+	wmb();
+	local_irq_restore(flags);
+
+#ifdef CONFIG_TANGO3
+	sbox_disconnect(sbox, mbus_idx2channel(regbase)); 
+#else
+	sbox_disconnect(sbox);
+#endif
+}
+
+/*
+ * irq handler for mbus interrupt
+ */
+static irqreturn_t mbus_intr(int irq, void *devinfo)
+{
+	int idx = irq - (LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE);
+
+#ifdef CONFIG_TANGO3
+	if (idx >= 4)
+		idx = irq - (LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE) + 4;
+#endif
+	if (g_mbus_intr_handler[idx]) {
+		mbus_irq_handler_t f;
+
+		f = g_mbus_intr_handler[idx];
+		g_mbus_intr_handler[idx] = NULL;
+		wmb();
+		f(irq, g_mbus_intr_handler_arg[idx]);
+	}
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * check if mbus is in use for given regbase
+ */
+static inline int mbus_inuse(unsigned int regbase)
+{
+	return (gbus_readl(regbase + MIF_cmd_offset) & 0x7) != 0;
+}
+
+/*
+ * setup mbus  register to start  a linear transfer (count  bytes from
+ * addr, where count < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_linear(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (linear): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, count);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x1);
+}
+
+/*
+ * setup mbus  register to start  a double transfer (count  bytes from
+ * addr and count2 bytes from addr2, where count < MBUS_LINEAR_MAX and
+ * count2 < MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_double(unsigned int regbase,
+					 unsigned int addr,
+					 unsigned int count,
+					 unsigned int addr2,
+					 unsigned int count2,
+					 unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address 0x%08x\n", addr);
+	if ((addr2 < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr2 >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (double): bad transfer address2 0x%08x\n", addr2);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (count2 << 16) | count);
+	gbus_writel(regbase + MIF_add2_skip_offset, addr2);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x2);
+}
+
+/*
+ * setup mbus  register to start  a rectangle transfer (horiz  * lines
+ * bytes  from  addr,  where  horiz  <  MBUS_LINEAR_MAX  and  lines  <
+ * MBUS_LINEAR_MAX)
+ */
+void mbus_setup_dma_rectangle(unsigned int regbase,
+					    unsigned int addr,
+					    unsigned int horiz,
+					    unsigned int lines,
+					    unsigned int flags)
+{
+#if !defined(CONFIG_SD_DIRECT_DMA) 
+	if ((addr < tangox_dma_address(CPHYSADDR(em8xxx_kmem_start))) || (addr >= (tangox_dma_address(CPHYSADDR(em8xxx_kmem_start)) + em8xxx_kmem_size)))
+		printk("MBUS Warning (rectangle): bad transfer address 0x%08x\n", addr);
+#endif
+
+	gbus_writel(regbase + MIF_add_offset, addr);
+	gbus_writel(regbase + MIF_cnt_offset, (lines << 16) | horiz);
+	gbus_writel(regbase + MIF_add2_skip_offset, horiz);
+	iob();
+	gbus_writel(regbase + MIF_cmd_offset, (flags<<2)|0x3);
+}
+
+/*
+ * register mbus interrupt if not done
+ */
+#ifdef CONFIG_TANGO3
+static inline void mbus_register_intr(int channel)
+#else
+static inline void mbus_register_intr(void)
+#endif
+{
+#ifdef CONFIG_TANGO3
+	static int done[3] = { 0, 0, 0 };
+
+	switch(channel) {
+		case 0: {	/* Use W0/R0 then */
+				if (done[0])
+					return;
+				done[0] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+			}
+			break;
+#ifdef WITH_MBUS_W1R1
+		case 1: {	/* Use W1/R1 instead */
+				if (done[1])
+					return;
+				done[1] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r1", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W1_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w1", NULL);
+			}
+			break;
+#endif
+		case 2: {	/* Use W2/R2 instead */
+				if (done[2])
+					return;
+				done[2] = 1;
+				request_irq(LOG2_CPU_HOST_MBUS_R2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_r2", NULL);
+				request_irq(LOG2_CPU_HOST_MBUS_W2_INT + IRQ_CONTROLLER_IRQ_BASE,
+					    mbus_intr, IRQF_DISABLED, "tangox_mbus_w2", NULL);
+			}
+			break;
+
+		default: BUG();
+			break;
+	}
+#else
+	static int done = 0;
+
+	if (done)
+		return;
+	done = 1;
+	/*
+	 * register irq handler for R0/W0 only (R1/W1 are not used for
+	 * the moment)
+	 */
+	request_irq(LOG2_CPU_HOST_MBUS_R0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_r0", NULL);
+
+	request_irq(LOG2_CPU_HOST_MBUS_W0_INT + IRQ_CONTROLLER_IRQ_BASE,
+		    mbus_intr, IRQF_DISABLED, "tangox_mbus_w0", NULL);
+
+#endif
+}
+
+/*
+ * setup void transaction 
+ */
+void em86xx_mbus_setup_dma_void(unsigned int regbase)
+{
+	while (mbus_inuse(regbase) != 0)
+		;
+	gbus_writel(regbase + MIF_cmd_offset, 4);
+}
+
+/*
+ * start  a   mbus  dma,   use  this  after   a  sucessfull   call  to
+ * em86xx_mbus_alloc_dma
+ */
+int em86xx_mbus_setup_dma(unsigned int regbase, unsigned int addr,
+			  unsigned int count, mbus_irq_handler_t handler,
+			  void *arg, unsigned int tflags)
+{
+	unsigned long flags;
+	unsigned int horiz, lines, sz;
+	unsigned int idx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+
+	/*
+	 * make sure no one uses the mbus before
+	 */
+	if (unlikely(mbus_inuse(regbase))) {
+		printk(KERN_ERR "MBUS: error previous command is pending\n");
+		return 1;
+	}
+
+	/*
+	 * "register" given handler if any
+	 */
+	if (handler) {
+#ifdef CONFIG_TANGO3
+		mbus_register_intr(mbus_idx2channel(regbase));
+#else
+		mbus_register_intr();
+#endif
+		local_irq_save(flags);
+		g_mbus_intr_handler[idx] = handler;
+		g_mbus_intr_handler_arg[idx] = arg;
+		wmb();
+		local_irq_restore(flags);
+	}
+
+	/*
+	 * decide which dma function to use depending on count
+	 */
+	if (count <= MBUS_LINEAR_MAX) {
+		mbus_setup_dma_linear(regbase, addr, count, tflags);
+		return 0;
+	}
+
+	if (count <= (MBUS_LINEAR_MAX * 2)) {
+		mbus_setup_dma_double(regbase, addr, MBUS_LINEAR_MAX,
+				      addr + MBUS_LINEAR_MAX,
+				      count - MBUS_LINEAR_MAX, tflags);
+		return 0;
+	}
+
+	/*
+	 * we need to use rectangle, compute  horiz & lines
+	 * values to use
+	 */
+	for (idx = 0, horiz = 1, sz = count; (idx < 10) && ((sz & 0x01) == 0); ++idx, horiz <<= 1, sz >>= 1)
+		;
+	lines = count >> idx;
+	if ((horiz > MBUS_LINEAR_MAX) || (lines > MBUS_LINEAR_MAX)) {
+		printk(KERN_ERR "MBUS: can't handle rectangle transfer "
+		       "of %d bytes (h: %d, v: %d)\n", count, horiz, lines);
+		BUG();
+	}
+	mbus_setup_dma_rectangle(regbase, addr, horiz, lines, tflags);
+
+	return 0;
+}
+
+/*
+ * Bit 0/8: MBUS_R0_SBOX
+ * Bit 1/9: MBUS_R1_SBOX
+ * Bit 2/10: PCI_MASTER_SBOX
+ * Bit 3/11: PCI_SLAVE_SBOX
+ * Bit 4/12: SATA1_SBOX
+ * Bit 5/13: IDE_ISA_SBOX
+ * Bit 6/14: IDE_DVD_SBOX
+ * Bit 7/15: SATA2_SBOX (Tango3)
+ * Bit 16/24: SBOX_MBUS_W0
+ * Bit 17/25: SBOX_MBUS_W1
+ * Bit 18/26: SBOX_PCI_MASTER
+ * Bit 19/27: SBOX_PCI_SLAVE
+ * Bit 20/28: SBOX_SATA1
+ * Bit 21/29: SBOX_ISA
+ * Bit 22/30: SBOX_DVD
+ * Bit 23/31: SBOX_SATA2 (Tango3)
+ *
+ * Bit 32/40: MBUS_R2_SBOX (Tango3)
+ * Bit 48/50: SBOX_MBUS_W2 (Tango3)
+ */
+#ifdef CONFIG_TANGO3
+static const u64 sbox_reset_vals[4][6] = {
+	{ 0x0000000001011010ULL, 0x0000000002021010ULL, 0x0000000010100101ULL, 0x0000000010100202ULL, 0x0101000000001010ULL, 0x0000010110100000ULL },
+	{ 0x0000000001012020ULL, 0x0000000002022020ULL, 0x0000000020200101ULL, 0x0000000020200202ULL, 0x0101000000002020ULL, 0x0000010120200000ULL },
+	{ 0x0000000001014040ULL, 0x0000000002024040ULL, 0x0000000040400101ULL, 0x0000000040400202ULL, 0x0101000000004040ULL, 0x0000010140400000ULL },
+	{ 0x0000000001018080ULL, 0x0000000002028080ULL, 0x0000000080800101ULL, 0x0000000080800202ULL, 0x0101000000008080ULL, 0x0000010180800000ULL },
+};
+#else
+static const unsigned int sbox_reset_vals[2][4] = {
+	{ 0x01012020, 0x02022020, 0x20200101, 0x20200202 },
+	{ 0x01014040, 0x02024040, 0x40400101, 0x40400202 }
+};
+#endif
+
+/*
+ * clear MBUS transaction for given regbase/sbox
+ */
+static void mbus_reset(unsigned int regbase, int sbox)
+{
+	int midx;
+	int sidx;
+
+#ifdef CONFIG_TANGO3
+	unsigned int rl, rh;
+
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_SATA1;
+
+	if (((midx < 0) || (midx > 5)) || ((sidx < 0) || (sidx > 3))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+	rl = sbox_reset_vals[sidx][midx] & 0xffffffff;
+	rh = (sbox_reset_vals[sidx][midx] >> 32) & 0xffffffff;
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh);
+	iob();
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET, rl & 0xff00ff00);
+	if (rh) 
+		gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET2, rh & 0xff00ff00);
+	iob();
+#else
+	midx = (regbase - (REG_BASE_host_interface + MIF_W0_ADD)) / 0x40;
+	sidx = sbox - SBOX_IDEFLASH;
+
+	if (((midx < 0) || (midx > 3)) || ((sidx < 0) || (sidx > 2))) {
+		printk("MBUS reset: out of range, midx %d, sidx %d\n",
+		       midx, sidx);
+		return;
+	}
+
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx]);
+	iob();
+	gbus_writel(REG_BASE_host_interface + SBOX_FIFO_RESET,
+		    sbox_reset_vals[sidx][midx] & 0xff00ff00);
+	iob();
+#endif
+}
+
+/* Fancy version of memcpy, both dst and src need to be physical address */
+/* The channels have to be allocated already */
+int mbus_memcpy(unsigned int regbase, unsigned int dst, unsigned int src, unsigned int size)
+{
+	/* Save the old SBOX route */
+	unsigned int sbox_route;
+	unsigned int w_base;
+	unsigned int r_base;
+	int channel = 0;
+/* 
+ * TRANSFER defines 4 bits, bit 0: followed by void (1) or not (0),
+ * bit 1: tiled buffer or not (tango3 only).
+ * bit 3-2: 0 = 8 bit, 1 = 16 bit, 2 = 32 bit (tango3 only).
+ */
+#ifdef CONFIG_TANGO3
+#define TRANSFER    0x1 /* or 0x9 for 32 bit transfer */
+#else
+#define TRANSFER    0x1
+#endif
+
+#ifdef CONFIG_TANGO3
+	channel = mbus_idx2channel(regbase);
+
+	if (channel == 0) /* W0/R0 channels are used */
+#endif
+	{
+		w_base = REG_BASE_host_interface + MIF_W0_ADD;
+		r_base = REG_BASE_host_interface + MIF_R0_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xffffff0f;
+
+		/* Hook up W0/R0 and left W1/R1 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff01);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W0 */
+			printk("MBUS: need to reset W0 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#ifdef CONFIG_TANGO3
+#ifdef WITH_MBUS_W1R1
+	else if (channel == 1) { /* W1/R1 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W1_ADD;
+		r_base = REG_BASE_host_interface + MIF_R1_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE) & 0xfffffff0;
+
+		/* Hook up W1/R1 and left W0/R0 the same as before */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, 0xffffff20);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W1 */
+			printk("MBUS: need to reset W1 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE, sbox_route);
+	}
+#endif
+	else { /* channel == 2: W2/R2 channels are used */
+		w_base = REG_BASE_host_interface + MIF_W2_ADD;
+		r_base = REG_BASE_host_interface + MIF_R2_ADD;
+		sbox_route = gbus_readl(REG_BASE_host_interface + SBOX_ROUTE2);
+
+		/* Hook up W2/R2 */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, 0xfffffff9);
+	
+		if (em86xx_mbus_setup_dma(w_base, dst, size, NULL, NULL, TRANSFER) != 0) {
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		} else if (em86xx_mbus_setup_dma(r_base, src, size, NULL, NULL, TRANSFER) != 0) {
+			/* TODO: should reset W2 */
+			printk("MBUS: need to reset W2 channel.\n");
+			gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+			return(0);
+		}
+
+		/* TODO: a timeout mechanism should be added to reset W0/R0 */
+		while (mbus_inuse(r_base) != 0)
+			;
+		while (mbus_inuse(w_base) != 0)
+			;
+
+		/* Restore SBOX route once we're done */
+		gbus_writel(REG_BASE_host_interface + SBOX_ROUTE2, sbox_route);
+	}
+#endif
+
+	return(size);
+}
+
+/*
+ * busy wait  for current mbus transfer  to finish, will  not wait for
+ * more than 20 ms. 0 is ok, 1 timeout, 2 for timeout + reset error.
+ */
+#define MBUS_TIMEOUT	20000
+
+int em86xx_mbus_wait(unsigned int regbase, int sbox)
+{
+	int timeout;
+
+	/* wait for mbus to be released */
+	timeout = 0;
+	do {
+		if (!mbus_inuse(regbase))
+			break;
+		udelay(1);
+		timeout++;
+	} while (timeout < MBUS_TIMEOUT);
+
+	if (timeout < MBUS_TIMEOUT ) {
+		/* ok */
+		if (sbox == SBOX_IDEFLASH){
+                        int i;
+			unsigned int pb_count = 0;
+
+			pb_count = gbus_readl(REG_BASE_host_interface + 
+					       PB_automode_control) & 0xffff;
+
+                        for (i = 0; pb_count && (i < MBUS_TIMEOUT); i++){
+                                udelay(1);
+				pb_count = gbus_readl(REG_BASE_host_interface +
+					       PB_automode_control) & 0xffff;
+			}
+
+                        if (i < MBUS_TIMEOUT) 
+				return 0;
+
+		} else
+			return 0;
+	}
+
+	/* timeout, let's dump some registers ! */
+        if (sbox == SBOX_IDEFLASH) {
+  		printk("MBUS timeout : MBUS CMD = %ld, PB Automode = %08x\n",
+                	(unsigned long)gbus_readl(regbase + MIF_cmd_offset) & 0x7,
+                	(unsigned int)gbus_readl(REG_BASE_host_interface + PB_automode_control));
+        } else {
+		printk("MBUS timeout : MBUS CMD = %08lx\n",
+			gbus_readl(regbase + MIF_cmd_offset) & 0x7);
+	}
+
+	printk("MBUS registers : %08lx %08lx %08lx %08lx\n",
+	       gbus_readl(regbase + MIF_add_offset),
+	       gbus_readl(regbase + MIF_cnt_offset),
+	       gbus_readl(regbase + MIF_add2_skip_offset),
+	       gbus_readl(regbase + MIF_cmd_offset));
+
+	printk(KERN_ERR "MBUS fails, resetting %d ..\n", sbox);
+	mbus_reset(regbase, sbox);
+
+	/* If not able to reset, return  1, so the DMA can be disabled
+	   accordingly  */
+	return mbus_inuse(regbase) ? 0 : 1;
+}
+
+int em86xx_mbus_init(void)
+{
+	static int done = 0;
+
+	if (done)
+		return 0;
+	done = 1;
+
+	/* reset sbox to default values */
+	sbox_init();
+
+	/* Give better MBUS bandwidth for Wx/Rx channel */
+#ifdef CONFIG_TANGO3
+	gbus_writel(REG_BASE_system_block + MARB_mid01_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid21_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid03_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid23_cfg, 0x12005);
+#ifdef WITH_MBUS_W1R1
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x12005);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x12005);
+#endif
+#else
+	gbus_writel(REG_BASE_system_block + MARB_mid02_cfg, 0x11f1f);
+	gbus_writel(REG_BASE_system_block + MARB_mid22_cfg, 0x11f1f);
+#endif
+
+	return 0;
+}
+
+#define offset_into_page(x) ((x) & (PAGE_SIZE - 1))
+
+static inline unsigned long tangox_getxtal(void)
+{
+	return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+extern void *memcpy2(void *__to, __const__ void *__from, size_t __n);
+void *memcpy(void *__to, __const__ void *__from, size_t __n)
+{
+    unsigned long virt_to = (unsigned long) __to;
+    unsigned long virt_from = (unsigned long) __from;
+    dma_addr_t dma_from;
+    dma_addr_t dma_to;
+    int len=__n;
+    int flag;
+    unsigned long t1,t2;
+
+
+    if(__n<512 || !usedma || virt_from < 0x90000000 || virt_to < 0x90000000 ||
+        virt_from>=0xA0000000 || virt_to >=0xA0000000)
+    {
+        em86_stats[10]+=__n;
+        return memcpy2(__to, __from, __n);
+    }
+
+    t1=tangox_getxtal();
+
+
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__n)&0xF) flush_dcache_line((virt_to+__n)&~0xF);
+
+    dma_from=virt_from;
+    dma_to=virt_to;
+
+    raw_local_irq_save(flag);
+    while(len>0)
+    {
+        int curlen= len>0x1FFF ? 0x1FFF : len;
+        blast_dcache_range(dma_from, dma_from+curlen);
+        blast_inv_dcache_range(dma_to, dma_to+curlen);
+        while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+
+//            printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, len>0x1FFF ? 0x1FFF : len);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+        // Start VDEC0_MBUS_R2 
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from) & 0xffff);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from) & 0x3fff0000) >> 16);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, curlen);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+        gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+        dma_to += curlen;
+        dma_from += curlen;
+        len-= curlen;
+    }
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+    t2=tangox_getxtal();
+    em86_stats[12]+=__n;
+    em86_stats[13]+=(t2-t1);
+    raw_local_irq_restore(flag);
+    return __to;
+}
+
+size_t __invoke_copy_to_user_dma(void __user * __cu_to, const void * __cu_from, long __cu_len)
+{
+    unsigned long virt_to = (unsigned long) __cu_to;
+    unsigned long virt_from = (unsigned long) __cu_from;
+    dma_addr_t dma_from;
+    int byte;
+    unsigned long _n;
+    int flag;
+    unsigned long t1,t2;
+
+    if(virt_to >= 0x80000000)
+    {
+        memcpy(__cu_to, __cu_from, __cu_len);
+        return 0;
+    }
+
+    if(__cu_len<512 || !usedma || virt_from >= 0xC0000000 || virt_to >= 0x80000000)
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    if(!(virt_addr_valid(__cu_from)) ||
+        !(virt_addr_valid(__cu_from + __cu_len)))
+    {
+        em86_stats[14]+=__cu_len;
+        return __invoke_copy_to_user(__cu_to, __cu_from, __cu_len);
+    }
+
+    // Verify all pages exist
+    for(byte = 0; byte < __cu_len; byte+=PAGE_SIZE)
+    {
+        __put_user_check(0, (unsigned char *) (virt_to+byte), 1);
+    }
+    __put_user_check(0, (unsigned char *) (virt_to+__cu_len-1), 1);
+
+    t1=tangox_getxtal();
+
+    // If the virt_to is not aligned we need to flush the data before it
+    if(virt_to&0xF) flush_dcache_line(virt_to&~0xF);
+    // If the virt_to+cu_len is not aligned we need to flush the data after it
+    if((virt_to+__cu_len)&0xF) flush_dcache_line((virt_to+__cu_len)&~0xF);
+
+    dma_from = virt_from;
+
+    // printk(KERN_ERR "dma transfer %X to %x len %X\n", __cu_from, __cu_to , __cu_len);
+
+    raw_local_irq_save(flag);
+
+    for (byte = 0, _n = __cu_len; byte < __cu_len;) 
+    {
+        int len = min(PAGE_SIZE - offset_into_page(virt_to + byte), _n);
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+        unsigned long pg_addr;
+        unsigned long dma_to;
+
+        pg_addr = (virt_to+byte) & PAGE_MASK; /* address of start page */
+
+        if (pg_addr > TASK_SIZE)
+            pgd = pgd_offset_k(pg_addr);
+        else
+            pgd = pgd_offset_gate(current->mm, pg_addr);
+        BUG_ON(pgd_none(*pgd));
+        pud = pud_offset(pgd, pg_addr);
+        BUG_ON(pud_none(*pud));
+        pmd = pmd_offset(pud, pg_addr);
+        if (pmd_none(*pmd)) 
+        {
+            printk(KERN_ERR "pmd_none\n");
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        pte = pte_offset_map(pmd, pg_addr);
+        if (pte_none(*pte)) {
+            pte_unmap(pte);
+            printk(KERN_ERR "pte_none\n");
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            goto unpin;
+        }
+        dma_to= (pte_val(*pte) & PAGE_MASK) + offset_into_page(virt_to + byte);
+        pte_unmap(pte);
+
+
+        if(dma_to<0x10000000 || dma_to>=0x30000000)
+        {
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+            em86_stats[14]+=__cu_len;
+            raw_local_irq_restore(flag);
+            printk(KERN_ERR "invalid copy to user %08X\n",dma_to);
+            goto unpin;
+        }
+        _n -= len;
+
+        while(len>0)
+        {
+            int curlen=len>0x1FFF ? 0x1FFF : len;
+
+            // printk(KERN_ERR "mbus transfer %X to %x len %X\n", dma_from+byte, dma_to, curlen);
+            
+            blast_dcache_range(dma_from+byte, dma_from+byte+curlen);
+            blast_inv_dcache_range(virt_to+byte, virt_to+byte+curlen);
+
+            while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+    
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac0, (dma_to) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac4, ((dma_to) & 0x3fff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ac8, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3acc, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3ad8, 0x5);
+            // Start VDEC0_MBUS_R2 
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b00, (dma_from+byte) & 0xffff);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b04, ((dma_from+byte) & 0x3fff0000) >> 16);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b08, len>0x1FFF ? 0x1FFF : len);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b0c, 0);
+            gbus_writel(DMEM_BASE_mpeg_engine_0 + 0x3b18, 0x5);
+            dma_to += curlen;
+            byte += curlen;
+            len-= curlen;
+        }
+    }
+    while ((gbus_readl(DMEM_BASE_mpeg_engine_0 + 0x3ad8) & 0x7) != 0);
+//	do_gettimeofday(&tv);
+//	t2=tv.tv_sec*1000000LL+tv.tv_usec;
+    raw_local_irq_restore(flag);
+//    em86dma_time+=(t2-t1);
+//    em86dma_csum_time+=(t2-t3);
+    em86_stats[0]+=__cu_len;
+    em86_stats[2]+=1;
+    t2=tangox_getxtal();
+    em86_stats[1]+=(t2-t1);
+unpin:
+    return _n;
+}
+
+EXPORT_SYMBOL(em86xx_mbus_alloc_dma);
+EXPORT_SYMBOL(em86xx_mbus_free_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma);
+EXPORT_SYMBOL(em86xx_mbus_setup_dma_void);
+EXPORT_SYMBOL(em86xx_mbus_wait);
+EXPORT_SYMBOL(em86xx_mbus_init);
+EXPORT_SYMBOL(mbus_setup_dma_linear);
+EXPORT_SYMBOL(mbus_setup_dma_double);
+EXPORT_SYMBOL(mbus_setup_dma_rectangle);
+EXPORT_SYMBOL(mbus_memcpy);
+
+EXPORT_SYMBOL(em86_stats);
+EXPORT_SYMBOL(memcpy);
+EXPORT_SYMBOL(__invoke_copy_to_user_dma);
diff -Naur linux-2.6.30-ori/arch/mips/tangox/platform.c linux-2.6.30-test/arch/mips/tangox/platform.c
--- linux-2.6.30-ori/arch/mips/tangox/platform.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/platform.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,191 @@
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/resource.h>
+#include <linux/mtd/physmap.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/hardware.h>
+#include <asm/tango3/tango3_gbus.h>
+#endif
+
+#define TANGOX_EHCI_BASE_ADDR           /*NON_CACHED*/(REG_BASE_host_interface + 0x1400)
+#define TANGOX_OHCI_BASE_ADDR           /*NON_CACHED*/(REG_BASE_host_interface + 0x1500)
+#define TANGOX_USB_CTL_STATUS_REG_BASE  /*NON_CACHED*/(REG_BASE_host_interface + 0x1700)
+#define TANGOX_EHCI_IRQ                 IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_EHCI_INT
+#define TANGOX_OHCI_IRQ                 IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_OHCI_INT
+
+/* OHCI (USB full speed host controller) */
+static struct resource tangox_usb_ohci_resources[] = {
+	[0] = {
+		.start		= TANGOX_OHCI_BASE_ADDR,
+		.end		= TANGOX_OHCI_BASE_ADDR + 0xFF,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= TANGOX_OHCI_IRQ,
+		.end		= TANGOX_OHCI_IRQ,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+/* The dmamask must be set for OHCI to work */
+static u64 ohci_dmamask = ~(u32)0;
+
+static struct platform_device tangox_usb_ohci_device = {
+	.name		= "tangox-ohci",
+	.id		= 0,
+	.dev = {
+		.dma_mask		= &ohci_dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(tangox_usb_ohci_resources),
+	.resource	= tangox_usb_ohci_resources,
+};
+
+/* EHCI (USB high speed host controller) */
+static struct resource tangox_usb_ehci_resources[] = {
+	[0] = {
+		.start		= TANGOX_EHCI_BASE_ADDR,
+		.end		= TANGOX_EHCI_BASE_ADDR + 0xFF,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= TANGOX_EHCI_IRQ,
+		.end		= TANGOX_EHCI_IRQ,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static u64 ehci_dmamask = ~(u32)0;
+
+static struct platform_device tangox_usb_ehci_device = {
+	.name		= "tangox-ehci",
+	.id		= 0,
+	.dev = {
+		.dma_mask		= &ehci_dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(tangox_usb_ehci_resources),
+	.resource	= tangox_usb_ehci_resources,
+};
+
+#define XENV_MAX_FLASH    4
+#define XENV_MAX_FLASH_PARTITIONS   16
+static struct mtd_partition *mtd_parts[XENV_MAX_FLASH] = { NULL, NULL, NULL, NULL };
+static unsigned int p_cnts[XENV_MAX_FLASH] = { 0, 0, 0, 0 };
+static unsigned int f_sizes[XENV_MAX_FLASH] = { 0, 0, 0, 0 };
+
+extern int tangox_flash_get_info(int cs, unsigned int *size, unsigned int *part_count);
+extern int tangox_flash_get_parts(int cs, unsigned int offset[], unsigned int size[]);
+
+static struct physmap_flash_data tangox_flash_data = {
+	.parts    = NULL,
+	.nr_parts = 0,
+	.width = 2, /* To be checked by PBI registers */
+};
+
+static struct resource tangox_flash_resource[XENV_MAX_FLASH] = {
+    {
+	.start = 0x48000000,
+	.end = 0, /* Found in XENV */
+	.flags = IORESOURCE_MEM,
+	}
+};
+
+static struct platform_device tangox_flash = {
+	.name          = "physmap-flash",
+	.id            = 0,
+	.dev           = { .platform_data = &tangox_flash_data, },
+	.resource      = &tangox_flash_resource,
+	.num_resources = 1,
+};
+
+static struct platform_device *tangox_platform_devices[] __initdata = {
+	&tangox_usb_ohci_device,
+	&tangox_usb_ehci_device,
+	&tangox_flash,
+};
+
+static int __init tangox_update_platform_flash(void)
+{
+	int cs;
+	int part_num = 0;
+	unsigned long csconfig = gbus_read_uint32(pGBus, REG_BASE_host_interface + PB_CS_config) & 0xf;
+
+	for (cs = 0; cs < 1; cs++) { // for now implement only 1 instead of XENV_MAX_FLASH 
+		/* Check XENV for availability */
+		f_sizes[cs] = p_cnts[cs] = 0;
+
+		tangox_flash_get_info(cs+2, &f_sizes[cs], &p_cnts[cs]);
+		if (f_sizes[cs] == 0)
+			continue;
+		else {
+			tangox_flash_resource[cs].end = tangox_flash_resource[cs].start + f_sizes[cs] - 1;
+			tangox_flash_data.width = ((csconfig >> cs) & 0x1) ? 1 : 2;
+		}
+
+		printk(KERN_INFO "physmap flash device CS%d: %lx at %lx\n", 
+				cs, f_sizes[cs], tangox_flash_resource[cs].start);
+
+#ifdef CONFIG_MTD_PARTITIONS
+		if (p_cnts[cs] > 0) {
+			int p, pcnt;
+			struct mtd_partition *part_ptr;
+			unsigned int offsets[XENV_MAX_FLASH_PARTITIONS];
+			unsigned int szs[XENV_MAX_FLASH_PARTITIONS];
+
+			if ((mtd_parts[cs] = (struct mtd_partition *)kmalloc(
+					sizeof(struct mtd_partition) * p_cnts[cs], GFP_KERNEL)) == NULL) {
+				printk(KERN_NOTICE "Out of memory.\n");
+				return -ENOMEM;
+			}
+			memset(mtd_parts[cs], 0, sizeof(struct mtd_partition) * p_cnts[cs]);
+			tangox_flash_get_parts(cs+2, offsets, szs);
+
+			printk(KERN_NOTICE "Using physmap partition definition\n");
+
+			/* Initialize each partition */
+			for (pcnt = 0, part_ptr = mtd_parts[cs], p = 0; p < p_cnts[cs]; p++) {
+				if (((szs[p] & 0x7fffffff) + offsets[p]) > f_sizes[cs]) {
+					printk(KERN_NOTICE "CS%d-Part%d (offset:0x%x, size:0x%x) outside physical map, removed.\n", 
+							cs, p + 1, offsets[p], szs[p] & 0x7fffffff);
+						continue;
+				}
+				part_ptr->size = szs[p] & 0x7fffffff;
+				part_ptr->offset = offsets[p];
+				if (part_ptr->size & 0x80000000)
+					part_ptr->mask_flags = MTD_WRITEABLE;
+				part_ptr->name = (char *)kmalloc(16, GFP_KERNEL); 
+				if (part_ptr->name != NULL) 
+					sprintf(part_ptr->name, "CS%d-Part%d", cs, p + 1);
+				pcnt++;
+				part_ptr++;
+			}
+			p_cnts[cs] = pcnt;
+
+			if (p_cnts[cs] > 0) {
+				printk(KERN_NOTICE "Adding partition #%d-#%d\n", part_num, part_num + p_cnts[cs] - 1);
+				tangox_flash_data.parts=mtd_parts[cs];
+				tangox_flash_data.nr_parts=p_cnts[cs];
+				part_num += p_cnts[cs];
+			}
+		}
+#endif
+	}
+	return 0;
+
+}
+
+int __init tangox_platform_init(void)
+{
+    tangox_update_platform_flash();
+    printk(KERN_INFO "Adding platform devices\n");
+	return platform_add_devices(tangox_platform_devices, ARRAY_SIZE(tangox_platform_devices));
+}
+
+arch_initcall(tangox_platform_init);
diff -Naur linux-2.6.30-ori/arch/mips/tangox/prom.c linux-2.6.30-test/arch/mips/tangox/prom.c
--- linux-2.6.30-ori/arch/mips/tangox/prom.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/prom.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,616 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <asm/bootinfo.h>
+#include <asm/page.h>
+#include <linux/module.h>
+
+#include "setup.h"
+
+#ifdef CONFIG_TANGO3
+#include "xenv.h"
+#include "xenvkeys.h"
+#endif
+
+/*
+ * em8xxx_sys_frequency may be used later in the serial  code, DON'T mark
+ * it as initdata
+ */
+unsigned long em8xxx_sys_frequency;
+unsigned long em8xxx_cpu_frequency;
+unsigned long em8xxx_kmem_start;
+unsigned long em8xxx_kmem_size;
+#ifdef CONFIG_TANGO3
+unsigned long phy_remap;
+unsigned long max_remap_size;
+#endif
+
+unsigned long tangox_chip_id(void);
+int is_tango2_chip(void);
+int is_tango3_chip(void);
+int is_tango3_es2(void);
+
+/*
+ * we will restore remap registers before rebooting
+ */
+#ifdef CONFIG_TANGO2
+unsigned long em8xxx_remap_registers[5];
+#elif defined(CONFIG_TANGO3)
+unsigned long em8xxx_remap_registers[8];
+#endif
+
+/*
+ * helper to access base registers
+ */
+#define RD_BASE_REG32(r)	\
+		gbus_readl(REG_BASE_system_block + (r))
+
+/*
+ * return system type (/proc/cpuinfo)
+ */
+const char *get_system_type(void)
+{
+	return "Sigma Designs TangoX";
+}
+
+/*
+ * return system frequency
+ */
+#ifdef CONFIG_TANGOX_SYS_FREQUENCY
+unsigned long tangox_get_sysclock(void)
+{
+	return(CONFIG_TANGOX_SYS_FREQUENCY);
+}
+#else
+unsigned long tangox_get_sysclock(void)
+{
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	unsigned long sys_clkgen_pll, sysclk_mux, sysclk_premux;
+	unsigned long n, m, freq, div, k, mux;
+
+	k = m = sys_clkgen_pll = 0;
+	sysclk_mux = RD_BASE_REG32(SYS_sysclk_mux);
+	sysclk_premux = RD_BASE_REG32(SYS_sysclk_premux);
+
+	switch (sysclk_premux & 0x3) {
+		case 0:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen0_pll);
+			m = (sys_clkgen_pll >> 16) & 0x1f;
+			k = (sys_clkgen_pll >> 14) & 0x3;
+			break;
+		case 1:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen1_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+		case 2:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen2_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+		case 3:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen3_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+	}
+	n = sys_clkgen_pll & 0x000003ff;
+
+	/* Not using XTAL_IN, cannot calculate */
+	if ((sys_clkgen_pll & 0x07000000) != 0x01000000)
+		return(0);
+
+	/* Calculate the divider */
+	mux = (sysclk_mux >> 8) & 0xf;
+	if (mux == 0) /* Get system clock frequency */
+		div = 2;
+	else if ((mux == 1) || ((mux >= 8) && (mux < 0xc)))
+		div = 4;
+	else if ((mux >= 2) && (mux < 8))
+		div = 3;
+	else
+		return(0); /* Wrong divider setting */
+
+	if (sysclk_mux & 0x1) 	/* PLL is used */
+		freq = ((TANGOX_BASE_FREQUENCY / (m + 2)) * (n + 2)) /
+			(div * (1 << k));
+	else
+		freq = TANGOX_BASE_FREQUENCY / div;
+#else
+	unsigned long sys_clkgen_pll, sysclk_mux, n, m, freq, div;
+
+	sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen_pll);
+	sysclk_mux = RD_BASE_REG32(SYS_sysclk_mux);
+	n = sys_clkgen_pll & 0x000003ff;
+	m = (sys_clkgen_pll & 0x003f0000) >> 16;
+
+	/* Calculate the divider */
+	if ((sysclk_mux & 0x300) == 0x000) /* Get system clock frequency */
+		div = 2;
+	else if ((sysclk_mux & 0x300) == 0x100)
+		div = 4;
+	else
+		div = 3;
+
+	if (sysclk_mux & 0x1) 	/* PLL is used */
+		freq = ((TANGOX_BASE_FREQUENCY / (m + 2)) * (n + 2)) / div;
+	else
+		freq = TANGOX_BASE_FREQUENCY / div;
+#endif
+	return(freq);
+}
+#endif
+
+/*
+ * return cpu frequency
+ */
+#ifdef CONFIG_TANGOX_CPU_FREQUENCY
+unsigned long tangox_get_cpuclock(void)
+{
+	return(CONFIG_TANGOX_CPU_FREQUENCY);
+}
+#else
+unsigned long tangox_get_cpuclock(void)
+{
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	unsigned long sys_clkgen_pll, sysclk_mux, sysclk_premux;
+	unsigned long n, m, freq, div, k, mux;
+
+	k = m = sys_clkgen_pll = 0;
+	sysclk_mux = RD_BASE_REG32(SYS_sysclk_mux);
+	sysclk_premux = RD_BASE_REG32(SYS_sysclk_premux);
+
+	switch(sysclk_premux & 0x3) {
+		case 0:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen0_pll);
+			m = (sys_clkgen_pll >> 16) & 0x1f;
+			k = (sys_clkgen_pll >> 14) & 0x3;
+			break;
+		case 1:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen1_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+		case 2:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen2_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+		case 3:
+			sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen3_pll);
+			m = (sys_clkgen_pll >> 16) & 0x7f;
+			break;
+	}
+	n = sys_clkgen_pll & 0x000003ff;
+
+	/* Not using XTAL_IN, cannot calculate */
+	if ((sys_clkgen_pll & 0x07000000) != 0x01000000)
+		return(0);
+
+	/* Calculate the divider */
+	mux = (sysclk_mux >> 8) & 0xf;
+	if ((mux == 3) || (mux == 4) || (mux == 6)) /* Get CPU frequency */
+		div = 3;
+	else if ((mux == 8) || (mux == 0xa))
+		div = 4;
+	else if ((mux == 0) || (mux == 1) || (mux == 2) ||
+		 (mux == 5) || (mux == 7) ||
+		 (mux == 9) || (mux == 0xb))
+		div = 2;
+	else
+		return(0); /* Wrong divider setting */
+
+	if (sysclk_mux & 0x1) 	/* PLL is used */
+		freq = ((TANGOX_BASE_FREQUENCY / (m + 2)) * (n + 2)) /
+			(div * (1 << k));
+	else
+		freq = TANGOX_BASE_FREQUENCY / div;
+#else
+	unsigned long sys_clkgen_pll, sysclk_mux, n, m, freq, div;
+
+	sys_clkgen_pll = RD_BASE_REG32(SYS_clkgen_pll);
+	sysclk_mux = RD_BASE_REG32(SYS_sysclk_mux);
+	n = sys_clkgen_pll & 0x000003ff;
+	m = (sys_clkgen_pll & 0x003f0000) >> 16;
+
+	if ((sysclk_mux & 0x300) == 0x300) /* Get CPU frequency */
+		div = 3;
+	else
+		div = 2;
+
+	/* Calculate the divider */
+	if (sysclk_mux & 0x1) 	/* PLL is used */
+		freq = ((TANGOX_BASE_FREQUENCY / (m + 2)) * (n + 2)) / div;
+	else
+		freq = TANGOX_BASE_FREQUENCY / div;
+#endif
+	return(freq);
+}
+#endif
+
+
+extern int do_syslog(int type, char * buf, int len);
+extern int __init xenv_config(void);
+extern void __init tangox_device_info(void);
+extern const char *tangox_xenv_cmdline(void);
+
+#ifdef CONFIG_TANGO3
+static inline unsigned long fixup_dram_address(unsigned long addr)
+{
+	if ((addr >= 0x10000000) && (addr < 0x20000000))
+		addr = (addr - 0x10000000) + 0x80000000; /* to DRAM0 */
+	else if ((addr >= 0x20000000) && (addr < 0x30000000))
+		addr = (addr - 0x20000000) + 0xc0000000; /* to DRAM1 */
+	return(addr);
+}
+#endif
+
+void __init prom_init(void)
+{
+	extern char _text;
+	unsigned long offset, em8xxx_kmem_end;
+	int clksel, xenv_res, i;
+	char *revStr = NULL;
+#ifdef CONFIG_TANGO2
+	memcfg_t *m;
+#endif
+
+	/*
+	 * save remap registers for reboot time
+	 */
+	for (i = 0; 
+#ifdef CONFIG_TANGO2
+		i < 5; 
+#elif defined(CONFIG_TANGO3)
+		i < 8; 
+#endif
+		i++) {
+		em8xxx_remap_registers[i] = gbus_readl(REG_BASE_cpu_block + CPU_remap + (i * 4));
+	}
+
+	/* 
+	 * Set remap so that 0x1fc00000 and 0x0 back to they should be...
+	 */
+	gbus_writel(REG_BASE_cpu_block + CPU_remap, 0x1fc00000);
+	gbus_writel(REG_BASE_cpu_block + CPU_remap1, 0x0);
+	iob();
+
+#ifdef CONFIG_TANGO3
+#define REMAP_IDX	(((CPU_REMAP_SPACE-CPU_remap2_address)/0x04000000)+2)
+	phy_remap = fixup_dram_address(em8xxx_remap_registers[REMAP_IDX]); 
+	max_remap_size = 0x04000000; /* minimum 64MB */
+	if (phy_remap != em8xxx_remap_registers[REMAP_IDX]) { /* fix up needed */ 
+		gbus_writel(REG_BASE_cpu_block + CPU_remap + REMAP_IDX * 4, phy_remap);
+		iob();
+	}
+	for (i = REMAP_IDX + 1; i < 8; i++) {
+		unsigned long newaddr = fixup_dram_address(em8xxx_remap_registers[i]);
+		if (newaddr == (phy_remap + (0x04000000 * (i - REMAP_IDX)))) {
+			max_remap_size += 0x04000000;
+			if (newaddr != em8xxx_remap_registers[i]) { /* fix up needed */
+				gbus_writel(REG_BASE_cpu_block + CPU_remap + i * 4, newaddr);
+				iob();
+			}
+		}
+	}
+	printk("Physcal map 0x%08lx to 0x%08x, max size is 0x%08lx\n",
+		phy_remap, CPU_REMAP_SPACE, max_remap_size);
+#endif
+	
+#if defined(CONFIG_TANGO2_SMP863X)
+	printk("Configured for SMP863%c (revision %s), ",
+#if defined(CONFIG_TANGO2_ES1)
+			'0', "ES1"
+#elif defined(CONFIG_TANGO2_ES2)
+			'0', "ES2"
+#elif defined(CONFIG_TANGO2_ES3)
+			'0', "ES3"
+#elif defined(CONFIG_TANGO2_ES4)
+			'4', "ES4"
+#elif defined(CONFIG_TANGO2_ES5)
+			'4', "ES5"
+#elif defined(CONFIG_TANGO2_ES6)
+			'x', "ES6+/RevA+"
+#elif defined(CONFIG_TANGO2_SD)
+			'x', "SD"
+#endif
+	      );
+#elif defined(CONFIG_TANGO3_SMP865X)
+	printk("Configured for SMP864x/SMP865x (revision %s), ",
+#if defined(CONFIG_TANGO3_ES1)
+			"ES1"
+#elif defined(CONFIG_TANGO3_ES2)
+			"ES2"
+#elif defined(CONFIG_TANGO3_ES3)
+			"ES3"
+#endif
+	      );
+#else
+#error Unsupported platform.
+#endif
+	printk("detected SMP%lx (revision ", (tangox_chip_id()>>16)&0xffff);
+	if (is_tango2_chip()) {
+		unsigned long revision = tangox_chip_id() & 0xff;
+		switch(revision) {
+			case 0x81: /* ES1-3 */
+				revStr = "ES1-3";
+				break;
+			case 0x82: /* ES4-5 */
+				revStr = "ES4-5";
+				break;
+			case 0x83: /* ES6/RevA */
+				revStr = "ES6/RevA";
+				break;
+			case 0x84: /* ES7/RevB */
+				revStr = "ES7/RevB";
+				break;
+			case 0x85: /* ES8 */
+				revStr = "ES8";
+				break;
+			case 0x86: /* ES9/RevC */
+				revStr = "ES9/RevC";
+				break;
+			default: /* Unknown */
+				revStr = "unknown";
+				break;
+		}
+	} else if (is_tango3_chip()) {
+		unsigned long revision = tangox_chip_id() & 0xff;
+		switch(revision) {
+			case 0x1: /* ES1 */
+				revStr = "ES1";
+				break;
+			case 0x2: /* ES2 */
+				revStr = "ES2";
+				break;
+			case 0x3: /* ES3 */
+				revStr = "ES3";
+				break;
+			default: /* Unknown */
+				revStr = "unknown";
+				break;
+		}
+	} else
+		revStr = "unknown";
+	
+	printk("%s).\n", revStr);
+	printk("Detected CPU/SYS Frequencies: %ld.%02ld/%ld.%02ldMHz\n",
+		tangox_get_cpuclock() / 1000000, (tangox_get_cpuclock() / 10000) % 100,
+		tangox_get_sysclock() / 1000000, (tangox_get_sysclock() / 10000) % 100);
+
+	/*
+	 * read xenv  configuration, we  need it quickly  to configure
+	 * console accordingly.
+	 *
+	 * NOTE: We  may stay STUCK in  this if safe  mode is required
+	 * and XENV is not valid !
+	 */
+	xenv_res = xenv_config();
+
+	/*
+	 * calculate cpu & sys frequency (may be needed for uart init)
+	 */
+	em8xxx_cpu_frequency = tangox_get_cpuclock();
+	em8xxx_sys_frequency = tangox_get_sysclock();
+
+	/*
+	 * program the right clock divider in both uart
+	 */
+#ifdef CONFIG_TANGOX_UART_USE_SYSCLK
+	clksel = 0;
+#else
+	clksel = 1;
+#endif
+	gbus_writel(REG_BASE_cpu_block + CPU_UART0_base + CPU_UART_CLKSEL, clksel);
+	if (is_tango3_es2()) {
+		/* for hwbug#291 */
+		i = gbus_readl(REG_BASE_cpu_block + CPU_UART0_base + CPU_UART_CLKSEL);
+		gbus_writel(REG_BASE_cpu_block + CPU_UART0_base + CPU_UART_CLKSEL, i);
+	}
+	gbus_writel(REG_BASE_cpu_block + CPU_UART1_base + CPU_UART_CLKSEL, clksel);
+	if (is_tango3_es2()) {
+		/* for hwbug#291 */
+		i = gbus_readl(REG_BASE_cpu_block + CPU_UART1_base + CPU_UART_CLKSEL);
+		gbus_writel(REG_BASE_cpu_block + CPU_UART1_base + CPU_UART_CLKSEL, i);
+	}
+
+	/*
+	 * show KERN_DEBUG message on console
+	 */
+	do_syslog(8, NULL, 8);
+
+#ifdef CONFIG_TANGOX_PROM_CONSOLE
+	/* initialize uart and register early console */
+	prom_console_register();
+#endif
+
+	/* warn user if we use failsafe values for xenv */
+	if (xenv_res)
+		printk("Invalid XENV content, using failsafe values\n");
+	tangox_device_info();
+
+	/*
+	 * compute kernel memory start address/size
+	 * _text section gives kernel address start
+	 */
+	em8xxx_kmem_start = ((unsigned long)(&_text)) & PAGE_MASK;
+	em8xxx_kmem_size = (((CONFIG_TANGOX_SYSTEMRAM_ACTUALSIZE << 20) + em8xxx_kmem_start) & 0xfff00000) - em8xxx_kmem_start;
+
+#ifdef CONFIG_TANGO3
+	if (em8xxx_kmem_size > max_remap_size)
+		em8xxx_kmem_size = max_remap_size;
+
+	em8xxx_kmem_end = KSEG1ADDR(em8xxx_kmem_start + em8xxx_kmem_size) - KSEG1ADDR(CPU_REMAP_SPACE);
+#else
+	em8xxx_kmem_end = KSEG1ADDR(em8xxx_kmem_start + em8xxx_kmem_size) - KSEG1ADDR(MEM_BASE_dram_controller_0_alias);
+#endif
+
+#ifdef CONFIG_TANGO3
+	/* Get information from LR_XENV2_RO and put information into LR_XENV2_RW */
+	xenv_set((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_KERNEL_END, &em8xxx_kmem_end, 0, sizeof(em8xxx_kmem_end)); 
+#else
+	/*
+	 * check/fill the memcfg
+	 */
+	m = (memcfg_t *)KSEG1ADDR(MEM_BASE_dram_controller_0_alias + FM_MEMCFG);
+	if (is_valid_memcfg(m) == 0) {
+		printk("Invalid MEMCFG, creating new one at 0x%08x.\n", MEM_BASE_dram_controller_0_alias + FM_MEMCFG);
+		memset(m, 0, sizeof (memcfg_t));
+		m->signature = MEMCFG_SIGNATURE;
+		m->dram0_size = TANGOX_SYSTEMRAM_ACTUALSIZE;
+		m->kernel_end = em8xxx_kmem_end;
+		gen_memcfg_checksum(m);
+	} else {
+		printk("Valid MEMCFG found at 0x%08x.\n", MEM_BASE_dram_controller_0_alias + FM_MEMCFG);
+		m->kernel_end = em8xxx_kmem_end + 512*1024;
+		gen_memcfg_checksum(m);
+	}
+#endif
+
+	/*
+	 * tell kernel about available memory size/offset
+	 */
+#ifdef CONFIG_TANGO3
+	offset = KSEG1ADDR(em8xxx_kmem_start) - KSEG1ADDR(CPU_REMAP_SPACE);
+	add_memory_region(CPU_REMAP_SPACE + offset, em8xxx_kmem_size, BOOT_MEM_RAM);
+#else
+	offset = KSEG1ADDR(em8xxx_kmem_start) - KSEG1ADDR(MEM_BASE_dram_controller_0_alias);
+	add_memory_region(MEM_BASE_dram_controller_0_alias + offset, em8xxx_kmem_size, BOOT_MEM_RAM);
+#endif
+
+#ifndef CONFIG_TANGOX_IGNORE_CMDLINE
+	/*
+	 * set up correct linux command line according to XENV, memcfg
+	 * and YAMON args, if not told to ignore them
+	 */
+
+	/* If specified by xenv, override the command line */
+	if (tangox_xenv_cmdline())
+		strcpy(arcs_cmdline, tangox_xenv_cmdline());
+
+	/* If specified by memcfg, override the command line */
+//	if (m->linux_cmd != 0 && strlen((char *)KSEG1ADDR(m->linux_cmd)) > 0)
+//disabled. e.m. 2006feb3rd		strcpy(arcs_cmdline, (char *)KSEG1ADDR(m->linux_cmd));
+
+	/* take regular args given by bootloader */
+	if ((fw_arg0 > 1) && (fw_arg0 < 65)) { /* Up to 64 arguments */
+		int argc, i, pos;
+		char **argv;
+
+		argc = fw_arg0;
+		arcs_cmdline[0] = '\0';
+		argv = (char **) fw_arg1;
+		pos = 0;
+		for (i = 1; i < argc; i++) {
+			int len;
+
+			len = strlen(argv[i]);
+			if (pos + 1 + len + 1 > sizeof (arcs_cmdline))
+				break;
+			if (pos)
+				arcs_cmdline[pos++] = ' ';
+			strcpy(arcs_cmdline + pos, argv[i]);
+			pos += len;
+		}
+	}
+#endif /* CONFIG_TANGOX_IGNORE_CMDLINE */
+
+	mips_machtype = MACH_TANGOX;
+}
+
+void __init prom_free_prom_memory(void)
+{
+}
+
+EXPORT_SYMBOL(tangox_get_sysclock);
+EXPORT_SYMBOL(tangox_get_cpuclock);
+
+unsigned long tangox_chip_id(void)
+{
+	return (((gbus_readl(REG_BASE_host_interface + PCI_REG0) & 0xffff) << 16) |
+                        (gbus_readl(REG_BASE_host_interface + PCI_REG1) & 0xff));
+}
+
+int is_tango2_chip(void)
+{
+	unsigned long chip = (tangox_chip_id()>>16) & 0xfff0;
+	return (chip == 0x8630) ? 1 : 0;
+}
+
+static inline int is_tango2_revision(unsigned char revid)
+{
+	unsigned char rev = tangox_chip_id() & 0xff;
+	return (is_tango2_chip() && rev == revid) ? 1 : 0;
+}
+
+int is_tango2_es123(void)
+{
+	return(is_tango2_revision(0x81));
+}
+
+int is_tango2_es45(void)
+{
+	return(is_tango2_revision(0x82));
+}
+
+int is_tango2_es6(void)
+{
+	return(is_tango2_revision(0x83));
+}
+
+int is_tango2_es7(void)
+{
+	return(is_tango2_revision(0x84));
+}
+
+int is_tango2_es89(void)
+{
+	return(is_tango2_revision(0x85) || is_tango2_revision(0x86));
+}
+
+static inline int is_tango3_revision(unsigned char revid)
+{
+	unsigned char rev = tangox_chip_id() & 0xff;
+	return (is_tango3_chip() && rev == revid) ? 1 : 0;
+}
+
+int is_tango3_chip(void)
+{
+	unsigned long chip = (tangox_chip_id()>>16) & 0xfff0;
+	return ((chip == 0x8640) || (chip == 0x8650)) ? 1 : 0;
+}
+
+int is_tango3_es1(void)
+{
+	return(is_tango3_revision(0x1));
+}
+
+int is_tango3_es2(void)
+{
+	return(is_tango3_revision(0x2));
+}
+
+int is_tango3_es3(void)
+{
+	return(is_tango3_revision(0x3));
+}
+
+EXPORT_SYMBOL(tangox_chip_id);
+EXPORT_SYMBOL(is_tango2_chip);
+EXPORT_SYMBOL(is_tango3_chip);
+EXPORT_SYMBOL(is_tango2_es123);
+EXPORT_SYMBOL(is_tango2_es45);
+EXPORT_SYMBOL(is_tango2_es6);
+EXPORT_SYMBOL(is_tango2_es7);
+EXPORT_SYMBOL(is_tango2_es89);
+EXPORT_SYMBOL(is_tango3_es1);
+EXPORT_SYMBOL(is_tango3_es2);
+EXPORT_SYMBOL(is_tango3_es3);
+#ifdef CONFIG_TANGO3
+EXPORT_SYMBOL(phy_remap);
+EXPORT_SYMBOL(max_remap_size);
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/setup.c linux-2.6.30-test/arch/mips/tangox/setup.c
--- linux-2.6.30-ori/arch/mips/tangox/setup.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/setup.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,426 @@
+/*
+ * Copyright (C) 2007 Sigma Designs, inc.
+ * Copyright 2001 MontaVista Software Inc.
+ * Author: Jun Sun, jsun@mvista.com or jsun@junsun.net
+ *
+ * arch/mips/tangox/setup.c
+ *     The setup file for tango2/tango3.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/serial_8250.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <asm/reboot.h>
+#include <asm/io.h>
+#include <asm/cacheflush.h>
+#include <asm/time.h>
+#include <asm/serial.h>
+
+#include "setup.h"
+
+#if defined(CONFIG_TANGO2) && defined(CONFIG_TANGOX_USE_TLB_REMAP_DRAM1)
+extern unsigned long em86xx_tlb_dram1_map_base;
+extern unsigned long em86xx_tlb_dram1_map_size;
+#endif
+
+/*
+ * helpers to access cpu block registers
+ */
+#define RD_CPU_REG32(r)	\
+		gbus_readl(REG_BASE_cpu_block + (r))
+
+#define WR_CPU_REG32(r, v)	\
+		gbus_writel(REG_BASE_cpu_block + (r), (v))
+
+
+#ifdef CONFIG_TANGO2
+/*
+ * we use xrpc to reboot
+*/
+struct xrpc_block_header {
+	u32 callerid;
+	u32 xrpcid;
+
+	u32 param0;
+	u32 param1;
+	u32 param2;
+	u32 param3;
+	u32 param4;
+
+	u32 headerandblocksize;
+};
+
+#define XRPC_ID_REBOOT		19
+#define SOFT_IRQ_XRPC		(1 << 4)
+#endif
+
+void tangox_machine_restart(char *command)
+{
+	unsigned long tmp;
+	int i;
+#ifdef CONFIG_TANGO2
+ 	struct xrpc_block_header *pB;
+	unsigned long base_addr;
+	int loop;
+#endif
+
+        printk("Entered tangox_machine_restart\n");
+        local_irq_disable();
+
+#ifndef CONFIG_TANGOX_USE_CPU_CLOCK
+        /* Disable timer */
+	WR_CPU_REG32(CPU_time0_clr, 1);
+#endif
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+	/* Resetting TangoX EHCI */
+	tmp = gbus_read_uint32(pGBus, REG_BASE_host_interface + 0x1410);
+	tmp &= ~1;
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1410, tmp);
+	mdelay(5);
+
+	/* Resetting TangoX OHCI */
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1514, 1<<31);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1504, 0);
+	mdelay(5);
+
+	/* Resetting internal USB PHY in USB Control space */
+	tmp = gbus_read_uint32(pGBus, REG_BASE_host_interface + 0x1700);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1700, tmp | 1);
+	udelay(30);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1700, tmp);
+	mdelay(5);
+
+	/* Resetting internal OHCI in USB OHCI space*/
+	tmp = gbus_read_uint32(pGBus, REG_BASE_host_interface + 0x1508);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1508, tmp | 0x01);
+
+	/* Reseting OHCI dpll, it says the bit is for simulation */
+	tmp = gbus_read_uint32(pGBus, REG_BASE_host_interface + 0x1700);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x1700, tmp | (1<<19));
+	mdelay(1);
+#endif
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) 
+	/* Resetting ethernet interface */
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x7018, 0);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x701c, 0);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + 0x7000, 1);
+	for (i = 0; (i < 10) && (gbus_read_uint32(pGBus, REG_BASE_host_interface + 0x7000) & 1); i++)
+		mdelay(1);
+
+	/* Resetting Video, MPEG0/MPEG1 blocks */ 
+	gbus_writel(REG_BASE_display_block + G2L_RESET_CONTROL, 3);
+	gbus_writel(REG_BASE_mpeg_engine_0 + G2L_RESET_CONTROL, 3);
+	gbus_writel(REG_BASE_mpeg_engine_1 + G2L_RESET_CONTROL, 3);
+	udelay(1);
+	gbus_writel(REG_BASE_mpeg_engine_0 + G2L_RESET_CONTROL, 2);
+	gbus_writel(REG_BASE_display_block + G2L_RESET_CONTROL, 2);
+	gbus_writel(REG_BASE_mpeg_engine_1 + G2L_RESET_CONTROL, 2);
+
+	/* Resetting Transport demux block */
+	gbus_writel(REG_BASE_demux_engine + G2L_RESET_CONTROL, 3);
+	udelay(1);
+	gbus_writel(REG_BASE_demux_engine + G2L_RESET_CONTROL, 2);
+
+	/* Resetting Audio0/1, host interface blocks */
+	gbus_writel(REG_BASE_audio_engine_0 + G2L_RESET_CONTROL, 3);
+	gbus_writel(REG_BASE_audio_engine_1 + G2L_RESET_CONTROL, 3);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + G2L_RESET_CONTROL, 3);
+	udelay(1);
+	gbus_writel(REG_BASE_audio_engine_0 + G2L_RESET_CONTROL, 2);
+	gbus_writel(REG_BASE_audio_engine_1 + G2L_RESET_CONTROL, 2);
+	gbus_write_uint32(pGBus, REG_BASE_host_interface + G2L_RESET_CONTROL, 2);
+#endif
+
+	/* restore remap registers to boot state */
+	for (i = 0; 
+#ifdef CONFIG_TANGO2
+		i < 5; 
+#elif defined(CONFIG_TANGO3)
+		i < 8; 
+#endif
+		i++) {
+		gbus_writel(REG_BASE_cpu_block + CPU_remap + i * 4, em8xxx_remap_registers[i]);
+	}
+	iob();
+
+	/* Now to handle CPU side */
+
+#ifdef CONFIG_TANGO3
+	/* Using watchdog to trigger reset here */
+	gbus_writeb(REG_BASE_system_block + SYS_watchdog_configuration + 3, 0x80); 
+	gbus_writeb(REG_BASE_system_block + SYS_watchdog_configuration, 0x1); /* Use XTAL_IN as source */
+
+	/* For ~100 usec delay */
+	gbus_writel(REG_BASE_system_block + SYS_watchdog_counter, TANGOX_BASE_FREQUENCY / 10000);
+	gbus_writeb(REG_BASE_system_block + SYS_watchdog_configuration + 3, 0); /* Start counting */
+#else
+	/* nowhere to  jump, everything is  in xload format,  lets ask
+	 * xpu to reboot */
+	base_addr = DMEM_BASE_audio_engine_0;
+
+	pB = (struct xrpc_block_header *)base_addr;
+	gbus_writel((unsigned long)&pB->callerid, 0);
+	gbus_writel((unsigned long)&pB->headerandblocksize,
+		    (sizeof(struct xrpc_block_header) + 63) & ~63);
+	gbus_writel((unsigned long)&pB->xrpcid, XRPC_ID_REBOOT);
+	gbus_writel((unsigned long)&pB->param0, 0);
+	gbus_writel((unsigned long)&pB->param1, 0);
+	gbus_writel((unsigned long)&pB->param2, 0);
+	gbus_writel((unsigned long)&pB->param3, 0);
+	gbus_writel((unsigned long)&pB->param4, 0);
+
+	/* try to lock xrpc mutex for at most 1 sec */
+        while(gbus_readl((RMuint32)XRPC_MUTEX));
+/*	for (loop = 0; loop < 1000; loop++) {
+		if (!gbus_readl((RMuint32)XRPC_MUTEX))
+                {
+			printk("got xrpc mutex\n");
+			break;
+                }
+		mdelay(1);
+	}*/
+	gbus_writel(REG_BASE_cpu_block + LR_XPU_STAGE, (unsigned long)pB);
+
+	/* cross our fingers now */
+	gbus_writel(REG_BASE_irq_handler_block + CPU_irq_softset,
+		    SOFT_IRQ_XRPC);
+#endif
+        printk("infinite loop\n");
+	while (1);
+}
+
+void tangox_machine_halt(void)
+{
+	while (1);
+}
+
+void tangox_machine_power_off(void)
+{
+	while (1);
+}
+
+void __init plat_time_init(void)
+{
+#ifndef CONFIG_TANGOX_USE_CPU_CLOCK
+	mips_hpt_frequency = em8xxx_cpu_frequency / 2;
+#else
+	/* FIXME:  we  will  need  to  unset this  if  we  reduce  cpu
+	 * frequency at runtime,  since gettimeoffset will then starts
+	 * to return bogus value */
+	mips_hpt_frequency = em8xxx_cpu_frequency / 2;
+#endif
+	/* Clear heart beat counter */
+	WR_CPU_REG32(LR_HB_CPU, 0);
+}
+
+/*
+ * two variants for linux system timer , we can use internal cpu timer
+ * or hw timer0
+ */
+#ifndef CONFIG_TANGOX_USE_CPU_CLOCK
+/*
+ * CPU_time0_load
+ *  clock / HZ / (2 * prescale)
+ * CPU_time0_ctrl
+ *  PS(D2-3) : prescale. 0x00 = 1, 0x01 = 16, 0x10 = 256
+ *    There is a bug, and the actual prescale is 0x01 = 32, 0x10 = 512
+ *  M(D6) : periodic mode
+ *  E(D7) : enable
+ */
+/*#define TICKS_PER_SEC           em8xxx_sys_frequency
+#define TIMER_PRESCALE          32
+#define TIMER_PRESCALEBITS      5
+#define TIMER_RELOAD            ((TICKS_PER_SEC / HZ) >> (TIMER_PRESCALEBITS))
+
+#define TIMER_ENABLE            0x80    // D7
+#define TIMER_PERIODIC          0x40    // D6
+#define TIMER_PRESCALE_1        0x00    // D[2-3] = 00b
+#define TIMER_PRESCALE_32       0x04    // D[2-3] = 01b
+#define TIMER_PRESCALE_512      0x08    // D[2-3] = 10b
+
+static void tangox_timer_ack(void)
+{
+	gbus_writel(REG_BASE_cpu_block + CPU_time0_clr, 1);
+}
+*/
+/*
+ * Setup Timer0 as the source
+ */
+/*static void __init tangox_timer_setup(struct irqaction *irq)
+{*/
+	/* CPU_time0_load  register contains  just  16-bits value  So,
+	   take cate not the value to overflow */
+/*	WR_CPU_REG32(CPU_time0_load, TIMER_RELOAD);
+	WR_CPU_REG32(CPU_time0_ctrl, TIMER_ENABLE | TIMER_PERIODIC |
+		     TIMER_PRESCALE_32);
+	WR_CPU_REG32(CPU_time0_clr, 1);
+
+	setup_irq(LOG2_CPU_TIMER0_INT + IRQ_CONTROLLER_IRQ_BASE, irq);
+*/
+	/* set ack callback */
+/*	mips_timer_ack = tangox_timer_ack;*/
+
+	/* Clear heart beat counter */
+/*	WR_CPU_REG32(LR_HB_CPU, 0);
+}*/
+#else
+/*
+ * Setup CPU timer as source
+ */
+/*static void __init tangox_timer_setup(struct irqaction *irq)
+{
+	setup_irq(MIPS_CPU_IRQ_BASE + STATUSB_IP7 - STATUSB_IP0, irq);
+*/
+	/* Clear heart beat counter */
+/*	WR_CPU_REG32(LR_HB_CPU, 0);
+}*/
+#endif /* CONFIG_TANGOX_USE_CPU_CLOCK */
+
+
+/*
+ * setup remap registers, we may need  to use ioremap() so we can't do
+ * this in plat_setup, this function is set as arch_initcall().
+ */
+static int __init tangox_remap_setup(void)
+{
+#if defined(CONFIG_TANGO2) && defined(CONFIG_TANGOX_USE_TLB_REMAP_DRAM1)
+	memcfg_t *m;
+#endif
+
+#if defined(CONFIG_TANGO2) 
+	/*
+	 * Program CPU_remap so we can see full 256MB space in KSEG0 /
+	 * KSEG1
+	 */
+#if defined(CONFIG_TANGOX_USE_TLB_REMAP_DRAM1)
+	/*
+	 * Use TLB mapping to map the DRAM1 (size specified by memcfg)
+	 * into KSEG2
+	 */
+	m = (memcfg_t *)KSEG1ADDR(MEM_BASE_dram_controller_0 + FM_MEMCFG);
+
+	if (m->dram1_size) {
+		em86xx_tlb_dram1_map_size = ((m->dram1_size > 0x20000000) ? 
+			0x20000000 : m->dram1_size); /* Max. 512MB */
+		em86xx_tlb_dram1_map_base =
+			(unsigned long)ioremap(MEM_BASE_dram_controller_1,
+					       m->dram1_size);
+		printk("tangox: creating TLB mapping for 0x%08x at 0x%08lx, "
+		       "size 0x%08lx.\n", MEM_BASE_dram_controller_1,
+		       em86xx_tlb_dram1_map_base, em86xx_tlb_dram1_map_size);
+	} else {
+		printk("tangox: dram1 size is 0, _not_ creating mapping\n");
+	}
+#else
+	/*
+	 * Use remap strategy (CPU_remap3/4 for 128MB resolution)
+	 */
+	printk("tangox: creating CPU mapping for 0x%08x at 0x%08x, "
+	       "size 0x%08x.\n", MEM_BASE_dram_controller_1,
+	       CPU_remap3_address, 0x08000000);
+
+	/*
+	 * remap dram controller 1 at 0x08000000 -> 0x0fffffff (128MB)
+	 * so Linux can see it in KSEG[01]
+	 */
+	gbus_writel(REG_BASE_cpu_block + CPU_remap3,
+		    MEM_BASE_dram_controller_1);
+	gbus_writel(REG_BASE_cpu_block + CPU_remap4,
+		    MEM_BASE_dram_controller_1 + 0x04000000);
+	iob();
+#endif
+#endif
+
+	return 0;
+}
+
+arch_initcall(tangox_remap_setup);
+
+extern int tangox_uart_enabled(int uart);
+extern int tangox_uart_baudrate(int uart);
+extern int tangox_uart_console_port(void);
+
+void __init plat_mem_setup(void)
+{
+#ifdef CONFIG_SERIAL_8250
+	int i;
+#endif
+
+	_machine_restart = tangox_machine_restart;
+	_machine_halt = tangox_machine_halt;
+	pm_power_off = tangox_machine_power_off;
+
+#ifdef CONFIG_SERIAL_8250
+	/*
+	 * register enable uart(s)
+	 */
+	if (tangox_uart_console_port()) { /* Console on UART1 */
+		for (i = 1; i >= 0; i--) {
+			struct uart_port uart;
+
+			if (!tangox_uart_enabled(i))
+				continue;
+
+			memset(&uart, 0, sizeof (uart));
+			uart.line = 1 - i; /* Reverse the order so it's UART1/UART0 instead of UART0/UART1 */
+			uart.uartclk = tangox_uart_baudrate(i) << 4;
+			uart.irq = IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_UART0_INT + i;
+			uart.flags = UPF_BOOT_AUTOCONF | UPF_SHARE_IRQ;
+			uart.membase = (unsigned char *)(REG_BASE_cpu_block +
+					CPU_UART0_base + i * 0x100);
+			uart.mapbase = (unsigned char *)(REG_BASE_cpu_block +
+					CPU_UART0_base + i * 0x100);
+			uart.iotype = UPIO_MEM;
+			uart.regshift = 2;
+
+			if (early_serial_setup(&uart))
+				printk("early_serial_setup failed\n");
+		}
+	} else {
+		for (i = 0; i < 2; i++) {
+			struct uart_port uart;
+
+			if (!tangox_uart_enabled(i))
+				continue;
+
+			memset(&uart, 0, sizeof (uart));
+			uart.line = i;
+			uart.uartclk = tangox_uart_baudrate(i) << 4;
+			uart.irq = IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_UART0_INT + i;
+			uart.flags = UPF_BOOT_AUTOCONF | UPF_SHARE_IRQ;
+			uart.membase = (unsigned char *)(REG_BASE_cpu_block +
+					CPU_UART0_base + i * 0x100);
+			uart.mapbase = (unsigned char *)(REG_BASE_cpu_block +
+					CPU_UART0_base + i * 0x100);
+			uart.iotype = UPIO_MEM;
+			uart.regshift = 2;
+
+			if (early_serial_setup(&uart))
+				printk("early_serial_setup failed\n");
+		}
+	}
+#endif
+
+	/*
+	 * set I/O /mem regions limit
+	 */
+	ioport_resource.start = 0;
+	ioport_resource.end = 0x80000000UL - 1;
+	iomem_resource.start = 0;
+	iomem_resource.end = 0x80000000UL - 1;
+
+	// This was called in the IDE driver but we always need it
+	em86xx_mbus_init();
+}
diff -Naur linux-2.6.30-ori/arch/mips/tangox/setup.h linux-2.6.30-test/arch/mips/tangox/setup.h
--- linux-2.6.30-ori/arch/mips/tangox/setup.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/setup.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,68 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ * misc vars/func shared by platform setup code
+ */
+
+#ifndef __SETUP_H
+#define __SETUP_H
+
+#ifdef CONFIG_TANGO2
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO2
+#include <linux/interrupt.h>
+#include <asm/tango2/rmem86xxid.h>
+#include <asm/tango2/rmdefs.h>
+#include <asm/tango2/emhwlib_dram.h>
+#include <asm/tango2/tango2_gbus.h>
+#include <asm/tango2/tango2.h>
+#include <asm/tango2/tango2api.h>
+#include <asm/tango2/memcfg.h>
+#elif defined(CONFIG_TANGO3)
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO3
+#include <linux/interrupt.h>
+#include <asm/tango3/rmem86xxid.h>
+#include <asm/tango3/rmdefs.h>
+#include <asm/tango3/emhwlib_dram.h>
+#include <asm/tango3/tango3_gbus.h>
+#include <asm/tango3/tango3.h>
+#include <asm/tango3/tango3api.h>
+#include <asm/tango3/hardware.h>
+#else
+#error "Unknown architecture"
+#endif
+
+/*
+ * in console.c
+ */
+void prom_console_register(void);
+
+/*
+ * in prom.c
+ */
+extern unsigned long em8xxx_cpu_frequency;
+extern unsigned long em8xxx_sys_frequency;
+#ifdef CONFIG_TANGO2
+extern unsigned long em8xxx_remap_registers[5];
+#elif defined(CONFIG_TANGO3)
+extern unsigned long em8xxx_remap_registers[8];
+#endif
+unsigned long tangox_get_cpuclock(void);
+unsigned long tangox_get_sysclock(void);
+
+/*
+ * in irq.c
+ */
+void tangox_dispatch(int ipline);
+
+/*
+ * in tangoxIRQ.S
+ */
+extern asmlinkage void tangoxIRQ(void);
+
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/tangox/sha.c linux-2.6.30-test/arch/mips/tangox/sha.c
--- linux-2.6.30-ori/arch/mips/tangox/sha.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/sha.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,110 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/crypto.h>
+#include <linux/cryptohash.h>
+#include <asm/scatterlist.h>
+#include <asm/byteorder.h>
+#include <crypto/sha.h>
+
+#include "sha.h"
+
+static void tangosha1_init(struct sha1_ctx *sctx)
+{
+	static const struct sha1_ctx initstate = {
+	  0,
+	  { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },
+	  { 0, }
+	};
+
+	*sctx = initstate;
+}
+
+static void tangosha1_update(struct sha1_ctx *sctx, const u8 *data,
+			unsigned int len)
+{
+	unsigned int partial, done;
+	const u8 *src;
+
+	partial = sctx->count & 0x3f;
+	sctx->count += len;
+	done = 0;
+	src = data;
+
+	if ((partial + len) > 63) {
+		u32 temp[SHA_WORKSPACE_WORDS];
+
+		if (partial) {
+			done = -partial;
+			memcpy(sctx->buffer + partial, data, done + 64);
+			src = sctx->buffer;
+		}
+
+		do {
+			sha_transform(sctx->state, src, temp);
+			done += 64;
+			src = data + done;
+		} while (done + 63 < len);
+
+		memset(temp, 0, sizeof(temp));
+		partial = 0;
+	}
+	memcpy(sctx->buffer + partial, src, len - done);
+}
+
+
+
+/* Add padding and return the message digest. */
+
+static void tangosha1_final(struct sha1_ctx *sctx, u8 *out)
+{
+	__be32 *dst = (__be32 *)out;
+	u32 i, index, padlen;
+	__be64 bits;
+	static const u8 padding[64] = { 0x80, };
+
+	bits = cpu_to_be64(sctx->count << 3);
+
+	/* Pad out to 56 mod 64 */
+	index = sctx->count & 0x3f;
+	padlen = (index < 56) ? (56 - index) : ((64+56) - index);
+	tangosha1_update(sctx, padding, padlen);
+
+	/* Append length */
+	tangosha1_update(sctx, (const u8 *)&bits, sizeof(bits));
+
+	/* Store state in digest */
+	for (i = 0; i < 5; i++)
+		dst[i] = cpu_to_be32(sctx->state[i]);
+
+	/* Wipe context */
+	memset(sctx, 0, sizeof *sctx);
+}
+
+#ifdef CONFIG_CRYPTO_SHA1
+void __init sha1_full(u8 *digest, const u8 *src, u32 len)
+{
+	struct sha1_ctx ctx;
+	int i;
+	u8 tmp;
+	tangosha1_init(&ctx);
+	tangosha1_update(&ctx, src, len);
+	tangosha1_final(&ctx, digest);
+
+	for (i = 0; i < SHA1_DIGEST_SIZE / 2; i++) {
+		tmp = digest[i];
+		digest[i] = digest[SHA1_DIGEST_SIZE - i - 1];
+		digest[SHA1_DIGEST_SIZE - i - 1] = tmp;
+	}
+}
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/tangox/sha.h linux-2.6.30-test/arch/mips/tangox/sha.h
--- linux-2.6.30-ori/arch/mips/tangox/sha.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/sha.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,29 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __SHA_H__
+#define __SHA_H__
+
+#ifdef CONFIG_CRYPTO_SHA1
+#define SHA1_DIGEST_SIZE        20
+
+struct sha1_ctx {
+	u64 count;
+        u32 state[5];
+        u8 buffer[64];
+};
+
+/*void sha1_init(struct crypto_tfm *tfm);
+void sha1_update(struct crypto_tfm *tfm, const u8 *data, unsigned int len);
+void sha1_final(struct crypto_tfm *tfm, u8 *out);*/
+#endif
+
+#endif
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/xenv.c linux-2.6.30-test/arch/mips/tangox/xenv.c
--- linux-2.6.30-ori/arch/mips/tangox/xenv.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/xenv.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,270 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include "setup.h"
+#include "xenv.h"
+#include "sha.h"
+
+#if defined(CONFIG_TANGO3)
+#include <asm/tango3/rmdefs.h>
+#endif
+
+#if 0
+# define DPRINTK(fmt, args...)	printk(KERN_DEBUG "xenv: " fmt, ## args)
+#else
+# define DPRINTK(fmt, args...)
+#endif
+
+#if defined(CONFIG_TANGO2)
+#define XENV_DIGEST_SIZE   SHA1_DIGEST_SIZE
+void sha1_full(u8 *digest, const u8 *src, u32 len);
+#elif defined(CONFIG_TANGO3)
+#define XENV_DIGEST_SIZE   SHA256_DIGEST_SIZE
+void sha256_full(u8 *digest, const u8 *src, u32 len);
+#endif
+
+#define XENV_HDR_SIZE      (XENV_DIGEST_SIZE + 4)
+#define REC_SIZE(x)	   ((((u16)x[0] & 0xff) << 8) | ((u16)x[1] & 0xff))
+#define REC_ATTR(x)	   ((x[0] & 0xff) >> 4)
+
+#define xos_strlen(x)	   strlen(x)
+#define xos_strcmp(x,y)	   strcmp(x,y)
+#define xos_memcpy(x,y,z)  memcpy(x,y,z)
+
+void __init xenv_digest_full(u8 *digest, const u8 *src, u32 len)
+{
+#if defined(CONFIG_TANGO2)
+	sha1_full(digest, src, len);
+#elif defined(CONFIG_TANGO3)
+	sha256_full(digest, src, len);
+#endif
+}
+
+/*
+ * check for valid XENV at given address
+ */
+int __init xenv_isvalid(u32 *base, u32 maxsize)
+{
+	u32 env_size = base[0];
+	u32 hash[XENV_DIGEST_SIZE/4];
+
+	if ((24 <= env_size) && (env_size <= maxsize)) {
+		memset(hash, 0, sizeof (hash));
+		xenv_digest_full((u8 *)hash, (const u8 *)(base + (XENV_HDR_SIZE / 4)), env_size - XENV_HDR_SIZE);
+		if (memcmp((const u8 *)(base + 1), hash, XENV_DIGEST_SIZE) != 0) {
+			DPRINTK("corrupted\n");
+			return -1;
+		}
+
+		/* valid xenv ! */
+		return env_size;
+	}
+
+	DPRINTK("runaway %d\n", env_size);
+	return -1;
+}
+
+int __init xenv_foreach(u32 *base, u32 size,
+			void (*cb)(char *recordname, void *data, u32 datasize))
+{
+	int i;
+
+	/* jump over first header */
+	i = XENV_HDR_SIZE;
+
+	/* loop on each record name */
+	while (i < size) {
+		u16 rec_size;
+		char *p, *recordname;
+		void *data;
+		u32 key_len, data_len;
+
+		p = (char *)base + i;
+		rec_size = REC_SIZE(p);
+		recordname = p + 2;
+		key_len = strlen(recordname);
+		data = recordname + key_len + 1;
+		data_len = rec_size - 2 - key_len - 1;
+
+		cb(recordname, data, data_len);
+		i += rec_size;
+	}
+
+	return -1;
+}
+
+#ifdef CONFIG_TANGO3
+/* Use this to set xenv to lrrw */
+static int __init xenv_lookup(RMuint32 *base,RMuint32 size,RMascii *recordname)
+{
+	RMascii *p;
+	int i;
+	int env_size;
+	
+	env_size=xenv_isvalid((u32 *)base,size);
+	
+	if (env_size<0) 
+		return -2;
+	
+	// RMDBGLOG((LOCALDBG, "[%s]\n",recordname));
+	
+	p=(RMascii *)base;
+	i=XENV_HDR_SIZE; 			// jump over header
+	
+	while(i<env_size){
+		RMuint16 rec_size=((p[i]&0xf)<<8) + (((RMuint16)p[i+1])&0xff);
+
+		if (!xos_strcmp(recordname, p+i+2)) 
+			return i;
+		
+		i+=rec_size;
+	}
+	
+	return -1;
+}
+
+/* Use this to get xenv to lrrw/lrro */
+int __init xenv_get(u32 *base, u32 size, char *recordname, void *dst, u32 *datasize)
+{
+	RMascii *p = (RMascii *)base;
+	RMuint32 data_len;
+	RMuint32 key_len;
+	RMuint32 env_size;
+	
+	int i;	
+	
+	env_size=base[0];
+	i = xenv_lookup((RMuint32 *)base, size, recordname);
+	if(i==-2) 
+		return -2 /* RM_ERROR */;
+	if(i==-1) 
+		return -1 /* RM_NOT_FOUND */;
+
+	// else we found the record
+	key_len=xos_strlen(recordname);
+	data_len=((p[i] & 0xf)<<8) + (((RMuint32)p[i+1])&0xff);
+	data_len-=2+key_len+1;
+	
+	if(data_len>*datasize) {
+		*datasize=data_len;
+
+		// RMDBGLOG((ENABLE,"cannot store result\n"));
+		return -3 /* RM_INSUFFICIENT_SIZE */;
+	}
+	
+	*datasize=data_len;
+	xos_memcpy(dst, p+i+2+key_len+1, data_len);
+
+	// RMDBGLOG((LOCALDBG, "found [%s], length %d\n",recordname,*datasize));
+
+	return 0 /* RM_OK */;
+}
+
+int __init xenv_set(u32 *base, u32 size, char *recordname, void *src, u8 attr, u32 datasize)
+{
+	RMascii *p;
+	RMuint32 env_size;
+	RMuint32 rec_attr;
+	RMuint32 rec_size;
+	RMuint32 key_len;
+	int i;
+
+	// RMDBGLOG((LOCALDBG, "[%s], length %d\n", recordname,datasize));
+	
+	p=(RMascii *)base;
+	i = xenv_lookup((RMuint32 *)base, size, recordname);
+	if(i==-2) 
+		return -1 /* RM_ERROR */;
+	env_size=base[0];
+
+	if(i>=0) {
+		// RMDBGLOG((LOCALDBG, "deleting record\n"));
+		
+		rec_attr=p[i]>>4;
+		rec_size=((p[i]&0xf)<<8) + (((RMuint32)p[i+1])&0xff);
+			
+#if 0
+		if ((rec_attr==XENV_ATTR_RO)&&src) {
+			// RMDBGLOG((ENABLE,"wanna change ro record\n"));
+			return RM_INVALIDMODE;
+		}
+		
+		if (rec_attr==XENV_ATTR_OTP) {
+			// RMDBGLOG((ENABLE,"wanna change/clear otp record\n"));
+			return RM_INVALIDMODE;
+		}
+#endif
+
+		// delete the record. Supposes memcpy is implemented increasing.
+		xos_memcpy(p+i, p+i+rec_size, env_size-(i+rec_size));
+		env_size-=rec_size;
+	}
+		
+	// add the record at the end if needed.
+	if(src) {
+		i=env_size;
+		key_len=xos_strlen(recordname);
+		rec_size=2+key_len+1+datasize;
+
+		if((i+rec_size)>=size)
+			return -3 /* RM_INSUFFICIENT_SIZE */;
+		
+		p[i]=((attr&0xf)<<4) | ((rec_size>>8)&0xf);
+		p[i+1]=rec_size&0xff;
+		
+		xos_memcpy(p+i+2, recordname, key_len+1);
+		xos_memcpy(p+i+2+key_len+1, src, datasize);
+		
+		env_size+=rec_size;
+	}
+	
+	base[0]=env_size;
+	//full_sha256(base+1,(const RMuint8 *)(base+9),env_size-36,0);
+	xenv_digest_full((u8 *)(base+1), (const u8 *)(base + (XENV_HDR_SIZE / 4)), env_size - XENV_HDR_SIZE);
+
+	return 0 /* RM_OK */;
+}
+#endif
+
+#ifdef CONFIG_TANGOX_XENV_DUMP
+void __init xenv_dump(u32 *base, u32 size)
+{
+	int i;
+	u32 records = 0;
+
+	printk("@%p\n", base);
+
+	/* jump over first header */
+	i = XENV_HDR_SIZE;
+
+	while (i < size){
+		u8 rec_attr;
+		u16 rec_size;
+		char *p, *recordname, *x;
+		u32 key_len;
+
+		p = (char *)base + i;
+		rec_attr = REC_ATTR(p);
+		rec_size = REC_SIZE(p);
+		recordname = p + 2;
+		key_len = strlen(recordname);
+
+		printk("(0x%02x) [%s] =", rec_attr, recordname);
+		for (x = recordname + key_len + 1;
+		     x < recordname + rec_size - 2; x++)
+			printk(" %02x", (u8)*x);
+		printk(" .\n");
+
+		records++;
+		i += rec_size;
+	}
+
+	printk("%d records, %d bytes\n\n", records, size);
+}
+#endif
diff -Naur linux-2.6.30-ori/arch/mips/tangox/xenv.h linux-2.6.30-test/arch/mips/tangox/xenv.h
--- linux-2.6.30-ori/arch/mips/tangox/xenv.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/xenv.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,97 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/**
+  @file   xenv.h
+  @brief
+
+  The prototypes below act on a clear area respecting the xenv format.
+
+  (De)ciphering the  area, as well as committing  the changes (writing
+  the area to flash) are trivial add-ons on top of this API.
+
+  The underlying  implementation is not optimized for  speed (read and
+  write in  O(nrecords)). There  is no fragmentation  (data completely
+  rearranged at each write).
+
+  It is  not advised to repeatedly  act on flash stored  data, for the
+  device does  not support  unlimited read/write operations  (refer to
+  spec)
+
+  Power  loss when  committing the  changes cause  loss of  the stored
+  data.  This  can be avoided  by storing the  same data twice  to two
+  different sectors.
+
+  --------------------------------------------------------------------------
+  Specification   of   a   secure   storage   on   serial   flash   of
+  reboot-persistent data (xenv format)
+
+  We  describe a  way  to  concatenate (at  most  4KByte area  (12bits
+  limit)) variable  length records identified  by a string,  the `key'
+  (working much like Windows registry)
+
+  Page, seen as a byte array, is
+
+  0          4                   24                 env_size         4KB
+  | env_size | SHA-1 of following | rec0 | rec1 | .. | recn | xx xx .. |
+
+  The SHA-1 extent is env_size-24.
+
+  Description of a rec (bytes):
+
+  |4bits   12bits (2bytes)   | variable, NULL terminated | variable         |
+  attr     total record size   record name (string)        record value
+
+  attr =
+   XENV_ATTR_RW
+   XENV_ATTR_RO can be written once only but can be deleted
+   XENV_ATTR_OTP this record can be written once only and cannot be deleted
+  --------------------------------------------------------------------------
+
+  @author Emmanuel Michon
+  @date   2005-05-17
+*/
+
+#ifndef __XENV_H__
+#define __XENV_H__
+
+#include "setup.h"
+
+#define MAX_XENV_SIZE   16384
+
+/**
+   Check for compliance with xenv format
+
+   May be corrupted by:
+   - forgot to format
+   - power loss during sflash write
+   - intrusion
+
+   @param base
+   @param size
+   @return -ReturnValue-: env_size>=0 if valid, -1 if not.
+*/
+int xenv_isvalid(u32 *base, u32 maxsize);
+
+int xenv_foreach(u32 *base, u32 size,
+		 void (*cb)(char *recordname, void *data, u32 datasize));
+
+int xenv_get(u32 *base, u32 size, char *recordname, void *dst, u32 *datasize);
+int xenv_set(u32 *base, u32 size, char *recordname, void *src, u8 attr, u32 datasize);
+
+void xenv_dump(u32 *base, u32 size);
+
+#ifdef CONFIG_TANGO3
+/*
+ * XENV sizes LRRO/LRRW
+ */
+#define MAX_LR_XENV2_RO 768
+#define MAX_LR_XENV2_RW 768
+#endif
+
+#endif // __XENV_H__
diff -Naur linux-2.6.30-ori/arch/mips/tangox/xenv_config.c linux-2.6.30-test/arch/mips/tangox/xenv_config.c
--- linux-2.6.30-ori/arch/mips/tangox/xenv_config.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/xenv_config.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,669 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ * Check and  read full xenv config  at boot if valid,  else will stop
+ * boot process or use failsafe values.
+ */
+
+#include "setup.h"
+#include "xenv.h"
+#include "xenvkeys.h"
+
+#include <linux/module.h>
+#include <asm/bootinfo.h>
+
+/*
+ * use CPU_remap1 to access XENV content
+ */
+#define TMP_REMAPPED_REG   CPU_remap1
+#define TMP_REMAPPED_BASE  CPU_remap1_address
+#define TMP_REMAPPED_SIZE  0x00010000
+#define TMP_REMAPPED_MASK  ~(TMP_REMAPPED_SIZE-1)
+
+/*
+ * cached values of xenv content
+ */
+#define XENV_MAX_FLASH_PARTITIONS   16
+
+/*
+ * default is  to have one  partition on each  flash at offset  0 that
+ * span all the flash. If CONFIG_TANGOX_XENV_DEF_CSx_SIZE is set to 0,
+ * cs will be ignored.
+ */
+#ifdef CONFIG_TANGOX_XENV_READ_SAFE
+/* The data will be filled from XENV later */
+static u32 cs_flash_size[4] = { 0, 0, 0, 0 };
+static u32 flash_parts_size[4][XENV_MAX_FLASH_PARTITIONS] = { { 0 }, { 0 }, { 0 }, { 0 }, };
+static u32 enabled_devices = 0;
+static u32 uart_baudrate = 0;
+static u32 uart_baudrates[2] = { 0, 0 };
+static u32 uart_used_ports = 0;
+static u32 pcidev_irq_route[4] = { 0, 0, 0, 0 };
+static u32 uart_console_port = 0;
+#else
+static u32 cs_flash_size[4] = {
+	CONFIG_TANGOX_XENV_DEF_CS0_SIZE,
+	CONFIG_TANGOX_XENV_DEF_CS1_SIZE,
+	CONFIG_TANGOX_XENV_DEF_CS2_SIZE,
+	CONFIG_TANGOX_XENV_DEF_CS3_SIZE
+};
+
+static u32 flash_parts_size[4][XENV_MAX_FLASH_PARTITIONS] = {
+	{ CONFIG_TANGOX_XENV_DEF_CS0_SIZE },
+	{ CONFIG_TANGOX_XENV_DEF_CS1_SIZE },
+	{ CONFIG_TANGOX_XENV_DEF_CS2_SIZE },
+	{ CONFIG_TANGOX_XENV_DEF_CS3_SIZE },
+};
+
+static u32 enabled_devices =
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID1 
+	(CONFIG_TANGOX_XENV_DEF_PCI_ID1 << PCI1_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID2 
+	(CONFIG_TANGOX_XENV_DEF_PCI_ID2 << PCI2_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID3 
+	(CONFIG_TANGOX_XENV_DEF_PCI_ID3 << PCI3_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID4 
+	(CONFIG_TANGOX_XENV_DEF_PCI_ID4 << PCI4_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_ENET 
+	(CONFIG_TANGOX_XENV_DEF_ENET << ETHERNET_SHIFT) |
+#else
+	0 | 
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_FIP 
+	(CONFIG_TANGOX_XENV_DEF_FIP << FIP_SHIFT) |
+#else 
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_I2CM 
+	(CONFIG_TANGOX_XENV_DEF_I2CM << I2CM_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_I2CS 
+	(CONFIG_TANGOX_XENV_DEF_I2CS << I2CS_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_BMIDE 
+	(CONFIG_TANGOX_XENV_DEF_BMIDE << BMIDE_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_ISAIDE 
+	(CONFIG_TANGOX_XENV_DEF_ISAIDE << ISAIDE_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_IR 
+	(CONFIG_TANGOX_XENV_DEF_IR << IR_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCIHOST
+	(CONFIG_TANGOX_XENV_DEF_PCIHOST << PCIHOST_SHIFT) |
+#else
+	0 |
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_USB 
+	(CONFIG_TANGOX_XENV_DEF_USB << USB_SHIFT)
+#else
+	0
+#endif
+	;
+
+static u32 uart_baudrate = CONFIG_TANGOX_XENV_DEF_BAUDRATE;
+static u32 uart_baudrates[2] = { CONFIG_TANGOX_XENV_DEF_BAUDRATE, CONFIG_TANGOX_XENV_DEF_BAUDRATE };
+
+static u32 uart_used_ports = 
+#ifdef CONFIG_TANGOX_XENV_DEF_UART0
+		1 +
+#else
+		0 +
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_UART1
+		1;
+#else
+		0;
+#endif
+
+static u32 pcidev_irq_route[4] = { 
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID1_IRQ
+	CONFIG_TANGOX_XENV_DEF_PCI_ID1_IRQ,
+#else
+	0,
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID2_IRQ
+	CONFIG_TANGOX_XENV_DEF_PCI_ID2_IRQ,
+#else
+	0,
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID3_IRQ
+	CONFIG_TANGOX_XENV_DEF_PCI_ID3_IRQ,
+#else
+	0,
+#endif
+#ifdef CONFIG_TANGOX_XENV_DEF_PCI_ID4_IRQ 
+	CONFIG_TANGOX_XENV_DEF_PCI_ID4_IRQ 
+#else
+	0
+#endif
+};
+
+static u32 uart_console_port = CONFIG_TANGOX_XENV_DEF_CONSOLE_UART_PORT;
+#endif
+
+static u32 cs_flash_parts[4] = { 1, 1, 1, 1 };
+static u32 flash_parts_offset[4][XENV_MAX_FLASH_PARTITIONS] = { { 0 }, { 0 }, { 0 }, { 0 }, };
+static u32 scard_off_pin = 0;
+static u32 scard_cmd_pin = 0;
+static u32 scard_5v_pin = 0;
+#ifdef CONFIG_TANGO3
+static u32 scard1_off_pin = 0;
+static u32 scard1_cmd_pin = 0;
+static u32 scard1_5v_pin = 0;
+#endif
+static u32 isaide_timing_slot = 0;
+static u32 isaide_irq = 0;
+
+static u32 xenv_gbus_addr = 0;
+
+/* mac address to use if xenv is not readable  */
+static const u8 def_mac_address[6] = { 0x48, 0x4a, 0xe5, 0x00, 0x00, 0x01 };
+static u8 mac_address[6];
+#ifdef CONFIG_TANGO3
+static u8 mac_address1[6];
+#endif
+
+static char xenv_cmdline[CL_SIZE] = { 0 };
+
+static u32 gpioled = 24;
+static u32 hdmioutput = 0;
+
+#ifdef CONFIG_TANGOX_XENV_READ
+/*
+ * called for each entry found in xenv
+ */
+void __init xenv_val_cb(char *recordname, void *data, u32 datasize)
+{
+	char buf[64];
+	int i;
+
+#define CHECK_AND_STORE(_key, _reqlen, _var)				\
+	if (!strcmp(_key, recordname) && datasize <= _reqlen)	{	\
+		memcpy(&_var, data, _reqlen);				\
+		return;							\
+	}
+
+	CHECK_AND_STORE("sagetv.hdmi", 4, hdmioutput);
+	CHECK_AND_STORE("sagetv.led", 4, gpioled);
+
+	CHECK_AND_STORE(XENV_KEY_ENABLED_DEVICES, 4, enabled_devices);
+	CHECK_AND_STORE(XENV_KEY_DEF_BAUDRATE, 4, uart_baudrate);
+	CHECK_AND_STORE(XENV_KEY_UART_USED_PORTS, 4, uart_used_ports);
+	CHECK_AND_STORE(XENV_KEY_CONSOLE_UART_PORT, 4, uart_console_port);
+
+	if (uart_console_port == 0) /* for backward compatibility */
+		uart_used_ports |= 1;
+
+	for (i = 0; i < 2; i++) {
+		sprintf(buf, XENV_KEYS_UART_BAUDRATE, i);
+		CHECK_AND_STORE(buf, 4, uart_baudrates[i]);
+	}
+
+	if (uart_baudrate == 0)
+		uart_baudrate = 115200; /* default 115200 */
+	if (uart_baudrates[0] == 0)
+		uart_baudrates[0] = uart_baudrate;
+	if (uart_baudrates[1] == 0)
+		uart_baudrates[1] = uart_baudrate;
+
+	for (i = 1; i < 5; i++) {
+		sprintf(buf, XENV_KEYS_PCI_IRQ_ROUTE, i);
+		CHECK_AND_STORE(buf, 4, pcidev_irq_route[i - 1]);
+	}
+
+	CHECK_AND_STORE(XENV_KEY_SCARD_OFF, 4, scard_off_pin);
+	CHECK_AND_STORE(XENV_KEY_SCARD_5V, 4, scard_5v_pin);
+	CHECK_AND_STORE(XENV_KEY_SCARD_CMD, 4, scard_cmd_pin);
+#ifdef CONFIG_TANGO3
+	CHECK_AND_STORE(XENV_KEY_SCARD1_OFF, 4, scard1_off_pin);
+	CHECK_AND_STORE(XENV_KEY_SCARD1_5V, 4, scard1_5v_pin);
+	CHECK_AND_STORE(XENV_KEY_SCARD1_CMD, 4, scard1_cmd_pin);
+#endif
+
+	for (i = 0; i < 4; i++) {
+		int j;
+
+		sprintf(buf, XENV_KEYS_CS_SIZE, i);
+		CHECK_AND_STORE(buf, 4, cs_flash_size[i]);
+
+		sprintf(buf, XENV_KEYS_CS_PARTS, i);
+		CHECK_AND_STORE(buf, 4, cs_flash_parts[i]);
+
+		for (j = 1; j < XENV_MAX_FLASH_PARTITIONS; j++) {
+
+			sprintf(buf, XENV_KEYS_CS_PART_SIZE, i, j);
+			CHECK_AND_STORE(buf, 4, flash_parts_size[i][j - 1]);
+
+			sprintf(buf, XENV_KEYS_CS_PART_OFFSET, i, j);
+			CHECK_AND_STORE(buf, 4, flash_parts_offset[i][j - 1]);
+		}
+	}
+
+	CHECK_AND_STORE(XENV_KEY_ISAIDE_IRQ_ROUTE, 4, isaide_irq);
+	CHECK_AND_STORE(XENV_KEY_ISAIDE_TIMING_SLOT, 4, isaide_timing_slot);
+
+	if (!strcmp(recordname, XENV_KEY_LINUX_CMD) &&
+	    datasize <= sizeof (xenv_cmdline) - 1) {
+		memcpy(xenv_cmdline, data, datasize);
+		xenv_cmdline[datasize] = 0;
+	}
+}
+
+/*
+ * try to read config from XENV
+ */
+static int __init xenv_read_content(void)
+{
+	unsigned long xenv_addr;
+	int xenv_size;
+	uint32_t mac_lo, mac_hi;
+
+	/*
+	 * fetch XENV address
+	 */
+#ifdef CONFIG_TANGO3
+	unsigned int size, tmp;
+	xenv_gbus_addr = xenv_addr = gbus_readl(REG_BASE_cpu_block + LR_ZBOOTXENV_LOCATION);
+#else
+	xenv_gbus_addr = xenv_addr = gbus_readl(REG_BASE_cpu_block + LR_XENV_LOCATION);
+#endif
+	if (!xenv_addr)
+		return 1;
+
+	/*
+	 * got the xenv address in  gbus form, now convert it in remap
+	 * form so we can access it
+	 */
+	gbus_writel(REG_BASE_cpu_block + TMP_REMAPPED_REG, xenv_addr & TMP_REMAPPED_MASK);
+	iob();
+	xenv_addr = KSEG1ADDR(TMP_REMAPPED_BASE) + (xenv_addr & (TMP_REMAPPED_SIZE-1));
+
+	/*
+	 * check xenv sanity
+	 */
+	xenv_size = xenv_isvalid((u32 *)xenv_addr, MAX_XENV_SIZE);
+	if (xenv_size < 0) {
+		xenv_gbus_addr = xenv_addr = 0;
+		return 1;
+	}
+
+#ifdef CONFIG_TANGOX_XENV_DUMP
+	xenv_dump((u32 *)xenv_addr, xenv_size);
+#endif
+
+	/*
+	 * ok, we can start to load each wanted value
+	 */
+	xenv_foreach((u32 *)xenv_addr, xenv_size, xenv_val_cb);
+
+	/*
+	 * load remaining values
+	 */
+#ifdef CONFIG_TANGO3
+	/* Getting information from LR_XENV2_RW */
+	mac_hi = mac_lo = 0x0;
+	if ((xenv_get((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_ETH_MACL, &tmp, &size) == 0) && (size == sizeof(unsigned int))) {
+		mac_lo = tmp;
+		if ((xenv_get((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_ETH_MACH, &tmp, &size) == 0) && (size == sizeof(unsigned int))) 
+			mac_hi = tmp;
+	}
+	mac_hi = cpu_to_be32(mac_hi);
+	mac_lo = cpu_to_be32(mac_lo);
+	memcpy(mac_address, (u8 *)&mac_hi + 2, 2);
+	memcpy(mac_address + 2, &mac_lo, 4);
+
+	mac_hi = mac_lo = 0x0;
+	if ((xenv_get((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_ETH1_MACL, &tmp, &size) == 0) && (size == sizeof(unsigned int))) {
+		mac_lo = tmp;
+		if ((xenv_get((void *)KSEG1ADDR(REG_BASE_cpu_block + LR_XENV2_RW), MAX_LR_XENV2_RW, XENV_LRRW_ETH1_MACH, &tmp, &size) == 0) && (size == sizeof(unsigned int))) 
+			mac_hi = tmp;
+	}
+	mac_hi = cpu_to_be32(mac_hi);
+	mac_lo = cpu_to_be32(mac_lo);
+	memcpy(mac_address1, (u8 *)&mac_hi + 2, 2);
+	memcpy(mac_address1 + 2, &mac_lo, 4);
+#else
+	mac_hi = gbus_readl(REG_BASE_cpu_block + LR_ETH_MAC_HI);
+	mac_lo = gbus_readl(REG_BASE_cpu_block + LR_ETH_MAC_LO);
+	mac_hi = cpu_to_be32(mac_hi);
+	mac_lo = cpu_to_be32(mac_lo);
+	memcpy(mac_address, (u8 *)&mac_hi + 2, 2);
+	memcpy(mac_address + 2, &mac_lo, 4);
+#endif
+
+	return 0;
+}
+#endif
+
+/*
+ * load default values and try to fetch xenv content
+ */
+int __init xenv_config(void)
+{
+#ifndef CONFIG_TANGOX_XENV_READ
+	/* will use default values */
+	return 0;
+#else
+	/*
+	 * try to load XENV content
+	 */
+	if (xenv_read_content() == 0) {
+		/* ok */
+		return 0;
+	}
+
+#ifndef CONFIG_TANGOX_XENV_READ_SAFE
+	/* fallback to failsafe values */
+	return 1;
+#else
+	/* stop boot process */
+	while (1)
+		cpu_relax();
+	/* not reached */
+	return 1;
+#endif
+
+#endif /* !CONFIG_TANGOX_XENV_READ */
+}
+
+
+/*
+ * helpers to access xenv configuration cached data
+ */
+
+/*
+ * enabled device query function
+ */
+#define BUILD_ENABLED(name, shift)					\
+int tangox_##name##_enabled(void)					\
+{									\
+	return (((enabled_devices >> shift) & 1) != 0) ? 1 : 0;	\
+} \
+EXPORT_SYMBOL(tangox_##name##_enabled);
+
+BUILD_ENABLED(isaide, ISAIDE_SHIFT)
+BUILD_ENABLED(bmide, BMIDE_SHIFT)
+BUILD_ENABLED(ir, IR_SHIFT)
+BUILD_ENABLED(fip, FIP_SHIFT)
+BUILD_ENABLED(usb, USB_SHIFT)
+BUILD_ENABLED(sdio, SDIO_SHIFT)
+BUILD_ENABLED(i2cm, I2CM_SHIFT)
+BUILD_ENABLED(i2cs, I2CS_SHIFT)
+BUILD_ENABLED(pci_host, PCIHOST_SHIFT)
+BUILD_ENABLED(sata, SATA_SHIFT)
+BUILD_ENABLED(gnet, GNET_SHIFT)
+
+int tangox_scard_enabled(int i)					
+{									
+#ifdef CONFIG_TANGO3
+	if (i != 0)
+		return((enabled_devices >> SCARD1_SHIFT) & 1) ? 1 : 0;
+#endif
+	return((enabled_devices >> SCARD_SHIFT) & 1) ? 1 : 0;
+}
+
+int tangox_ethernet_enabled(int i)					
+{									
+#ifdef CONFIG_TANGO3
+	if (i != 0)
+		return((enabled_devices >> ETHERNET1_SHIFT) & 1) ? 1 : 0;
+#endif
+	return((enabled_devices >> ETHERNET_SHIFT) & 1) ? 1 : 0;
+}
+
+int tangox_pcidev_enabled(int idsel)
+{
+	if (!tangox_pci_host_enabled())
+		return 0;
+
+	idsel--;
+	return (((enabled_devices >> (idsel + PCI1_SHIFT)) & 1) != 0) ? 1 : 0;
+}
+
+int tangox_pcidev_irq_map(int pci_idsel, int int_num)
+{
+	int route;
+	int irq;
+
+	route = pcidev_irq_route[pci_idsel - 1];
+
+	/* int_num: 0-3 = INTA-D */
+	irq = (int)((route >> (int_num * 8)) & 0x3);
+	if (irq >= 0)
+		irq += (IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_PCI_INTA);
+	return irq;
+}
+
+int tangox_isaide_irq_map(void)
+{
+	int irq = 0;
+
+	if (tangox_isaide_enabled() == 0)
+		return(-1);
+	irq = isaide_irq;
+	if (irq >= 0)
+		irq += (IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_PCI_INTA);
+	return irq;
+}
+
+int tangox_isaide_cs_select(void)
+{
+        int i;
+        unsigned long cs_config = (gbus_readl(REG_BASE_host_interface + PB_CS_config) >> 12) & 0xf;
+
+        if (tangox_isaide_enabled() == 0)
+                return(-1);
+
+        for (i = 0; i < 4; i++) {
+                if ((cs_config & 0x1) != 0)
+                        return(i);
+                else
+                        cs_config >>= 1;
+        }
+        return(-1);
+}
+
+int tangox_isaide_timing_slot(void)
+{
+        return(isaide_timing_slot & 0x7);
+}
+
+EXPORT_SYMBOL(tangox_isaide_irq_map);
+EXPORT_SYMBOL(tangox_isaide_cs_select);
+EXPORT_SYMBOL(tangox_isaide_timing_slot);
+EXPORT_SYMBOL(tangox_scard_enabled);
+EXPORT_SYMBOL(tangox_ethernet_enabled);
+
+int tangox_ethernet_getmac(int idx, unsigned char *mac)
+{
+#ifdef CONFIG_TANGO3
+	if (idx != 0) {
+		/* filter broadcast & multicast addresses */
+		if (mac_address1[0] == 0x01 || mac_address1[0] == 0xff)
+			memcpy(mac, def_mac_address, 6);
+		else
+			memcpy(mac, mac_address1, 6);
+		return 0;
+	}
+#endif
+	/* filter broadcast & multicast addresses */
+	if (mac_address[0] == 0x01 || mac_address[0] == 0xff)
+		memcpy(mac, def_mac_address, 6);
+	else
+		memcpy(mac, mac_address, 6);
+	return 0;
+}
+
+int tangox_uart_baudrate(int uart)
+{
+	return uart_baudrates[uart];
+}
+
+int tangox_uart_console_port(void)
+{
+	return uart_console_port;
+}
+
+int tangox_uart_enabled(int uart)
+{
+	return (((uart_used_ports >= 2) || (uart_console_port == uart)) ? 1 : 0);
+}
+
+int tangox_flash_get_info(int cs, unsigned int *size, unsigned int *part_count)
+{
+	if (cs > 3)
+		return 1;
+
+	*size = cs_flash_size[cs];
+	*part_count = 0;
+	if (cs_flash_size[cs] > 0)
+		*part_count = cs_flash_parts[cs];
+
+	return 0;
+}
+
+int tangox_flash_get_parts(int cs, unsigned int offset[], unsigned int size[])
+{
+	int i;
+
+	if (!cs_flash_size[cs])
+		return 1;
+
+	for (i = 0; i < cs_flash_parts[cs]; i++) {
+		offset[i] = flash_parts_offset[cs][i];
+		size[i] = flash_parts_size[cs][i];
+	}
+
+	return 0;
+}
+
+const char *tangox_xenv_cmdline(void)
+{
+	/* remove "" from command line */
+	if (xenv_cmdline[0] == '"') {
+		int len;
+
+		len = strlen(xenv_cmdline);
+		if (xenv_cmdline[len - 1] == '"')
+			xenv_cmdline[len - 1] = 0;
+		return xenv_cmdline + 1;
+	}
+	return xenv_cmdline;
+}
+
+int tangox_get_scard_info(int scard_no, int *pin_5v, int *pin_cmd, int *pin_off)
+{
+#ifdef CONFIG_TANGO3
+	if (scard_no != 0) {
+		*pin_5v = scard1_5v_pin;
+		*pin_off = scard1_off_pin;
+		*pin_cmd = scard1_cmd_pin;
+		return 0;
+	}
+#endif
+	*pin_5v = scard_5v_pin;
+	*pin_off = scard_off_pin;
+	*pin_cmd = scard_cmd_pin;
+	return 0;
+}
+
+/*
+ * show enabled devices according to xenv content
+ */
+void __init tangox_device_info(void)
+{
+	int i;
+
+	if (!xenv_gbus_addr) 
+		return;
+
+	printk(KERN_INFO "SMP863x/SMP865x Enabled Devices under Linux/"
+	       "XENV 0x%08x = 0x%08x\n", xenv_gbus_addr, enabled_devices);
+
+	printk(KERN_INFO);
+	if (tangox_isaide_enabled())
+		printk(" ISA/IDE");
+	if (tangox_bmide_enabled())
+		printk(" BM/IDE");
+	if (tangox_pci_host_enabled())
+		printk(" PCIHost");
+	if (tangox_ethernet_enabled(0))
+		printk(" Ethernet");
+#ifdef CONFIG_TANGO3
+	if (tangox_ethernet_enabled(1))
+		printk(" Ethernet1");
+#endif
+	if (tangox_ir_enabled())
+		printk(" IR");
+	if (tangox_fip_enabled())
+		printk(" FIP");
+	if (tangox_i2cm_enabled())
+		printk(" I2CM");
+	if (tangox_i2cs_enabled())
+		printk(" I2CS");
+	if (tangox_sdio_enabled())
+		printk(" SDIO");
+	if (tangox_usb_enabled())
+		printk(" USB");
+	for (i = 1; i <= 6; i++) {
+		if (tangox_pcidev_enabled(i))
+			printk(" PCIDev%d", i);
+	}
+	if (tangox_sata_enabled())
+		printk(" SATA");
+	if (tangox_scard_enabled(0))
+		printk(" SCARD");
+#ifdef CONFIG_TANGO3
+	if (tangox_scard_enabled(1))
+		printk(" SCARD1");
+#endif
+	if (tangox_gnet_enabled())
+		printk(" GNET");
+	printk("\n");
+}
+
+EXPORT_SYMBOL(tangox_ethernet_getmac);
+EXPORT_SYMBOL(tangox_get_scard_info);
+
+int tangox_get_hdmioutput(void)
+{
+    return hdmioutput;
+}
+
+int tangox_get_gpioled(void)
+{
+    return gpioled;
+}
+
+EXPORT_SYMBOL(tangox_get_hdmioutput);
+EXPORT_SYMBOL(tangox_get_gpioled);
+
diff -Naur linux-2.6.30-ori/arch/mips/tangox/xenvkeys.h linux-2.6.30-test/arch/mips/tangox/xenvkeys.h
--- linux-2.6.30-ori/arch/mips/tangox/xenvkeys.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/arch/mips/tangox/xenvkeys.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,182 @@
+
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/* 
+ * The keys defined in XENV, more can be added.
+ */
+
+#ifndef __XENV_KEYS_H__
+#define __XENV_KEYS_H__
+
+#define XENV_KEY_BOARD_ID           "a.board_id"
+#define XENV_KEY_CHIP_REV           "a.chip_rev"
+
+#define XENV_KEY_PREMUX             "a.premux"
+#define XENV_KEY_AVCLK_MUX          "a.avclk_mux"
+#define XENV_KEY_HOSTCLK_MUX        "a.hostclk_mux"
+#define XENV_KEY_IRQ_RISE_EDGE_LO   "a.irq_rise_edge_lo"
+#define XENV_KEY_IRQ_FALL_EDGE_LO   "a.irq_fall_edge_lo"
+#define XENV_KEY_GPIO_IRQ_MAP       "a.gpio_irq_map"
+
+#define XENV_KEY_DEF_BAUDRATE       "a.baudrate"
+#define XENV_KEY_CONSOLE_UART_PORT  "a.uart_console_port"
+#define XENV_KEY_UART_USED_PORTS    "a.uart_used_ports"
+
+#define XENV_KEY_PB_CS_CONFIG       "a.pb_cs_config"
+#ifdef CONFIG_TANGO3
+#define XENV_KEY_PB_CS_CONFIG1      "a.pb_cs_config1"
+#define XENV_KEY_PB_CS_CTRL         "a.pb_cs_ctrl"
+#endif
+#define XENV_KEY_DEF_TIMING         "a.pb_def_timing"
+#define XENV_KEY_PB_TIMING0         "a.pb_timing0"
+#define XENV_KEY_PB_USE_TIMING0     "a.pb_use_timing0"
+#define XENV_KEY_PB_TIMING1         "a.pb_timing1"
+#define XENV_KEY_PB_USE_TIMING1     "a.pb_use_timing1"
+#define XENV_KEY_PB_TIMING2         "a.pb_timing2"
+#define XENV_KEY_PB_USE_TIMING2     "a.pb_use_timing2"
+#define XENV_KEY_PB_TIMING3         "a.pb_timing3"
+#define XENV_KEY_PB_USE_TIMING3     "a.pb_use_timing3"
+#define XENV_KEY_PB_TIMING4         "a.pb_timing4"
+#define XENV_KEY_PB_USE_TIMING4     "a.pb_use_timing4"
+#define XENV_KEY_PB_TIMING5         "a.pb_timing5"
+#define XENV_KEY_PB_USE_TIMING5     "a.pb_use_timing5"
+
+#if (defined(CONFIG_TANGO2) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3)
+#define XENV_KEY_IRQ_RISE_EDGE_HI   "a.irq_rise_edge_hi"
+#define XENV_KEY_IRQ_FALL_EDGE_HI   "a.irq_fall_edge_hi"
+#endif
+
+#define XENV_KEY_ENABLED_DEVICES    "a.enable_devices"
+
+#define XENV_KEY_ETH_MAC            "a.eth_mac"
+#ifdef CONFIG_TANGO3
+#define XENV_KEY_ETH1_MAC           "a.eth1_mac"
+#endif
+
+#define XENV_KEY_SCARD_OFF          "a.scard_off_pin"
+#define XENV_KEY_SCARD_5V           "a.scard_5v_pin"
+#define XENV_KEY_SCARD_CMD          "a.scard_cmd_pin"
+
+#ifdef CONFIG_TANGO3
+#define XENV_KEY_SCARD1_OFF         "a.scard1_off_pin"
+#define XENV_KEY_SCARD1_5V          "a.scard1_5v_pin"
+#define XENV_KEY_SCARD1_CMD         "a.scard1_cmd_pin"
+#endif
+
+#define XENV_KEY_ISAIDE_IRQ_ROUTE   "a.isaide_irq_route"
+#define XENV_KEY_ISAIDE_TIMING_SLOT "a.isaide_timing_slot"
+
+#define XENV_KEY_GPIO_DIR           "a.gpio_dir"
+#define XENV_KEY_GPIO_DATA          "a.gpio_data"
+
+#define XENV_KEY_LINUX_CMD          "a.linux_cmd"
+
+#define XENV_KEY_Z_BOOT_DEF         "z.default_boot"
+
+#define XENV_KEY_Z_PROD_TEST        "z.dt"
+#define XENV_KEY_Z_PROD_LOOPS       "z.prod_loops"
+#define XENV_KEY_Z_PROD_FTEST       "z.prod_ftest"
+#define XENV_KEY_Z_PROD_FSTART      "z.prod_fstart"
+#define XENV_KEY_Z_PROD_FEND        "z.prod_fend"
+#define XENV_KEY_Z_PROD_FSTEP       "z.prod_fstep"
+#define XENV_KEY_Z_PROD_RWIN        "z.prod_rwindow"
+#define XENV_KEY_Z_PROD_WWIN        "z.prod_wwindow"
+#define XENV_KEY_Z_PROD_CL          "z.prod_cl"
+#define XENV_KEY_Z_PROD_NBLOCKS     "z.prod_nblocks"
+
+#define XENV_KEY_YAMON_ENV          "y.env"
+#define XENV_KEY_YAMON_IPADDR       "y.ipaddr"
+#define XENV_KEY_YAMON_SUBNET       "y.subnetmask"
+#define XENV_KEY_YAMON_GATEWAY      "y.gateway"
+#define XENV_KEY_YAMON_START        "y.start"
+#define XENV_KEY_YAMON_STARTDELAY   "y.startdelay"
+
+#define XENV_KEYS_PCI_IRQ_ROUTE     "a.pcidev%d_irq_route"
+#define XENV_KEYS_CD_FREQUENCY      "a.cd%d_freq"
+#define XENV_KEYS_CD_DIV            "a.cd%d_div"
+#define XENV_KEYS_UART_GPIO_MODE    "a.uart%d_gpio_mode"
+#define XENV_KEYS_UART_GPIO_DIR     "a.uart%d_gpio_dir"
+#define XENV_KEYS_UART_GPIO_DATA    "a.uart%d_gpio_data"
+#define XENV_KEYS_UART_BAUDRATE     "a.uart%d_baudrate"
+#define XENV_KEYS_GPIO_PULSE        "a.gpio%d_pulse"
+
+#define XENV_KEYS_Z_BOOT_LOCATION   "z.boot%d"
+
+#define XENV_KEYS_CS_SIZE           "l.cs%d_size"
+#define XENV_KEYS_CS_PARTS          "l.cs%d_parts"
+
+#define XENV_KEYS_CS_PART_SIZE      "l.cs%d_part%d_size"
+#define XENV_KEYS_CS_PART_OFFSET    "l.cs%d_part%d_offset" 
+
+#ifndef CONFIG_SIGBLOCK_SUPPORT
+#define ISAIDE_SHIFT		0
+#define BMIDE_SHIFT		1
+#define PCIHOST_SHIFT		2
+#define ETHERNET_SHIFT		3
+#define IR_SHIFT		4
+#define FIP_SHIFT		5	
+#define I2CM_SHIFT		6
+#define I2CS_SHIFT		7
+#define SDIO_SHIFT		8
+#define USB_SHIFT		9
+#define PCI1_SHIFT		10
+#define PCI2_SHIFT		11
+#define PCI3_SHIFT		12
+#define PCI4_SHIFT		13
+#define PCI5_SHIFT		14
+#define PCI6_SHIFT		15
+#define SATA_SHIFT		16
+#define SCARD_SHIFT		17
+#define GNET_SHIFT		18
+#ifdef CONFIG_TANGO3
+#define SCARD1_SHIFT		19
+#define ETHERNET1_SHIFT		20
+#endif
+#endif
+
+/* Only used internally for LR_XENV2_RW and LR_XENV2_RO. Will be prefixed with z. when read off pfla */
+#ifdef CONFIG_TANGO3
+/* lrrw */
+#define XENV_LRRW_ETH_MACL	     "lrrw.maclo"
+#define XENV_LRRW_ETH_MACH	     "lrrw.machi"
+#define XENV_LRRW_ETH1_MACL	     "lrrw.mac1lo"
+#define XENV_LRRW_ETH1_MACH	     "lrrw.mac1hi"
+#define XENV_LRRW_KERNEL_END	     "lrrw.kend"
+
+#define XENV_LRRW_0_UZDATA_OFFSET    "lrrw.0.uzdata_offset"
+#define XENV_LRRW_0_ZDATA_OFFSET     "lrrw.0.zdata_offset"
+#define XENV_LRRW_0_DSP_OFFSET       "lrrw.0.dsp_offset"
+#define XENV_LRRW_0_XPU_OFFSET       "lrrw.0.xpu_offset"
+#define XENV_LRRW_1_UZDATA_OFFSET    "lrrw.1.uzdata_offset"
+#define XENV_LRRW_1_ZDATA_OFFSET     "lrrw.1.zdata_offset"
+#define XENV_LRRW_1_DSP_OFFSET       "lrrw.1.dsp_offset"
+#define XENV_LRRW_1_XPU_OFFSET       "lrrw.1.xpu_offset"
+
+#define XENV_LRRW_CHANNEL_INDEX_GA   "lrrw.channel_index_ga"
+#define XENV_LRRW_CHANNEL_INDEX_SIZE "lrrw.channel_index_size"
+#define XENV_LRRW_IOS_GA             "lrrw.ios_ga"
+#define XENV_LRRW_IOS_SIZE           "lrrw.ios_size"
+#define XENV_LRRW_XOS_PUBLIC_GA      "lrrw.xos_public_ga"
+#define XENV_LRRW_XOS_PUBLIC_SIZE    "lrrw.xos_public_size"
+#define XENV_LRRW_IHAPI_GA           "lrrw.ihapi_ga"
+#define XENV_LRRW_MM_VERSION         "lrrw.mm_version"
+
+/* For handshaking and setup purpose */
+#define XENV_HS_RUAMM0_OFFSET	     "a.ruamm0_offset"
+#define XENV_HS_RUAMM1_OFFSET	     "a.ruamm1_offset"
+#define XENV_HS_XOS_PUBLIC_SIZE      "a.xos_public_size"
+#define XENV_HS_IOS_SIZE	     "a.ios_size"
+
+/* lrro */
+#define XENV_LRRO_LOCKED	     "lrro.locked"
+
+#endif
+
+#endif
+
diff -Naur linux-2.6.30-ori/drivers/char/Kconfig linux-2.6.30-test/drivers/char/Kconfig
--- linux-2.6.30-ori/drivers/char/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/char/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -420,6 +420,35 @@
 
 source "drivers/serial/Kconfig"
 
+config TANGOX_IR
+       tristate "SMP86xx IR remote support" if TANGOX
+       default m
+       help
+         Support Infra-Red remote controller interface for SMP86xx.
+
+config TANGOX_FIP
+       tristate "SMP863x/SMP865x Front Panel support" if TANGOX
+       default m
+       help
+         Support Front Panel interface for SMP863x/SMP865x.
+
+choice
+       prompt "SMP863x/SMP865x reference platform"
+       depends on TANGOX_FIP
+       default TANGOX_FIP_REF1
+
+config TANGOX_FIP_REF1
+       bool "Ref1"
+       help
+         For reference platform 1.
+
+config TANGOX_FIP_REF2
+       bool "Ref2"
+       help
+         For reference platform 2.
+
+endchoice
+
 config UNIX98_PTYS
 	bool "Unix98 PTY support" if EMBEDDED
 	default y
diff -Naur linux-2.6.30-ori/drivers/char/Makefile linux-2.6.30-test/drivers/char/Makefile
--- linux-2.6.30-ori/drivers/char/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/char/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -97,6 +97,8 @@
 obj-$(CONFIG_GPIO_VR41XX)	+= vr41xx_giu.o
 obj-$(CONFIG_GPIO_TB0219)	+= tb0219.o
 obj-$(CONFIG_TELCLOCK)		+= tlclk.o
+obj-$(CONFIG_TANGOX_IR) += irkernel.o
+obj-$(CONFIG_TANGOX_FIP) += fipkernel.o
 
 obj-$(CONFIG_MWAVE)		+= mwave/
 obj-$(CONFIG_AGP)		+= agp/
diff -Naur linux-2.6.30-ori/drivers/char/fipkernel.c linux-2.6.30-test/drivers/char/fipkernel.c
--- linux-2.6.30-ori/drivers/char/fipkernel.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/char/fipkernel.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,1312 @@
+/*****************************************
+ *  Copyright  2001-2007
+ *  Sigma Designs, Inc. All Rights Reserved
+ *  Proprietary and Confidential
+ *  Modified for KiSS Front Panel support
+ *  By Stefan Hallas Andersen
+ ******************************************/
+
+#ifdef __KERNEL__ 
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/irq.h>
+#include <linux/poll.h>
+#include <linux/interrupt.h>
+#include <linux/timer.h>
+#include <asm/delay.h>
+#include <asm/io.h>
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/tango2_gbus.h>
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/fip.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/tango3_gbus.h>
+#include <asm/tango3/hardware.h>
+#include <asm/tango3/fip.h>
+#endif
+#else
+#include "version.h"
+#include "config.h"
+#include "io.h"
+#endif /* __KERNEL__ */
+
+extern int tangox_fip_enabled(void);
+
+/* chip specific register definitions */
+
+/* EM85XX */
+#if 0
+#define	FIP_BASE				0x00500D00
+#define	FIP_COMMAND				0x00
+#define	FIP_DISPLAY_DATA			0x04
+#define	FIP_LED_DATA				0x08
+#define	FIP_KEY_DATA1				0x0C
+#define	FIP_KEY_DATA2				0x10
+#define	FIP_SWITCH_DATA				0x14
+#define	FIP_CLK_DIV				0x20
+#define	FIP_TRISTATE_MODE			0x24
+
+#define FIP_TRISTATE_MODE_MASK			0x2
+#define FIP_DIVIDER				40
+#endif
+
+#ifndef CONFIG_TANGOX
+#error "Only TANGOX is supported/tested."
+#endif
+
+/* TANGOX */
+#define	FIP_BASE				(REG_BASE_system_block + 0x500)
+#define	FIP_COMMAND				0x40
+#define	FIP_DISPLAY_DATA			0x44
+#define	FIP_LED_DATA				0x48
+#define	FIP_KEY_DATA1				0x4c
+#define	FIP_KEY_DATA2				0x50
+#define	FIP_SWITCH_DATA				0x54
+#define FIP_CONFIG				0x58
+#define FIP_INT					0x5c
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+#define FIP_DIVIDER				27	/* default value */
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+#define FIP_DIVIDER				54	/* default value */
+#endif
+
+#define FIP_BUSY				0x200
+#define FIP_ENABLE				0x400
+
+/* FIP commands							*/
+#define	FIP_CMD_DISP_MODE_08DIGITS_20SEGMENTS		0x00
+#define	FIP_CMD_DISP_MODE_09DIGITS_19SEGMENTS		0x08
+#define	FIP_CMD_DISP_MODE_10DIGITS_18SEGMENTS		0x09
+#define	FIP_CMD_DISP_MODE_11DIGITS_17SEGMENTS		0x0a
+#define	FIP_CMD_DISP_MODE_12DIGITS_16SEGMENTS		0x0b
+#define	FIP_CMD_DISP_MODE_13DIGITS_15SEGMENTS		0x0c
+#define	FIP_CMD_DISP_MODE_14DIGITS_14SEGMENTS		0x0d
+#define	FIP_CMD_DISP_MODE_15DIGITS_13SEGMENTS		0x0e
+#define	FIP_CMD_DISP_MODE_16DIGITS_12SEGMENTS		0x0f
+#define	FIP_CMD_DATA_SET_RW_MODE_WRITE_DISPLAY		0x40
+#define	FIP_CMD_DATA_SET_RW_MODE_WRITE_LED_PORT		0x41
+#define	FIP_CMD_DATA_SET_RW_MODE_READ_KEYS		0x42
+#define	FIP_CMD_DATA_SET_RW_MODE_READ_SWITCHES		0x43
+#define	FIP_CMD_DATA_SET_ADR_MODE_INCREMENT_ADR		0x40
+#define	FIP_CMD_DATA_SET_ADR_MODE_FIXED_ADR		0x44
+#define	FIP_CMD_DATA_SET_OP_MODE_NORMAL_OPERATION	0x40
+#define	FIP_CMD_DATA_SET_OP_MODE_TEST_MODE		0x48
+#define	FIP_CMD_ADR_SETTING				0xC0
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_1_16		0x80
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_2_16		0x81
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_4_16		0x82
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_10_16		0x83
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_11_16		0x84
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_12_16		0x85
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_13_16		0x86
+#define	FIP_CMD_DISP_CTRL_PULSE_WIDTH_14_16		0x87
+#define	FIP_CMD_DISP_CTRL_TURN_DISPLAY_OFF_MASK		0x87
+#define	FIP_CMD_DISP_CTRL_TURN_DISPLAY_ON		0x88
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+#define FIP_DISPLAY_MODE	0xa
+#define MAX_FIP_RAM		23
+#define NUM_SYMBOLS		23
+#define NUM_CHARACTERS		72
+#define NUM_DIGITS		7
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+#define FIP_DISPLAY_MODE	0x0a
+#define MAX_FIP_RAM		0x2f
+#define NUM_SYMBOLS		206
+#define NUM_CHARACTERS		69
+#define NUM_X_CHARACTERS	12
+#define NUM_DIGITS		8
+#define NUM_X_DIGITS		4
+#endif
+
+#define L_OFF			-1	//means light is or should be off
+#define FIP_NO_CLEAR		0x0004
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+/*
+  14 SEGMENT LCD (EXTENDED CHARACTERS MAP)
+
+     a 
+   -----
+f |\j| /| b 
+  |i\|/k|
+  g-- --h
+e |n/|\l| c
+  |/m| \|
+   -----
+     d   
+*/
+#define DIGIT_L(b7,b6,c,l,m,n,e,d)	((b7 << 7) | (b6 << 6) | (c << 5) | (l << 4) | (m << 3) | (n << 2) | (e << 1) | d)
+#define DIGIT_H(g,h,i,j,k,a,b,f)	((g << 7) | (h << 6) | (i << 5) | (j << 4) | (k << 3) | (a << 2) | (b << 1) | f)
+
+/* sequence must match fipcharacters */
+static const char fipcharactersmap[NUM_CHARACTERS+1] = " +-/0123456789<>ABCDEFGHIJKLMNOPQRSTUVWXYZ\\-abcdefghijklmnopqrstuvwxyz|_";
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+#define DIGIT_L(M,C,E,R,P,B,D,U)	((M << 7) | (C << 6) | (E << 5) | (R << 4) | (P << 3) | (B << 2) | (D << 1) | U)
+#define DIGIT_H(A,B,F,H,J,K,G,S)	((A << 7) | (B << 6) | (F << 5) | (H << 4) | (J << 3) | (K << 2) | (G << 1) | S)
+// Following definition is for Title/Track/Chaspter digits
+#define DIGIT_X(A,B,F,G,C,E,D,U)		((A << 7) | (B << 6) | (F << 5) | (G << 4) | (C << 3) | (E << 2) | (D << 1) | U)
+ 
+static const char fipcharactersmap[NUM_CHARACTERS+1] = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~";
+static const char fipxcharactersmap[NUM_X_CHARACTERS+1] = "0123456789- ";
+#endif
+
+/* we use the inverted mask for clearing a digit without clearing other things */
+static const char fipcharactermask[2] = {
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	DIGIT_L(1,1,0,0,0,0,0,0), 
+	DIGIT_H(0,0,0,0,0,0,0,0)
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	DIGIT_L(0,0,0,0,0,0,0,0), 
+	DIGIT_H(0,0,0,0,0,0,0,0)
+#endif
+};
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+/* the format is lower byte, higher byte */
+static const char fipcharacters[NUM_CHARACTERS][2] = {
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(0,0,0,0,0,0,0,0)},	//
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(1,1,0,1,0,0,0,0)},	// +
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(1,1,0,0,0,0,0,0)},	// -
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,1,0,0,0)},	// /
+
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(0,0,0,0,0,1,1,1)},	// 0
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,1,0,0,0,0)},	// 1
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,1,0)},	// 2
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,1,0)},	// 3
+	{DIGIT_L(0,0,1,0,0,0,0,0), DIGIT_H(1,1,0,0,0,0,1,1)},	// 4
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// 5
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// 6
+	{DIGIT_L(0,0,1,0,0,0,0,0), DIGIT_H(0,0,0,0,0,1,1,0)},	// 7
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,1,1)},	// 8
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,1,1)},	// 9
+
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,0,1,0,0,0)},	// <
+	{DIGIT_L(0,0,0,0,0,1,0,0), DIGIT_H(0,0,0,1,0,0,0,0)},	// >
+
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(1,1,0,0,0,1,1,1)},	// A
+	{DIGIT_L(0,0,1,0,1,0,0,1), DIGIT_H(0,1,0,1,0,1,1,0)},	// B
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(0,0,0,0,0,1,0,1)},	// C
+	{DIGIT_L(0,0,1,0,1,0,0,1), DIGIT_H(0,0,0,1,0,1,1,0)},	// D
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// E
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(1,1,0,0,0,1,0,1)},	// F
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// G
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(1,1,0,0,0,0,1,1)},	// H
+	{DIGIT_L(0,0,0,0,1,0,0,1), DIGIT_H(0,0,0,1,0,1,0,0)},	// I
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(0,0,0,0,0,0,1,0)},	// J
+	{DIGIT_L(0,0,0,1,0,0,1,0), DIGIT_H(1,0,0,0,1,0,0,1)},	// K
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(0,0,0,0,0,0,0,1)},	// L
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(0,0,1,0,1,0,1,1)},	// M
+	{DIGIT_L(0,0,1,1,0,0,1,0), DIGIT_H(0,0,1,0,0,0,1,1)},	// N
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(0,0,0,0,0,1,1,1)},	// O
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(1,1,0,0,0,1,1,1)},	// P
+	{DIGIT_L(0,0,1,1,0,0,1,1), DIGIT_H(0,0,0,0,0,1,1,1)},	// Q
+	{DIGIT_L(0,0,0,1,0,0,1,0), DIGIT_H(1,1,0,0,0,1,1,1)},	// R
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// S
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,1,0,1,0,0)},	// T
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(0,0,0,0,0,0,1,1)},	// U
+	{DIGIT_L(0,0,1,1,0,0,0,0), DIGIT_H(0,0,1,0,0,0,1,0)},	// V
+	{DIGIT_L(0,0,1,1,0,1,1,0), DIGIT_H(0,0,0,0,0,0,1,1)},	// W
+	{DIGIT_L(0,0,0,1,0,1,0,0), DIGIT_H(0,0,1,0,1,0,0,0)},	// X
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,1,0,1,0,0,0)},	// Y
+	{DIGIT_L(0,0,0,0,0,1,0,1), DIGIT_H(0,0,0,0,1,1,0,0)},	// Z
+
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,1,0,0,0,0,0)},	// Slash
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(1,1,0,0,0,0,0,0)},	// -
+
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// a
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,0,1)},	// b
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// c
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,1,0)},	// d
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(1,1,0,0,0,1,1,1)},	// e
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(1,0,0,0,0,1,0,1)},	// f
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,1,1)},	// g
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(1,1,0,0,0,0,0,1)},	// h
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,0,0,0,0)},	// i
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(0,0,0,0,0,0,0,0)},	// j
+	{DIGIT_L(0,0,0,1,1,0,0,0), DIGIT_H(0,1,0,1,0,0,0,0)},	// k
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(0,0,0,0,0,0,0,1)},	// l
+	{DIGIT_L(0,0,1,0,1,0,1,0), DIGIT_H(1,1,0,0,0,0,0,0)},	// m
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(1,1,0,0,0,0,0,0)},	// n
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// o
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(1,1,0,0,0,1,1,1)},	// p
+	{DIGIT_L(0,0,1,0,0,0,0,0), DIGIT_H(1,1,0,0,0,1,1,1)},	// q
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(1,0,0,0,0,0,0,0)},	// r
+	{DIGIT_L(0,0,1,0,0,0,0,1), DIGIT_H(1,1,0,0,0,1,0,1)},	// s
+	{DIGIT_L(0,0,0,0,0,0,1,1), DIGIT_H(1,0,0,0,0,0,0,1)},	// t
+	{DIGIT_L(0,0,1,0,0,0,1,1), DIGIT_H(0,0,0,0,0,0,0,0)},	// u
+	{DIGIT_L(0,0,1,1,0,0,0,0), DIGIT_H(0,0,0,0,0,0,0,0)},	// v
+	{DIGIT_L(0,0,1,1,0,1,1,0), DIGIT_H(0,0,0,0,0,0,0,0)},	// w
+	{DIGIT_L(0,0,0,1,1,0,0,0), DIGIT_H(1,1,0,0,0,0,0,0)},	// x
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,1,1,0,0,0)},	// y
+	{DIGIT_L(0,0,0,0,1,0,0,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// z
+
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,1,0,0,0,0)},	// |
+	{DIGIT_L(0,0,0,0,0,0,0,1), DIGIT_H(0,0,0,0,0,0,0,0)}	// _
+};
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+/* the format is lower byte, higher byte */
+static const char fipcharacters[NUM_CHARACTERS][2] = {
+	{DIGIT_L(0,1,1,0,0,0,1,1), DIGIT_H(1,1,1,0,0,0,0,0)},	// 0
+	{DIGIT_L(0,0,0,0,1,0,0,1), DIGIT_H(0,0,0,0,1,0,0,1)},	// 1
+	{DIGIT_L(1,0,1,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,1,1)},	// 2
+	{DIGIT_L(1,1,0,0,0,0,1,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// 3
+	{DIGIT_L(1,1,0,0,0,0,0,1), DIGIT_H(0,1,1,0,0,0,1,1)},	// 4
+	{DIGIT_L(1,1,0,0,0,0,1,1), DIGIT_H(1,0,1,0,0,0,1,1)},	// 5
+	{DIGIT_L(1,1,1,0,0,0,1,1), DIGIT_H(1,0,1,0,0,0,1,1)},	// 6
+	{DIGIT_L(0,1,0,0,0,0,0,1), DIGIT_H(1,1,0,0,0,0,0,0)},	// 7
+	{DIGIT_L(1,1,1,0,0,0,1,1), DIGIT_H(1,1,1,0,0,0,1,1)},	// 8
+	{DIGIT_L(1,1,0,0,0,0,0,1), DIGIT_H(1,1,1,0,0,0,1,1)},	// 9
+	{DIGIT_L(1,1,1,0,0,0,0,0), DIGIT_H(1,1,1,0,0,0,1,1)},	// A
+	{DIGIT_L(1,1,0,0,1,0,1,0), DIGIT_H(1,1,0,0,1,0,0,1)},	// B
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(1,0,1,0,0,0,0,0)},	// C
+	{DIGIT_L(0,1,0,0,1,0,1,0), DIGIT_H(1,1,0,0,1,0,0,1)},	// D
+	{DIGIT_L(1,0,1,0,0,0,1,0), DIGIT_H(1,0,1,0,0,0,1,1)},	// E
+	{DIGIT_L(0,0,1,0,0,0,0,0), DIGIT_H(1,0,1,0,0,0,1,1)},	// F
+	{DIGIT_L(1,1,1,0,0,0,1,0), DIGIT_H(1,0,1,0,0,0,0,0)},	// G
+	{DIGIT_L(1,1,1,0,0,0,0,0), DIGIT_H(0,1,1,0,0,0,1,1)},	// H
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,1,0,0,1)},	// I
+	{DIGIT_L(0,1,1,0,0,0,1,0), DIGIT_H(0,1,0,0,0,0,0,0)},	// J
+	{DIGIT_L(0,0,1,0,0,1,0,0), DIGIT_H(0,0,1,0,0,1,1,1)},	// K
+	{DIGIT_L(0,0,1,0,0,0,1,0), DIGIT_H(0,0,1,0,0,0,0,0)},	// L
+	{DIGIT_L(0,1,1,0,0,0,0,0), DIGIT_H(0,1,1,1,0,1,0,1)},	// M
+	{DIGIT_L(0,1,1,0,0,1,0,0), DIGIT_H(0,1,1,1,0,0,0,1)},	// N
+	{DIGIT_L(0,1,1,0,0,0,1,0), DIGIT_H(1,1,1,0,0,0,0,0)},	// O
+	{DIGIT_L(1,0,1,0,0,0,0,0), DIGIT_H(1,1,1,0,0,0,1,1)},	// P
+	{DIGIT_L(0,1,1,0,0,1,1,0), DIGIT_H(1,1,1,0,0,0,0,0)},	// Q
+	{DIGIT_L(1,0,1,0,0,1,0,0), DIGIT_H(1,1,1,0,0,0,1,1)},	// R
+	{DIGIT_L(1,1,0,0,0,0,1,0), DIGIT_H(1,0,1,0,0,0,1,1)},	// S
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(1,0,0,0,1,0,0,1)},	// T
+	{DIGIT_L(0,1,1,0,0,0,1,0), DIGIT_H(0,1,1,0,0,0,0,0)},	// U
+	{DIGIT_L(0,0,1,1,0,0,0,0), DIGIT_H(0,0,1,0,0,1,0,1)},	// V
+	{DIGIT_L(0,1,1,1,0,1,0,0), DIGIT_H(0,1,1,0,0,0,0,1)},	// W
+	{DIGIT_L(0,0,0,1,0,1,0,0), DIGIT_H(0,0,0,1,0,1,0,0)},	// X
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,1,0,1,0,1)},	// Y
+	{DIGIT_L(0,0,0,1,0,0,1,0), DIGIT_H(1,0,0,0,0,1,0,1)},	// Z
+	{0,0},							// Space
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,1,0,0,1)},	// !
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(0,0,1,0,1,0,0,0)},	// "
+	{DIGIT_L(1,0,0,1,1,0,0,0), DIGIT_H(0,0,0,1,1,0,1,1)},	// #
+	{DIGIT_L(1,1,0,0,1,0,1,0), DIGIT_H(1,0,1,0,1,0,1,1)},	// $
+	{DIGIT_L(0,1,0,1,0,0,0,0), DIGIT_H(0,0,1,0,0,1,0,1)},	// %
+	{DIGIT_L(0,0,1,0,1,0,1,0), DIGIT_H(1,0,0,1,0,1,1,1)},	// &
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(0,0,0,0,0,1,0,0)},	// '
+	{DIGIT_L(0,0,0,0,0,1,0,0), DIGIT_H(0,0,0,0,0,1,0,0)}, 	// (
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,1,0,0,0,0)}, 	// )
+	{DIGIT_L(1,0,0,1,1,1,0,0), DIGIT_H(0,0,0,1,1,1,1,1)}, 	// *
+	{DIGIT_L(1,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,1,0,1,1)}, 	// +
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,0,0,0,0,0)}, 	// ,
+	{DIGIT_L(1,0,0,0,0,0,0,0), DIGIT_H(0,0,0,0,0,0,1,1)}, 	// -
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(0,0,0,0,0,0,0,1)}, 	// .
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,0,0,1,0,1)}, 	// /
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,0,0,0,1)}, 	// :
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,0,0,0,0,1)}, 	// ;
+	{DIGIT_L(0,0,0,0,0,1,0,0), DIGIT_H(0,0,0,0,0,1,0,1)}, 	// <
+	{DIGIT_L(1,0,0,0,0,0,1,0), DIGIT_H(0,0,0,0,0,0,1,1)}, 	// =
+	{DIGIT_L(0,0,0,1,0,0,0,0), DIGIT_H(0,0,0,1,0,0,0,1)}, 	// >
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(1,0,1,0,0,1,0,1)}, 	// ?
+	{DIGIT_L(1,0,1,0,0,0,1,0), DIGIT_H(1,1,1,0,1,1,0,1)}, 	// @
+	{DIGIT_L(0,0,0,1,0,0,1,0), DIGIT_H(1,0,0,1,0,0,0,0)}, 	// [
+	{DIGIT_L(0,0,0,0,0,1,0,0), DIGIT_H(0,0,0,1,0,0,0,1)}, 	// / 
+	{DIGIT_L(0,1,0,0,0,0,1,0), DIGIT_H(1,1,0,0,0,0,0,0)}, 	// ]
+	{DIGIT_L(0,0,0,1,0,1,0,0), DIGIT_H(0,0,0,0,0,0,0,1)}, 	// ^
+	{DIGIT_L(0,0,0,0,0,0,1,0), DIGIT_H(0,0,0,0,0,0,0,0)}, 	// _
+	{DIGIT_L(0,0,0,0,0,0,0,0), DIGIT_H(0,0,0,1,0,0,0,0)}, 	// `
+	{DIGIT_L(0,0,0,1,0,0,1,0), DIGIT_H(1,0,0,1,0,0,1,0)}, 	// {
+	{DIGIT_L(0,0,0,0,1,0,0,0), DIGIT_H(0,0,0,0,1,0,0,1)}, 	// |
+	{DIGIT_L(1,0,0,0,0,1,1,0), DIGIT_H(1,0,0,0,0,1,0,1)}, 	// }
+	{DIGIT_L(1,0,0,0,0,0,0,0), DIGIT_H(0,0,0,0,0,0,1,0)}	// ~
+};
+
+static const char fipxcharacters[NUM_X_CHARACTERS] = {
+	DIGIT_X(1,1,1,0,1,1,1,1),	// 0
+	DIGIT_X(0,1,0,0,1,0,0,1),	// 1
+	DIGIT_X(1,1,0,1,0,1,1,1),	// 2
+	DIGIT_X(1,1,0,1,1,0,1,1),	// 3
+	DIGIT_X(0,1,1,1,1,0,0,1),	// 4
+	DIGIT_X(1,0,1,1,1,0,1,1),	// 5
+	DIGIT_X(1,0,1,1,1,1,1,1),	// 6
+	DIGIT_X(1,1,0,0,1,0,0,1),	// 7
+	DIGIT_X(1,1,1,1,1,1,1,1),	// 8
+	DIGIT_X(1,1,1,1,1,0,1,1),	// 9
+	DIGIT_X(0,0,0,1,0,0,0,0),	// -
+	DIGIT_X(0,0,0,0,0,0,0,0)	// 
+};
+#endif
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+/* this array is used to display individual symbols
+   the format is [byte position][bit to turn on] - both zero based */
+static const char fipsymbols[NUM_SYMBOLS][2] = {
+	{0, 0}, 	/* DVD */
+	{0, 1}, 	/* PLAY */
+	{0, 2}, 	/* DTS */
+	{0, 3}, 	/* MP3 */
+	{0, 4}, 	/* DOLBY DIGITAL */
+	{0, 5}, 	/* MPEG4 */
+	{0, 6},		/* PAUSE */
+	{0, 7}, 	/* DVI */
+	{1, 0}, 	/* TWIRL1 */
+	{1, 1}, 	/* TWIRL2 */
+	{1, 2}, 	/* TWIRL3 */
+	{1, 3}, 	/* TWIRL4 */
+	{1, 4}, 	/* TWIRL5 */
+	{1, 5}, 	/* TWIRL6 */
+	{1, 6}, 	/* ALL */
+	{1, 7}, 	/* REPEAT */
+	{9, 6},		/* COLON_MIN_SEC */
+	{9, 7}, 	/* R1080 */
+	{12, 7}, 	/* R720 */
+	{15, 6}, 	/* COLON_HOUR_MIN */
+	{15, 7}, 	/* R480 */
+	{18, 7}, 	/* PAL */
+	{21, 7},	/* NTSC */
+};
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+/* this array is used to display individual symbols
+   the format is [byte position][bit to turn on] - both zero based */
+static const char fipsymbols[NUM_SYMBOLS][2] = {
+	{0, 1},		// DVD
+	{0, 2},		// VCD
+	{0, 4},		// MP3
+	{0, 8}, 	// CD
+	{29, 1}, 	// Title
+	{27, 1}		// Track
+};
+#endif
+
+/* The buffer size defines the size of circular buffer to keep the FIP keys */
+#define BUF_SIZE		2
+
+/* Wait period, to avoid bouncing or repeatation? */
+#define WAIT_PERIOD		100
+
+/* Default brightness level */
+#define BRIGHTNESS		0x7
+
+/* The number of key polling per second */
+#define POLL_PER_SECOND		10
+
+#ifdef __KERNEL__
+/* The major device number and name */
+#define FIP_DEV_MAJOR		0
+
+#define DRIVER_VERSION         "1.15"
+
+MODULE_DESCRIPTION("TANGOX front panel fip driver\n");
+MODULE_AUTHOR("TANGOX standalone team");
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRIVER_VERSION);
+
+/* Wait queue, may be used if block mode is on */
+DECLARE_WAIT_QUEUE_HEAD(fip_wq);
+
+static int major_num = FIP_DEV_MAJOR;
+static int buffer_size = BUF_SIZE;
+static int wait_period = WAIT_PERIOD;
+static int brightness = BRIGHTNESS;
+static unsigned int poll_per_sec = POLL_PER_SECOND;
+module_param(major_num, int, 0);
+module_param(buffer_size, int, 0);
+module_param(wait_period, int, 0);
+module_param(brightness, int, 0);
+module_param(poll_per_sec, int, 0);
+
+/* Some prototypes */
+static int fip_open(struct inode *, struct file *);
+static int fip_release(struct inode *, struct file *);
+static int fip_read(struct file *, char *, size_t, loff_t *);
+static int fip_write(struct file *, const char *, size_t, loff_t *);
+static int fip_ioctl(struct inode *, struct file *, unsigned int, unsigned long);
+static unsigned int fip_poll(struct file *, struct poll_table_struct *);
+static int fip_irq = LOG2_CPU_FRONTPANEL_INT + IRQ_CONTROLLER_IRQ_BASE;
+static irqreturn_t fip_isr(int irq, void *dev_id);
+static void fip_poll_key(unsigned long devid);
+
+static struct timer_list fip_timer;
+#if 0
+static struct tq_struct immediate;
+#endif
+
+static void fip_write_text(const int position, const char *text, const int flags);
+static int fip_show_hms(int hour, int minute, int second);
+static void fip_display_symbol(const int symbol, const int on);
+static int fip_display_character(const int position, const char character);
+static void fip_display_raw(const int byte, const int bit, const int on); 
+static int is_fip_busy(void);
+static int is_fip_busy_nowait(void);
+static void fip_clear(void);
+
+#else /* For Bootloader */
+
+void fip_write_text(const int position, const char *text, const int flags);
+void fip_display_symbol(const int symbol, const int on);
+int fip_display_character(const int position, const char character);
+void fip_display_raw(const int byte, const int bit, const int on); 
+int is_fip_busy(void);
+void fip_clear(void);
+int fip_init(void);
+int fip_exit(void);
+
+/* Some external functions from bootloader core */
+void em86xx_usleep(int usec);
+int uart_printf(const char *fmt, ...);
+int strlen(const char *str);
+
+#endif /* __KERNEL__ */
+
+#define FIP_DEV_NAME		"fip"
+
+static void fip_write_reg(unsigned int offset, unsigned int val);
+static unsigned int fip_read_reg(unsigned int offset);
+
+#ifdef __KERNEL__ 
+#define CMDQ_SIZE	256
+
+/* Private data structure */
+struct cmd_request {
+	unsigned int cmd;
+	unsigned int data;
+};
+
+struct fip_private {
+	unsigned long *buffer;		/* Circular buffer */
+	unsigned p_idx;			/* Index of producer */
+	unsigned c_idx; 		/* Index of consumer */
+	unsigned ref_cnt;		/* Reference count */
+	spinlock_t lock;		/* Spin lock */
+	unsigned char b_mode;		/* Blocking mode or not */
+	unsigned long last_jiffies;	/* Timestamp for last reception */
+#ifdef ENABLE_WRITE_INTR
+	struct cmd_request cmds[CMDQ_SIZE];
+	unsigned cmd_pidx;
+	unsigned cmd_cidx;
+	unsigned cmdq_empty;
+#endif
+};
+
+static struct file_operations fip_fops = {
+	open: fip_open,
+	read: fip_read,
+	ioctl: fip_ioctl,
+	poll: fip_poll,
+	write: fip_write,
+	release: fip_release,
+	owner: THIS_MODULE,
+};
+
+static void fip_push_key(struct fip_private *priv, unsigned long key);
+#ifdef ENABLE_WRITE_INTR
+static void fip_issue_command(struct fip_private *priv);
+static void fip_queue_command(unsigned int cmd, unsigned int data);
+#endif
+
+/* Global data */
+static struct fip_private fip_priv;
+#endif /* __KERNEL__ */
+
+static char *fip_devname = FIP_DEV_NAME;
+static unsigned long fip_base = (unsigned long)FIP_BASE;
+static char fipram[MAX_FIP_RAM] = {0};
+
+#ifdef __KERNEL__
+
+static irqreturn_t fip_isr(int irq, void *dev_id)
+{
+	struct fip_private *priv = (struct fip_private *)dev_id;
+	unsigned long stat;
+	unsigned long key;
+
+	if (irq == fip_irq) {
+		//gbus_write_uint32(pGBus, REG_BASE_CPU + CPU_edge_rawstat,  IRQMASKOF(irq));
+		stat = (fip_read_reg(FIP_INT) & 0x3);
+		fip_write_reg(FIP_INT, stat); /* Clear the interrupt */
+
+		if (!is_fip_busy_nowait()) {
+			if (stat & 0x2) {
+				key = fip_read_reg(FIP_KEY_DATA1);
+				fip_push_key(priv, key);
+			}
+#ifdef ENABLE_WRITE_INTR
+			fip_issue_command(priv);
+#endif
+		}
+		return IRQ_HANDLED;
+	} else {
+		printk("Unknown IRQ %d\n", irq);
+		return IRQ_NONE;
+	}
+
+}
+
+static void fip_poll_key(unsigned long devid)
+{
+	struct fip_private *priv = (struct fip_private *)devid;
+
+	/* Sending command, and later ISR will pick up the interrupt and read
+           the key */
+	if (!is_fip_busy_nowait()) {
+		fip_write_reg(FIP_COMMAND, FIP_CMD_DATA_SET_RW_MODE_READ_KEYS);
+#ifdef ENABLE_WRITE_INTR
+		if (priv->cmdq_empty != 0) {
+			fip_issue_command(priv);
+		}
+#endif
+	}
+
+	if (priv->ref_cnt != 0) {
+		mod_timer(&fip_timer, jiffies + (HZ / poll_per_sec));
+#if 0
+		queue_task(&immediate, &tq_immediate);
+		mark_bh(IMMEDIATE_BH);
+#endif
+	}
+}
+
+/* Produce data */
+static void fip_push_key(struct fip_private *priv, unsigned long key)
+{
+	unsigned pidx;
+	static unsigned long oldkey = 0;
+
+	spin_lock(&priv->lock);
+
+	if ((key == 0) || (key == 0xffffffff)) {
+		oldkey = 0;
+		goto out;
+	} else if (time_after(priv->last_jiffies + wait_period, jiffies) 
+			&& (key == oldkey))
+		goto out;
+	else
+		priv->last_jiffies = jiffies;
+	
+	printk(KERN_DEBUG "%s: got data 0x%08lx\n", fip_devname, key);
+
+	pidx = priv->p_idx;	/* Save the old index before proceeding */
+
+	/* Save it to buffer */
+	if (((priv->p_idx + 1) % buffer_size) == priv->c_idx) {
+		/* Adjust consumer index since buffer is full */
+		/* Keep the latest one and drop the oldest one */
+		priv->c_idx = (priv->c_idx + 1) % buffer_size;
+
+		printk(KERN_WARNING "%s: buffer full\n", fip_devname);
+	}
+
+	priv->buffer[priv->p_idx] = oldkey = key;
+	priv->p_idx = (priv->p_idx + 1) % buffer_size;
+
+	/* Buffer was empty and block mode is on, wake up the reader */
+	if ((priv->b_mode != 0) && (priv->c_idx == pidx))
+		wake_up_interruptible(&fip_wq);
+
+out:
+	spin_unlock(&priv->lock);
+}
+
+/* Reading from driver's buffer, note that it can return read size
+   less than specified */
+static int fip_consume(void *dev_id, unsigned long *buf, int count)
+{
+	struct fip_private *priv = (struct fip_private *)dev_id;
+	int cnt = 0;
+	unsigned long flags;
+
+	/* If block mode is on, check the emptiness of buffer */
+	if (priv->b_mode != 0) {
+		/* Sleep when buffer is empty */
+		wait_event_interruptible(fip_wq, priv->c_idx != priv->p_idx);
+	}
+	if (signal_pending(current))
+		return(cnt);
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	/* Get the data out and adjust consumer index */
+	for (cnt = 0; (priv->c_idx != priv->p_idx) && (cnt < count); cnt++) {
+		*buf = priv->buffer[priv->c_idx];
+		priv->c_idx = (priv->c_idx + 1) % buffer_size;
+		buf++;
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return(cnt);
+}
+
+/* Poll function */
+static unsigned int fip_poll(struct file *fptr, struct poll_table_struct *ptable){
+	struct fip_private *priv = (struct fip_private *)fptr->private_data;
+	unsigned int mask = 0;
+
+	poll_wait(fptr, &fip_wq, ptable);
+	if (priv->c_idx != priv->p_idx)
+		mask |= (POLLIN | POLLRDNORM);
+	return(mask);
+}
+
+#ifdef ENABLE_WRITE_INTR
+static void fip_issue_command(struct fip_private *priv)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	if (priv->cmd_pidx == priv->cmd_cidx) {
+		priv->cmdq_empty = 1;
+		goto out;
+	} else if (!is_fip_busy_nowait()) {
+		priv->cmdq_empty = 0;
+		fip_wait_ready();
+		fip_write_reg(FIP_DISPLAY_DATA, priv->cmds[priv->cmd_cidx].data);
+		fip_wait_ready();
+		fip_write_reg(FIP_COMMAND, priv->cmds[priv->cmd_cidx].cmd);
+		fip_wait_ready();
+		priv->cmd_cidx = ((priv->cmd_cidx + 1) % CMDQ_SIZE);
+		if (priv->cmd_pidx == priv->cmd_cidx) 
+			priv->cmdq_empty = 1;
+	}
+out:
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+#endif
+
+static int fip_open(struct inode *inode_ptr, struct file *fptr)
+{
+	/* This device is exclusive, that is, only one process can use it */
+	if (fip_priv.ref_cnt != 0) {
+		printk(KERN_WARNING "%s: exclusive access only\n", fip_devname);
+		return(-EIO);
+	} 
+
+	/* Set the block mode and increase reference count */
+	fip_priv.ref_cnt++;
+	fip_priv.b_mode = ((fptr->f_flags & O_NONBLOCK) ? 0 : 1);
+	fip_priv.last_jiffies = jiffies;
+
+	/* Flush the buffer */
+	fip_priv.p_idx = fip_priv.c_idx = 0;
+
+	fptr->f_op = &fip_fops;
+	fptr->private_data = (void *)&fip_priv;
+
+	fip_timer.function = fip_poll_key;
+	fip_timer.data = (unsigned long)&fip_priv;
+	fip_timer.expires = jiffies + (HZ / poll_per_sec);
+	add_timer(&fip_timer);
+
+#if 0
+	immediate.sync = 0;
+	immediate.data = (void *)&fip_priv;
+	immediate.routine = fip_poll_key;
+	queue_task(&immediate, &tq_immediate);
+	mark_bh(IMMEDIATE_BH);
+#endif
+
+	fip_clear();
+	return(0);
+}
+
+static int fip_release(struct inode *inode_ptr, struct file *fptr) 
+{
+	unsigned long start = 0;
+
+	/* Adjust reference count */
+	fip_priv.ref_cnt--;
+
+	/* Wait for timer expiration */
+	for (start = jiffies; time_after(start + 2 * (HZ / poll_per_sec), jiffies););
+	del_timer_sync(&fip_timer);
+	return(0);
+}
+
+static int fip_read(struct file *fptr, char *bufptr, size_t size, loff_t *fp)
+{
+	unsigned long buf[buffer_size];
+	int count = 0;
+
+	/* Check the alignment */
+	if (size % sizeof(unsigned long)) {
+		printk(KERN_WARNING "%s: read size not aligned to %d\n",
+			fip_devname, sizeof(unsigned long));
+		return(-EIO);
+	}
+
+	count = fip_consume(fptr->private_data, &buf[0], 
+			size / sizeof(unsigned long)) * sizeof(unsigned long);
+
+	/* Get the data to user */
+	if (count && copy_to_user(bufptr, (char *)&buf[0], count)) 
+		return(-EFAULT);
+
+	return(count);
+}
+
+static int fip_write(struct file *fptr, const char *bufptr, size_t size, loff_t *fp)
+{
+	fip_wait_ready();
+	fip_write_text(0, bufptr, FIP_CENTER); 
+	fip_wait_ready();
+	return(size);
+}
+
+static int fip_ioctl(struct inode *inode, struct file *fptr, unsigned int cmd, unsigned long arg)
+{
+	int on = 0;
+	int symbol;
+	int i, j, k;
+
+	switch(cmd) {
+		case FIP_IOCSHOWSYMBOL:
+			on = ((arg & 0x80000000)) == 0 ? 0 : 1;
+			symbol = (int)(arg & 0xff);
+			fip_display_symbol(symbol, on);
+			break;
+		case FIP_IOCSHOWHMS:
+			k = (int)(arg & 0xff);
+			j = (int)((arg >> 8) & 0xff);
+			i = (int)((arg >> 16) & 0xff);
+			fip_show_hms(i, j, k);
+			break;
+		case FIP_IOCDISPCHAR:
+			k = (int)(arg & 0xff);
+			j = (int)((arg >> 8) & 0xff);
+			fip_display_character(j, k);
+			break;
+		case FIP_IOCDISPRAW:
+			on = ((arg & 0x80000000)) == 0 ? 0 : 1;
+			k = (int)(arg & 0xff);
+			j = (int)((arg >> 8) & 0xff);
+			fip_display_raw(j, k, on);
+			break;
+		case FIP_IOCDISPTEXT:
+			printk("%s: ioctl FIP_IOCDISPTEXT not implemented.\n", fip_devname);
+			return(-EIO);
+		case FIP_IOCCLEAR:
+			fip_clear();
+			break;
+		case FIP_IOCGETFPTYPE:
+			{
+				unsigned long *ptr = (unsigned long *)arg;
+				unsigned long type = 0;
+#if defined(CONFIG_TANGOX_FIP_REF1)
+				type = 1;
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+				type = 2;
+#else
+				return(-EIO);
+#endif
+				if (copy_to_user(ptr, (char *)&type, sizeof(unsigned long))) 
+					return(-EFAULT);
+			}
+			break;
+		default:
+			return(-EIO);
+	}
+	return(0);
+}
+
+#endif /* __KERNEL__ */
+
+/* Micro-second sleep */
+static void fip_usleep(unsigned usec)
+{
+#ifdef __KERNEL__
+	udelay(usec);
+#else
+	em86xx_usleep(usec);
+#endif /* __KERNEL__ */
+}
+
+static unsigned int fip_read_reg(unsigned int offset)
+{
+//	unsigned int val = *((volatile unsigned int *)(fip_base + offset));
+	unsigned int val = gbus_read_uint32(pGBus, fip_base + offset);
+	return(val);
+}
+
+static void fip_write_reg(unsigned int offset, unsigned int val)
+{
+	fip_wait_ready();
+//	*((volatile unsigned int *)(fip_base + offset)) = val;
+	gbus_write_uint32(pGBus, fip_base + offset, val);
+	fip_wait_ready();
+}
+
+#ifdef __KERNEL__
+#ifdef ENABLE_WRITE_INTR
+/* To queue the write request */
+static void fip_queue_command(unsigned int cmd, unsigned int data)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&fip_priv.lock, flags);
+	if (((fip_priv.cmd_pidx + 1) % CMDQ_SIZE) == fip_priv.cmd_cidx) {
+		printk(KERN_ERR "Command queue full.\n");
+		fip_issue_command(&fip_priv);
+	} else {
+		fip_priv.cmds[fip_priv.cmd_pidx].cmd = cmd;
+		fip_priv.cmds[fip_priv.cmd_pidx].data = data;
+		fip_priv.cmd_pidx = ((fip_priv.cmd_pidx + 1) % CMDQ_SIZE);
+	}
+	spin_unlock_irqrestore(&fip_priv.lock, flags);
+}
+#endif
+#endif
+
+#ifdef __KERNEL__
+static int is_fip_busy_nowait(void)
+{
+	return((fip_read_reg(FIP_CONFIG) & FIP_BUSY) != 0);
+}
+#endif
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+int is_fip_busy(void)
+{
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	fip_usleep(10);
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	fip_usleep(20);
+#endif
+	return((fip_read_reg(FIP_CONFIG) & FIP_BUSY) != 0);
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+void fip_wait_ready(void)
+{
+	while (is_fip_busy());
+#if defined(CONFIG_TANGOX_FIP_REF2)
+	fip_usleep(20);
+#endif
+}
+
+static void fip_user_display(int adr, int data)
+{
+#ifdef __KERNEL__
+#ifdef ENABLE_WRITE_INTR
+	fip_wait_ready();
+	fip_queue_command(FIP_CMD_ADR_SETTING | (adr), data);
+#else
+	fip_wait_ready();
+	fip_write_reg(FIP_DISPLAY_DATA, data);
+	fip_write_reg(FIP_COMMAND, FIP_CMD_ADR_SETTING | (adr));
+#endif
+#else
+	fip_wait_ready();
+	fip_write_reg(FIP_DISPLAY_DATA, data);
+	fip_wait_ready();
+	fip_write_reg(FIP_COMMAND, FIP_CMD_ADR_SETTING | (adr));
+	fip_wait_ready();
+#endif
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+int fip_display_character(const int position, const char character) 
+{
+	int i, byte1, byte2;
+	unsigned char current_contents0, current_contents1;
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	const int min_pos = 1;
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	const int min_pos = 0;
+#endif
+	
+	if ((position < min_pos) || (position > NUM_DIGITS)) {
+#ifdef __KERNEL__
+		printk(KERN_DEBUG "%s: position %d not available/supported.\n",
+				fip_devname, position);
+#else
+		uart_printf("%s: position %d not available/supported.\n",
+				fip_devname, position);
+#endif /* __KERNEL__ */
+		return(0);
+	}
+
+	for (i = 0; i < NUM_CHARACTERS; i++) {
+		if (character == fipcharactersmap[i]) {
+			byte1 = 24 - (3 * position);
+			byte2 = 25 - (3 * position);
+
+			current_contents0 = fipram[byte1];
+			current_contents1 = fipram[byte2];
+
+			/* clear */	
+			fipram[byte1] &= fipcharactermask[0];
+			fipram[byte2] &= fipcharactermask[1];
+			
+			/* set new bits */
+			fipram[byte1] |= fipcharacters[i][0];
+			fipram[byte2] |= fipcharacters[i][1];
+
+			/* display if necessary */
+			if (current_contents0 != fipram[byte1])
+				fip_user_display(byte1, fipram[byte1]);
+			if (current_contents1 != fipram[byte2])
+				fip_user_display(byte2, fipram[byte2]);
+			return(1);
+		}
+	}
+#ifdef __KERNEL__
+	printk(KERN_DEBUG "%s: character '%c' not available/supported.\n", fip_devname, character);
+#else
+	uart_printf("%s: character '%c' not available/supported.\n", fip_devname, character);
+#endif /* __KERNEL__ */
+	return(0);
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+void fip_clear(void)
+{
+	register int i;
+
+	for (i = 0; i < MAX_FIP_RAM; i++) {
+		fipram[i] = 0;
+		fip_user_display(i, fipram[i]);
+	}
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+void fip_display_raw(const int byte, const int bit, const int on) 
+{
+	unsigned char current_contents;
+	current_contents = fipram[byte];
+	if (on != 0)
+		fipram[byte] |= (1 << bit);
+	else
+		fipram[byte] &= ~(1 << bit);
+
+	/* display only if necessary */
+	if (current_contents != fipram[byte])
+		fip_user_display(byte, fipram[byte]);
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+void fip_display_symbol(const int symbol, const int on) 
+{
+	if ((symbol < 0) || (symbol >= NUM_SYMBOLS)) {
+#ifdef __KERNEL__
+		printk(KERN_DEBUG "%s: symbol #%d not available/supported.\n", fip_devname, symbol);
+#else
+		uart_printf("%s: symbol #%d not available/supported.\n", fip_devname, symbol);
+#endif /* __KERNEL__ */
+		return;
+	}
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	fip_display_raw(fipsymbols[symbol][0], fipsymbols[symbol][1], on);
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	//0-99 displays tra/chap number field (0-99)
+	//100-199 displays title number field (0-99)
+	//200 clears all in this area
+	//201-206 displays symbols without effecting other fields
+	if (symbol > 200) {
+		 //fip_display_raw(fipsymbols[symbol-200][0], fipsymbols[symbol-200][1], on);
+		 switch(symbol) {
+		 	case 201:
+				fip_user_display(0, 1);
+				break;
+			case 202:
+				fip_user_display(0, 2);
+				break;
+			case 203:
+				fip_user_display(0, 4);
+				break;
+			case 204:
+				fip_user_display(0, 8);
+				break;
+			case 205:
+				fip_user_display(27, 1);
+				break;
+			case 206:
+				fip_user_display(29, 1);
+				break;
+		 }
+	} else if (symbol == 200) { 
+		fipram[27] = fipxcharacters[11];
+		fipram[28] = fipxcharacters[11];
+		fipram[30] = fipxcharacters[11];
+		fipram[31] = fipxcharacters[11];
+		fip_user_display(27, fipram[27]);
+		fip_user_display(28, fipram[28]);	
+		fip_user_display(30, fipram[30]);
+		fip_user_display(31, fipram[31]);
+			
+	} else if (symbol >= 100) { 
+		fipram[27] = fipxcharacters[(symbol-100)/10];
+		fipram[28] = fipxcharacters[(symbol-100)%10];
+		fip_user_display(27, fipram[27]);
+		fip_user_display(28, fipram[28]);
+	} else if (symbol >= 0) {
+		fipram[30] = fipxcharacters[symbol/10];
+		fipram[31] = fipxcharacters[symbol%10];	
+		fip_user_display(30, fipram[30]);
+		fip_user_display(31, fipram[31]);	
+	}
+#endif
+}
+
+#ifdef __KERNEL__
+static
+#endif /* __KERNEL__ */
+void fip_write_text(const int position, const char *text, const int flags) 
+{
+	int x, i, j;
+	int textLen = strlen (text);
+
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	if (flags & FIP_CENTER)
+		x = (position > 0) ? position - textLen / 2 : (NUM_DIGITS - textLen) / 2 + 1;
+	else if (flags & FIP_RIGHT)
+		x = (position > 0) ? position - textLen : NUM_DIGITS - textLen + 1;
+	else 
+		x = (position > 0) ? position : 1;
+	if (x < 1)
+		x = 1;
+
+	if ((flags & FIP_NO_CLEAR) == 0) {
+		/* clear colons */
+		fip_display_symbol(COLON_HOUR_MIN_FIP_ON, 0);
+		fip_display_symbol(COLON_MIN_SEC_FIP_ON, 0);
+	}
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	if (flags & FIP_CENTER)
+		x = (position >= 0) ? position - textLen / 2 : (NUM_DIGITS - textLen) / 2 + 1;
+	else if (flags & FIP_RIGHT)
+		x = (position >= 0) ? position - textLen : NUM_DIGITS - textLen + 1;
+	else 
+		x = (position >= 0) ? position : 1;
+	if (x < 1)
+		x = 1;
+#endif
+
+	/* show/write text */
+	j = 0;
+	for (i = 1; i <= NUM_DIGITS; i++) {
+		if ((i < x) || (i >= (x+textLen)))
+			fip_display_character(i, ' ');
+		else if (!fip_display_character(i, text[j++])) {
+#ifdef __KERNEL__
+			printk(KERN_DEBUG "%s: cannot show text '%s'.\n", fip_devname, text);
+#else
+			uart_printf("%s: cannot show text '%s'.\n", fip_devname, text);
+#endif /* __KERNEL__ */
+			break;
+		}
+	}
+}
+
+#ifdef __KERNEL__ 
+static 
+#endif /* __KERNEL__ */
+int fip_show_hms(int hour, int minute, int second)
+{
+	if (hour < L_OFF || minute < L_OFF || second < L_OFF ||
+		hour > 99 || minute > 59 || second > 59) {
+#ifdef __KERNEL__
+		printk(KERN_DEBUG "%s: parameters passed not in valid range\n", fip_devname);
+#else
+		uart_printf("%s: parameters passed not in valid range\n", fip_devname);
+#endif
+		return(1);
+	}
+ 
+#if defined(CONFIG_TANGOX_FIP_REF1)
+	// hour
+	fip_display_character(1, ' ');
+	fip_display_character(2, (hour==L_OFF) ? ' ' : hour/10 + '0');
+	fip_display_character(3, (hour==L_OFF) ? ' ' : hour%10 + '0');
+
+	// minute 
+	fip_display_character(4, (minute==L_OFF) ? ' ' : minute/10 + '0');
+	fip_display_character(5, (minute==L_OFF) ? ' ' : minute%10 + '0');
+
+	// second
+	fip_display_character(6, (second==L_OFF) ? ' ' : second/10 + '0');
+	fip_display_character(7, (second==L_OFF) ? ' ' : second%10 + '0');
+
+	// show colons if needed
+	fip_display_symbol(COLON_HOUR_MIN_FIP_ON, (hour == L_OFF) ? 0 : 1);
+	fip_display_symbol(COLON_MIN_SEC_FIP_ON, ((hour == L_OFF) && (minute == L_OFF)) ? 0 : 1);
+#elif defined(CONFIG_TANGOX_FIP_REF2)
+	// hour
+	fip_display_character(0, (hour==L_OFF) ? ' ' : hour/10 + '0');
+	fip_display_character(1, (hour==L_OFF) ? ' ' : hour%10 + '0');
+
+	// minute 
+	fip_display_character(2, (minute==L_OFF) ? ' ' : minute/10 + '0');
+	fip_display_character(3, (minute==L_OFF) ? ' ' : minute%10 + '0');
+
+	// second
+	fip_display_character(4, (second==L_OFF) ? ' ' : second/10 + '0');
+	fip_display_character(5, (second==L_OFF) ? ' ' : second%10 + '0');
+	fip_display_character(6, ' ');
+	fip_display_character(7, ' ');
+#endif
+	return(0);
+}
+
+#ifdef __KERNEL__ 
+static 
+#endif /* __KERNEL__ */
+int fip_init(void)
+{
+	static int initflag = 0;
+
+	if (initflag != 0)
+		return(0);
+
+#ifdef __KERNEL__
+	/* Disable FIP and interrupt first */
+	fip_wait_ready();
+	fip_write_reg(FIP_CONFIG, 0);
+	fip_wait_ready();
+
+#ifdef ENABLE_WRITE_INTR
+	/* Enable FIP and interrupts (read: 0x20000, write: 0x10000) */
+	fip_write_reg(FIP_CONFIG, (FIP_DIVIDER | FIP_ENABLE | 0x30000));
+#else
+	/* Enable FIP and interrupts (read: 0x20000) */
+	fip_write_reg(FIP_CONFIG, (FIP_DIVIDER | FIP_ENABLE | 0x20000));
+#endif
+#else
+	fip_wait_ready();
+	/* Enable FIP wthout enabling interrupt */
+	fip_write_reg(FIP_CONFIG, (FIP_DIVIDER | FIP_ENABLE));
+#endif /* __KERNEL__ */
+	fip_wait_ready();
+
+	/* Clear exisiting IRQ, if any */
+	fip_write_reg(FIP_INT, 0x3);
+	fip_wait_ready();
+
+	/* select display mode */
+	fip_write_reg(FIP_COMMAND, FIP_DISPLAY_MODE);
+	fip_wait_ready();
+
+	/* select brightness of display and turn it on */
+	fip_write_reg(FIP_COMMAND, FIP_CMD_DISP_CTRL_TURN_DISPLAY_ON | brightness);
+	fip_wait_ready();
+
+	/* select write to display and fixed addressing */
+	fip_write_reg(FIP_COMMAND, FIP_CMD_DATA_SET_ADR_MODE_FIXED_ADR);
+	fip_wait_ready();
+
+	fip_clear();
+	fip_wait_ready();
+	initflag = 1;
+	return(0);
+}
+
+#ifdef __KERNEL__ 
+static 
+#endif /* __KERNEL__ */
+int fip_exit(void)
+{
+	fip_clear();
+
+	/* Disable FIP and interrupt */
+	fip_write_reg(FIP_CONFIG, 0);
+	fip_wait_ready();
+	return(0);
+}
+
+#ifndef __KERNEL__ 
+unsigned long fip_readkey(void)
+{
+	unsigned long key = 0L;
+
+	fip_wait_ready();
+	fip_write_reg(FIP_COMMAND, FIP_CMD_DATA_SET_RW_MODE_READ_KEYS);
+	key = fip_read_reg(FIP_KEY_DATA1); 
+	return(key);
+}
+#endif /* __KERNEL__ */
+
+#ifdef __KERNEL__
+int __init fip_init_module(void)
+{
+	int status = 0;
+
+	if (tangox_fip_enabled() == 0)
+		return(0);
+
+	/* Initialize private data structure */
+	memset(&fip_priv, 0, sizeof(struct fip_private)); 
+#ifdef ENABLE_WRITE_INTR
+	fip_priv.cmdq_empty = 1;
+#endif
+	spin_lock_init(&fip_priv.lock);
+
+	if (buffer_size < 1) {
+		printk(KERN_ERR "%s: buffer size (%d) error\n", fip_devname,
+			buffer_size); 
+		return(-EIO);
+	} 
+	if ((fip_priv.buffer = kmalloc(buffer_size * sizeof(unsigned long), GFP_KERNEL)) == NULL) {
+		printk(KERN_ERR "%s: out of memory for buffer\n", fip_devname); 
+		return(-ENOMEM);
+	}
+
+	/* Register device, and may be allocating major# */
+	status = register_chrdev(major_num, fip_devname, &fip_fops);
+	if (status < 0) {
+		printk(KERN_ERR "%s: cannot get major number\n", fip_devname); 
+		if (fip_priv.buffer != NULL)
+			kfree(fip_priv.buffer);
+		return(status);
+	} else if (major_num == 0)
+		major_num = status;	/* Dynamic major# allocation */
+
+	/* Hook up ISR */
+	if (request_irq(fip_irq, fip_isr, IRQF_SHARED, fip_devname, &fip_priv) != 0) {
+		printk(KERN_ERR "%s: cannot register IRQ (%d)\n", fip_devname,
+			fip_irq);
+		unregister_chrdev(major_num, fip_devname);	
+		if (fip_priv.buffer != NULL)
+			kfree(fip_priv.buffer);
+		return(-EIO);
+	}
+
+	fip_init();
+	init_timer(&fip_timer);
+
+	printk("SMP863x %s (%d:0): driver loaded (buffer_size = %d)\n", 
+		fip_devname, major_num, buffer_size);
+	return(0);
+}
+
+void __exit fip_cleanup_module(void)
+{
+	if (tangox_fip_enabled() == 0)
+		return;
+
+	unregister_chrdev(major_num, fip_devname);
+	free_irq(fip_irq, &fip_priv);
+
+	if (fip_priv.buffer != NULL)
+		kfree(fip_priv.buffer);
+
+	fip_exit();
+
+	printk(KERN_DEBUG "%s: driver unloaded\n", fip_devname);
+}
+
+module_init(fip_init_module);
+module_exit(fip_cleanup_module);
+
+#endif /* __KERNEL__ */
+
diff -Naur linux-2.6.30-ori/drivers/char/irkernel.c linux-2.6.30-test/drivers/char/irkernel.c
--- linux-2.6.30-ori/drivers/char/irkernel.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/char/irkernel.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,768 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/slab.h>
+#include <linux/irq.h>
+#include <linux/poll.h>
+#include <asm/io.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/tango2_gbus.h>
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/ir.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/tango3_gbus.h>
+#include <asm/tango3/hardware.h>
+#include <asm/tango3/ir.h>
+#endif
+
+/* For all SMP86xx, it's always there */
+#if defined(CONFIG_TANGO2_SMP863X) || defined(CONFIG_TANGO3_SMP865X)
+#define WITH_RC5_CONTROL
+/* For SMP863xES4 or above, it's always there */
+#if (defined(CONFIG_TANGO2_SMP863X) && (EM86XX_REVISION > 3)) || defined(CONFIG_TANGO3_SMP865X)
+#define WITH_RC6_CONTROL
+#endif
+#endif
+
+//#define DEBUG_IR
+//#define ALL_KEYS_REPEATABLE
+
+#define SYS_gpio_base		SYS_gpio_dir
+
+/* NEC Control */
+#define IR_NEC_CTRL             (REG_BASE_system_block + SYS_gpio_base + 0x18)
+#define IR_NEC_CAPTURE_DATA    	(REG_BASE_system_block + SYS_gpio_base + 0x1c)
+
+#ifdef WITH_RC5_CONTROL
+/* RC5 Control */
+#define IR_RC5_CTRL             (REG_BASE_system_block + SYS_gpio_base + 0x20)
+#define IR_RC5_DECODE_CLK_DIV  	(REG_BASE_system_block + SYS_gpio_base + 0x24)
+#define IR_RC5_DECODER_DATA    	(REG_BASE_system_block + SYS_gpio_base + 0x28)
+#define IR_RC5_INT_STATUS    	(REG_BASE_system_block + SYS_gpio_base + 0x2c)
+#endif /* WITH_RC5_CONTROL */
+
+#ifdef WITH_RC6_CONTROL
+/* RC6 Control */
+#define RC6_DWORDS		5	/* 5 dwords = 20 bytes */
+#define IR_RC6_CTRL             (REG_BASE_system_block + SYS_gpio_base + 0xe0)
+#define IR_RC6_T_CTRL           (REG_BASE_system_block + SYS_gpio_base + 0xe4)
+#define IR_RC6_DATA_OUT0        (REG_BASE_system_block + SYS_gpio_base + 0xe8)
+#define IR_RC6_DATA_OUT1        (REG_BASE_system_block + SYS_gpio_base + 0xec)
+#define IR_RC6_DATA_OUT2        (REG_BASE_system_block + SYS_gpio_base + 0xf0)
+#define IR_RC6_DATA_OUT3        (REG_BASE_system_block + SYS_gpio_base + 0xf4)
+#define IR_RC6_DATA_OUT4        (REG_BASE_system_block + SYS_gpio_base + 0xf8)
+#endif
+
+/* The buffer size defines the size of circular buffer to keep the IR data */
+#ifdef WITH_RC6_CONTROL
+#define BUF_SIZE		6 	/* Minimum 20 bytes */
+#else
+#define BUF_SIZE		2
+#endif
+
+/* Wait period, to avoid bouncing? */
+#define WAIT_PERIOD		10
+
+/* Max. size of key table */
+#define MAX_KEYS		32
+
+/* The major device number and name */
+#define IR_DEV_MAJOR		0
+#define IR_DEV_NAME		"ir"
+
+#define DRIVER_VERSION         "1.17"
+
+MODULE_DESCRIPTION("TANGOX ir remote driver\n");
+MODULE_AUTHOR("TANGOX standalone team");
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRIVER_VERSION);
+
+#ifdef WITH_RC5_CONTROL
+static int rc5_clk_div = 48006;	/* 48006 = 1.778ms, 36018 = 1.334ms, */
+				/* 59994 = 2.222ms */
+module_param(rc5_clk_div, int, 0);
+#endif /* WITH_RC5_CONTROL */
+
+static int wait_period = ((((WAIT_PERIOD * HZ) / 1000) == 0) ? 1 : ((WAIT_PERIOD * HZ) / 1000));
+module_param(wait_period, int, 0);
+static int wp_var; /* Variable wait period */
+
+static int buffer_size = BUF_SIZE;
+module_param(buffer_size, int, 0);
+
+static int max_keys = MAX_KEYS;
+module_param(max_keys, int, 0);
+
+static int major_num = IR_DEV_MAJOR;
+module_param(major_num, int, 0);
+
+static int repeat_sends_zero = 0;
+module_param(repeat_sends_zero, int, 0);
+
+/* Wait queue, may be used if block mode is on */
+DECLARE_WAIT_QUEUE_HEAD(ir_wq);
+
+/* Private data structure */
+struct ir_private {
+	unsigned long *buffer;		/* Circular buffer */
+	unsigned long *key_table;	/* Table for repetition keys */
+	unsigned p_idx;			/* Index of producer */
+	unsigned c_idx; 		/* Index of consumer */
+	unsigned ref_cnt;		/* Reference count */
+	spinlock_t lock;		/* Spin lock */
+	unsigned char b_mode;		/* Blocking mode or not */
+	unsigned long last_jiffies;	/* Timestamp for last reception */
+	unsigned int num_keys;		/* Number of keys in the table */
+};
+
+/* Some prototypes */
+static int ir_open(struct inode *, struct file *);
+static int ir_release(struct inode *, struct file *);
+static int ir_read(struct file *, char *, size_t, loff_t *);
+static int ir_ioctl(struct inode *, struct file *, unsigned int, unsigned long);
+static unsigned int ir_poll(struct file *, struct poll_table_struct *);
+
+/* Global data */
+static struct ir_private ir_priv;
+static char *ir_devname = IR_DEV_NAME;
+static int ir_irq = LOG2_CPU_INFRARED_INT + IRQ_CONTROLLER_IRQ_BASE;
+
+static struct file_operations ir_fops = {
+	open: ir_open,
+	read: ir_read,
+	ioctl: ir_ioctl,
+	poll: ir_poll,
+	release: ir_release,
+	owner: THIS_MODULE,
+};
+
+/* Check to see if we can find the key in the repetition key table */
+static int ir_findkey(struct ir_private *priv, unsigned long key)
+{
+#ifdef ALL_KEYS_REPEATABLE
+	return(key);
+#else
+	register unsigned int i;
+	unsigned long *ptr = priv->key_table;
+
+	for (i = 0; i < priv->num_keys; i++, ptr++)
+		if (key == *ptr)
+			return(key);
+	return(0);
+#endif
+}
+
+/* Produce data */
+static void ir_produce(struct ir_private *priv, unsigned long status)
+{
+	static unsigned long old_key = 0;
+	static unsigned long save_key = 0;
+	unsigned long data = 0;
+	unsigned pidx;
+	int repeat_key = 0;
+#ifdef WITH_RC6_CONTROL
+	static unsigned long save_rc6_key[RC6_DWORDS];	/* Only used for RC6 */
+#endif
+
+	spin_lock(&priv->lock);
+
+#ifdef WITH_RC6_CONTROL
+	if ((status & 0x80000000) != 0) {	// RC6 Data in IRQ
+		unsigned long dx[RC6_DWORDS];
+		dx[0] = gbus_read_uint32(pGBus, IR_RC6_DATA_OUT0);
+		dx[1] = gbus_read_uint32(pGBus, IR_RC6_DATA_OUT1);
+		dx[2] = gbus_read_uint32(pGBus, IR_RC6_DATA_OUT2);
+		dx[3] = gbus_read_uint32(pGBus, IR_RC6_DATA_OUT3);
+		dx[4] = gbus_read_uint32(pGBus, IR_RC6_DATA_OUT4);
+#ifdef DEBUG_IR
+		printk(KERN_DEBUG "D0-4: 0x%08lx 0x%08lx 0x%08lx 0x%08lx 0x%08lx\n", dx[0], 
+				dx[1], dx[2], dx[3], dx[4]);
+#endif
+		if ((dx[0] & 0x1f) != 0x1c) { 
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "Not acceptable RC6 code 0x%08lx\n", dx[0]);
+#endif
+			goto out;	/* Not valid */
+		} else if (time_after(priv->last_jiffies + wait_period, jiffies) && 
+			(memcmp(&save_rc6_key, &dx, sizeof(unsigned long) * RC6_DWORDS) == 0)) {
+			/* Throw away this key if this is the same key and came too
+		   	   fast */
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "%s: same data\n", ir_devname);
+#endif
+			save_key = 0;
+			goto out;
+		} 
+
+		/* Save the key */
+		memcpy(&save_rc6_key, &dx, sizeof(unsigned long) * RC6_DWORDS);
+
+		priv->last_jiffies = jiffies;
+		pidx = priv->p_idx;	/* Save the old index before proceeding */
+
+		/* Save it to buffer */
+		if (((priv->p_idx + 1) % buffer_size) == priv->c_idx) {
+			/* Adjust consumer index since buffer is full */
+			/* Keep the latest one and drop the oldest one */
+			priv->c_idx = (priv->c_idx + 1) % buffer_size;
+			printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+		} else if (((priv->p_idx + 2) % buffer_size) == priv->c_idx) {
+			/* Adjust consumer index since buffer is full */
+			/* Keep the latest one and drop the oldest ones */
+			priv->c_idx = (priv->c_idx + 2) % buffer_size;
+			printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+		} else if (((priv->p_idx + 3) % buffer_size) == priv->c_idx) {
+			/* Adjust consumer index since buffer is full */
+			/* Keep the latest one and drop the oldest ones */
+			priv->c_idx = (priv->c_idx + 3) % buffer_size;
+			printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+		} else if (((priv->p_idx + 4) % buffer_size) == priv->c_idx) {
+			/* Adjust consumer index since buffer is full */
+			/* Keep the latest one and drop the oldest ones */
+			priv->c_idx = (priv->c_idx + 4) % buffer_size;
+			printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+		} else if (((priv->p_idx + 5) % buffer_size) == priv->c_idx) {
+			/* Adjust consumer index since buffer is full */
+			/* Keep the latest one and drop the oldest ones */
+			priv->c_idx = (priv->c_idx + 5) % buffer_size;
+			printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+		}
+
+/*		priv->buffer[priv->p_idx] = dx[0];
+		priv->p_idx = (priv->p_idx + 1) % buffer_size;*/
+		priv->buffer[priv->p_idx] = dx[1]<<4; // Experimental support for miniclient... JFT
+		priv->p_idx = (priv->p_idx + 1) % buffer_size;
+/*		priv->buffer[priv->p_idx] = dx[2];
+		priv->p_idx = (priv->p_idx + 1) % buffer_size;
+		priv->buffer[priv->p_idx] = dx[3];
+		priv->p_idx = (priv->p_idx + 1) % buffer_size;
+		priv->buffer[priv->p_idx] = dx[4];
+		priv->p_idx = (priv->p_idx + 1) % buffer_size;*/
+
+		/* Buffer was empty and block mode is on, wake up the reader */
+		if ((priv->b_mode != 0) && (priv->c_idx == pidx)) 
+			wake_up_interruptible(&ir_wq);
+
+		goto out;
+	}
+#endif
+
+#ifdef WITH_RC5_CONTROL
+	if (status & 0x00000001) {	// RC5 IRQ
+		data = gbus_read_uint32(pGBus, IR_RC5_DECODER_DATA);
+		gbus_write_uint32(pGBus, IR_RC5_DECODER_DATA, 0);
+		if ((data & 0x80000000) != 0)  /* Invalid RC5 decoder data */
+			goto out;
+	} else if (status & 0x00000002) {	// NEC IRQ
+		data = gbus_read_uint32(pGBus, IR_NEC_CAPTURE_DATA);
+		gbus_write_uint32(pGBus, IR_NEC_CAPTURE_DATA, 0);
+	} else
+		goto out;
+#else
+	data = gbus_read_uint32(pGBus, IR_NEC_CAPTURE_DATA);
+	gbus_write_uint32(pGBus, IR_NEC_CAPTURE_DATA, 0);
+#endif
+
+	/* Discard not used data if needed */
+	if (data == 0) {
+		if (save_key == 0)
+			goto out;
+		old_key = 0;
+#ifdef DEBUG_IR
+		printk(KERN_DEBUG "%s: no data\n", ir_devname);
+#endif
+		if (time_after(priv->last_jiffies + wp_var, jiffies)) {
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "%s: repetition too fast\n", ir_devname);
+#endif
+			goto out; 	/* Key repeats too fast, drop it */
+		} else if (time_before(priv->last_jiffies + (wait_period * 4), jiffies)) {
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "%s: got slow repetition, glitch?\n", ir_devname);
+#endif
+			save_key = 0;	/* Disallow key repitition */
+			goto out;	/* Repeat too slow, drop it */
+		} else if (ir_findkey(priv, save_key) == 0) {
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "%s: not repeatable key 0x%lx\n", ir_devname, save_key);
+#endif
+			goto out; /* If the key is not in the table, drop it */
+		}
+
+#ifdef DEBUG_IR
+		printk(KERN_DEBUG "%s: got repeated key 0x%lx\n", ir_devname, save_key);
+#endif
+		data = save_key; /* Valid repeated key */
+		repeat_key = 1;
+	} else if (time_after(priv->last_jiffies + wait_period, jiffies) && 
+			(data == old_key)) {
+		/* Throw away this key if this is the same key and came too
+		   fast */
+#ifdef DEBUG_IR
+		printk(KERN_DEBUG "%s: same data\n", ir_devname);
+#endif
+		save_key = 0;
+		goto out;
+	} 
+
+	/* Shrink the wait time for repeat key if current one is repeated */
+	wp_var = (repeat_key ? (wait_period / 2) : wait_period); 
+	priv->last_jiffies = jiffies;
+	save_key = old_key = data;
+
+#ifdef DEBUG_IR
+	printk(KERN_DEBUG "%s: got data 0x%08lx\n", ir_devname, data);
+#endif
+
+	pidx = priv->p_idx;	/* Save the old index before proceeding */
+
+	if (repeat_sends_zero && repeat_key)
+		data = 0; /* clear the data */
+
+	/* Save it to buffer */
+	if (((priv->p_idx + 1) % buffer_size) == priv->c_idx) {
+		/* Adjust consumer index since buffer is full */
+		/* Keep the latest one and drop the oldest one */
+		priv->c_idx = (priv->c_idx + 1) % buffer_size;
+
+		printk(KERN_WARNING "%s: buffer full\n", ir_devname);
+	}
+
+	priv->buffer[priv->p_idx] = data;
+	priv->p_idx = (priv->p_idx + 1) % buffer_size;
+
+	/* Buffer was empty and block mode is on, wake up the reader */
+	if ((priv->b_mode != 0) && (priv->c_idx == pidx)) 
+		wake_up_interruptible(&ir_wq);
+
+out:
+	spin_unlock(&priv->lock);
+}
+
+/* ISR for IR device */
+static irqreturn_t ir_isr(int irq, void *dev_id)
+{
+	struct ir_private *priv = (struct ir_private *)dev_id;
+	unsigned long status = 0;
+
+	if (priv != &ir_priv)		/* Paranoid check */
+		return IRQ_NONE;
+
+	// gbus_write_uint32(pGBus, REG_BASE_CPU + CPU_edge_rawstat, IRQMASKOF(ir_irq));
+	
+#ifdef WITH_RC6_CONTROL 
+	status = gbus_read_uint32(pGBus, IR_RC6_CTRL);
+	if ((status & 0xc0000000) != 0) {
+		gbus_write_uint32(pGBus, IR_RC6_CTRL, status); /* Clear interrupt */
+#ifdef DEBUG_IR
+		if ((status & 0x40000000) != 0) 
+			printk(KERN_DEBUG "RC6 Err IRQ (0x%08lx)\n", status);
+#endif
+		if ((status & 0x80000000) != 0) {
+			/* We have RC6 data */
+#ifdef DEBUG_IR
+			printk(KERN_DEBUG "RC6 Datain IRQ (0x%08lx)\n", status);
+#endif
+			ir_produce(priv, status);
+
+#ifdef WITH_RC5_CONTROL
+			/* Force to clear RC5 interrupt status */
+			status = gbus_read_uint32(pGBus, IR_RC5_INT_STATUS);
+			if ((status & 0x00000003) != 0)
+				gbus_write_uint32(pGBus, IR_RC5_INT_STATUS, status); /* Clear interrupt if any */
+#endif
+			return IRQ_HANDLED;
+		} 
+	}
+#endif
+
+#ifdef WITH_RC5_CONTROL
+	status = gbus_read_uint32(pGBus, IR_RC5_INT_STATUS);
+#ifdef DEBUG_IR
+	if ((status & 0x00000001) != 0) {
+		/* RC5 interrupt */
+		printk(KERN_DEBUG "RC5 IRQ (0x%08lx)\n", status);
+	}
+	if ((status & 0x00000002) != 0) {
+		/* NEC interrupt */
+		printk(KERN_DEBUG "NEC IRQ (0x%08lx)\n", status);
+	}
+#endif
+	gbus_write_uint32(pGBus, IR_RC5_INT_STATUS, status); /* Clear interrupt */
+	status &= 0x00000003;
+#endif /* WITH_RC5_CONTROL */
+
+	ir_produce(priv, status);
+	return IRQ_HANDLED;
+}
+
+/* Reading from driver's buffer, note that it can return read size
+   less than specified */
+static int ir_consume(void *dev_id, unsigned long *buf, int count)
+{
+	struct ir_private *priv = (struct ir_private *)dev_id;
+	int cnt = 0;
+	unsigned long flags;
+
+	/* If block mode is on, check the emptiness of buffer */
+	if (priv->b_mode != 0) {
+		/* Sleep when buffer is empty */
+		wait_event_interruptible(ir_wq, priv->c_idx != priv->p_idx);
+	}
+	if (signal_pending(current))
+		return(cnt);
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	/* Get the data out and adjust consumer index */
+	for (cnt = 0; (priv->c_idx != priv->p_idx) && (cnt < count); cnt++) {
+		*buf = priv->buffer[priv->c_idx];
+		priv->c_idx = (priv->c_idx + 1) % buffer_size;
+		buf++;
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return(cnt);
+}
+
+/* Reading data */
+static int ir_read(struct file *fptr, char *bufptr, size_t size, loff_t *fp)
+{
+	unsigned long buf[buffer_size];
+	int count;
+
+	/* Check the alignment */
+	if (size % sizeof(unsigned long)) {
+		printk(KERN_WARNING "%s: read size not aligned to %d\n",
+			ir_devname, sizeof(unsigned long));
+		return(-EIO);
+	}
+
+	count = ir_consume(fptr->private_data, &buf[0], 
+			size / sizeof(unsigned long)) * sizeof(unsigned long);
+
+	/* Get the data to user */
+	if (count && copy_to_user(bufptr, (char *)&buf[0], count)) 
+		return(-EFAULT);
+
+	return(count);
+}
+
+extern int tangox_get_gpioled();
+
+/* ioctl function */
+static int ir_ioctl(struct inode *inode, struct file *fptr, unsigned int cmd, unsigned long arg)
+{
+	unsigned long *ptr = (unsigned long *)arg;
+	unsigned long key_no = 0;
+	struct ir_private *priv = (struct ir_private *)fptr->private_data;
+	unsigned long flags;
+
+	if (ptr == NULL && cmd!=FIP_IOCSHOWLED)
+		return(-EIO);
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	switch(cmd) {
+		case IR_IOCSETREPEATKEYS: /* Set the repetition keys */
+			if (copy_from_user(&key_no, ptr, sizeof(unsigned long))) {
+				spin_unlock_irqrestore(&priv->lock, flags);
+				return(-EFAULT);
+			} else if ((key_no <= 0) || (key_no > max_keys)) {
+				spin_unlock_irqrestore(&priv->lock, flags);
+				return(-EIO);
+			} else
+				priv->num_keys = key_no;
+			copy_from_user(priv->key_table, ptr + 1, sizeof(unsigned long) * key_no);
+			break;
+		case IR_IOCGETREPEATKEYS: /* Get the repetition keys */
+			key_no = priv->num_keys;
+			copy_to_user(ptr, &key_no, sizeof(unsigned long));
+			if (key_no > 0)
+				copy_to_user(ptr + 1, priv->key_table, sizeof(unsigned long) * key_no);
+			break;
+		case IR_IOCSETWAITPERIOD:
+			wait_period = wp_var = ((((arg * HZ) / 1000) == 0) ? 1 : ((arg * HZ) / 1000));
+			break;
+		case IR_IOCGETWAITPERIOD: {
+				int wp = (wait_period * 1000) / HZ;
+				copy_to_user(ptr, &wp, sizeof(int));
+			}
+			break;
+		case FIP_IOCSHOWLED:
+			if(tangox_get_gpioled()<16)
+				gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_dir, 
+					GPIO_DIR_OUTPUT(tangox_get_gpioled()));
+			else
+				gbus_write_uint32(pGBus, REG_BASE_host_interface + ETH_gpio_dir2, 
+					GPIO_DIR_OUTPUT(tangox_get_gpioled()-16));
+			if(arg==12)
+			{
+				if(tangox_get_gpioled()<16)
+					gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_data, 
+						GPIO_DATA_SET(tangox_get_gpioled()));
+				else
+					gbus_write_uint32(pGBus, REG_BASE_host_interface + ETH_gpio_data2, 
+						GPIO_DATA_SET(tangox_get_gpioled()-16));
+			}
+			else if(arg==4)
+			{
+				if(tangox_get_gpioled()<16)
+					gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_data, 
+						GPIO_DATA_CLEAR(tangox_get_gpioled()));
+				else
+					gbus_write_uint32(pGBus, REG_BASE_host_interface + ETH_gpio_data2, 
+						GPIO_DATA_CLEAR(tangox_get_gpioled()-16));
+			}
+			else if(arg==0)
+			{
+				if(tangox_get_gpioled()<16)
+					gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_data, 
+						GPIO_DATA_SET(tangox_get_gpioled()));
+				else
+					gbus_write_uint32(pGBus, REG_BASE_host_interface + ETH_gpio_data2, 
+						GPIO_DATA_SET(tangox_get_gpioled()-16));
+			}
+			else
+			{
+				if(tangox_get_gpioled()<16)
+					gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_data, 
+						GPIO_DATA_SET(tangox_get_gpioled()));
+				else
+					gbus_write_uint32(pGBus, REG_BASE_host_interface + ETH_gpio_data2, 
+						GPIO_DATA_SET(tangox_get_gpioled()-16));
+			}
+			break;
+		default:
+			spin_unlock_irqrestore(&priv->lock, flags);
+                        return(-EIO);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return(0);
+}
+
+/* Poll function */
+static unsigned int ir_poll(struct file *fptr, struct poll_table_struct *ptable)
+{
+	struct ir_private *priv = (struct ir_private *)fptr->private_data;
+	unsigned int mask = 0;
+	unsigned long flags;
+
+	poll_wait(fptr, &ir_wq, ptable);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	if (priv->c_idx != priv->p_idx)
+		mask |= (POLLIN | POLLRDNORM);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return(mask);
+}
+
+/* Open the device */
+static int ir_open(struct inode *inode_ptr, struct file *fptr)
+{
+	/* This device is exclusive, that is, only one process can use it */
+	if (ir_priv.ref_cnt != 0) {
+		printk(KERN_WARNING "%s: exclusive access only\n", ir_devname);
+		return(-EIO);
+	/* This device is read-only */
+	} else if ((fptr->f_flags & O_ACCMODE) != O_RDONLY) {
+		printk(KERN_WARNING "%s: read-only device\n", ir_devname);
+		return(-EIO);
+	} 
+
+	/* Set the block mode and increase reference count */
+	ir_priv.ref_cnt++;
+	ir_priv.b_mode = ((fptr->f_flags & O_NONBLOCK) ? 0 : 1);
+	ir_priv.last_jiffies = jiffies;
+
+	/* Flush the buffer */
+	ir_priv.p_idx = ir_priv.c_idx = 0;
+
+	fptr->f_op = &ir_fops;
+	fptr->private_data = (void *)&ir_priv;
+
+	/* Enable the NEC device (CTRL register) */
+	/*	31:30 - reserved */
+	/*	29:24 	IR_CAPTURE_NBITS [5:0] -> set to 0x1f */
+	/*	23:22 - reserved */
+	/*	21:16 	GPIO_INFREARED_SEL [5:0] -> set to 12 */
+	/*	15:14 - reserved */
+	/*	13:0	IR_PREDIV_DEVIDER [13:0] -> set to 0x3b10 */
+	gbus_write_uint32(pGBus, REG_BASE_system_block + SYS_gpio_dir, GPIO_DIR_INPUT(12));
+	gbus_write_uint32(pGBus, IR_NEC_CAPTURE_DATA, 0);
+	gbus_write_uint32(pGBus, IR_NEC_CTRL, 0x1f0c3b10);
+
+	wp_var = wait_period;
+
+	printk(KERN_DEBUG "%s: Enable NEC decoder (0x%08lx)\n", 
+			ir_devname, gbus_read_uint32(pGBus, IR_NEC_CAPTURE_DATA));
+
+#ifdef WITH_RC5_CONTROL
+	/* Enable the RC5 device (CTRL register) */
+	/*	31:10 - reserved */
+	/*	9	IR_RC5_INT_ENABLE -> set */
+	/*	8	IR_NEC_INT_DISABLE */
+	/*	7	IR_DEBOUNCE_SEL1 -> set */
+	/*	6	IR_DEBOUNCE_SEL0 -> set */
+	/*	5	IR_DEBOUNCE_ENABLE -> set */
+	/*	4	IR_NEC_DISABLE */
+	/*	3	IR_RSYNC_1/4 -> set */
+	/*	2	IR_RSYNC_1/8 */
+	/*	1	IR_SIGNAL_INVERT */
+	/*	0	IR_RC5_DECODE_ENABLE -> set */
+	gbus_write_uint32(pGBus, IR_RC5_DECODE_CLK_DIV, rc5_clk_div);
+	gbus_write_uint32(pGBus, IR_RC5_DECODER_DATA, 0);
+	gbus_write_uint32(pGBus, IR_RC5_CTRL, 0x000002e9);
+
+	printk(KERN_DEBUG "%s: Enable RC5 decoder (0x%08lx)\n", 
+			ir_devname, gbus_read_uint32(pGBus, IR_RC5_DECODER_DATA));
+#endif /* WITH_RC5_CONTROL */
+
+#ifdef WITH_RC6_CONTROL
+	/* Enable the RC6 device (CTRL register) */
+	/*	7	IR_RC6_DATA_IN_INT_ENABLE -> set */
+	/*	6	IR_RC6_ERROR_INT_ENABLE -> set */
+	/*	5:2	reserved */
+	/*	1	IR_SIGNAL_INVERT */
+	/*	0	IR_RC6_DECODE_ENABLE -> set */
+	gbus_write_uint32(pGBus, IR_RC6_CTRL, 0xc1);
+	/* Tolerance and Duration */
+	/*	31:18	Tolerance (typ. 0xbb8) */
+	/*	17:0	Duration (typ. 0x2ee0) */
+	gbus_write_uint32(pGBus, IR_RC6_T_CTRL, (0xbb8 << 18) | 0x2ee0);
+
+	printk(KERN_DEBUG "%s: Enable RC6 decoder\n", ir_devname);
+#endif
+	return(0);
+}
+
+/* Close the device */
+static int ir_release(struct inode *inode_ptr, struct file *fptr) 
+{
+	/* Disable the NEC device */
+	printk(KERN_DEBUG "%s: Disable NEC decoder\n", ir_devname);
+	gbus_write_uint32(pGBus, IR_NEC_CAPTURE_DATA, 0);
+	gbus_write_uint32(pGBus, IR_NEC_CTRL, 0);
+
+#ifdef WITH_RC5_CONTROL
+	/* Disable RC5 control */
+	printk(KERN_DEBUG "%s: Disable RC5 decoder\n", ir_devname);
+	gbus_write_uint32(pGBus,  IR_RC5_CTRL, (gbus_read_uint32(pGBus, IR_RC5_CTRL) & 0xfffffdfe) | 0x00000100);
+#endif /* WITH_RC5_CONTROL */
+
+#ifdef WITH_RC6_CONTROL
+	printk(KERN_DEBUG "%s: Disable RC6 decoder\n", ir_devname);
+	gbus_write_uint32(pGBus, IR_RC6_CTRL, 0xc0000000);
+#endif /* WITH_RC6_CONTROL */
+
+	/* Adjust reference count */
+	ir_priv.ref_cnt--;
+
+	return(0);
+}
+
+int __init ir_init_module(void)
+{
+	int status = 0;
+
+	extern int tangox_ir_enabled(void);
+	if (tangox_ir_enabled() == 0)
+		return(0);
+
+	/* Initialize private data structure */
+	memset(&ir_priv, 0, sizeof(struct ir_private)); 
+	spin_lock_init(&ir_priv.lock);
+
+#ifdef WITH_RC6_CONTROL
+	if (buffer_size < 6) {
+		printk(KERN_ERR "%s: buffer size (%d) error, minimum 6.\n", ir_devname,
+			buffer_size); 
+		return(-EIO);
+	} 
+#else
+	if (buffer_size < 2) {
+		printk(KERN_ERR "%s: buffer size (%d) error, minimum 2.\n", ir_devname,
+			buffer_size); 
+		return(-EIO);
+	} 
+#endif
+
+	if ((ir_priv.buffer = kmalloc(buffer_size * sizeof(unsigned long), GFP_KERNEL)) == NULL) {
+		printk(KERN_ERR "%s: out of memory for buffer\n", ir_devname); 
+		return(-ENOMEM);
+	} else if ((ir_priv.key_table = kmalloc(max_keys * sizeof(unsigned long), GFP_KERNEL)) == NULL) {
+		printk(KERN_ERR "%s: out of memory for key table\n", ir_devname); 
+		kfree(ir_priv.buffer);
+		return(-ENOMEM);
+	}
+
+	/* Register device, and may be allocating major# */
+	status = register_chrdev(major_num, ir_devname, &ir_fops);
+	if (status < 0) {
+		printk(KERN_ERR "%s: cannot get major number\n", ir_devname); 
+		kfree(ir_priv.buffer);
+		kfree(ir_priv.key_table);
+		return(status);
+	} else if (major_num == 0)
+		major_num = status;	/* Dynamic major# allocation */
+
+	/* Make sure interrupt is disabled, will be re-enabled in device
+	   open stage */
+	gbus_write_uint32(pGBus, IR_NEC_CTRL, 0);
+
+#ifdef WITH_RC5_CONTROL
+	gbus_write_uint32(pGBus, IR_RC5_CTRL, (gbus_read_uint32(pGBus, IR_RC5_CTRL) & 0xfffffdfe) | 0x00000100);
+#endif
+
+#ifdef WITH_RC6_CONTROL
+	gbus_write_uint32(pGBus, IR_RC6_CTRL, 0xc0000000);
+#endif
+
+	/* Hook up ISR */
+	if (request_irq(ir_irq, ir_isr, IRQF_SHARED, ir_devname, 
+			&ir_priv) != 0) {
+		printk(KERN_ERR "%s: cannot register IRQ (%d)\n", ir_devname,
+			ir_irq);
+		unregister_chrdev(major_num, ir_devname);	
+		kfree(ir_priv.buffer);
+		kfree(ir_priv.key_table);
+		return(-EIO);
+	}
+
+	printk(KERN_INFO "SMP86xx %s (%d:0): driver loaded (wait_period = %dms, "
+		"buffer_size = %d)\n", ir_devname, major_num, wait_period, buffer_size);
+	return(0);
+}
+
+void __exit ir_cleanup_module(void)
+{
+	extern int tangox_ir_enabled(void);
+	if (tangox_ir_enabled() == 0)
+		return;
+
+	unregister_chrdev(major_num, ir_devname);
+	free_irq(ir_irq, &ir_priv);
+
+	if (ir_priv.buffer != NULL)
+		kfree(ir_priv.buffer);
+	if (ir_priv.key_table != NULL)
+		kfree(ir_priv.key_table);
+
+	printk(KERN_INFO "%s: driver unloaded\n", ir_devname);
+}
+
+module_init(ir_init_module);
+module_exit(ir_cleanup_module);
+
diff -Naur linux-2.6.30-ori/drivers/mtd/chips/cfi_cmdset_0002.c linux-2.6.30-test/drivers/mtd/chips/cfi_cmdset_0002.c
--- linux-2.6.30-ori/drivers/mtd/chips/cfi_cmdset_0002.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/mtd/chips/cfi_cmdset_0002.c	2009-06-12 18:32:43.000000000 -0400
@@ -529,6 +529,22 @@
  * correctly and is therefore not done	(particulary with interleaved chips
  * as each chip must be checked independantly of the others).
  */
+#ifdef CONFIG_TANGOX
+/* For TANGOX, verify content in start address as well */
+static int __xipram chip_ready(struct map_info *map, unsigned long addr, unsigned long start, map_word z_val)
+{
+	map_word d, t, z;
+
+	d = map_read(map, addr);
+	mb();
+	t = map_read(map, addr);
+	mb();
+	z = map_read(map, start);
+	mb();
+
+	return map_word_equal(map, d, t) && map_word_equal(map, z, z_val);
+}
+#else
 static int __xipram chip_ready(struct map_info *map, unsigned long addr)
 {
 	map_word d, t;
@@ -538,6 +554,7 @@
 
 	return map_word_equal(map, d, t);
 }
+#endif
 
 /*
  * Return true if the chip is ready and has the correct value.
@@ -571,6 +588,9 @@
 	struct cfi_private *cfi = map->fldrv_priv;
 	unsigned long timeo;
 	struct cfi_pri_amdstd *cfip = (struct cfi_pri_amdstd *)cfi->cmdset_priv;
+#ifdef CONFIG_TANGOX
+	map_word z_val = map_read(map, chip->start);
+#endif
 
  resettime:
 	timeo = jiffies + HZ;
@@ -579,8 +599,13 @@
 
 	case FL_STATUS:
 		for (;;) {
+#ifdef CONFIG_TANGOX
+			if (chip_ready(map, adr, chip->start, z_val))
+				break;
+#else
 			if (chip_ready(map, adr))
 				break;
+#endif
 
 			if (time_after(jiffies, timeo)) {
 				printk(KERN_ERR "Waiting for chip to be ready timed out.\n");
@@ -611,6 +636,12 @@
 		    )))
 			goto sleep;
 
+		/* ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+		 * Sentivision FIX: map_write here whole flash operation freeze on VIP1216 STB.
+		 *   So we just will sleep waitting for state change: */
+		goto sleep;
+		/* ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ */
+
 		/* We could check to see if we're trying to access the sector
 		 * that is currently being erased. However, no user will try
 		 * anything like that so we just wait for the timeout. */
@@ -623,8 +654,13 @@
 		chip->state = FL_ERASE_SUSPENDING;
 		chip->erase_suspended = 1;
 		for (;;) {
+#ifdef CONFIG_TANGOX
+			if (chip_ready(map, adr, chip->start, z_val))
+				break;
+#else
 			if (chip_ready(map, adr))
 				break;
+#endif
 
 			if (time_after(jiffies, timeo)) {
 				/* Should have suspended the erase by now.
@@ -1080,6 +1116,9 @@
 	int ret = 0;
 	map_word oldd;
 	int retry_cnt = 0;
+#ifdef CONFIG_TANGOX
+	map_word z_val;
+#endif
 
 	adr += chip->start;
 
@@ -1099,6 +1138,9 @@
 	 * data at other locations when 0xff is written to a location that
 	 * already contains 0xff.
 	 */
+#ifdef CONFIG_TANGOX
+	z_val = ((adr == chip->start) ? datum : map_read(map, chip->start));
+#endif
 	oldd = map_read(map, adr);
 	if (map_word_equal(map, oldd, datum)) {
 		DEBUG( MTD_DEBUG_LEVEL3, "MTD %s(): NOP\n",
@@ -1137,15 +1179,25 @@
 			continue;
 		}
 
-		if (time_after(jiffies, timeo) && !chip_ready(map, adr)){
+#ifdef CONFIG_TANGOX
+		if (time_after(jiffies, timeo) && !chip_ready(map, adr, chip->start, z_val))
+#else
+		if (time_after(jiffies, timeo) && !chip_ready(map, adr))
+#endif
+		{
 			xip_enable(map, chip, adr);
 			printk(KERN_WARNING "MTD %s(): software timeout\n", __func__);
 			xip_disable(map, chip, adr);
 			break;
 		}
 
+#ifdef CONFIG_TANGOX
+		if (chip_ready(map, adr, chip->start, z_val))
+			break;
+#else
 		if (chip_ready(map, adr))
 			break;
+#endif
 
 		/* Latency issues. Drop the lock, wait a while and retry */
 		UDELAY(map, chip, adr, 1);
@@ -1328,6 +1380,9 @@
 	unsigned long cmd_adr;
 	int z, words;
 	map_word datum;
+#ifdef CONFIG_TANGOX
+	map_word z_val;
+#endif
 
 	adr += chip->start;
 	cmd_adr = adr;
@@ -1348,6 +1403,9 @@
 	ENABLE_VPP(map);
 	xip_disable(map, chip, cmd_adr);
 
+#ifdef CONFIG_TANGOX
+	z_val = ((adr == chip->start) ? datum : map_read(map, chip->start));
+#endif
 	cfi_send_gen_cmd(0xAA, cfi->addr_unlock1, chip->start, map, cfi, cfi->device_type, NULL);
 	cfi_send_gen_cmd(0x55, cfi->addr_unlock2, chip->start, map, cfi, cfi->device_type, NULL);
 	//cfi_send_gen_cmd(0xA0, cfi->addr_unlock1, chip->start, map, cfi, cfi->device_type, NULL);
@@ -1398,10 +1456,20 @@
 			continue;
 		}
 
+#ifdef CONFIG_TANGOX
+		if (time_after(jiffies, timeo) && !chip_ready(map, adr, chip->start, z_val))
+			break;
+#else
 		if (time_after(jiffies, timeo) && !chip_ready(map, adr))
 			break;
+#endif
 
-		if (chip_ready(map, adr)) {
+#ifdef CONFIG_TANGOX
+		if (chip_ready(map, adr, chip->start, z_val)) 
+#else
+		if (chip_ready(map, adr)) 
+#endif
+		{
 			xip_enable(map, chip, adr);
 			goto op_done;
 		}
@@ -1519,6 +1587,10 @@
 	unsigned long int adr;
 	DECLARE_WAITQUEUE(wait, current);
 	int ret = 0;
+#ifdef CONFIG_TANGOX
+	map_word z_val;
+	z_val.x[0] = ((map->bankwidth == 1) ? 0xff : 0xffff);
+#endif
 
 	adr = cfi->addr_unlock1;
 
@@ -1571,8 +1643,13 @@
 			chip->erase_suspended = 0;
 		}
 
+#ifdef CONFIG_TANGOX
+		if (chip_ready(map, adr, chip->start, z_val))
+			break;
+#else
 		if (chip_ready(map, adr))
 			break;
+#endif
 
 		if (time_after(jiffies, timeo)) {
 			printk(KERN_WARNING "MTD %s(): software timeout\n",
@@ -1607,6 +1684,9 @@
 	unsigned long timeo = jiffies + HZ;
 	DECLARE_WAITQUEUE(wait, current);
 	int ret = 0;
+#ifdef CONFIG_TANGOX
+	map_word z_val;
+#endif
 
 	adr += chip->start;
 
@@ -1620,6 +1700,13 @@
 	DEBUG( MTD_DEBUG_LEVEL3, "MTD %s(): ERASE 0x%.8lx\n",
 	       __func__, adr );
 
+#ifdef CONFIG_TANGOX
+	if (adr == chip->start)
+		z_val.x[0] = ((map->bankwidth == 1) ? 0xff : 0xffff);
+	else
+		z_val = map_read(map, chip->start);
+#endif
+
 	XIP_INVAL_CACHED_RANGE(map, adr, len);
 	ENABLE_VPP(map);
 	xip_disable(map, chip, adr);
@@ -1653,13 +1740,18 @@
 			continue;
 		}
 		if (chip->erase_suspended) {
-			/* This erase was suspended and resumed.
+		/* This erase was suspended and resumed.
 			   Adjust the timeout */
 			timeo = jiffies + (HZ*20); /* FIXME */
 			chip->erase_suspended = 0;
 		}
 
-		if (chip_ready(map, adr)) {
+#ifdef CONFIG_TANGOX
+		if (chip_ready(map, adr, chip->start, z_val))
+#else
+		if (chip_ready(map, adr)) 
+#endif
+		{
 			xip_enable(map, chip, adr);
 			break;
 		}
diff -Naur linux-2.6.30-ori/drivers/mtd/maps/Kconfig linux-2.6.30-test/drivers/mtd/maps/Kconfig
--- linux-2.6.30-ori/drivers/mtd/maps/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/mtd/maps/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -36,7 +36,7 @@
 
 config MTD_PHYSMAP_START
 	hex "Physical start address of flash mapping"
-	depends on MTD_PHYSMAP_COMPAT
+	depends on MTD_PHYSMAP_COMPAT && TANGOX_XENV_READ!=y
 	default "0x8000000"
 	help
 	  This is the physical memory location at which the flash chips
@@ -60,9 +60,9 @@
 	  Ignore this option if you use run-time physmap configuration
 	  (i.e., run-time calling physmap_configure()).
 
-config MTD_PHYSMAP_BANKWIDTH
+config MTD_PHYSMAP_BANKWIDTH 
 	int "Bank width in octets"
-	depends on MTD_PHYSMAP_COMPAT
+	depends on MTD_PHYSMAP_COMPAT && TANGOX_XENV_READ!=y
 	default "2"
 	help
 	  This is the total width of the data bus of the flash devices
diff -Naur linux-2.6.30-ori/drivers/net/Kconfig linux-2.6.30-test/drivers/net/Kconfig
--- linux-2.6.30-ori/drivers/net/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/net/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -1301,6 +1301,24 @@
 
 source "drivers/net/ibm_newemac/Kconfig"
 
+config TANGO2_ENET
+	tristate "SMP863x Builtin Ethernet support"
+	depends on NET_ETHERNET && TANGO2 && !TANGO2_SD
+	select MII
+	select CRC32
+	help
+	 This option adds support for the SMP863x integrated Ethernet
+	 controller.  This driver uses NAPI and generic Linux MII
+	 support.
+
+config TANGO2_ENET_OLD
+	tristate "SMP863x Builtin Ethernet support (old driver)"
+	depends on NET_ETHERNET && TANGO2 && !TANGO2_SD
+	help
+	 This option adds support  for the SMP863x integrated Ethernet
+	 controller. This  is the orignal driver from  Sigma with only
+	 small changes.
+
 config NET_PCI
 	bool "EISA, VLB, PCI and on board controllers"
 	depends on ISA || EISA || PCI
diff -Naur linux-2.6.30-ori/drivers/net/Makefile linux-2.6.30-test/drivers/net/Makefile
--- linux-2.6.30-ori/drivers/net/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/net/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -239,6 +239,10 @@
 obj-$(CONFIG_DNET) += dnet.o
 obj-$(CONFIG_MACB) += macb.o
 
+# For SMP863x ethernet
+obj-$(CONFIG_TANGO2_ENET) += tango2_enet.o
+obj-$(CONFIG_TANGO2_ENET_OLD) += tango2_enet_old.o
+
 obj-$(CONFIG_ARM) += arm/
 obj-$(CONFIG_DEV_APPLETALK) += appletalk/
 obj-$(CONFIG_TR) += tokenring/
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet.c linux-2.6.30-test/drivers/net/tango2_enet.c
--- linux-2.6.30-ori/drivers/net/tango2_enet.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet.c	2009-06-23 18:39:38.000000000 -0400
@@ -0,0 +1,1440 @@
+/*
+ * New driver for SMP863x builtin Ethernet mac
+ *
+ * This driver uses NAPI and generic linux MII support.
+ *
+ * Tx path limits the number of interrupt by reclaiming sent buffer in
+ * a timer.  In case  the tx starts  to go  faster, it will  switch to
+ * interrupt mode.
+ *
+ * Note that OOM condition is not handled correctly, and can leave the
+ * rx path  in bad  shape. down/up the  interface should make  it work
+ * again though. But anyway, it's not likely to happen.
+ *
+ * Copyright (C) 2005 Maxime Bizon <mbizon@freebox.fr>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/etherdevice.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/crc32.h>
+
+#include "tango2_enet.h"
+
+#define PFX	"tango2_enet: "
+
+MODULE_DESCRIPTION("SMP863x internal ethernet mac driver");
+MODULE_AUTHOR("Maxime Bizon <mbizon@freebox.fr>");
+MODULE_LICENSE("GPL");
+
+static int gphy_id = -1;
+module_param(gphy_id, int, 0);
+MODULE_PARM_DESC(gphy_id, "PHY id, else autodetect");
+
+static struct net_device *gdev;
+
+extern long long em86_netstats[];
+
+static inline unsigned long tangox_getxtal(void)
+{
+        return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+// Structures used by the IOP
+
+struct iopfifo {
+	unsigned int base;
+	unsigned int size;
+	unsigned int rd;
+	unsigned int wr;
+};
+
+// NOTE: the fifo pointers are gbus address and not real pointers
+static void iopfifo_get_pointer(struct iopfifo *fifo, 
+	unsigned int *base, unsigned int *size, unsigned int *rd, unsigned int *wr)
+{
+	if(base) *base = gbus_readl((unsigned int) &(fifo->base));
+	if(size) *size = gbus_readl((unsigned int) &(fifo->size));
+	if(rd) *rd = gbus_readl((unsigned int) &(fifo->rd));
+	if(wr) *wr = gbus_readl((unsigned int) &(fifo->wr));
+}
+
+static unsigned int iopfifo_get_writable_size(struct iopfifo *fifo, unsigned int *wr_ptr1, 
+    unsigned int *wr_size1, unsigned int *wr_ptr2)
+{
+	unsigned int base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	*wr_ptr1 = base + wr;
+
+	if (wr >= rd) {
+		if (rd > 0) {
+			*wr_size1 = size - wr;
+			*wr_ptr2 = base;
+			return (*wr_size1 + rd - 1);
+		}
+		else {
+			*wr_size1 = size - 1 - wr;
+			*wr_ptr2 = 0;
+			return (*wr_size1);
+		}
+	}
+	else {
+		*wr_size1 = rd - 1 - wr;
+		*wr_ptr2 = 0;
+		return (*wr_size1);
+	}
+}
+
+static unsigned int iopfifo_get_readable_size(struct iopfifo *fifo, unsigned int *rd_ptr1, 
+    unsigned int *rd_size1, unsigned int *rd_ptr2)
+{
+	unsigned int base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	*rd_ptr1 = base + rd;
+
+	if (wr >= rd) {
+		*rd_size1 = wr - rd;
+		*rd_ptr2 = 0;
+		return (*rd_size1);
+	}
+	else {
+		*rd_size1 = size - rd;
+		*rd_ptr2 = base;
+		return (*rd_size1 + wr);
+	}
+}
+
+
+
+static void iopfifo_incr_write_ptr(struct iopfifo *fifo, unsigned int incr)
+{
+	unsigned int size, wr;
+
+	iopfifo_get_pointer(fifo, NULL, &size, NULL, &wr);
+
+	wr += incr;
+	if (wr >= size)
+		wr -= size;
+
+	gbus_writel((unsigned int) &(fifo->wr), wr);
+
+}
+
+static void iopfifo_incr_read_ptr(struct iopfifo *fifo, unsigned int incr)
+{
+	unsigned int  size, rd;
+
+	iopfifo_get_pointer(fifo, NULL, &size, &rd, NULL);
+
+	rd += incr;
+	if (rd >= size)
+		rd -= size;
+
+	gbus_writel((unsigned int) &(fifo->rd), rd);
+}
+
+// Fill the IOP buffer fifo with new skbs
+static void iopFillBufferFifo(struct tango2_enet_priv *priv)
+{
+    struct net_device *dev = priv->dev;
+    struct iopfifo *buffifo= (struct iopfifo *) (0x204*4+0x1B0000); // gbus address of the buffifo
+    unsigned int  write1,write2,size1;
+    struct sk_buff *skb;
+    unsigned long t1,t2;
+
+    t1=tangox_getxtal();
+
+    while(iopfifo_get_writable_size(buffifo,&write1, &size1, &write2)>=4)
+    {
+        if(size1==0) write1=write2; // We assume it doesn't go over from end
+        skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+        if(unlikely(!skb))
+        {
+            printk(KERN_ERR "iopFillBufferFifo couldn't allocate skb\n");
+            break;
+        }
+        skb_reserve(skb, SKB_RESERVE_SIZE);
+        skb->dev = dev; // We will need to update that to support more than 1 device
+        dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+        gbus_writel(write1*4+0x1B0000, PHYSADDR(skb->data));
+        gbus_writel(write1*4+0x1B0000+4, RX_BUF_SIZE2);
+        gbus_writel(write1*4+0x1B0000+8, (unsigned int) skb);
+        gbus_writel(write1*4+0x1B0000+12, 0);
+        iopfifo_incr_write_ptr(buffifo, 4);
+        em86_netstats[9]+=1;
+    }
+
+    t2=tangox_getxtal();
+    em86_netstats[8]+=(t2-t1);
+}
+
+static int iopGetOutputFifo(struct tango2_enet_priv *priv)
+{
+    struct net_device *dev = priv->dev;
+    struct iopfifo *outfifo= (struct iopfifo *) (0x208*4+0x1B0000); // gbus address of the outfifo
+    unsigned int  read1,read2,size1;
+    struct sk_buff *skb;
+    unsigned int flaglen;
+    int count=0;
+
+    while(iopfifo_get_readable_size(outfifo,&read1, &size1, &read2)>=4)
+    {
+        if(size1==0) read1=read2; // We assume it doesn't go over from end
+        flaglen=gbus_readl(read1*4+0x1B0000+4);
+        skb=(struct sk_buff *) gbus_readl(read1*4+0x1B0000+8);
+        iopfifo_incr_read_ptr(outfifo, 4);
+
+        // This skb isn't needed anymore since it was merged, we could reuse it
+        if ((flaglen&0x03000000) == 0x03000000)
+        {
+            if(priv->recyclecount<32)
+            {
+                priv->recycle_skbs[priv->recyclecount]=skb;
+                priv->recyclecount+=1;
+            }
+            else
+            {
+                em86_netstats[19]+=1;
+                consume_skb(skb);
+            }
+            continue;
+        }
+
+        skb_put(skb, flaglen&0xFFFF);
+        skb->protocol = eth_type_trans(skb, dev);
+
+        if ((flaglen&0xFFFF0000) == 0x10B0000)
+        {
+            em86_netstats[4]+=1;
+            skb->ip_summed = CHECKSUM_UNNECESSARY;
+        }
+        else
+        {
+            if((flaglen&0x01030000) == 0x1030000)
+            {
+                em86_netstats[5]+=1;
+            }
+            else
+            {
+                em86_netstats[6]+=1;
+            }
+            skb->ip_summed = CHECKSUM_NONE;
+        }
+
+        {
+            unsigned long t1,t2;
+            t1=tangox_getxtal();
+            netif_receive_skb(skb);
+            t2=tangox_getxtal();
+            em86_netstats[10]+=(t2-t1);
+            em86_netstats[11]+=1;
+        }
+        count+=1;
+    }
+    return count;
+    // 	enet_iop_enable_interrupts(priv, 1);
+}
+
+/*
+ * mdio read/write callback, can run from userspace or timer
+ */
+static __inline int enet_mdio_read(struct net_device *dev, int phy_id,
+				   int location)
+{
+	int val;
+
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	enet_writel(ENET_MAC_MIIAR, MIIAR_ADDR(phy_id) | MIIAR_REG(location));
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	val = enet_readl(ENET_MAC_MIIDR);
+
+	return val;
+}
+
+static void enet_mdio_write(struct net_device *dev, int phy_id,
+				     int location, int val)
+{
+	enet_writel(ENET_MAC_MIIDR, val);
+	enet_writel(ENET_MAC_MIIAR,
+		    MIIAR_ADDR(phy_id) | MIIAR_REG(location) | MIIAR_WRITE);
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+}
+
+/*
+ * enable/disable interrupt helpers
+ * need proper locks since we will call them from any context
+ */
+static __inline void enet_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val &= ~IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, 0);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val |= IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, IER_NIS | IER_R | IER_T);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+
+static __inline void enet_iop_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,0); // disable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_iop_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,1); // enable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+/*
+ * rx poll func, called by network core
+ */
+static int enet_poll(struct napi_struct *napi, int budget)
+{
+	struct tango2_enet_priv *priv = container_of(napi, struct tango2_enet_priv, napi);
+	struct net_device *dev = priv->dev;
+	int received=0;
+    unsigned long pollt1,pollt2;
+    pollt1=tangox_getxtal();
+
+    em86_netstats[18]=gbus_readl(0x1B0004);
+
+	/* process no more than "limit" done rx */
+	do {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+		uint32_t rdes0_cache;
+		unsigned int len;
+
+		rx = &priv->rx_descs[priv->last_rx_desc];
+
+		/* we  need  multiple  read  on this  volatile,  avoid
+		 * memory access at each time */
+		rdes0_cache = rx->rdes0;
+		if (rdes0_cache & RDES0_OWN) {
+			break;
+		}
+
+		if (received>=budget)
+			break;
+
+		if (likely(skb = priv->rx_skbs[priv->last_rx_desc])) {
+
+			/* we don't handle multipacket frame */
+			if (!(rdes0_cache & RDES0_FIRST) ||
+			    !(rdes0_cache & RDES0_LAST)) {
+				/* we don't handle multipacket frame */
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check for CRC */
+			if (rdes0_cache & RDES0_CRC) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_crc_errors++;
+				goto rearm;
+			}
+
+			/* sanity check on len field */
+			len = RDES0_FRAME_LEN(rdes0_cache);
+			if (rdes0_cache & (RDES0_TOO_LONG | RDES0_TRUNC) ||
+			    len > RX_BUF_SIZE2) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check remaining error */
+			if (rdes0_cache & (RDES0_ERR_SUM | RDES0_COLLISION |
+					   RDES0_WATCHDOG_TMOUT |
+					   RDES0_MII_ERROR)) {
+				priv->stats.rx_errors++;
+				goto rearm;
+			}
+
+			// We have a valid skb, give it to IOP input fifo
+			{
+                struct iopfifo *infifo= (struct iopfifo *) (0x200*4+0x1B0000); // gbus address of the infifo
+                unsigned int  write1,write2,size1;
+
+                if(iopfifo_get_writable_size(infifo,&write1, &size1, &write2)>=4)
+                {
+                    if(size1==0) write1=write2; // We assume it doesn't go over from end
+                    gbus_writel(write1*4+0x1B0000, PHYSADDR(skb->data));
+                    gbus_writel(write1*4+0x1B0000+4, len);
+                    gbus_writel(write1*4+0x1B0000+8, (unsigned int) skb);
+                    iopfifo_incr_write_ptr(infifo, 4);
+                }
+                else
+                {
+                    // Discard that skb?
+                    unsigned long t1,t2;
+                    printk(KERN_ERR "tango2_enet couldn't send skb to IOP\n");
+                    skb_put(skb, len);
+                    skb->protocol = eth_type_trans(skb, dev);
+                    skb->ip_summed = CHECKSUM_NONE;
+                    t1=tangox_getxtal();
+                    netif_receive_skb(skb);
+                    t2=tangox_getxtal();
+                    em86_netstats[10]+=(t2-t1);
+                    em86_netstats[11]+=1;
+                    em86_netstats[7]+=1;
+                }
+            }
+			priv->stats.rx_packets++;
+			priv->stats.rx_bytes += len;
+			dev->last_rx = jiffies;
+			priv->rx_skbs[priv->last_rx_desc] = NULL;
+			/* we will realloc an skb for this slot */
+		}
+
+        if(priv->recyclecount>0)
+        {
+            priv->recyclecount-=1;
+            skb = priv->recycle_skbs[priv->recyclecount];
+            rx->rdes2 = PHYSADDR(skb->data);
+            priv->rx_skbs[priv->last_rx_desc] = skb;
+        }
+        else
+        {
+            unsigned long t1,t2;
+            t1=tangox_getxtal();
+
+			skb = dev_alloc_skb(RX_BUF_SIZE + SKB_RESERVE_SIZE);
+			if (unlikely(!skb))
+			{
+				printk(KERN_ERR "tango2_enet couldn't allocate skb\n");
+				break;
+			}
+            t2=tangox_getxtal();
+            em86_netstats[12]+=(t2-t1);
+
+            t1=tangox_getxtal();
+			skb_reserve(skb, SKB_RESERVE_SIZE);
+			skb->dev = dev; // We will need to update that to support more than 1 device
+			rx->rdes2 = PHYSADDR(skb->data);
+			dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE);
+			priv->rx_skbs[priv->last_rx_desc] = skb;
+            t2=tangox_getxtal();
+            em86_netstats[13]+=(t2-t1);
+        }
+rearm:
+		/* rearm descriptor */
+		wmb();
+		rx->rdes0 = RDES0_OWN;
+		priv->last_rx_desc++;
+		priv->last_rx_desc &= (ENET_RX_DESC_COUNT - 1);
+		received++;
+
+	} while (1);
+
+    iopFillBufferFifo(priv);
+    received+=iopGetOutputFifo(priv);
+
+    pollt2=tangox_getxtal();
+    em86_netstats[14]+=(pollt2-pollt1);
+
+	if (received>=budget) 
+	{
+		/* breaked, but there is still work to do */
+		return received;
+	}
+
+	napi_complete(napi);
+	enet_enable_interrupts(priv, 1);
+	enet_iop_enable_interrupts(priv, 1);
+	return received;
+}
+
+/*
+ * tx reclaim func. Called by timer or tx done tasklet to reclaim sent
+ * buffers.
+ */
+static void enet_tx_reclaim(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	spin_lock(&priv->tx_lock);
+
+	while (priv->free_tx_desc_count < ENET_TX_DESC_COUNT) {
+		uint32_t tdes0_cache;
+		struct sk_buff *skb;
+
+		tx = &priv->tx_descs[priv->dirty_tx_desc];
+
+		tdes0_cache = tx->tdes0;
+		if (tdes0_cache & TDES0_OWN)
+			break;
+
+		skb = priv->tx_skbs[priv->dirty_tx_desc];
+		priv->stats.tx_packets++;
+
+		/* check  for  transmission  errors and  update  stats
+		 * accordingly */
+		if (tdes0_cache & (TDES0_ERR_SUM | TDES0_CARRIER_LOST |
+				   TDES0_NO_CARRIER | TDES0_LATE_COLLISION |
+				   TDES0_EXC_COLLISION | TDES0_HEARTBEAT |
+				   TDES0_EXC_DEFERAL | TDES0_UNDERFLOW)) {
+			priv->stats.tx_errors++;
+		} else {
+			priv->stats.tx_bytes += skb->len;
+		}
+
+		dev_kfree_skb(skb);
+		priv->tx_skbs[priv->dirty_tx_desc] = NULL;
+		priv->dirty_tx_desc++;
+		priv->dirty_tx_desc %= ENET_TX_DESC_COUNT;
+		priv->free_tx_desc_count++;
+	}
+
+	if (priv->free_tx_desc_count != 0 && netif_queue_stopped(dev))
+		netif_wake_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+}
+
+/*
+ * tx done timer callback, just call tx_done and reschedule timer
+ */
+static void enet_tx_reclaim_timer(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+	enet_tx_reclaim(data);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+}
+
+
+/*
+ * tx request callback
+ */
+static int enet_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+	unsigned long tdes1_cache;
+
+	spin_lock(&priv->tx_lock);
+
+	priv = netdev_priv(dev);
+	tx = &priv->tx_descs[priv->next_tx_desc];
+
+	/* make sure the next free tx desc is available */
+	if (unlikely(priv->free_tx_desc_count == 0)) {
+		/* no, this  should not happen since  queue is stopped
+		 * before we run out of tx desc */
+		printk(KERN_WARNING PFX "no free tx desc to handle pkt\n");
+//		dev_kfree_skb(skb);
+		netif_stop_queue(dev);
+		spin_unlock(&priv->tx_lock);
+		return NETDEV_TX_BUSY;
+	}
+
+	/* fill the tx desc with this skb address */
+	tdes1_cache = (TDES1_FIRST | TDES1_LAST);
+	if (priv->next_tx_desc == ENET_TX_DESC_COUNT - 1)
+		tdes1_cache |= TDES1_TER;
+
+	/* if we  start to  run low  on free tx  desc, then  enable tx
+	 * interrupt to reclaim them faster */
+	if (priv->free_tx_desc_count == ENET_TX_DESC_LOW) {
+		tdes1_cache |= (TDES1_ENABLE_ISR);
+	}
+	tdes1_cache |= TDES1_TBS1(skb->len);
+
+	tx->tdes1 = tdes1_cache;
+	tx->tdes2 = PHYSADDR(skb->data);
+	dma_cache_wback((unsigned long)skb->data, skb->len);
+
+	/* keep a pointer to it for later and give it to dma  */
+	priv->tx_skbs[priv->next_tx_desc] = skb;
+	wmb();
+	tx->tdes0 = TDES0_OWN;
+
+	/* kick tx dma in case it was suspended */
+	wmb();
+	enet_writel(ENET_DMA_TPDR, 0x1);
+
+	priv->next_tx_desc++;
+	priv->next_tx_desc %= ENET_TX_DESC_COUNT;
+
+	/* if next  tx descriptor is not  clean, then we  have to stop
+	 * queue */
+	if (unlikely(--priv->free_tx_desc_count == 0))
+		netif_stop_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+
+	return NETDEV_TX_OK;
+}
+
+// IOP signaled events
+static irqreturn_t enet_isr_iop(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long status;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+	status = gbus_read_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softset);
+	if ((status & 0x80000000) == 0)
+		return IRQ_HANDLED;
+	gbus_write_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softclr, 0x80000000);
+	em86_netstats[16]+=1;
+	if(napi_schedule_prep(&priv->napi))
+	{
+		em86_netstats[17]+=1;
+		/* disable rx interrupt */
+		enet_disable_interrupts(priv, 1);
+		// This won't be useful since we won't be able to schedule
+		enet_iop_disable_interrupts(priv, 1);
+		__napi_schedule(&priv->napi);
+	}
+	return IRQ_HANDLED;
+}
+
+/*
+ * our  irq handler, just  ack it  and schedule  the right  tasklet to
+ * handle this
+ */
+static irqreturn_t enet_isr(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+
+	/* fetch status & ack them */
+	val = enet_readl(ENET_DMA_SR);
+	enet_writel(ENET_DMA_SR, val);
+
+	/* handle interrupt */
+	if (val & SR_NIS) {
+		if (val & SR_T) {
+			tasklet_schedule(&priv->tx_reclaim_tasklet);
+		}
+
+		if (val & SR_R) {
+			if(napi_schedule_prep(&priv->napi))
+			{
+				/* disable rx interrupt */
+				enet_disable_interrupts(priv, 1);
+				// This won't be useful since we won't be able to schedule
+				enet_iop_disable_interrupts(priv, 1);
+
+				/* ack  any  interrupt  that may  have
+				 * arrived  between last ack  to avoid
+				 * reentering */
+				enet_writel(ENET_DMA_SR, SR_NIS | SR_R);
+				__napi_schedule(&priv->napi);
+			}
+		}
+	}
+
+    return IRQ_HANDLED;
+}
+
+/*
+ * start/stop dma engine
+ */
+static __inline void enet_start_dma(struct tango2_enet_priv *priv)
+{
+	/* send start command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, CR_SF | CR_SR | CR_ST);
+}
+
+static __inline void enet_stop_dma(struct tango2_enet_priv *priv)
+{
+	unsigned long val;
+
+	/* send stop command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, 0);
+
+	/* wait for them to reach stopped state, should not be long */
+	do {
+		udelay(1);
+		val = enet_readl(ENET_DMA_SR);
+		if ((val & SR_TPS) && (val & SR_RPS))
+			break;
+	} while (1);
+}
+
+/*
+ * reconfigure mac for new link state
+ */
+static void enet_link_reconfigure(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	if (dev->flags & IFF_UP)
+		enet_stop_dma(priv);
+
+	/* reflect duplex status in dma register */
+	spin_lock(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+	if (priv->mii.full_duplex)
+		val |= MACCR_F;
+	else
+		val &= ~MACCR_F;
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock(&priv->maccr_lock);
+
+	if (dev->flags & IFF_UP)
+		enet_start_dma(priv);
+}
+
+/*
+ * link check timer callback
+ */
+static void enet_link_check(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	/* check for duplex change */
+	spin_lock(&priv->mii_lock);
+	ret = mii_check_media(&priv->mii, 1, 0);
+	spin_unlock(&priv->mii_lock);
+
+	if (ret)
+		enet_link_reconfigure(dev);
+
+	/* reschedule timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+}
+
+/*
+ * program given mac address in hw registers
+ */
+static int enet_set_mac_address(struct net_device *dev, void *addr)
+{
+	unsigned long hi_mac, low_mac;
+	struct sockaddr *sock = addr;
+
+	/* to make it safe, we won't do this while running */
+	if (netif_running(dev))
+		return -EBUSY;
+
+	memcpy(dev->dev_addr, sock->sa_data, ETH_ALEN);
+
+	hi_mac = (dev->dev_addr[5] << 8) | dev->dev_addr[4];
+	low_mac = (dev->dev_addr[3] << 24)| (dev->dev_addr[2] << 16) |
+		(dev->dev_addr[1] << 8) | dev->dev_addr[0];
+
+	enet_writel(ENET_MAC_MACAHR, hi_mac);
+	enet_writel(ENET_MAC_MACALR, low_mac);
+
+	return 0;
+}
+
+/*
+ * update hash table to reflect new device multicast address list
+ */
+static void enet_set_multicast_list(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	struct dev_mc_list *mclist;
+	unsigned long val;
+	uint32_t mc_filter[2];
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* the link check timer might change MACCR, we need to protect
+	 * against it */
+	spin_lock_bh(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+
+        if (dev->flags & IFF_PROMISC) {
+                val |= MACCR_PR | MACCR_PM;
+	} else {
+		val &= ~MACCR_PR;
+		/* if we want all multicast or if address count is too
+		 * high, don't try to compute hash value */
+		if (dev->mc_count > 64 || dev->flags & IFF_ALLMULTI) {
+			val |= MACCR_PM;
+		}
+	}
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock_bh(&priv->maccr_lock);
+
+	/* we  don't  need  to  update  hash  table  if  we  pass  all
+	 * multicast */
+	if (val & MACCR_PM)
+		return;
+
+	mc_filter[0] = mc_filter[1] = 0;
+	mclist = dev->mc_list;
+
+	for (i = 0; i < dev->mc_count; i++) {
+		unsigned int n;
+		char *addr;
+
+		addr = mclist->dmi_addr;
+		mclist = mclist->next;
+		if (!(*addr & 1))
+			continue;
+
+		n = ether_crc(ETH_ALEN, addr) >> 26;
+		mc_filter[n >> 5] |= 1 << (n & 31);
+	}
+
+	enet_writel(ENET_MAC_MALR, mc_filter[0]);
+	enet_writel(ENET_MAC_MAHR, mc_filter[1]);
+}
+
+/*
+ * open callback
+ */
+static int enet_open(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	/* check link */
+	if (mii_check_media(&priv->mii, 1, 1))
+		enet_link_reconfigure(dev);
+
+	/* start rx & tx dma engine */
+	enet_start_dma(priv);
+
+	napi_enable(&priv->napi);
+
+	/* enable mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val |= MACCR_TE | MACCR_RE;
+	enet_writel(ENET_MAC_MACCR, val);
+
+	/*
+	 * clear & enable interrupts, we want:
+	 * - receive complete
+	 * - transmit complete
+	 */
+	enet_writel(ENET_DMA_SR, SR_NIS | SR_R | SR_T);
+	enet_enable_interrupts(priv, 0);
+	enet_iop_enable_interrupts(priv, 0);
+
+	/* start link check & tx reclaim timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+
+	/* and finally start tx queue */
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+/*
+ * stop callback
+ */
+static int enet_stop(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* stop link timer */
+	del_timer_sync(&priv->link_check_timer);
+
+	/* stop tx queue */
+	netif_stop_queue(dev);
+	napi_disable(&priv->napi);
+
+	/* wait for all tx buffers to be reclaimed */
+	while (priv->free_tx_desc_count != ENET_TX_DESC_COUNT)
+		yield();
+
+	/* stop tx reclaim timer */
+	del_timer_sync(&priv->tx_reclaim_timer);
+
+	/* disable all interrupts */
+	enet_disable_interrupts(priv, 0);
+	enet_iop_disable_interrupts(priv, 0);
+
+	/* stop dma */
+	enet_stop_dma(priv);
+
+	/* stop mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val &= ~(MACCR_TE | MACCR_RE);
+	enet_writel(ENET_MAC_MACCR, val);
+
+    while(gbus_readl(0x1BFA40)); // Get IOP mutex
+    //gbus_writel(0x1B0040,2); // Send IOP reset command
+    // TODO: clear the fifos and skb...
+    gbus_writel(0x1BFA40,0); // Release IOP mutex
+
+	/* while we were stopping it,  the rx dma may have filled some
+	 * buffer, consider it junk and rearm all descriptor */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+	}
+
+	/* make  the dma engine  restarts at  first descriptor  in the
+	 * list */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->last_rx_desc = 0;
+
+	return 0;
+}
+
+/*
+ * get_stats callback
+ */
+static struct net_device_stats *enet_get_stats(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+
+	priv = netdev_priv(dev);
+
+	return &priv->stats;
+}
+
+/*
+ * ethtool callbacks
+ */
+static int enet_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_gset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_sset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_nway_reset(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_nway_restart(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static u32 enet_get_link(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_link_ok(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static struct ethtool_ops enet_ethtool_ops = {
+	.get_settings		= enet_get_settings,
+	.set_settings		= enet_set_settings,
+	.nway_reset		= enet_nway_reset,
+	.get_link		= enet_get_link,
+};
+
+static int enet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii);
+	ret = generic_mii_ioctl(&priv->mii, if_mii(rq), cmd, NULL);
+	spin_unlock_bh(&priv->mii);
+
+	return ret;
+}
+
+/*
+ * dma ring allocation is done here
+ */
+static int enet_dma_init(struct tango2_enet_priv *priv)
+{
+	unsigned int size;
+	int i;
+
+	/*
+	 * allocate rx descriptor list & rx buffers
+	 *
+	 * We allocate  skb now and fill buffer  with their addresses,
+	 * note that we reserve 4 bytes at beginning of data buffer to
+	 * store skb address.
+	 *
+	 */
+	size = ENET_RX_DESC_COUNT * sizeof (struct enet_rx_desc);
+	if (!(priv->rx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->rx_descs = (volatile struct enet_rx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->rx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->rx_descs_cached, size);
+
+	/*
+	 * initialize all rx descs
+	 */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+
+		rx->rdes1 = RDES1_RBS2(0) | RDES1_RBS1(RX_BUF_SIZE);
+		if (i == ENET_RX_DESC_COUNT - 1)
+			rx->rdes1 |= RDES1_RER;
+
+		skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+		if (!skb)
+			return -ENOMEM;
+
+		skb_reserve(skb, SKB_RESERVE_SIZE);
+		rx->rdes2 = PHYSADDR(skb->data);
+		rx->rdes3 = 0;
+
+		dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+		priv->rx_skbs[i] = skb;
+	}
+	priv->last_rx_desc = 0;
+
+	/*
+	 * allocate tx descriptor list
+	 *
+	 * We allocate  only the descriptor list and  prepare them for
+	 * further use. When tx is needed, we will set the right flags
+	 * and kick the dma.
+	 */
+	size = ENET_TX_DESC_COUNT * sizeof (struct enet_tx_desc);
+	if (!(priv->tx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->tx_descs = (volatile struct enet_tx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->tx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->tx_descs_cached, size);
+
+	/*
+	 * initialize tx descs
+	 */
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		volatile struct enet_tx_desc *tx;
+
+		tx = &priv->tx_descs[i];
+		tx->tdes0 = 0;
+		tx->tdes1 = 0;
+		if (i == ENET_TX_DESC_COUNT - 1)
+			tx->tdes1 |= TDES1_TER;
+		tx->tdes2 = 0;
+		tx->tdes3 = 0;
+	}
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->free_tx_desc_count = ENET_TX_DESC_COUNT;
+
+	/*
+	 * write rx desc list & tx desc list addresses in registers
+	 */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+
+    printk(KERN_ERR "tango2_enet rx desc at %X tx desc at %X\n",(unsigned int) PHYSADDR(priv->rx_descs),
+        (unsigned int) PHYSADDR(priv->tx_descs));
+	return 0;
+}
+
+/*
+ * free  all dma rings  memory, called  at uninit  time or  when error
+ * occurs at init time
+ */
+static void enet_dma_free(struct tango2_enet_priv *priv)
+{
+	int i;
+
+	/* note: kfree(NULL) is ok */
+	kfree(priv->rx_descs_cached);
+	kfree(priv->tx_descs_cached);
+
+	/* note: kfree_skb(NULL) is _not_ ok */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		if (priv->rx_skbs[i])
+			kfree_skb(priv->rx_skbs[i]);
+	}
+
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		if (priv->tx_skbs[i])
+			kfree_skb(priv->tx_skbs[i]);
+	}
+}
+
+/*
+ * mac hw init is done here
+ */
+static int enet_hw_init(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int loop;
+
+	priv = netdev_priv(dev);
+
+	/* reset phy */
+	enet_mdio_write(dev, priv->mii.phy_id, MII_BMCR, BMCR_RESET);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_mdio_read(dev, priv->mii.phy_id,
+				     MII_BMCR) & BMCR_RESET))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "PHY reset does not complete...\n");
+		return -EBUSY;
+	}
+
+	/* reset dma engine */
+	enet_writel(ENET_DMA_BMR, BMR_SWR);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_readl(ENET_DMA_BMR) & BMR_SWR))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "dma engine does not exit reset...\n");
+		return -EBUSY;
+	}
+
+	/* set bus mode */
+	enet_writel(ENET_DMA_BMR, BMR_PBL(32));
+
+	/* enable MAC flow ctrl */
+	enet_writel(ENET_MAC_FCR, FCR_ENABLE);
+
+	/* configure MAC ctrller to do hash perfect filtering  */
+	enet_writel(ENET_MAC_MACCR, MACCR_ASTP | MACCR_HP);
+
+	/* clear hash table */
+	enet_writel(ENET_MAC_MAHR, 0xffffffff);
+	enet_writel(ENET_MAC_MALR, 0xffffffff);
+
+	return 0;
+}
+
+
+
+/*
+ * allocate  netdevice structure,  do  all dma  rings allocations  and
+ * register the netdevice
+ */
+extern int tangox_ethernet_getmac(int i, unsigned char *);
+extern int em86xx_mbus_init(void);
+
+static int enet_probe(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+	int ret;
+	struct sockaddr sock;
+
+	printk(KERN_INFO PFX "ethernet driver for SMP863x internal mac\n");
+	/* allocate  netdevice structure  with enough  length  for our
+	 * context data */
+	dev = alloc_etherdev(sizeof (*priv));
+	if (!dev)
+		return -ENOMEM;
+
+    // Init mbus registers
+    em86xx_mbus_init();
+
+	/* initialize private data */
+	priv = netdev_priv(dev);
+	memset(priv, 0, sizeof (*priv));
+	spin_lock_init(&priv->tx_lock);
+	spin_lock_init(&priv->ier_lock);
+	spin_lock_init(&priv->maccr_lock);
+
+	/* init tx done tasklet */
+	tasklet_init(&priv->tx_reclaim_tasklet, enet_tx_reclaim,
+		     (unsigned long)dev);
+
+	/* init tx reclaim timer */
+	init_timer(&priv->tx_reclaim_timer);
+	priv->tx_reclaim_timer.data = (unsigned long )dev;
+	priv->tx_reclaim_timer.function = enet_tx_reclaim_timer;
+
+	/* init link check timer and mii lock */
+	init_timer(&priv->link_check_timer);
+	priv->link_check_timer.data = (unsigned long)dev;
+	priv->link_check_timer.function = enet_link_check;
+	spin_lock_init(&priv->mii_lock);
+
+	/* fill mii info */
+	priv->mii.dev = dev;
+	priv->mii.phy_id_mask = 0x1f;
+	priv->mii.reg_num_mask = 0x1f;
+	priv->mii.mdio_read = enet_mdio_read;
+	priv->mii.mdio_write = enet_mdio_write;
+
+	if (gphy_id != -1) {
+		/* phy id forced, just check for sanity */
+		if (gphy_id < 0 || gphy_id > 31) {
+			ret = -EINVAL;
+			goto err_free;
+		}
+		priv->mii.phy_id = gphy_id;
+
+	} else {
+		int i;
+
+		/* try to probe phy if not given */
+		for (i = 0; i < 32; i++) {
+			uint32_t id;
+			int val;
+
+			val = enet_mdio_read(dev, i, MII_PHYSID1);
+			id = (val << 16);
+			val = enet_mdio_read(dev, i, MII_PHYSID2);
+			id |= val;
+
+			if (id != 0xffffffff && id != 0x00000000)
+				break;
+		}
+
+		if (i == 32) {
+			printk(KERN_ERR PFX "unable to autodetect phy\n");
+			ret = -EIO;
+			goto err_free;
+		}
+
+		printk(KERN_ERR PFX "detected phy at address 0x%02x\n", i);
+		priv->mii.phy_id = i;
+	}
+
+	/* initialize hardware */
+	if ((ret = enet_hw_init(dev)))
+		goto err_free;
+
+	/* initialize dma rings */
+	if ((ret = enet_dma_init(priv)))
+		goto err_free;
+
+	/* register interrupt handler */
+	ret = request_irq(ENET_IRQ, enet_isr, IRQF_SHARED|IRQF_DISABLED,
+			  "tango2_enet", dev);
+	if (ret)
+		goto err_free;
+	dev->irq = ENET_IRQ;
+
+    iopFillBufferFifo(priv);
+	printk(KERN_ERR "Clearing soft irq status %X\n",
+		(unsigned int) gbus_readl(REG_BASE_cpu_block + CPU_irq_softclr));
+	// It seems we get a soft irq on startup so clear them
+	gbus_writel(REG_BASE_cpu_block + CPU_irq_softclr, 0xFFFFFFFF);
+
+	ret = request_irq((IRQ_CONTROLLER_IRQ_BASE+0), enet_isr_iop, IRQF_SHARED|IRQF_DISABLED,
+			  "tango2_enet_iop", dev);
+	if (ret)
+		goto err_free;
+
+	/* install driver callbacks and register netdevice */
+	priv->dev = dev;
+	dev->open = enet_open;
+	dev->stop = enet_stop;
+	dev->hard_start_xmit = enet_xmit;
+	dev->get_stats = enet_get_stats;
+	dev->set_mac_address = enet_set_mac_address;
+	dev->set_multicast_list = enet_set_multicast_list;
+	dev->ethtool_ops = &enet_ethtool_ops;
+	dev->do_ioctl = enet_ioctl;
+	netif_napi_add(dev, &priv->napi, enet_poll, 16);
+
+	/* set default mac address */
+	tangox_ethernet_getmac(0, dev->dev_addr);
+	memcpy(&(sock.sa_data), dev->dev_addr, ETH_ALEN);
+	enet_set_mac_address(dev, &sock);
+
+	if ((ret = register_netdev(dev))) {
+		printk(KERN_ERR PFX "unable to register netdevice\n");
+		goto err_free;
+	}
+
+	printk(KERN_INFO PFX "mac address %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       dev->dev_addr[0], dev->dev_addr[1], dev->dev_addr[2],
+	       dev->dev_addr[3], dev->dev_addr[4], dev->dev_addr[5]);
+
+	gdev = dev;
+	return 0;
+
+err_free:
+	if (dev->irq)
+		free_irq(dev->irq, dev);
+	enet_dma_free(priv);
+	free_netdev(dev);
+	return ret;
+}
+
+
+/*
+ * entry point, checks if ethernet is  enabled on the board and if so,
+ * probes it
+ */
+extern int tangox_ethernet_enabled(int);
+
+int __init tango2_enet_init(void)
+{
+    // Start IOP
+    gbus_writel(0x1B003C,0);
+    gbus_writel(0xDFFFC,3);
+    gbus_writel(0xDFFFC,1);
+    gbus_writel(0xDFFFC,0);
+    while(gbus_readl(0x1B003C)!=0xCAFE);
+
+	if (!tangox_ethernet_enabled(0)) {
+		printk(KERN_NOTICE PFX "ethernet support is disabled\n");
+		return -ENODEV;
+	}
+
+	return enet_probe();
+}
+
+/*
+ * exit func, stops hardware and unregisters netdevice
+ */
+void __exit tango2_enet_exit(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+
+	dev = gdev;
+
+	free_irq(dev->irq, dev);
+	unregister_netdev(dev);
+
+	priv = netdev_priv(dev);
+	enet_dma_free(priv);
+
+	free_netdev(dev);
+}
+
+
+module_init(tango2_enet_init);
+module_exit(tango2_enet_exit);
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet.c.backup20090619 linux-2.6.30-test/drivers/net/tango2_enet.c.backup20090619
--- linux-2.6.30-ori/drivers/net/tango2_enet.c.backup20090619	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet.c.backup20090619	2009-06-19 18:48:21.000000000 -0400
@@ -0,0 +1,1241 @@
+/*
+ * New driver for SMP863x builtin Ethernet mac
+ *
+ * This driver uses NAPI and generic linux MII support.
+ *
+ * Tx path limits the number of interrupt by reclaiming sent buffer in
+ * a timer.  In case  the tx starts  to go  faster, it will  switch to
+ * interrupt mode.
+ *
+ * Note that OOM condition is not handled correctly, and can leave the
+ * rx path  in bad  shape. down/up the  interface should make  it work
+ * again though. But anyway, it's not likely to happen.
+ *
+ * Copyright (C) 2005 Maxime Bizon <mbizon@freebox.fr>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/etherdevice.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/crc32.h>
+
+#include "tango2_enet.h"
+
+#define PFX	"tango2_enet: "
+
+MODULE_DESCRIPTION("SMP863x internal ethernet mac driver");
+MODULE_AUTHOR("Maxime Bizon <mbizon@freebox.fr>");
+MODULE_LICENSE("GPL");
+
+static int gphy_id = -1;
+module_param(gphy_id, int, 0);
+MODULE_PARM_DESC(gphy_id, "PHY id, else autodetect");
+
+static struct net_device *gdev;
+
+/*
+ * mdio read/write callback, can run from userspace or timer
+ */
+static __inline int enet_mdio_read(struct net_device *dev, int phy_id,
+				   int location)
+{
+	int val;
+
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	enet_writel(ENET_MAC_MIIAR, MIIAR_ADDR(phy_id) | MIIAR_REG(location));
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	val = enet_readl(ENET_MAC_MIIDR);
+
+	return val;
+}
+
+static void enet_mdio_write(struct net_device *dev, int phy_id,
+				     int location, int val)
+{
+	enet_writel(ENET_MAC_MIIDR, val);
+	enet_writel(ENET_MAC_MIIAR,
+		    MIIAR_ADDR(phy_id) | MIIAR_REG(location) | MIIAR_WRITE);
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+}
+
+/*
+ * enable/disable interrupt helpers
+ * need proper locks since we will call them from any context
+ */
+static __inline void enet_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val &= ~IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, 0);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val |= IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, IER_NIS | IER_R | IER_T);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+
+static __inline void enet_iop_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,0); // disable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_iop_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,1); // enable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+extern long long em86_netstats[];
+
+static inline unsigned long tangox_getxtal(void)
+{
+        return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+/*
+ * rx poll func, called by network core
+ */
+static int enet_poll(struct napi_struct *napi, int budget)
+{
+	struct tango2_enet_priv *priv = container_of(napi, struct tango2_enet_priv, napi);
+	struct net_device *dev = priv->dev;
+	int received=0;
+    unsigned long pollt1,pollt2;
+    pollt1=tangox_getxtal();
+
+//    gbus_writel(0x1B0040,1); // Update IOP
+//    while(gbus_readl(0x1B0040)!=0); // Update IOP
+    em86_netstats[18]=gbus_readl(0x1B0004);
+
+	/* process no more than "limit" done rx */
+	do {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+		uint32_t rdes0_cache;
+		unsigned int len;
+
+		rx = &priv->rx_descs[priv->last_rx_desc];
+
+		/* we  need  multiple  read  on this  volatile,  avoid
+		 * memory access at each time */
+		rdes0_cache = rx->rdes0;
+		if (rdes0_cache & RDES0_OWN) {
+			break;
+		}
+
+		if (!(rx->rdes3&0x10000))
+		{
+			break;
+		}
+
+		if (received>=budget)
+			break;
+
+		if (likely(skb = priv->rx_skbs[priv->last_rx_desc])) {
+            // Packet has been marged, simply rearm
+			if (rx->rdes3&0x20000)
+			{
+				goto rearm;
+			}
+
+			/* we don't handle multipacket frame */
+			if (!(rdes0_cache & RDES0_FIRST) ||
+			    !(rdes0_cache & RDES0_LAST)) {
+				/* we don't handle multipacket frame */
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check for CRC */
+			if (rdes0_cache & RDES0_CRC) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_crc_errors++;
+				goto rearm;
+			}
+
+			/* sanity check on len field */
+			len = RDES0_FRAME_LEN(rdes0_cache);
+			if (rdes0_cache & (RDES0_TOO_LONG | RDES0_TRUNC) ||
+			    len > RX_BUF_SIZE2) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check remaining error */
+			if (rdes0_cache & (RDES0_ERR_SUM | RDES0_COLLISION |
+					   RDES0_WATCHDOG_TMOUT |
+					   RDES0_MII_ERROR)) {
+				priv->stats.rx_errors++;
+				goto rearm;
+			}
+
+			if (!(rx->rdes3&0x10000))
+			{
+				printk(KERN_ERR "RX descriptor not processed by IOP\n");
+			}
+
+			/* ok, seems  valid, adjust skb  proto and len
+			 * and give it to kernel */
+			skb->dev = dev;
+			skb_put(skb, len);
+			skb->protocol = eth_type_trans(skb, dev);
+
+			if ((rx->rdes3 == 0x1000B)) {
+				em86_netstats[4]+=1;
+				skb->ip_summed = CHECKSUM_UNNECESSARY;
+			}
+			else
+			{
+				if ((rx->rdes3&0x10003)==0x10003)
+				{
+					em86_netstats[6]+=1;
+				}
+				else
+				{
+					em86_netstats[8]+=1;
+				}
+				skb->ip_summed = CHECKSUM_NONE;
+			}
+			
+			{
+                unsigned long t1,t2;
+                t1=tangox_getxtal();
+                netif_receive_skb(skb);
+                t2=tangox_getxtal();
+                em86_netstats[10]+=(t2-t1);
+                em86_netstats[11]+=1;
+            }
+			priv->stats.rx_packets++;
+			priv->stats.rx_bytes += len;
+			dev->last_rx = jiffies;
+			priv->rx_skbs[priv->last_rx_desc] = NULL;
+			/* we will realloc an skb for this slot */
+		}
+
+        {
+            unsigned long t1,t2;
+            t1=tangox_getxtal();
+
+			skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+			if (unlikely(!skb))
+			{
+				printk(KERN_ERR "tango2_enet couldn't allocate skb\n");
+				break;
+			}
+            t2=tangox_getxtal();
+            em86_netstats[12]+=(t2-t1);
+
+            t1=tangox_getxtal();
+			skb_reserve(skb, SKB_RESERVE_SIZE);
+			rx->rdes2 = PHYSADDR(skb->data);
+			dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+			priv->rx_skbs[priv->last_rx_desc] = skb;
+            t2=tangox_getxtal();
+            em86_netstats[13]+=(t2-t1);
+        }
+rearm:
+		/* rearm descriptor */
+		wmb();
+		rx->rdes0 = RDES0_OWN;
+		rx->rdes3 = 0; // Clear checksum state
+		priv->last_rx_desc++;
+		priv->last_rx_desc &= (ENET_RX_DESC_COUNT - 1);
+		received++;
+
+	} while (1);
+
+    pollt2=tangox_getxtal();
+    em86_netstats[14]+=(pollt2-pollt1);
+
+	if (received==budget) 
+	{
+		/* breaked, but there is still work to do */
+		return received;
+	}
+
+	napi_complete(napi);
+	enet_enable_interrupts(priv, 1);
+	enet_iop_enable_interrupts(priv, 1);
+	return received;
+}
+
+/*
+ * tx reclaim func. Called by timer or tx done tasklet to reclaim sent
+ * buffers.
+ */
+static void enet_tx_reclaim(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	spin_lock(&priv->tx_lock);
+
+	while (priv->free_tx_desc_count < ENET_TX_DESC_COUNT) {
+		uint32_t tdes0_cache;
+		struct sk_buff *skb;
+
+		tx = &priv->tx_descs[priv->dirty_tx_desc];
+
+		tdes0_cache = tx->tdes0;
+		if (tdes0_cache & TDES0_OWN)
+			break;
+
+		skb = priv->tx_skbs[priv->dirty_tx_desc];
+		priv->stats.tx_packets++;
+
+		/* check  for  transmission  errors and  update  stats
+		 * accordingly */
+		if (tdes0_cache & (TDES0_ERR_SUM | TDES0_CARRIER_LOST |
+				   TDES0_NO_CARRIER | TDES0_LATE_COLLISION |
+				   TDES0_EXC_COLLISION | TDES0_HEARTBEAT |
+				   TDES0_EXC_DEFERAL | TDES0_UNDERFLOW)) {
+			priv->stats.tx_errors++;
+		} else {
+			priv->stats.tx_bytes += skb->len;
+		}
+
+		dev_kfree_skb(skb);
+		priv->tx_skbs[priv->dirty_tx_desc] = NULL;
+		priv->dirty_tx_desc++;
+		priv->dirty_tx_desc %= ENET_TX_DESC_COUNT;
+		priv->free_tx_desc_count++;
+	}
+
+	if (priv->free_tx_desc_count != 0 && netif_queue_stopped(dev))
+		netif_wake_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+}
+
+/*
+ * tx done timer callback, just call tx_done and reschedule timer
+ */
+static void enet_tx_reclaim_timer(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+	enet_tx_reclaim(data);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+}
+
+
+/*
+ * tx request callback
+ */
+static int enet_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+	unsigned long tdes1_cache;
+
+	spin_lock(&priv->tx_lock);
+
+	priv = netdev_priv(dev);
+	tx = &priv->tx_descs[priv->next_tx_desc];
+
+	/* make sure the next free tx desc is available */
+	if (unlikely(priv->free_tx_desc_count == 0)) {
+		/* no, this  should not happen since  queue is stopped
+		 * before we run out of tx desc */
+		printk(KERN_WARNING PFX "no free tx desc to handle pkt\n");
+//		dev_kfree_skb(skb);
+		netif_stop_queue(dev);
+		spin_unlock(&priv->tx_lock);
+		return NETDEV_TX_BUSY;
+	}
+
+	/* fill the tx desc with this skb address */
+	tdes1_cache = (TDES1_FIRST | TDES1_LAST);
+	if (priv->next_tx_desc == ENET_TX_DESC_COUNT - 1)
+		tdes1_cache |= TDES1_TER;
+
+	/* if we  start to  run low  on free tx  desc, then  enable tx
+	 * interrupt to reclaim them faster */
+	if (priv->free_tx_desc_count == ENET_TX_DESC_LOW) {
+		tdes1_cache |= (TDES1_ENABLE_ISR);
+	}
+	tdes1_cache |= TDES1_TBS1(skb->len);
+
+	tx->tdes1 = tdes1_cache;
+	tx->tdes2 = PHYSADDR(skb->data);
+	dma_cache_wback((unsigned long)skb->data, skb->len);
+
+	/* keep a pointer to it for later and give it to dma  */
+	priv->tx_skbs[priv->next_tx_desc] = skb;
+	wmb();
+	tx->tdes0 = TDES0_OWN;
+
+	/* kick tx dma in case it was suspended */
+	wmb();
+	enet_writel(ENET_DMA_TPDR, 0x1);
+
+	priv->next_tx_desc++;
+	priv->next_tx_desc %= ENET_TX_DESC_COUNT;
+
+	/* if next  tx descriptor is not  clean, then we  have to stop
+	 * queue */
+	if (unlikely(--priv->free_tx_desc_count == 0))
+		netif_stop_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+
+	return NETDEV_TX_OK;
+}
+
+// IOP signaled events
+static irqreturn_t enet_isr_iop(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+	unsigned long status;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+	status = gbus_read_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softset);
+	if ((status & 0x80000000) == 0)
+		return IRQ_HANDLED;
+	em86_netstats[16]+=1;
+	if (napi_schedule_prep(&priv->napi))
+	{
+		enet_disable_interrupts(priv, 1);
+		enet_iop_disable_interrupts(priv, 1);
+		gbus_write_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softclr, 0x80000000);
+		em86_netstats[17]+=1;
+		__napi_schedule(&priv->napi);
+	}
+	return IRQ_HANDLED;
+}
+
+/*
+ * our  irq handler, just  ack it  and schedule  the right  tasklet to
+ * handle this
+ */
+static irqreturn_t enet_isr(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+    unsigned long flags;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+
+	/* fetch status & ack them */
+	val = enet_readl(ENET_DMA_SR);
+	enet_writel(ENET_DMA_SR, val);
+
+	/* handle interrupt */
+	if (val & SR_NIS) {
+		if (val & SR_T) {
+			tasklet_schedule(&priv->tx_reclaim_tasklet);
+		}
+
+		if (val & SR_R) {
+//			enet_disable_interrupts(priv, 1);
+			spin_lock_irqsave(&priv->ier_lock, flags);
+			while(gbus_readl(0x1BFA40)); // Get IOP mutex
+			gbus_writel(0x1B0040,1); // Send IOP mutex command
+			gbus_writel(0x1BFA40,0); // Release IOP mutex
+			spin_unlock_irqrestore(&priv->ier_lock, flags);
+		}
+	}
+
+        return IRQ_HANDLED;
+}
+
+/*
+ * start/stop dma engine
+ */
+static __inline void enet_start_dma(struct tango2_enet_priv *priv)
+{
+	/* send start command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, CR_SF | CR_SR | CR_ST);
+}
+
+static __inline void enet_stop_dma(struct tango2_enet_priv *priv)
+{
+	unsigned long val;
+
+	/* send stop command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, 0);
+
+	/* wait for them to reach stopped state, should not be long */
+	do {
+		udelay(1);
+		val = enet_readl(ENET_DMA_SR);
+		if ((val & SR_TPS) && (val & SR_RPS))
+			break;
+	} while (1);
+}
+
+/*
+ * reconfigure mac for new link state
+ */
+static void enet_link_reconfigure(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	if (dev->flags & IFF_UP)
+		enet_stop_dma(priv);
+
+	/* reflect duplex status in dma register */
+	spin_lock(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+	if (priv->mii.full_duplex)
+		val |= MACCR_F;
+	else
+		val &= ~MACCR_F;
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock(&priv->maccr_lock);
+
+	if (dev->flags & IFF_UP)
+		enet_start_dma(priv);
+}
+
+/*
+ * link check timer callback
+ */
+static void enet_link_check(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	/* check for duplex change */
+	spin_lock(&priv->mii_lock);
+	ret = mii_check_media(&priv->mii, 1, 0);
+	spin_unlock(&priv->mii_lock);
+
+	if (ret)
+		enet_link_reconfigure(dev);
+
+	/* reschedule timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+}
+
+/*
+ * program given mac address in hw registers
+ */
+static int enet_set_mac_address(struct net_device *dev, void *addr)
+{
+	unsigned long hi_mac, low_mac;
+	struct sockaddr *sock = addr;
+
+	/* to make it safe, we won't do this while running */
+	if (netif_running(dev))
+		return -EBUSY;
+
+	memcpy(dev->dev_addr, sock->sa_data, ETH_ALEN);
+
+	hi_mac = (dev->dev_addr[5] << 8) | dev->dev_addr[4];
+	low_mac = (dev->dev_addr[3] << 24)| (dev->dev_addr[2] << 16) |
+		(dev->dev_addr[1] << 8) | dev->dev_addr[0];
+
+	enet_writel(ENET_MAC_MACAHR, hi_mac);
+	enet_writel(ENET_MAC_MACALR, low_mac);
+
+	return 0;
+}
+
+/*
+ * update hash table to reflect new device multicast address list
+ */
+static void enet_set_multicast_list(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	struct dev_mc_list *mclist;
+	unsigned long val;
+	uint32_t mc_filter[2];
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* the link check timer might change MACCR, we need to protect
+	 * against it */
+	spin_lock_bh(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+
+        if (dev->flags & IFF_PROMISC) {
+                val |= MACCR_PR | MACCR_PM;
+	} else {
+		val &= ~MACCR_PR;
+		/* if we want all multicast or if address count is too
+		 * high, don't try to compute hash value */
+		if (dev->mc_count > 64 || dev->flags & IFF_ALLMULTI) {
+			val |= MACCR_PM;
+		}
+	}
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock_bh(&priv->maccr_lock);
+
+	/* we  don't  need  to  update  hash  table  if  we  pass  all
+	 * multicast */
+	if (val & MACCR_PM)
+		return;
+
+	mc_filter[0] = mc_filter[1] = 0;
+	mclist = dev->mc_list;
+
+	for (i = 0; i < dev->mc_count; i++) {
+		unsigned int n;
+		char *addr;
+
+		addr = mclist->dmi_addr;
+		mclist = mclist->next;
+		if (!(*addr & 1))
+			continue;
+
+		n = ether_crc(ETH_ALEN, addr) >> 26;
+		mc_filter[n >> 5] |= 1 << (n & 31);
+	}
+
+	enet_writel(ENET_MAC_MALR, mc_filter[0]);
+	enet_writel(ENET_MAC_MAHR, mc_filter[1]);
+}
+
+/*
+ * open callback
+ */
+static int enet_open(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	/* check link */
+	if (mii_check_media(&priv->mii, 1, 1))
+		enet_link_reconfigure(dev);
+
+	/* start rx & tx dma engine */
+	enet_start_dma(priv);
+
+	napi_enable(&priv->napi);
+
+	/* enable mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val |= MACCR_TE | MACCR_RE;
+	enet_writel(ENET_MAC_MACCR, val);
+
+	/*
+	 * clear & enable interrupts, we want:
+	 * - receive complete
+	 * - transmit complete
+	 */
+	enet_writel(ENET_DMA_SR, SR_NIS | SR_R | SR_T);
+	enet_enable_interrupts(priv, 0);
+	enet_iop_enable_interrupts(priv, 0);
+
+	/* start link check & tx reclaim timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+
+	/* and finally start tx queue */
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+/*
+ * stop callback
+ */
+static int enet_stop(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* stop link timer */
+	del_timer_sync(&priv->link_check_timer);
+
+	/* stop tx queue */
+	netif_stop_queue(dev);
+	napi_disable(&priv->napi);
+
+	/* wait for all tx buffers to be reclaimed */
+	while (priv->free_tx_desc_count != ENET_TX_DESC_COUNT)
+		yield();
+
+	/* stop tx reclaim timer */
+	del_timer_sync(&priv->tx_reclaim_timer);
+
+	/* disable all interrupts */
+	enet_disable_interrupts(priv, 0);
+	enet_iop_disable_interrupts(priv, 0);
+
+	/* stop dma */
+	enet_stop_dma(priv);
+
+	/* stop mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val &= ~(MACCR_TE | MACCR_RE);
+	enet_writel(ENET_MAC_MACCR, val);
+
+    while(gbus_readl(0x1BFA40)); // Get IOP mutex
+    gbus_writel(0x1B0040,2); // Send IOP reset command
+    gbus_writel(0x1BFA40,0); // Release IOP mutex
+
+	/* while we were stopping it,  the rx dma may have filled some
+	 * buffer, consider it junk and rearm all descriptor */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+		rx->rdes3 = 0; // Clear checksum state
+	}
+
+	/* make  the dma engine  restarts at  first descriptor  in the
+	 * list */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->last_rx_desc = 0;
+
+	return 0;
+}
+
+/*
+ * get_stats callback
+ */
+static struct net_device_stats *enet_get_stats(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+
+	priv = netdev_priv(dev);
+
+	return &priv->stats;
+}
+
+/*
+ * ethtool callbacks
+ */
+static int enet_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_gset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_sset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_nway_reset(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_nway_restart(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static u32 enet_get_link(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_link_ok(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static struct ethtool_ops enet_ethtool_ops = {
+	.get_settings		= enet_get_settings,
+	.set_settings		= enet_set_settings,
+	.nway_reset		= enet_nway_reset,
+	.get_link		= enet_get_link,
+};
+
+static int enet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii);
+	ret = generic_mii_ioctl(&priv->mii, if_mii(rq), cmd, NULL);
+	spin_unlock_bh(&priv->mii);
+
+	return ret;
+}
+
+/*
+ * dma ring allocation is done here
+ */
+static int enet_dma_init(struct tango2_enet_priv *priv)
+{
+	unsigned int size;
+	int i;
+
+	/*
+	 * allocate rx descriptor list & rx buffers
+	 *
+	 * We allocate  skb now and fill buffer  with their addresses,
+	 * note that we reserve 4 bytes at beginning of data buffer to
+	 * store skb address.
+	 *
+	 */
+	size = ENET_RX_DESC_COUNT * sizeof (struct enet_rx_desc);
+	if (!(priv->rx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->rx_descs = (volatile struct enet_rx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->rx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->rx_descs_cached, size);
+
+	/*
+	 * initialize all rx descs
+	 */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+
+		rx->rdes1 = RDES1_RBS2(0) | RDES1_RBS1(RX_BUF_SIZE);
+		if (i == ENET_RX_DESC_COUNT - 1)
+			rx->rdes1 |= RDES1_RER;
+
+		skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+		if (!skb)
+			return -ENOMEM;
+
+		skb_reserve(skb, SKB_RESERVE_SIZE);
+		rx->rdes2 = PHYSADDR(skb->data);
+		rx->rdes3 = 0;
+
+		dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+		priv->rx_skbs[i] = skb;
+	}
+	priv->last_rx_desc = 0;
+
+	/*
+	 * allocate tx descriptor list
+	 *
+	 * We allocate  only the descriptor list and  prepare them for
+	 * further use. When tx is needed, we will set the right flags
+	 * and kick the dma.
+	 */
+	size = ENET_TX_DESC_COUNT * sizeof (struct enet_tx_desc);
+	if (!(priv->tx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->tx_descs = (volatile struct enet_tx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->tx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->tx_descs_cached, size);
+
+	/*
+	 * initialize tx descs
+	 */
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		volatile struct enet_tx_desc *tx;
+
+		tx = &priv->tx_descs[i];
+		tx->tdes0 = 0;
+		tx->tdes1 = 0;
+		if (i == ENET_TX_DESC_COUNT - 1)
+			tx->tdes1 |= TDES1_TER;
+		tx->tdes2 = 0;
+		tx->tdes3 = 0;
+	}
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->free_tx_desc_count = ENET_TX_DESC_COUNT;
+
+	/*
+	 * write rx desc list & tx desc list addresses in registers
+	 */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+
+    printk(KERN_ERR "tango2_enet rx desc at %X tx desc at %X\n",PHYSADDR(priv->rx_descs),
+        PHYSADDR(priv->tx_descs));
+	return 0;
+}
+
+/*
+ * free  all dma rings  memory, called  at uninit  time or  when error
+ * occurs at init time
+ */
+static void enet_dma_free(struct tango2_enet_priv *priv)
+{
+	int i;
+
+	/* note: kfree(NULL) is ok */
+	kfree(priv->rx_descs_cached);
+	kfree(priv->tx_descs_cached);
+
+	/* note: kfree_skb(NULL) is _not_ ok */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		if (priv->rx_skbs[i])
+			kfree_skb(priv->rx_skbs[i]);
+	}
+
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		if (priv->tx_skbs[i])
+			kfree_skb(priv->tx_skbs[i]);
+	}
+}
+
+/*
+ * mac hw init is done here
+ */
+static int enet_hw_init(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int loop;
+
+	priv = netdev_priv(dev);
+
+	/* reset phy */
+	enet_mdio_write(dev, priv->mii.phy_id, MII_BMCR, BMCR_RESET);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_mdio_read(dev, priv->mii.phy_id,
+				     MII_BMCR) & BMCR_RESET))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "PHY reset does not complete...\n");
+		return -EBUSY;
+	}
+
+	/* reset dma engine */
+	enet_writel(ENET_DMA_BMR, BMR_SWR);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_readl(ENET_DMA_BMR) & BMR_SWR))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "dma engine does not exit reset...\n");
+		return -EBUSY;
+	}
+
+	/* set bus mode */
+	enet_writel(ENET_DMA_BMR, BMR_PBL(32));
+
+	/* enable MAC flow ctrl */
+	enet_writel(ENET_MAC_FCR, FCR_ENABLE);
+
+	/* configure MAC ctrller to do hash perfect filtering  */
+	enet_writel(ENET_MAC_MACCR, MACCR_ASTP | MACCR_HP);
+
+	/* clear hash table */
+	enet_writel(ENET_MAC_MAHR, 0xffffffff);
+	enet_writel(ENET_MAC_MALR, 0xffffffff);
+
+	return 0;
+}
+
+
+
+/*
+ * allocate  netdevice structure,  do  all dma  rings allocations  and
+ * register the netdevice
+ */
+extern int tangox_ethernet_getmac(int i, unsigned char *);
+extern int em86xx_mbus_init(void);
+
+static int enet_probe(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+	int ret;
+	struct sockaddr sock;
+
+	printk(KERN_INFO PFX "ethernet driver for SMP863x internal mac\n");
+	/* allocate  netdevice structure  with enough  length  for our
+	 * context data */
+	dev = alloc_etherdev(sizeof (*priv));
+	if (!dev)
+		return -ENOMEM;
+
+    // Init mbus registers
+    em86xx_mbus_init();
+
+	/* initialize private data */
+	priv = netdev_priv(dev);
+	memset(priv, 0, sizeof (*priv));
+	spin_lock_init(&priv->tx_lock);
+	spin_lock_init(&priv->ier_lock);
+	spin_lock_init(&priv->maccr_lock);
+
+	/* init tx done tasklet */
+	tasklet_init(&priv->tx_reclaim_tasklet, enet_tx_reclaim,
+		     (unsigned long)dev);
+
+	/* init tx reclaim timer */
+	init_timer(&priv->tx_reclaim_timer);
+	priv->tx_reclaim_timer.data = (unsigned long )dev;
+	priv->tx_reclaim_timer.function = enet_tx_reclaim_timer;
+
+	/* init link check timer and mii lock */
+	init_timer(&priv->link_check_timer);
+	priv->link_check_timer.data = (unsigned long)dev;
+	priv->link_check_timer.function = enet_link_check;
+	spin_lock_init(&priv->mii_lock);
+
+	/* fill mii info */
+	priv->mii.dev = dev;
+	priv->mii.phy_id_mask = 0x1f;
+	priv->mii.reg_num_mask = 0x1f;
+	priv->mii.mdio_read = enet_mdio_read;
+	priv->mii.mdio_write = enet_mdio_write;
+
+	if (gphy_id != -1) {
+		/* phy id forced, just check for sanity */
+		if (gphy_id < 0 || gphy_id > 31) {
+			ret = -EINVAL;
+			goto err_free;
+		}
+		priv->mii.phy_id = gphy_id;
+
+	} else {
+		int i;
+
+		/* try to probe phy if not given */
+		for (i = 0; i < 32; i++) {
+			uint32_t id;
+			int val;
+
+			val = enet_mdio_read(dev, i, MII_PHYSID1);
+			id = (val << 16);
+			val = enet_mdio_read(dev, i, MII_PHYSID2);
+			id |= val;
+
+			if (id != 0xffffffff && id != 0x00000000)
+				break;
+		}
+
+		if (i == 32) {
+			printk(KERN_ERR PFX "unable to autodetect phy\n");
+			ret = -EIO;
+			goto err_free;
+		}
+
+		printk(KERN_ERR PFX "detected phy at address 0x%02x\n", i);
+		priv->mii.phy_id = i;
+	}
+
+	/* initialize hardware */
+	if ((ret = enet_hw_init(dev)))
+		goto err_free;
+
+	/* initialize dma rings */
+	if ((ret = enet_dma_init(priv)))
+		goto err_free;
+
+	/* register interrupt handler */
+	ret = request_irq(ENET_IRQ, enet_isr, IRQF_SHARED,
+			  "tango2_enet", dev);
+	if (ret)
+		goto err_free;
+	dev->irq = ENET_IRQ;
+
+	printk(KERN_ERR "Clearing soft irq status %X\n",
+		gbus_readl(REG_BASE_cpu_block + CPU_irq_softclr));
+	// It seems we get a soft irq on startup so clear them
+	gbus_writel(REG_BASE_cpu_block + CPU_irq_softclr, 0xFFFFFFFF);
+
+	ret = request_irq((IRQ_CONTROLLER_IRQ_BASE+0), enet_isr_iop, IRQF_SHARED,
+			  "tango2_enet_iop", dev);
+	if (ret)
+		goto err_free;
+
+	/* install driver callbacks and register netdevice */
+	priv->dev = dev;
+	dev->open = enet_open;
+	dev->stop = enet_stop;
+	dev->hard_start_xmit = enet_xmit;
+	dev->get_stats = enet_get_stats;
+	dev->set_mac_address = enet_set_mac_address;
+	dev->set_multicast_list = enet_set_multicast_list;
+	dev->ethtool_ops = &enet_ethtool_ops;
+	dev->do_ioctl = enet_ioctl;
+	netif_napi_add(dev, &priv->napi, enet_poll, 16);
+
+	/* set default mac address */
+	tangox_ethernet_getmac(0, dev->dev_addr);
+	memcpy(&(sock.sa_data), dev->dev_addr, ETH_ALEN);
+	enet_set_mac_address(dev, &sock);
+
+	if ((ret = register_netdev(dev))) {
+		printk(KERN_ERR PFX "unable to register netdevice\n");
+		goto err_free;
+	}
+
+	printk(KERN_INFO PFX "mac address %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       dev->dev_addr[0], dev->dev_addr[1], dev->dev_addr[2],
+	       dev->dev_addr[3], dev->dev_addr[4], dev->dev_addr[5]);
+
+	gdev = dev;
+	return 0;
+
+err_free:
+	if (dev->irq)
+		free_irq(dev->irq, dev);
+	enet_dma_free(priv);
+	free_netdev(dev);
+	return ret;
+}
+
+
+/*
+ * entry point, checks if ethernet is  enabled on the board and if so,
+ * probes it
+ */
+extern int tangox_ethernet_enabled(int);
+
+int __init tango2_enet_init(void)
+{
+    // Start IOP
+    gbus_writel(0x1B003C,0);
+    gbus_writel(0xDFFFC,3);
+    gbus_writel(0xDFFFC,1);
+    gbus_writel(0xDFFFC,0);
+    while(gbus_readl(0x1B003C)!=0xCAFE);
+
+	if (!tangox_ethernet_enabled(0)) {
+		printk(KERN_NOTICE PFX "ethernet support is disabled\n");
+		return -ENODEV;
+	}
+
+	return enet_probe();
+}
+
+/*
+ * exit func, stops hardware and unregisters netdevice
+ */
+void __exit tango2_enet_exit(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+
+	dev = gdev;
+
+	free_irq(dev->irq, dev);
+	unregister_netdev(dev);
+
+	priv = netdev_priv(dev);
+	enet_dma_free(priv);
+
+	free_netdev(dev);
+}
+
+
+module_init(tango2_enet_init);
+module_exit(tango2_enet_exit);
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet.c~ linux-2.6.30-test/drivers/net/tango2_enet.c~
--- linux-2.6.30-ori/drivers/net/tango2_enet.c~	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet.c~	2009-06-23 18:36:54.000000000 -0400
@@ -0,0 +1,1443 @@
+/*
+ * New driver for SMP863x builtin Ethernet mac
+ *
+ * This driver uses NAPI and generic linux MII support.
+ *
+ * Tx path limits the number of interrupt by reclaiming sent buffer in
+ * a timer.  In case  the tx starts  to go  faster, it will  switch to
+ * interrupt mode.
+ *
+ * Note that OOM condition is not handled correctly, and can leave the
+ * rx path  in bad  shape. down/up the  interface should make  it work
+ * again though. But anyway, it's not likely to happen.
+ *
+ * Copyright (C) 2005 Maxime Bizon <mbizon@freebox.fr>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/etherdevice.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/crc32.h>
+
+#include "tango2_enet.h"
+
+#define PFX	"tango2_enet: "
+
+MODULE_DESCRIPTION("SMP863x internal ethernet mac driver");
+MODULE_AUTHOR("Maxime Bizon <mbizon@freebox.fr>");
+MODULE_LICENSE("GPL");
+
+static int gphy_id = -1;
+module_param(gphy_id, int, 0);
+MODULE_PARM_DESC(gphy_id, "PHY id, else autodetect");
+
+static struct net_device *gdev;
+
+extern long long em86_netstats[];
+
+static inline unsigned long tangox_getxtal(void)
+{
+        return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
+// Structures used by the IOP
+
+struct iopfifo {
+	unsigned int base;
+	unsigned int size;
+	unsigned int rd;
+	unsigned int wr;
+};
+
+// NOTE: the fifo pointers are gbus address and not real pointers
+static void iopfifo_get_pointer(struct iopfifo *fifo, 
+	unsigned int *base, unsigned int *size, unsigned int *rd, unsigned int *wr)
+{
+	*base = gbus_readl((unsigned int) &(fifo->base));
+	*size = gbus_readl((unsigned int) &(fifo->size));
+	*rd = gbus_readl((unsigned int) &(fifo->rd));
+	*wr = gbus_readl((unsigned int) &(fifo->wr));
+}
+
+static unsigned int iopfifo_get_writable_size(struct iopfifo *fifo, unsigned int *wr_ptr1, 
+    unsigned int *wr_size1, unsigned int *wr_ptr2)
+{
+	unsigned int base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	*wr_ptr1 = base + wr;
+
+	if (wr >= rd) {
+		if (rd > 0) {
+			*wr_size1 = size - wr;
+			*wr_ptr2 = base;
+			return (*wr_size1 + rd - 1);
+		}
+		else {
+			*wr_size1 = size - 1 - wr;
+			*wr_ptr2 = 0;
+			return (*wr_size1);
+		}
+	}
+	else {
+		*wr_size1 = rd - 1 - wr;
+		*wr_ptr2 = 0;
+		return (*wr_size1);
+	}
+}
+
+static unsigned int iopfifo_get_readable_size(struct iopfifo *fifo, unsigned int *rd_ptr1, 
+    unsigned int *rd_size1, unsigned int *rd_ptr2)
+{
+	unsigned int base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	*rd_ptr1 = base + rd;
+
+	if (wr >= rd) {
+		*rd_size1 = wr - rd;
+		*rd_ptr2 = 0;
+		return (*rd_size1);
+	}
+	else {
+		*rd_size1 = size - rd;
+		*rd_ptr2 = base;
+		return (*rd_size1 + wr);
+	}
+}
+
+
+
+static unsigned int iopfifo_incr_write_ptr(struct iopfifo *fifo, unsigned int incr)
+{
+	unsigned int base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	wr += incr;
+	if (wr >= size)
+		wr -= size;
+
+	gbus_writel((unsigned int) &(fifo->wr), wr);
+
+	return wr + base;
+}
+
+static unsigned int iopfifo_incr_read_ptr(struct iopfifo *fifo, unsigned int incr)
+{
+	unsigned int  base, size, rd, wr;
+
+	iopfifo_get_pointer(fifo, &base, &size, &rd, &wr);
+
+	rd += incr;
+	if (rd >= size)
+		rd -= size;
+
+	gbus_writel((unsigned int) &(fifo->rd), rd);
+
+	return rd + base;
+}
+
+// Fill the IOP buffer fifo with new skbs
+static void iopFillBufferFifo(struct tango2_enet_priv *priv)
+{
+    struct net_device *dev = priv->dev;
+    struct iopfifo *buffifo= (struct iopfifo *) (0x204*4+0x1B0000); // gbus address of the buffifo
+    unsigned int  write1,write2,size1;
+    struct sk_buff *skb;
+    unsigned long t1,t2;
+
+    t1=tangox_getxtal();
+
+    while(iopfifo_get_writable_size(buffifo,&write1, &size1, &write2)>=4)
+    {
+        if(size1==0) write1=write2; // We assume it doesn't go over from end
+        skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+        if(unlikely(!skb))
+        {
+            printk(KERN_ERR "iopFillBufferFifo couldn't allocate skb\n");
+            break;
+        }
+        skb_reserve(skb, SKB_RESERVE_SIZE);
+        skb->dev = dev; // We will need to update that to support more than 1 device
+        dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+        gbus_writel(write1*4+0x1B0000, PHYSADDR(skb->data));
+        gbus_writel(write1*4+0x1B0000+4, RX_BUF_SIZE2);
+        gbus_writel(write1*4+0x1B0000+8, (unsigned int) skb);
+        gbus_writel(write1*4+0x1B0000+12, 0);
+        iopfifo_incr_write_ptr(buffifo, 4);
+        em86_netstats[9]+=1;
+    }
+
+    t2=tangox_getxtal();
+    em86_netstats[8]+=(t2-t1);
+}
+
+static int iopGetOutputFifo(struct tango2_enet_priv *priv)
+{
+    struct net_device *dev = priv->dev;
+    struct iopfifo *outfifo= (struct iopfifo *) (0x208*4+0x1B0000); // gbus address of the outfifo
+    unsigned int  read1,read2,size1;
+    struct sk_buff *skb;
+    unsigned int flaglen;
+    int count=0;
+
+    while(iopfifo_get_readable_size(outfifo,&read1, &size1, &read2)>=4)
+    {
+        if(size1==0) read1=read2; // We assume it doesn't go over from end
+        flaglen=gbus_readl(read1*4+0x1B0000+4);
+        skb=(struct sk_buff *) gbus_readl(read1*4+0x1B0000+8);
+        iopfifo_incr_read_ptr(outfifo, 4);
+
+        // This skb isn't needed anymore since it was merged, we could reuse it
+        if ((flaglen&0x03000000) == 0x03000000)
+        {
+            if(priv->recyclecount<32)
+            {
+                priv->recycle_skbs[priv->recyclecount]=skb;
+                priv->recyclecount+=1;
+            }
+            else
+            {
+                em86_netstats[19]+=1;
+                consume_skb(skb);
+            }
+            continue;
+        }
+
+        skb_put(skb, flaglen&0xFFFF);
+        skb->protocol = eth_type_trans(skb, dev);
+
+        if ((flaglen&0xFFFF0000) == 0x10B0000)
+        {
+            em86_netstats[4]+=1;
+            skb->ip_summed = CHECKSUM_UNNECESSARY;
+        }
+        else
+        {
+            if((flaglen&0x01030000) == 0x1030000)
+            {
+                em86_netstats[5]+=1;
+            }
+            else
+            {
+                em86_netstats[6]+=1;
+            }
+            skb->ip_summed = CHECKSUM_NONE;
+        }
+
+        {
+            unsigned long t1,t2;
+            t1=tangox_getxtal();
+            netif_receive_skb(skb);
+            t2=tangox_getxtal();
+            em86_netstats[10]+=(t2-t1);
+            em86_netstats[11]+=1;
+        }
+        count+=1;
+    }
+    return count;
+    // 	enet_iop_enable_interrupts(priv, 1);
+}
+
+/*
+ * mdio read/write callback, can run from userspace or timer
+ */
+static __inline int enet_mdio_read(struct net_device *dev, int phy_id,
+				   int location)
+{
+	int val;
+
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	enet_writel(ENET_MAC_MIIAR, MIIAR_ADDR(phy_id) | MIIAR_REG(location));
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+	val = enet_readl(ENET_MAC_MIIDR);
+
+	return val;
+}
+
+static void enet_mdio_write(struct net_device *dev, int phy_id,
+				     int location, int val)
+{
+	enet_writel(ENET_MAC_MIIDR, val);
+	enet_writel(ENET_MAC_MIIAR,
+		    MIIAR_ADDR(phy_id) | MIIAR_REG(location) | MIIAR_WRITE);
+	udelay(1);
+	while (enet_readl(ENET_MAC_MIIAR) & MIIAR_BUSY);
+}
+
+/*
+ * enable/disable interrupt helpers
+ * need proper locks since we will call them from any context
+ */
+static __inline void enet_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val &= ~IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, 0);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags, val;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+	if (rx_only) {
+		val = enet_readl(ENET_DMA_IER);
+		val |= IER_R;
+		enet_writel(ENET_DMA_IER, val);
+	} else
+		enet_writel(ENET_DMA_IER, IER_NIS | IER_R | IER_T);
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+
+static __inline void enet_iop_disable_interrupts(struct tango2_enet_priv *priv,
+					     int rx_only)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,0); // disable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+static __inline void enet_iop_enable_interrupts(struct tango2_enet_priv *priv,
+					    int rx_only)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->ier_lock, flags);
+		while(gbus_readl(0x1BFA44)); // Get IOP irq mutex
+		gbus_writel(0x1B0044,1); // enable IOP irq
+		gbus_writel(0x1BFA44,0); // Release IOP irq mutex
+	spin_unlock_irqrestore(&priv->ier_lock, flags);
+}
+
+/*
+ * rx poll func, called by network core
+ */
+static int enet_poll(struct napi_struct *napi, int budget)
+{
+	struct tango2_enet_priv *priv = container_of(napi, struct tango2_enet_priv, napi);
+	struct net_device *dev = priv->dev;
+	int received=0;
+    unsigned long pollt1,pollt2;
+    pollt1=tangox_getxtal();
+
+    em86_netstats[18]=gbus_readl(0x1B0004);
+
+	/* process no more than "limit" done rx */
+	do {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+		uint32_t rdes0_cache;
+		unsigned int len;
+
+		rx = &priv->rx_descs[priv->last_rx_desc];
+
+		/* we  need  multiple  read  on this  volatile,  avoid
+		 * memory access at each time */
+		rdes0_cache = rx->rdes0;
+		if (rdes0_cache & RDES0_OWN) {
+			break;
+		}
+
+		if (received>=budget)
+			break;
+
+		if (likely(skb = priv->rx_skbs[priv->last_rx_desc])) {
+
+			/* we don't handle multipacket frame */
+			if (!(rdes0_cache & RDES0_FIRST) ||
+			    !(rdes0_cache & RDES0_LAST)) {
+				/* we don't handle multipacket frame */
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check for CRC */
+			if (rdes0_cache & RDES0_CRC) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_crc_errors++;
+				goto rearm;
+			}
+
+			/* sanity check on len field */
+			len = RDES0_FRAME_LEN(rdes0_cache);
+			if (rdes0_cache & (RDES0_TOO_LONG | RDES0_TRUNC) ||
+			    len > RX_BUF_SIZE2) {
+				priv->stats.rx_errors++;
+				priv->stats.rx_length_errors++;
+				goto rearm;
+			}
+
+			/* check remaining error */
+			if (rdes0_cache & (RDES0_ERR_SUM | RDES0_COLLISION |
+					   RDES0_WATCHDOG_TMOUT |
+					   RDES0_MII_ERROR)) {
+				priv->stats.rx_errors++;
+				goto rearm;
+			}
+
+			// We have a valid skb, give it to IOP input fifo
+			{
+                struct iopfifo *infifo= (struct iopfifo *) (0x200*4+0x1B0000); // gbus address of the infifo
+                unsigned int  write1,write2,size1;
+
+                if(iopfifo_get_writable_size(infifo,&write1, &size1, &write2)>=4)
+                {
+                    if(size1==0) write1=write2; // We assume it doesn't go over from end
+                    gbus_writel(write1*4+0x1B0000, PHYSADDR(skb->data));
+                    gbus_writel(write1*4+0x1B0000+4, len);
+                    gbus_writel(write1*4+0x1B0000+8, (unsigned int) skb);
+                    iopfifo_incr_write_ptr(infifo, 4);
+                }
+                else
+                {
+                    // Discard that skb?
+                    unsigned long t1,t2;
+                    printk(KERN_ERR "tango2_enet couldn't send skb to IOP\n");
+                    skb_put(skb, len);
+                    skb->protocol = eth_type_trans(skb, dev);
+                    skb->ip_summed = CHECKSUM_NONE;
+                    t1=tangox_getxtal();
+                    netif_receive_skb(skb);
+                    t2=tangox_getxtal();
+                    em86_netstats[10]+=(t2-t1);
+                    em86_netstats[11]+=1;
+                    em86_netstats[7]+=1;
+                }
+            }
+			priv->stats.rx_packets++;
+			priv->stats.rx_bytes += len;
+			dev->last_rx = jiffies;
+			priv->rx_skbs[priv->last_rx_desc] = NULL;
+			/* we will realloc an skb for this slot */
+		}
+
+        if(priv->recyclecount>0)
+        {
+            priv->recyclecount-=1;
+            skb = priv->recycle_skbs[priv->recyclecount];
+            rx->rdes2 = PHYSADDR(skb->data);
+            priv->rx_skbs[priv->last_rx_desc] = skb;
+        }
+        else
+        {
+            unsigned long t1,t2;
+            t1=tangox_getxtal();
+
+			skb = dev_alloc_skb(RX_BUF_SIZE + SKB_RESERVE_SIZE);
+			if (unlikely(!skb))
+			{
+				printk(KERN_ERR "tango2_enet couldn't allocate skb\n");
+				break;
+			}
+            t2=tangox_getxtal();
+            em86_netstats[12]+=(t2-t1);
+
+            t1=tangox_getxtal();
+			skb_reserve(skb, SKB_RESERVE_SIZE);
+			skb->dev = dev; // We will need to update that to support more than 1 device
+			rx->rdes2 = PHYSADDR(skb->data);
+			dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE);
+			priv->rx_skbs[priv->last_rx_desc] = skb;
+            t2=tangox_getxtal();
+            em86_netstats[13]+=(t2-t1);
+        }
+rearm:
+		/* rearm descriptor */
+		wmb();
+		rx->rdes0 = RDES0_OWN;
+		priv->last_rx_desc++;
+		priv->last_rx_desc &= (ENET_RX_DESC_COUNT - 1);
+		received++;
+
+	} while (1);
+
+    iopFillBufferFifo(priv);
+    received+=iopGetOutputFifo(priv);
+
+    pollt2=tangox_getxtal();
+    em86_netstats[14]+=(pollt2-pollt1);
+
+	if (received>=budget) 
+	{
+		/* breaked, but there is still work to do */
+		return received;
+	}
+
+	napi_complete(napi);
+	enet_enable_interrupts(priv, 1);
+	enet_iop_enable_interrupts(priv, 1);
+	return received;
+}
+
+/*
+ * tx reclaim func. Called by timer or tx done tasklet to reclaim sent
+ * buffers.
+ */
+static void enet_tx_reclaim(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	spin_lock(&priv->tx_lock);
+
+	while (priv->free_tx_desc_count < ENET_TX_DESC_COUNT) {
+		uint32_t tdes0_cache;
+		struct sk_buff *skb;
+
+		tx = &priv->tx_descs[priv->dirty_tx_desc];
+
+		tdes0_cache = tx->tdes0;
+		if (tdes0_cache & TDES0_OWN)
+			break;
+
+		skb = priv->tx_skbs[priv->dirty_tx_desc];
+		priv->stats.tx_packets++;
+
+		/* check  for  transmission  errors and  update  stats
+		 * accordingly */
+		if (tdes0_cache & (TDES0_ERR_SUM | TDES0_CARRIER_LOST |
+				   TDES0_NO_CARRIER | TDES0_LATE_COLLISION |
+				   TDES0_EXC_COLLISION | TDES0_HEARTBEAT |
+				   TDES0_EXC_DEFERAL | TDES0_UNDERFLOW)) {
+			priv->stats.tx_errors++;
+		} else {
+			priv->stats.tx_bytes += skb->len;
+		}
+
+		dev_kfree_skb(skb);
+		priv->tx_skbs[priv->dirty_tx_desc] = NULL;
+		priv->dirty_tx_desc++;
+		priv->dirty_tx_desc %= ENET_TX_DESC_COUNT;
+		priv->free_tx_desc_count++;
+	}
+
+	if (priv->free_tx_desc_count != 0 && netif_queue_stopped(dev))
+		netif_wake_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+}
+
+/*
+ * tx done timer callback, just call tx_done and reschedule timer
+ */
+static void enet_tx_reclaim_timer(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+	enet_tx_reclaim(data);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+}
+
+
+/*
+ * tx request callback
+ */
+static int enet_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	volatile struct enet_tx_desc *tx;
+	unsigned long tdes1_cache;
+
+	spin_lock(&priv->tx_lock);
+
+	priv = netdev_priv(dev);
+	tx = &priv->tx_descs[priv->next_tx_desc];
+
+	/* make sure the next free tx desc is available */
+	if (unlikely(priv->free_tx_desc_count == 0)) {
+		/* no, this  should not happen since  queue is stopped
+		 * before we run out of tx desc */
+		printk(KERN_WARNING PFX "no free tx desc to handle pkt\n");
+//		dev_kfree_skb(skb);
+		netif_stop_queue(dev);
+		spin_unlock(&priv->tx_lock);
+		return NETDEV_TX_BUSY;
+	}
+
+	/* fill the tx desc with this skb address */
+	tdes1_cache = (TDES1_FIRST | TDES1_LAST);
+	if (priv->next_tx_desc == ENET_TX_DESC_COUNT - 1)
+		tdes1_cache |= TDES1_TER;
+
+	/* if we  start to  run low  on free tx  desc, then  enable tx
+	 * interrupt to reclaim them faster */
+	if (priv->free_tx_desc_count == ENET_TX_DESC_LOW) {
+		tdes1_cache |= (TDES1_ENABLE_ISR);
+	}
+	tdes1_cache |= TDES1_TBS1(skb->len);
+
+	tx->tdes1 = tdes1_cache;
+	tx->tdes2 = PHYSADDR(skb->data);
+	dma_cache_wback((unsigned long)skb->data, skb->len);
+
+	/* keep a pointer to it for later and give it to dma  */
+	priv->tx_skbs[priv->next_tx_desc] = skb;
+	wmb();
+	tx->tdes0 = TDES0_OWN;
+
+	/* kick tx dma in case it was suspended */
+	wmb();
+	enet_writel(ENET_DMA_TPDR, 0x1);
+
+	priv->next_tx_desc++;
+	priv->next_tx_desc %= ENET_TX_DESC_COUNT;
+
+	/* if next  tx descriptor is not  clean, then we  have to stop
+	 * queue */
+	if (unlikely(--priv->free_tx_desc_count == 0))
+		netif_stop_queue(dev);
+
+	spin_unlock(&priv->tx_lock);
+
+	return NETDEV_TX_OK;
+}
+
+// IOP signaled events
+static irqreturn_t enet_isr_iop(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long status;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+	status = gbus_read_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softset);
+	if ((status & 0x80000000) == 0)
+		return IRQ_HANDLED;
+	gbus_write_uint32(pGBus, REG_BASE_cpu_block + CPU_irq_softclr, 0x80000000);
+	em86_netstats[16]+=1;
+	if(napi_schedule_prep(&priv->napi))
+	{
+		em86_netstats[17]+=1;
+		/* disable rx interrupt */
+		enet_disable_interrupts(priv, 1);
+		// This won't be useful since we won't be able to schedule
+		enet_iop_disable_interrupts(priv, 1);
+		__napi_schedule(&priv->napi);
+	}
+	return IRQ_HANDLED;
+}
+
+/*
+ * our  irq handler, just  ack it  and schedule  the right  tasklet to
+ * handle this
+ */
+static irqreturn_t enet_isr(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+
+	/* fetch status & ack them */
+	val = enet_readl(ENET_DMA_SR);
+	enet_writel(ENET_DMA_SR, val);
+
+	/* handle interrupt */
+	if (val & SR_NIS) {
+		if (val & SR_T) {
+			tasklet_schedule(&priv->tx_reclaim_tasklet);
+		}
+
+		if (val & SR_R) {
+			if(napi_schedule_prep(&priv->napi))
+			{
+				/* disable rx interrupt */
+				enet_disable_interrupts(priv, 1);
+				// This won't be useful since we won't be able to schedule
+				enet_iop_disable_interrupts(priv, 1);
+
+				/* ack  any  interrupt  that may  have
+				 * arrived  between last ack  to avoid
+				 * reentering */
+				enet_writel(ENET_DMA_SR, SR_NIS | SR_R);
+				__napi_schedule(&priv->napi);
+			}
+		}
+	}
+
+    return IRQ_HANDLED;
+}
+
+/*
+ * start/stop dma engine
+ */
+static __inline void enet_start_dma(struct tango2_enet_priv *priv)
+{
+	/* send start command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, CR_SF | CR_SR | CR_ST);
+}
+
+static __inline void enet_stop_dma(struct tango2_enet_priv *priv)
+{
+	unsigned long val;
+
+	/* send stop command to rx & tx dma */
+	enet_writel(ENET_DMA_CR, 0);
+
+	/* wait for them to reach stopped state, should not be long */
+	do {
+		udelay(1);
+		val = enet_readl(ENET_DMA_SR);
+		if ((val & SR_TPS) && (val & SR_RPS))
+			break;
+	} while (1);
+}
+
+/*
+ * reconfigure mac for new link state
+ */
+static void enet_link_reconfigure(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	if (dev->flags & IFF_UP)
+		enet_stop_dma(priv);
+
+	/* reflect duplex status in dma register */
+	spin_lock(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+	if (priv->mii.full_duplex)
+		val |= MACCR_F;
+	else
+		val &= ~MACCR_F;
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock(&priv->maccr_lock);
+
+	if (dev->flags & IFF_UP)
+		enet_start_dma(priv);
+}
+
+/*
+ * link check timer callback
+ */
+static void enet_link_check(unsigned long data)
+{
+	struct net_device *dev;
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	dev = (struct net_device *)data;
+	priv = netdev_priv(dev);
+
+	/* check for duplex change */
+	spin_lock(&priv->mii_lock);
+	ret = mii_check_media(&priv->mii, 1, 0);
+	spin_unlock(&priv->mii_lock);
+
+	if (ret)
+		enet_link_reconfigure(dev);
+
+	/* reschedule timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+}
+
+/*
+ * program given mac address in hw registers
+ */
+static int enet_set_mac_address(struct net_device *dev, void *addr)
+{
+	unsigned long hi_mac, low_mac;
+	struct sockaddr *sock = addr;
+
+	/* to make it safe, we won't do this while running */
+	if (netif_running(dev))
+		return -EBUSY;
+
+	memcpy(dev->dev_addr, sock->sa_data, ETH_ALEN);
+
+	hi_mac = (dev->dev_addr[5] << 8) | dev->dev_addr[4];
+	low_mac = (dev->dev_addr[3] << 24)| (dev->dev_addr[2] << 16) |
+		(dev->dev_addr[1] << 8) | dev->dev_addr[0];
+
+	enet_writel(ENET_MAC_MACAHR, hi_mac);
+	enet_writel(ENET_MAC_MACALR, low_mac);
+
+	return 0;
+}
+
+/*
+ * update hash table to reflect new device multicast address list
+ */
+static void enet_set_multicast_list(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	struct dev_mc_list *mclist;
+	unsigned long val;
+	uint32_t mc_filter[2];
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* the link check timer might change MACCR, we need to protect
+	 * against it */
+	spin_lock_bh(&priv->maccr_lock);
+	val = enet_readl(ENET_MAC_MACCR);
+
+        if (dev->flags & IFF_PROMISC) {
+                val |= MACCR_PR | MACCR_PM;
+	} else {
+		val &= ~MACCR_PR;
+		/* if we want all multicast or if address count is too
+		 * high, don't try to compute hash value */
+		if (dev->mc_count > 64 || dev->flags & IFF_ALLMULTI) {
+			val |= MACCR_PM;
+		}
+	}
+	enet_writel(ENET_MAC_MACCR, val);
+	spin_unlock_bh(&priv->maccr_lock);
+
+	/* we  don't  need  to  update  hash  table  if  we  pass  all
+	 * multicast */
+	if (val & MACCR_PM)
+		return;
+
+	mc_filter[0] = mc_filter[1] = 0;
+	mclist = dev->mc_list;
+
+	for (i = 0; i < dev->mc_count; i++) {
+		unsigned int n;
+		char *addr;
+
+		addr = mclist->dmi_addr;
+		mclist = mclist->next;
+		if (!(*addr & 1))
+			continue;
+
+		n = ether_crc(ETH_ALEN, addr) >> 26;
+		mc_filter[n >> 5] |= 1 << (n & 31);
+	}
+
+	enet_writel(ENET_MAC_MALR, mc_filter[0]);
+	enet_writel(ENET_MAC_MAHR, mc_filter[1]);
+}
+
+/*
+ * open callback
+ */
+static int enet_open(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+
+	priv = netdev_priv(dev);
+
+	/* check link */
+	if (mii_check_media(&priv->mii, 1, 1))
+		enet_link_reconfigure(dev);
+
+	/* start rx & tx dma engine */
+	enet_start_dma(priv);
+
+	napi_enable(&priv->napi);
+
+	/* enable mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val |= MACCR_TE | MACCR_RE;
+	enet_writel(ENET_MAC_MACCR, val);
+
+	/*
+	 * clear & enable interrupts, we want:
+	 * - receive complete
+	 * - transmit complete
+	 */
+	enet_writel(ENET_DMA_SR, SR_NIS | SR_R | SR_T);
+	enet_enable_interrupts(priv, 0);
+	enet_iop_enable_interrupts(priv, 0);
+
+	/* start link check & tx reclaim timer */
+	priv->link_check_timer.expires = jiffies + LINK_CHECK_TIMER_FREQ;
+	add_timer(&priv->link_check_timer);
+
+	priv->tx_reclaim_timer.expires = jiffies + TX_RECLAIM_TIMER_FREQ;
+	add_timer(&priv->tx_reclaim_timer);
+
+	/* and finally start tx queue */
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+/*
+ * stop callback
+ */
+static int enet_stop(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	unsigned long val;
+	int i;
+
+	priv = netdev_priv(dev);
+
+	/* stop link timer */
+	del_timer_sync(&priv->link_check_timer);
+
+	/* stop tx queue */
+	netif_stop_queue(dev);
+	napi_disable(&priv->napi);
+
+	/* wait for all tx buffers to be reclaimed */
+	while (priv->free_tx_desc_count != ENET_TX_DESC_COUNT)
+		yield();
+
+	/* stop tx reclaim timer */
+	del_timer_sync(&priv->tx_reclaim_timer);
+
+	/* disable all interrupts */
+	enet_disable_interrupts(priv, 0);
+	enet_iop_disable_interrupts(priv, 0);
+
+	/* stop dma */
+	enet_stop_dma(priv);
+
+	/* stop mac rx & tx */
+	val = enet_readl(ENET_MAC_MACCR);
+	val &= ~(MACCR_TE | MACCR_RE);
+	enet_writel(ENET_MAC_MACCR, val);
+
+    while(gbus_readl(0x1BFA40)); // Get IOP mutex
+    //gbus_writel(0x1B0040,2); // Send IOP reset command
+    // TODO: clear the fifos and skb...
+    gbus_writel(0x1BFA40,0); // Release IOP mutex
+
+	/* while we were stopping it,  the rx dma may have filled some
+	 * buffer, consider it junk and rearm all descriptor */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+	}
+
+	/* make  the dma engine  restarts at  first descriptor  in the
+	 * list */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->last_rx_desc = 0;
+
+	return 0;
+}
+
+/*
+ * get_stats callback
+ */
+static struct net_device_stats *enet_get_stats(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+
+	priv = netdev_priv(dev);
+
+	return &priv->stats;
+}
+
+/*
+ * ethtool callbacks
+ */
+static int enet_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_gset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_ethtool_sset(&priv->mii, cmd);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static int enet_nway_reset(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_nway_restart(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static u32 enet_get_link(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii_lock);
+	ret = mii_link_ok(&priv->mii);
+	spin_unlock_bh(&priv->mii_lock);
+
+	return ret;
+}
+
+static struct ethtool_ops enet_ethtool_ops = {
+	.get_settings		= enet_get_settings,
+	.set_settings		= enet_set_settings,
+	.nway_reset		= enet_nway_reset,
+	.get_link		= enet_get_link,
+};
+
+static int enet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	struct tango2_enet_priv *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+
+	spin_lock_bh(&priv->mii);
+	ret = generic_mii_ioctl(&priv->mii, if_mii(rq), cmd, NULL);
+	spin_unlock_bh(&priv->mii);
+
+	return ret;
+}
+
+/*
+ * dma ring allocation is done here
+ */
+static int enet_dma_init(struct tango2_enet_priv *priv)
+{
+	unsigned int size;
+	int i;
+
+	/*
+	 * allocate rx descriptor list & rx buffers
+	 *
+	 * We allocate  skb now and fill buffer  with their addresses,
+	 * note that we reserve 4 bytes at beginning of data buffer to
+	 * store skb address.
+	 *
+	 */
+	size = ENET_RX_DESC_COUNT * sizeof (struct enet_rx_desc);
+	if (!(priv->rx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->rx_descs = (volatile struct enet_rx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->rx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->rx_descs_cached, size);
+
+	/*
+	 * initialize all rx descs
+	 */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		volatile struct enet_rx_desc *rx;
+		struct sk_buff *skb;
+
+		rx = &priv->rx_descs[i];
+		rx->rdes0 = RDES0_OWN;
+
+		rx->rdes1 = RDES1_RBS2(0) | RDES1_RBS1(RX_BUF_SIZE);
+		if (i == ENET_RX_DESC_COUNT - 1)
+			rx->rdes1 |= RDES1_RER;
+
+		skb = dev_alloc_skb(RX_BUF_SIZE2 + SKB_RESERVE_SIZE);
+		if (!skb)
+			return -ENOMEM;
+
+		skb_reserve(skb, SKB_RESERVE_SIZE);
+		rx->rdes2 = PHYSADDR(skb->data);
+		rx->rdes3 = 0;
+
+		dma_cache_inv((unsigned long)skb->data, RX_BUF_SIZE2);
+		priv->rx_skbs[i] = skb;
+	}
+	priv->last_rx_desc = 0;
+
+	/*
+	 * allocate tx descriptor list
+	 *
+	 * We allocate  only the descriptor list and  prepare them for
+	 * further use. When tx is needed, we will set the right flags
+	 * and kick the dma.
+	 */
+	size = ENET_TX_DESC_COUNT * sizeof (struct enet_tx_desc);
+	if (!(priv->tx_descs_cached = kmalloc(size, GFP_KERNEL)))
+		return -ENOMEM;
+	priv->tx_descs = (volatile struct enet_tx_desc *)
+		CACHE_TO_NONCACHE((unsigned long)priv->tx_descs_cached);
+	dma_cache_wback_inv((unsigned long)priv->tx_descs_cached, size);
+
+	/*
+	 * initialize tx descs
+	 */
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		volatile struct enet_tx_desc *tx;
+
+		tx = &priv->tx_descs[i];
+		tx->tdes0 = 0;
+		tx->tdes1 = 0;
+		if (i == ENET_TX_DESC_COUNT - 1)
+			tx->tdes1 |= TDES1_TER;
+		tx->tdes2 = 0;
+		tx->tdes3 = 0;
+	}
+	priv->dirty_tx_desc = priv->next_tx_desc = 0;
+	priv->free_tx_desc_count = ENET_TX_DESC_COUNT;
+
+	/*
+	 * write rx desc list & tx desc list addresses in registers
+	 */
+	enet_writel(ENET_DMA_RBAR, PHYSADDR(priv->rx_descs));
+	enet_writel(ENET_DMA_TBAR, PHYSADDR(priv->tx_descs));
+
+    printk(KERN_ERR "tango2_enet rx desc at %X tx desc at %X\n",(unsigned int) PHYSADDR(priv->rx_descs),
+        (unsigned int) PHYSADDR(priv->tx_descs));
+	return 0;
+}
+
+/*
+ * free  all dma rings  memory, called  at uninit  time or  when error
+ * occurs at init time
+ */
+static void enet_dma_free(struct tango2_enet_priv *priv)
+{
+	int i;
+
+	/* note: kfree(NULL) is ok */
+	kfree(priv->rx_descs_cached);
+	kfree(priv->tx_descs_cached);
+
+	/* note: kfree_skb(NULL) is _not_ ok */
+	for (i = 0; i < ENET_RX_DESC_COUNT; i++) {
+		if (priv->rx_skbs[i])
+			kfree_skb(priv->rx_skbs[i]);
+	}
+
+	for (i = 0; i < ENET_TX_DESC_COUNT; i++) {
+		if (priv->tx_skbs[i])
+			kfree_skb(priv->tx_skbs[i]);
+	}
+}
+
+/*
+ * mac hw init is done here
+ */
+static int enet_hw_init(struct net_device *dev)
+{
+	struct tango2_enet_priv *priv;
+	int loop;
+
+	priv = netdev_priv(dev);
+
+	/* reset phy */
+	enet_mdio_write(dev, priv->mii.phy_id, MII_BMCR, BMCR_RESET);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_mdio_read(dev, priv->mii.phy_id,
+				     MII_BMCR) & BMCR_RESET))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "PHY reset does not complete...\n");
+		return -EBUSY;
+	}
+
+	/* reset dma engine */
+	enet_writel(ENET_DMA_BMR, BMR_SWR);
+
+	/* wait for the reset bit to clear */
+	udelay(100);
+	loop = 100;
+	while (loop) {
+		if (!(enet_readl(ENET_DMA_BMR) & BMR_SWR))
+			break;
+		mdelay(1);
+		loop--;
+	}
+
+	if (!loop) {
+		printk(KERN_ERR PFX "dma engine does not exit reset...\n");
+		return -EBUSY;
+	}
+
+	/* set bus mode */
+	enet_writel(ENET_DMA_BMR, BMR_PBL(32));
+
+	/* enable MAC flow ctrl */
+	enet_writel(ENET_MAC_FCR, FCR_ENABLE);
+
+	/* configure MAC ctrller to do hash perfect filtering  */
+	enet_writel(ENET_MAC_MACCR, MACCR_ASTP | MACCR_HP);
+
+	/* clear hash table */
+	enet_writel(ENET_MAC_MAHR, 0xffffffff);
+	enet_writel(ENET_MAC_MALR, 0xffffffff);
+
+	return 0;
+}
+
+
+
+/*
+ * allocate  netdevice structure,  do  all dma  rings allocations  and
+ * register the netdevice
+ */
+extern int tangox_ethernet_getmac(int i, unsigned char *);
+extern int em86xx_mbus_init(void);
+
+static int enet_probe(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+	int ret;
+	struct sockaddr sock;
+
+	printk(KERN_INFO PFX "ethernet driver for SMP863x internal mac\n");
+	/* allocate  netdevice structure  with enough  length  for our
+	 * context data */
+	dev = alloc_etherdev(sizeof (*priv));
+	if (!dev)
+		return -ENOMEM;
+
+    // Init mbus registers
+    em86xx_mbus_init();
+
+	/* initialize private data */
+	priv = netdev_priv(dev);
+	memset(priv, 0, sizeof (*priv));
+	spin_lock_init(&priv->tx_lock);
+	spin_lock_init(&priv->ier_lock);
+	spin_lock_init(&priv->maccr_lock);
+
+	/* init tx done tasklet */
+	tasklet_init(&priv->tx_reclaim_tasklet, enet_tx_reclaim,
+		     (unsigned long)dev);
+
+	/* init tx reclaim timer */
+	init_timer(&priv->tx_reclaim_timer);
+	priv->tx_reclaim_timer.data = (unsigned long )dev;
+	priv->tx_reclaim_timer.function = enet_tx_reclaim_timer;
+
+	/* init link check timer and mii lock */
+	init_timer(&priv->link_check_timer);
+	priv->link_check_timer.data = (unsigned long)dev;
+	priv->link_check_timer.function = enet_link_check;
+	spin_lock_init(&priv->mii_lock);
+
+	/* fill mii info */
+	priv->mii.dev = dev;
+	priv->mii.phy_id_mask = 0x1f;
+	priv->mii.reg_num_mask = 0x1f;
+	priv->mii.mdio_read = enet_mdio_read;
+	priv->mii.mdio_write = enet_mdio_write;
+
+	if (gphy_id != -1) {
+		/* phy id forced, just check for sanity */
+		if (gphy_id < 0 || gphy_id > 31) {
+			ret = -EINVAL;
+			goto err_free;
+		}
+		priv->mii.phy_id = gphy_id;
+
+	} else {
+		int i;
+
+		/* try to probe phy if not given */
+		for (i = 0; i < 32; i++) {
+			uint32_t id;
+			int val;
+
+			val = enet_mdio_read(dev, i, MII_PHYSID1);
+			id = (val << 16);
+			val = enet_mdio_read(dev, i, MII_PHYSID2);
+			id |= val;
+
+			if (id != 0xffffffff && id != 0x00000000)
+				break;
+		}
+
+		if (i == 32) {
+			printk(KERN_ERR PFX "unable to autodetect phy\n");
+			ret = -EIO;
+			goto err_free;
+		}
+
+		printk(KERN_ERR PFX "detected phy at address 0x%02x\n", i);
+		priv->mii.phy_id = i;
+	}
+
+	/* initialize hardware */
+	if ((ret = enet_hw_init(dev)))
+		goto err_free;
+
+	/* initialize dma rings */
+	if ((ret = enet_dma_init(priv)))
+		goto err_free;
+
+	/* register interrupt handler */
+	ret = request_irq(ENET_IRQ, enet_isr, IRQF_SHARED|IRQF_DISABLED,
+			  "tango2_enet", dev);
+	if (ret)
+		goto err_free;
+	dev->irq = ENET_IRQ;
+
+    iopFillBufferFifo(priv);
+	printk(KERN_ERR "Clearing soft irq status %X\n",
+		(unsigned int) gbus_readl(REG_BASE_cpu_block + CPU_irq_softclr));
+	// It seems we get a soft irq on startup so clear them
+	gbus_writel(REG_BASE_cpu_block + CPU_irq_softclr, 0xFFFFFFFF);
+
+	ret = request_irq((IRQ_CONTROLLER_IRQ_BASE+0), enet_isr_iop, IRQF_SHARED|IRQF_DISABLED,
+			  "tango2_enet_iop", dev);
+	if (ret)
+		goto err_free;
+
+	/* install driver callbacks and register netdevice */
+	priv->dev = dev;
+	dev->open = enet_open;
+	dev->stop = enet_stop;
+	dev->hard_start_xmit = enet_xmit;
+	dev->get_stats = enet_get_stats;
+	dev->set_mac_address = enet_set_mac_address;
+	dev->set_multicast_list = enet_set_multicast_list;
+	dev->ethtool_ops = &enet_ethtool_ops;
+	dev->do_ioctl = enet_ioctl;
+	netif_napi_add(dev, &priv->napi, enet_poll, 16);
+
+	/* set default mac address */
+	tangox_ethernet_getmac(0, dev->dev_addr);
+	memcpy(&(sock.sa_data), dev->dev_addr, ETH_ALEN);
+	enet_set_mac_address(dev, &sock);
+
+	if ((ret = register_netdev(dev))) {
+		printk(KERN_ERR PFX "unable to register netdevice\n");
+		goto err_free;
+	}
+
+	printk(KERN_INFO PFX "mac address %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       dev->dev_addr[0], dev->dev_addr[1], dev->dev_addr[2],
+	       dev->dev_addr[3], dev->dev_addr[4], dev->dev_addr[5]);
+
+	gdev = dev;
+	return 0;
+
+err_free:
+	if (dev->irq)
+		free_irq(dev->irq, dev);
+	enet_dma_free(priv);
+	free_netdev(dev);
+	return ret;
+}
+
+
+/*
+ * entry point, checks if ethernet is  enabled on the board and if so,
+ * probes it
+ */
+extern int tangox_ethernet_enabled(int);
+
+int __init tango2_enet_init(void)
+{
+    // Start IOP
+    gbus_writel(0x1B003C,0);
+    gbus_writel(0xDFFFC,3);
+    gbus_writel(0xDFFFC,1);
+    gbus_writel(0xDFFFC,0);
+    while(gbus_readl(0x1B003C)!=0xCAFE);
+
+	if (!tangox_ethernet_enabled(0)) {
+		printk(KERN_NOTICE PFX "ethernet support is disabled\n");
+		return -ENODEV;
+	}
+
+	return enet_probe();
+}
+
+/*
+ * exit func, stops hardware and unregisters netdevice
+ */
+void __exit tango2_enet_exit(void)
+{
+	struct tango2_enet_priv *priv;
+	struct net_device *dev;
+
+	dev = gdev;
+
+	free_irq(dev->irq, dev);
+	unregister_netdev(dev);
+
+	priv = netdev_priv(dev);
+	enet_dma_free(priv);
+
+	free_netdev(dev);
+}
+
+
+module_init(tango2_enet_init);
+module_exit(tango2_enet_exit);
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet.h linux-2.6.30-test/drivers/net/tango2_enet.h
--- linux-2.6.30-ori/drivers/net/tango2_enet.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet.h	2009-06-23 16:08:21.000000000 -0400
@@ -0,0 +1,318 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __TANGO2_ENET_H
+#define __TANGO2_ENET_H
+
+#include <linux/types.h>
+#include <linux/skbuff.h>
+#include <linux/mii.h>
+#include <linux/timer.h>
+
+#include <asm/addrspace.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+#else
+#error "Unknown architecture"
+#endif
+
+#define ENET_IRQ	((IRQ_CONTROLLER_IRQ_BASE) + (LOG2_CPU_ETH_MAC_INT))
+
+/*
+ * number of rx/tx buffers available
+ * !!! MUST BE A POWER OF 2 !!!
+ */
+#define ENET_RX_DESC_COUNT	64
+#define ENET_TX_DESC_COUNT	64
+
+/*
+ * we enable tx  interrupt when there is equal to  this number of free
+ * tx desc. Keep it lower than ENET_TX_DESC_COUNT if you change it.
+ */
+#define ENET_TX_DESC_LOW	20
+
+/*
+ * sizeof rx buffers we give to the dma controller
+ */
+#define RX_BUF_SIZE		0x600
+// JFT the buffers are really 8k for iop
+#define RX_BUF_SIZE2	0x2000
+
+/*
+ * ipv4 stack  assumes received  ip header is  32 bits aligned,  so we
+ * keep 2 bytes to align ip header
+ */
+#define SKB_RESERVE_SIZE	2
+
+/*
+ * we reclaim  transmited using a  timer, we switch to  interrupt mode
+ * under high load. this is the timer frequency
+ */
+#define TX_RECLAIM_TIMER_FREQ	(HZ / 100)
+
+/*
+ * link status  is polled on a regular  basis by a timer,  this is its
+ * frequency
+ */
+#define LINK_CHECK_TIMER_FREQ	(HZ)
+
+
+/*
+ * address space conversion
+ */
+#define CACHE_TO_NONCACHE(x)	KSEG1ADDR(x)
+#define PHYSADDR(x)		tangox_dma_address(CPHYSADDR(x))
+
+
+/*
+ * Mac/DMA registers offset, refer to documentation
+ */
+#define ENET_HOST_BASE		REG_BASE_host_interface
+
+/* mac registers */
+#define ENET_MAC_BASE		(ENET_HOST_BASE + 0x6000)
+#define ENET_MAC_MACCR		(ENET_MAC_BASE + 0x0)
+#define MACCR_F			(1 << 20)
+#define MACCR_PM		(1 << 19)
+#define MACCR_PR		(1 << 18)
+#define MACCR_HP		(1 << 13)
+#define MACCR_ASTP		(1 << 8)
+#define MACCR_TE		(1 << 3)
+#define MACCR_RE		(1 << 2)
+#define ENET_MAC_MACAHR		(ENET_MAC_BASE + 0x4)
+#define ENET_MAC_MACALR		(ENET_MAC_BASE + 0x8)
+#define ENET_MAC_MAHR		(ENET_MAC_BASE + 0xc)
+#define ENET_MAC_MALR		(ENET_MAC_BASE + 0x10)
+#define ENET_MAC_MIIAR		(ENET_MAC_BASE + 0x14)
+#define MIIAR_ADDR(x)		((x) << 11)
+#define MIIAR_REG(x)		((x) << 6)
+#define MIIAR_WRITE		(1 << 1)
+#define MIIAR_BUSY		(1 << 0)
+#define ENET_MAC_MIIDR		(ENET_MAC_BASE + 0x18)
+#define ENET_MAC_FCR		(ENET_MAC_BASE + 0x1c)
+#define FCR_ENABLE		(1 << 1)
+
+/* dma registers */
+#define ENET_DMA_BASE		(ENET_HOST_BASE + 0x7000)
+#define ENET_DMA_BMR		(ENET_DMA_BASE + 0x00)
+#define BMR_PBL(x)		((x & 0x3f) << 8)
+#define BMR_SWR			(1 << 0)
+#define ENET_DMA_TPDR		(ENET_DMA_BASE + 0x04)
+#define ENET_DMA_RPDR		(ENET_DMA_BASE + 0x08)
+#define ENET_DMA_RBAR		(ENET_DMA_BASE + 0x0c)
+#define ENET_DMA_TBAR		(ENET_DMA_BASE + 0x10)
+#define ENET_DMA_SR		(ENET_DMA_BASE + 0x14)
+#define SR_EB(x)		(((x) >> 23) & 0x3)
+#define SR_TS(x)		(((x) >> 20) & 0x7)
+#define SR_RS(x)		(((x) >> 17) & 0x7)
+#define SR_NIS			(1 << 16)
+#define SR_AIS			(1 << 15)
+#define SR_ERI			(1 << 14)
+#define SR_FBE			(1 << 13)
+#define SR_ETI			(1 << 12)
+#define SR_RWT			(1 << 11)
+#define SR_RPS			(1 << 8)
+#define SR_RU			(1 << 7)
+#define SR_R			(1 << 6)
+#define SR_UNF			(1 << 5)
+#define SR_TU			(1 << 4)
+#define SR_TPS			(1 << 1)
+#define SR_T			(1 << 0)
+#define ENET_DMA_CR		(ENET_DMA_BASE + 0x18)
+#define CR_SF			(1 << 21)
+#define CR_ST			(1 << 13)
+#define CR_SR			(1 << 1)
+#define ENET_DMA_IER		(ENET_DMA_BASE + 0x1c)
+#define IER_NIS			(1 << 16)
+#define IER_AIS			(1 << 15)
+#define IER_ERE			(1 << 14)
+#define IER_FBE			(1 << 13)
+#define IER_ETE			(1 << 10)
+#define IER_RWT			(1 << 9)
+#define IER_RS			(1 << 8)
+#define IER_RU			(1 << 7)
+#define IER_R			(1 << 6)
+#define IER_UE			(1 << 5)
+#define IER_TBU			(1 << 2)
+#define IER_TS			(1 << 1)
+#define IER_T			(1 << 0)
+#define ENET_DMA_CHRBA		(ENET_DMA_BASE + 0x54)
+
+
+/*
+ * rx dma descriptor definition
+ */
+struct enet_rx_desc {
+	unsigned long rdes0;
+	unsigned long rdes1;
+	unsigned long rdes2;
+	unsigned long rdes3;
+};
+
+#define RDES0_OWN		(1 << 31)
+#define RDES0_FILTER_FAIL	(1 << 30)
+#define RDES0_FRAME_LEN(x)	(((x) & 0x1fff0000) >> 16)
+#define RDES0_ERR_SUM		(1 << 15)
+#define RDES0_TRUNC		(1 << 14)
+#define RDES0_FIRST		(1 << 9)
+#define RDES0_LAST		(1 << 8)
+#define RDES0_TOO_LONG		(1 << 7)
+#define RDES0_COLLISION		(1 << 6)
+#define RDES0_WATCHDOG_TMOUT	(1 << 4)
+#define RDES0_MII_ERROR		(1 << 3)
+#define RDES0_CRC		(1 << 1)
+
+#define RDES1_DISABLE_ISR	(1 << 31)
+#define RDES1_RER		(1 << 25)
+#define RDES1_RCH		(1 << 24)
+#define RDES1_RBS2(x)		((x) << 11)
+#define RDES1_RBS1(x)		(x)
+
+
+
+/*
+ * tx dma descriptor definition
+ */
+struct enet_tx_desc {
+	uint32_t tdes0;
+	uint32_t tdes1;
+	uint32_t tdes2;
+	uint32_t tdes3;
+};
+
+#define TDES0_OWN		(1 << 31)
+#define TDES0_ERR_SUM		(1 << 15)
+#define TDES0_CARRIER_LOST	(1 << 11)
+#define TDES0_NO_CARRIER	(1 << 10)
+#define TDES0_LATE_COLLISION	(1 << 9)
+#define TDES0_EXC_COLLISION	(1 << 8)
+#define TDES0_HEARTBEAT		(1 << 7)
+#define TDES0_EXC_DEFERAL	(1 << 2)
+#define TDES0_UNDERFLOW		(1 << 1)
+
+#define TDES1_ENABLE_ISR	(1 << 31)
+#define TDES1_LAST	 	(1 << 30)
+#define TDES1_FIRST		(1 << 29)
+#define TDES1_DISABLE_FCS	(1 << 26)
+#define TDES1_TER	 	(1 << 25)
+#define TDES1_TCH	 	(1 << 24)
+#define TDES1_DISABLE_PADDING	(1 << 23)
+#define TDES1_TBS2(x)		((x) << 11)
+#define TDES1_TBS1(x)		(x)
+
+
+/*
+ * our private context
+ */
+struct tango2_enet_priv {
+
+	/*
+	 * rx related
+	 */
+
+	/* pointer to rx descriptor array */
+	volatile struct enet_rx_desc	*rx_descs;
+	struct enet_rx_desc		*rx_descs_cached;
+
+	/* last rx descriptor processed */
+	unsigned int			last_rx_desc;
+
+	/* we keep a list of skb given */
+	struct sk_buff			*rx_skbs[ENET_RX_DESC_COUNT];
+
+	/* ethernet device stats */
+	struct net_device_stats		stats;
+
+
+
+
+	/*
+	 * tx related
+	 */
+
+	/* access  to  tx related  dma  stuffs  is  protected by  this
+	 * spinlock, this is because we  access them via a tasklet and
+	 * a timer */
+	spinlock_t			tx_lock;
+
+	/* pointer to tx descriptor array */
+	volatile struct enet_tx_desc	*tx_descs;
+	struct enet_tx_desc		*tx_descs_cached;
+
+	/* index of current dirty tx descriptor */
+	unsigned int			dirty_tx_desc;
+
+	/* index of next clean tx descriptor to use */
+	unsigned int			next_tx_desc;
+
+	/* count of free tx desc to avoid its computation */
+	unsigned int			free_tx_desc_count;
+
+	/* list of sent skb */
+	struct sk_buff			*tx_skbs[ENET_TX_DESC_COUNT];
+
+	/* tx  done operation is  done under  these tasklet  and timer
+	 * context */
+	struct tasklet_struct		tx_reclaim_tasklet;
+	struct timer_list		tx_reclaim_timer;
+
+
+	/*
+	 * misc
+	 */
+
+	/* spinlock used to protect interrupt enable register */
+	spinlock_t			ier_lock;
+
+	/* spinlock used to protect maccr register */
+	spinlock_t			maccr_lock;
+
+	/* our mii state */
+	struct mii_if_info		mii;
+
+	/* mii access is protected by following spinlock */
+	spinlock_t			mii_lock;
+
+	/* link status is checked periodically by this timer */
+	struct timer_list		link_check_timer;
+	struct napi_struct	napi;
+	struct net_device	*dev;
+	
+	struct sk_buff			*recycle_skbs[32];
+	int recyclecount;
+};
+
+/*
+ * helpers to access registers
+ */
+
+static inline unsigned long enet_readl(unsigned long addr)
+{
+	unsigned long tmp = 0;
+	unsigned long res = gbus_readl(addr);
+	extern int is_tango2_es6(void);
+	if (is_tango2_es6()) 
+		tmp = gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt);
+	return(res);
+}
+
+static inline void enet_writel(unsigned long addr, unsigned long data)
+{
+	gbus_writel(addr, data);
+
+	/* some write  read sequence seems  to freeze completly  if no
+	 * barrier is done between each access. To be safe, we do this
+	 * after all write access */
+	iob();
+}
+
+#endif /* __TANGO2_ENET_H */
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet.h~ linux-2.6.30-test/drivers/net/tango2_enet.h~
--- linux-2.6.30-ori/drivers/net/tango2_enet.h~	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet.h~	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,315 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+#ifndef __TANGO2_ENET_H
+#define __TANGO2_ENET_H
+
+#include <linux/types.h>
+#include <linux/skbuff.h>
+#include <linux/mii.h>
+#include <linux/timer.h>
+
+#include <asm/addrspace.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+#else
+#error "Unknown architecture"
+#endif
+
+#define ENET_IRQ	((IRQ_CONTROLLER_IRQ_BASE) + (LOG2_CPU_ETH_MAC_INT))
+
+/*
+ * number of rx/tx buffers available
+ * !!! MUST BE A POWER OF 2 !!!
+ */
+#define ENET_RX_DESC_COUNT	64
+#define ENET_TX_DESC_COUNT	64
+
+/*
+ * we enable tx  interrupt when there is equal to  this number of free
+ * tx desc. Keep it lower than ENET_TX_DESC_COUNT if you change it.
+ */
+#define ENET_TX_DESC_LOW	20
+
+/*
+ * sizeof rx buffers we give to the dma controller
+ */
+#define RX_BUF_SIZE		0x600
+// JFT the buffers are really 8k for iop
+#define RX_BUF_SIZE2	0x2000
+
+/*
+ * ipv4 stack  assumes received  ip header is  32 bits aligned,  so we
+ * keep 2 bytes to align ip header
+ */
+#define SKB_RESERVE_SIZE	2
+
+/*
+ * we reclaim  transmited using a  timer, we switch to  interrupt mode
+ * under high load. this is the timer frequency
+ */
+#define TX_RECLAIM_TIMER_FREQ	(HZ / 100)
+
+/*
+ * link status  is polled on a regular  basis by a timer,  this is its
+ * frequency
+ */
+#define LINK_CHECK_TIMER_FREQ	(HZ)
+
+
+/*
+ * address space conversion
+ */
+#define CACHE_TO_NONCACHE(x)	KSEG1ADDR(x)
+#define PHYSADDR(x)		tangox_dma_address(CPHYSADDR(x))
+
+
+/*
+ * Mac/DMA registers offset, refer to documentation
+ */
+#define ENET_HOST_BASE		REG_BASE_host_interface
+
+/* mac registers */
+#define ENET_MAC_BASE		(ENET_HOST_BASE + 0x6000)
+#define ENET_MAC_MACCR		(ENET_MAC_BASE + 0x0)
+#define MACCR_F			(1 << 20)
+#define MACCR_PM		(1 << 19)
+#define MACCR_PR		(1 << 18)
+#define MACCR_HP		(1 << 13)
+#define MACCR_ASTP		(1 << 8)
+#define MACCR_TE		(1 << 3)
+#define MACCR_RE		(1 << 2)
+#define ENET_MAC_MACAHR		(ENET_MAC_BASE + 0x4)
+#define ENET_MAC_MACALR		(ENET_MAC_BASE + 0x8)
+#define ENET_MAC_MAHR		(ENET_MAC_BASE + 0xc)
+#define ENET_MAC_MALR		(ENET_MAC_BASE + 0x10)
+#define ENET_MAC_MIIAR		(ENET_MAC_BASE + 0x14)
+#define MIIAR_ADDR(x)		((x) << 11)
+#define MIIAR_REG(x)		((x) << 6)
+#define MIIAR_WRITE		(1 << 1)
+#define MIIAR_BUSY		(1 << 0)
+#define ENET_MAC_MIIDR		(ENET_MAC_BASE + 0x18)
+#define ENET_MAC_FCR		(ENET_MAC_BASE + 0x1c)
+#define FCR_ENABLE		(1 << 1)
+
+/* dma registers */
+#define ENET_DMA_BASE		(ENET_HOST_BASE + 0x7000)
+#define ENET_DMA_BMR		(ENET_DMA_BASE + 0x00)
+#define BMR_PBL(x)		((x & 0x3f) << 8)
+#define BMR_SWR			(1 << 0)
+#define ENET_DMA_TPDR		(ENET_DMA_BASE + 0x04)
+#define ENET_DMA_RPDR		(ENET_DMA_BASE + 0x08)
+#define ENET_DMA_RBAR		(ENET_DMA_BASE + 0x0c)
+#define ENET_DMA_TBAR		(ENET_DMA_BASE + 0x10)
+#define ENET_DMA_SR		(ENET_DMA_BASE + 0x14)
+#define SR_EB(x)		(((x) >> 23) & 0x3)
+#define SR_TS(x)		(((x) >> 20) & 0x7)
+#define SR_RS(x)		(((x) >> 17) & 0x7)
+#define SR_NIS			(1 << 16)
+#define SR_AIS			(1 << 15)
+#define SR_ERI			(1 << 14)
+#define SR_FBE			(1 << 13)
+#define SR_ETI			(1 << 12)
+#define SR_RWT			(1 << 11)
+#define SR_RPS			(1 << 8)
+#define SR_RU			(1 << 7)
+#define SR_R			(1 << 6)
+#define SR_UNF			(1 << 5)
+#define SR_TU			(1 << 4)
+#define SR_TPS			(1 << 1)
+#define SR_T			(1 << 0)
+#define ENET_DMA_CR		(ENET_DMA_BASE + 0x18)
+#define CR_SF			(1 << 21)
+#define CR_ST			(1 << 13)
+#define CR_SR			(1 << 1)
+#define ENET_DMA_IER		(ENET_DMA_BASE + 0x1c)
+#define IER_NIS			(1 << 16)
+#define IER_AIS			(1 << 15)
+#define IER_ERE			(1 << 14)
+#define IER_FBE			(1 << 13)
+#define IER_ETE			(1 << 10)
+#define IER_RWT			(1 << 9)
+#define IER_RS			(1 << 8)
+#define IER_RU			(1 << 7)
+#define IER_R			(1 << 6)
+#define IER_UE			(1 << 5)
+#define IER_TBU			(1 << 2)
+#define IER_TS			(1 << 1)
+#define IER_T			(1 << 0)
+#define ENET_DMA_CHRBA		(ENET_DMA_BASE + 0x54)
+
+
+/*
+ * rx dma descriptor definition
+ */
+struct enet_rx_desc {
+	unsigned long rdes0;
+	unsigned long rdes1;
+	unsigned long rdes2;
+	unsigned long rdes3;
+};
+
+#define RDES0_OWN		(1 << 31)
+#define RDES0_FILTER_FAIL	(1 << 30)
+#define RDES0_FRAME_LEN(x)	(((x) & 0x1fff0000) >> 16)
+#define RDES0_ERR_SUM		(1 << 15)
+#define RDES0_TRUNC		(1 << 14)
+#define RDES0_FIRST		(1 << 9)
+#define RDES0_LAST		(1 << 8)
+#define RDES0_TOO_LONG		(1 << 7)
+#define RDES0_COLLISION		(1 << 6)
+#define RDES0_WATCHDOG_TMOUT	(1 << 4)
+#define RDES0_MII_ERROR		(1 << 3)
+#define RDES0_CRC		(1 << 1)
+
+#define RDES1_DISABLE_ISR	(1 << 31)
+#define RDES1_RER		(1 << 25)
+#define RDES1_RCH		(1 << 24)
+#define RDES1_RBS2(x)		((x) << 11)
+#define RDES1_RBS1(x)		(x)
+
+
+
+/*
+ * tx dma descriptor definition
+ */
+struct enet_tx_desc {
+	uint32_t tdes0;
+	uint32_t tdes1;
+	uint32_t tdes2;
+	uint32_t tdes3;
+};
+
+#define TDES0_OWN		(1 << 31)
+#define TDES0_ERR_SUM		(1 << 15)
+#define TDES0_CARRIER_LOST	(1 << 11)
+#define TDES0_NO_CARRIER	(1 << 10)
+#define TDES0_LATE_COLLISION	(1 << 9)
+#define TDES0_EXC_COLLISION	(1 << 8)
+#define TDES0_HEARTBEAT		(1 << 7)
+#define TDES0_EXC_DEFERAL	(1 << 2)
+#define TDES0_UNDERFLOW		(1 << 1)
+
+#define TDES1_ENABLE_ISR	(1 << 31)
+#define TDES1_LAST	 	(1 << 30)
+#define TDES1_FIRST		(1 << 29)
+#define TDES1_DISABLE_FCS	(1 << 26)
+#define TDES1_TER	 	(1 << 25)
+#define TDES1_TCH	 	(1 << 24)
+#define TDES1_DISABLE_PADDING	(1 << 23)
+#define TDES1_TBS2(x)		((x) << 11)
+#define TDES1_TBS1(x)		(x)
+
+
+/*
+ * our private context
+ */
+struct tango2_enet_priv {
+
+	/*
+	 * rx related
+	 */
+
+	/* pointer to rx descriptor array */
+	volatile struct enet_rx_desc	*rx_descs;
+	struct enet_rx_desc		*rx_descs_cached;
+
+	/* last rx descriptor processed */
+	unsigned int			last_rx_desc;
+
+	/* we keep a list of skb given */
+	struct sk_buff			*rx_skbs[ENET_RX_DESC_COUNT];
+
+	/* ethernet device stats */
+	struct net_device_stats		stats;
+
+
+
+
+	/*
+	 * tx related
+	 */
+
+	/* access  to  tx related  dma  stuffs  is  protected by  this
+	 * spinlock, this is because we  access them via a tasklet and
+	 * a timer */
+	spinlock_t			tx_lock;
+
+	/* pointer to tx descriptor array */
+	volatile struct enet_tx_desc	*tx_descs;
+	struct enet_tx_desc		*tx_descs_cached;
+
+	/* index of current dirty tx descriptor */
+	unsigned int			dirty_tx_desc;
+
+	/* index of next clean tx descriptor to use */
+	unsigned int			next_tx_desc;
+
+	/* count of free tx desc to avoid its computation */
+	unsigned int			free_tx_desc_count;
+
+	/* list of sent skb */
+	struct sk_buff			*tx_skbs[ENET_TX_DESC_COUNT];
+
+	/* tx  done operation is  done under  these tasklet  and timer
+	 * context */
+	struct tasklet_struct		tx_reclaim_tasklet;
+	struct timer_list		tx_reclaim_timer;
+
+
+	/*
+	 * misc
+	 */
+
+	/* spinlock used to protect interrupt enable register */
+	spinlock_t			ier_lock;
+
+	/* spinlock used to protect maccr register */
+	spinlock_t			maccr_lock;
+
+	/* our mii state */
+	struct mii_if_info		mii;
+
+	/* mii access is protected by following spinlock */
+	spinlock_t			mii_lock;
+
+	/* link status is checked periodically by this timer */
+	struct timer_list		link_check_timer;
+	struct napi_struct	napi;
+	struct net_device	*dev;
+};
+
+/*
+ * helpers to access registers
+ */
+
+static inline unsigned long enet_readl(unsigned long addr)
+{
+	unsigned long tmp = 0;
+	unsigned long res = gbus_readl(addr);
+	extern int is_tango2_es6(void);
+	if (is_tango2_es6()) 
+		tmp = gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt);
+	return(res);
+}
+
+static inline void enet_writel(unsigned long addr, unsigned long data)
+{
+	gbus_writel(addr, data);
+
+	/* some write  read sequence seems  to freeze completly  if no
+	 * barrier is done between each access. To be safe, we do this
+	 * after all write access */
+	iob();
+}
+
+#endif /* __TANGO2_ENET_H */
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet_old.c linux-2.6.30-test/drivers/net/tango2_enet_old.c
--- linux-2.6.30-ori/drivers/net/tango2_enet_old.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet_old.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,2294 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+/*
+ *  Embedded Ethernet driver for TANGO2 ES4 or above
+ */
+#ifdef BOOTLOADER
+#include "config.h"
+#include "version.h"
+#include "util.h"
+#include "net.h"
+#include "net_ipv4.h"
+#include "em86xxapi.h"
+#include "irqs.h"
+#include "errno.h"
+#include "uart.h"
+#include "memcfg.h"
+#else
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/spinlock.h>
+#include <linux/interrupt.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/module.h>
+//#include <linux/compatmac.h>
+#include <linux/mm.h>
+#include <linux/init.h>
+#include <linux/timer.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/crc32.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/memcfg.h>
+#else
+#include <asm/virtconvert.h>
+#include <asm/arch/irqs.h>
+#include <asm/arch/memcfg.h>
+#endif
+
+// Use kernel timer implementation for polling the link status
+// #define USE_KERNEL_TIMER
+
+#endif //BOOTLOADER
+
+#include "tango2_enet_old.h"
+
+#define DRV_NAME	"em86xx-eth"
+#define DRV_VERSION     "-0.0.0.0.1"
+
+/* Uncomment this for different messages */
+//#define ETH_DEBUG 
+#define ETH_ERRMSG 
+#define ETH_MSG
+//#define ETH_DBG_INOUT
+//#define DEBUG_RX_TX_STATE
+//#define DEBUG_MDIO
+
+#ifdef BOOTLOADER
+#define DRIVER "em86xx_eth"
+
+/* For static buffer allocation */
+// #define STATIC_BUF_ALLOC
+#define printk          uart_printf
+
+#define PAGE_SHIFT	12
+#define PAGE_SIZE	(1UL << PAGE_SHIFT)
+#define PAGE_MASK	(~(PAGE_SIZE-1))
+#define MAX_ORDER	10
+
+#endif /* BOOTLOADER */
+
+/* For software filtering*/
+//#define USE_SW_FILTERING
+#define USE_HW_FILTERING
+
+#ifdef ETH_DEBUG
+#define DBG_PRINT	printk
+#else
+static void inline DBG_PRINT(const char *x, ...) { ; }
+#endif /* ETH_DEBUG */
+
+#ifdef ETH_ERRMSG
+#define ERR_PRINT	printk
+#else
+static void inline ERR_PRINT(const char *x, ...) { ; }
+#endif /* ETH_ERRMSG */
+
+#ifdef ETH_MSG
+#define MSG_PRINT	printk
+#else
+static void inline MSG_PRINT(const char *x, ...) { ; }
+#endif /* ETH_ERRMSG */
+
+#ifdef ETH_DBG_INOUT
+#define DBG_PRINT_INOUT_FUNC(x) printk("%s: %s\n", __func__, x);
+#define MSG_PRINT	printk
+#else
+static void inline DBG_PRINT_INOUT_FUNC(const char *x, ...) { ; }
+#endif /* ETH_ERRMSG */
+
+/* Hack: this is the mac address by default */
+#define DEF_MAC_HI	0x00000011
+#ifdef BOOTLOADER
+#define DEF_MAC_LO	0xdeadbeef
+#else
+#define DEF_MAC_LO	0xaabbccdd
+#endif
+
+/* Default maximum link wait */
+#ifdef USE_KERNEL_TIMER
+#define DEF_LINK_LOOP		0x10000
+#else
+#define DEF_LINK_LOOP		0x100
+#endif
+#define DEF_MAX_LINK_LOOP	(DEF_LINK_LOOP * 16)
+
+#define ETH_IRQ_FLAGS   (DmaIntNormal     | DmaIntAbnormal    | DmaIntRxStopped         | \
+		         DmaIntRxNoBuffer | DmaIntRxCompleted | DmaIeTxUnderflow        | \
+                         DmaIeTxStopped   | DmaIeTxCompleted) 
+/*	(DmaIntNormal	  | DmaIntAbnormal    | DmaIntRxStopped		| \
+			 DmaIntRxNoBuffer | DmaIntRxCompleted | DmaIntTxCompleted)
+*/
+#define ETH_RXTX_FLAGS	(DmaTxStart       | DmaRxStart	      | DmaStoreAndForward)
+
+#ifndef USE_HW_FILTERING 
+#define ETH_MAC_FLAGS   (MacTxEnable      |  MacRxEnable       | MacPromiscuousModeOn	| \
+                        MacPadStripEnable |  MacHashFilterOn   | MacPerfectFilterOff 	| \
+                        MacRetryEnable    |  MacHeartBeatOff)
+#else 
+#define ETH_MAC_FLAGS	(MacTxEnable   	  | MacRxEnable        | MacPromiscuousModeOff  | \
+			MacPadStripEnable | MacHashFilterOn    | MacPerfectFilterOn     | \
+                        MacRetryEnable    | MacMulticastFilterOn | MacHeartBeatOff)
+#define DEFAULT_BROADCAST_ADDRESS { 0xFF,0xFF,0xFF,0xFF,0xFF,0xFF }
+static void em86xx_eth_set_multicast_list(struct net_device *dev);
+#endif /*USE_HW_FILTERING*/
+
+#define MD_FRAME_FLAGS  (DescRxLast        | DescRxFirst)
+#define TX_DESC1_FLAGS 	(DescTxLast        | DescTxFirst        | DescChain             | \
+			 DescTxIntEnable)
+#define RX_ERROR_FLAGS  (DescFilteringFail | DescError		| DescRxTruncated	| \
+			 DescLengthError   | DescRxDamaged 	| DescRxLongFrame	| \
+			 DescRxCollision   | DescRxMiiError	| DescRxCrc)
+#define TX_ERROR_FLAGS  (DescTxLostCarrier | DescTxNoCarrier	| DescTxLateCollision 	| \
+			 DescTxExcCollisions| DescTxHeartbeatFail| DescTxUnderflow)
+
+#if defined(CONFIG_TANGOX) 
+extern int tangox_ethernet_getmac(int idx, unsigned char *mac);
+#endif
+
+#define PHY_10BASET_HD_ANAR  	 (CSMACD | BASET10 | FLOWCONTROL | RF)
+#define PHY_10BASET_FD_ANAR 	 (CSMACD | BASET10 | BASET10FD | FLOWCONTROL | RF)
+#define PHY_100BASET_HD_ANAR	 (CSMACD | BASET10 | BASET10FD | BASET100 | FLOWCONTROL | RF)
+#define PHY_100BASET_FD_ANAR	 (CSMACD | BASET10 | BASET10FD | BASET100 | BASET100FD | FLOWCONTROL | RF)
+
+/* Number of descriptors and buffer size */
+#define MIN_NUM_RDESC	8
+#define MIN_NUM_TDESC	8
+#define NUM_RDESC 	64
+#define NUM_TDESC	64
+#define R_BUF_SIZE	0x700	/* needs to be < 2KB */
+#define T_BUF_SIZE	0x700	/* needs to be < 2KB */
+
+#if (R_BUF_SIZE < (1 << 14))
+/* For multi-descriptor frame support: only when receive buffer size < 16384 */
+#define MULTI_DESCS_FRAME_SUPPORT
+#endif
+
+/* Private data for this ethernet device */
+typedef struct {
+	struct net_device_stats stats; /* stats */
+	unsigned long last_rxidx;      /* last rx idx to descriptor */
+	unsigned long next_txidx;      /* next tx idx to descriptor */
+
+
+	spinlock_t lock;
+	/* MII transceiver section. */
+	struct mii_if_info mii_if;
+        /* Mode selection */
+        int autoneg_active;
+        int phy_loopback;	
+
+	/* Descriptors and buffers: notice the alignments */
+#ifdef STATIC_BUF_ALLOC 
+	struct em86xx_desc eth_rxdsc[NUM_RDESC] __attribute__ ((__aligned__(16)));
+	struct em86xx_desc eth_txdsc[NUM_TDESC] __attribute__ ((__aligned__(16)));
+	unsigned char eth_rxbuf[NUM_RDESC * R_BUF_SIZE] __attribute__ ((__aligned__(16)));
+	unsigned char eth_txbuf[NUM_TDESC * T_BUF_SIZE] __attribute__ ((__aligned__(16)));
+#else
+	struct em86xx_desc *eth_rxdsc;
+	struct em86xx_desc *eth_txdsc;
+	unsigned char *eth_rxbuf;
+	unsigned char *eth_txbuf;
+	unsigned long desc_page;
+	unsigned long rxbuf_pages;
+	unsigned long txbuf_pages;
+#ifndef BOOTLOADER
+	unsigned long rxbuf_order;
+	unsigned long txbuf_order;
+#endif
+#endif
+
+	/* Number of descriptors */
+	unsigned long num_rxdesc;
+	unsigned long num_txdesc;
+
+/* The real data pointer to be accessed in non-cache region */
+	volatile struct em86xx_desc *rxdsc;
+	volatile struct em86xx_desc *txdsc;
+	volatile unsigned char *rxbuf;
+	volatile unsigned char *txbuf;
+
+	/* Reference count for device */
+	int dev_count;
+
+	int reset_flag;
+	int phy_id;
+	int stop_thread;
+
+#ifndef BOOTLOADER
+#ifdef USE_KERNEL_TIMER 
+	struct timer_list eth_timer;
+#endif
+	struct sk_buff **rx_skb_list;
+	int need_restart_tx_queue; 
+#endif
+
+} EM86XX_ETH_PRIV;
+
+/* For storing MAC address */
+static unsigned long def_mac_hi = DEF_MAC_HI;
+static unsigned long def_mac_lo = DEF_MAC_LO;
+unsigned long num_rxdesc_param = NUM_RDESC;
+unsigned long num_txdesc_param = NUM_TDESC;
+
+/* Default PHY address: -1 for search */
+static int phy_address = -1;
+/* Default to 100BaseT/FD*/
+
+static int em86xx_eth_reset_desc(struct net_device *dev, int *reset);
+
+#ifdef BOOTLOADER
+static void em86xx_eth_intr_handler(int irq, void *dev_id);
+#else
+static struct net_device em86xx_eth_dev;
+static irqreturn_t em86xx_eth_intr_handler(int irq, void *dev_id, struct pt_regs *regs);
+static int netdev_get_settings(struct net_device *dev, struct ethtool_cmd *cmd);
+
+MODULE_AUTHOR("Craig Qu");
+MODULE_DESCRIPTION("Sigma Designs ethernet driver");
+MODULE_LICENSE("GPL");
+
+MODULE_PARM(def_mac_hi, "i");
+MODULE_PARM(def_mac_lo, "i");
+MODULE_PARM(phy_address, "i");
+MODULE_PARM_DESC(phy_address, "PHY address connecting to the MAC.");
+
+#ifndef STATIC_BUF_ALLOC 
+MODULE_PARM(num_rxdesc_param, "i");
+MODULE_PARM(num_txdesc_param, "i");
+#endif
+#endif /* BOOTLOADER */
+
+#define TX_ERRORS       12
+#define TX_ERRORS_START 1
+
+#define RX_ERRORS       31
+#define RX_ERRORS_START 1
+
+static const char *rx_error_msg[RX_ERRORS]= {
+	NULL,
+	"A CRC error is detected.",
+	NULL,
+	"A receive error was detected during frame reception.",
+	NULL,NULL,
+	"The frame has seen a collision after the collision window.",
+	"The frame is longer than 1518 bytes.",
+	NULL,NULL,NULL,
+	"The frame is prematurely terminated before the collision window.",	
+	"The actual length does not match with the Length Type field of the incoming frame.",
+	NULL,
+	"No more descriptors for receive frame.",
+	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
+	"The frame failed the address recognizing filtering.",
+};
+
+static const int rx_stat_offset[RX_ERRORS] = {
+	-1,
+	(int)&(((struct net_device_stats *)0)->rx_crc_errors),
+	-1,-1,-1,-1,
+	(int)&(((struct net_device_stats *)0)->collisions),
+	-1,-1,-1,-1,-1,
+	(int)&(((struct net_device_stats *)0)->rx_length_errors),
+	-1,
+	(int)&(((struct net_device_stats *)0)->rx_over_errors),
+	-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,
+}; 
+
+static const char *tx_error_msg[TX_ERRORS]= {
+	NULL,
+	"Late data arrival from the memory.",
+	"Excessive deferral.",
+	NULL,NULL,NULL,NULL,
+	"Heartbeat collision check failure.",
+	"Transmission aborted after 16 collisions.",
+	"Transmission aborted due to collision.",
+	"No carrier signal from the tranceiver.",
+	"Loss of carrier during transmission.",	
+};
+
+static const int tx_stat_offset[TX_ERRORS] = {
+	-1,
+	(int)&(((struct net_device_stats *)0)->tx_aborted_errors),
+	(int)&(((struct net_device_stats *)0)->tx_aborted_errors),
+	-1,-1,-1,-1,
+	(int)&(((struct net_device_stats *)0)->tx_heartbeat_errors),
+	(int)&(((struct net_device_stats *)0)->collisions),
+	(int)&(((struct net_device_stats *)0)->collisions),
+	(int)&(((struct net_device_stats *)0)->tx_carrier_errors),
+	(int)&(((struct net_device_stats *)0)->tx_carrier_errors),
+}; 
+
+/* Helper routine */
+static void wait_ms (int ms)
+{
+	DBG_PRINT_INOUT_FUNC("START");
+	if (!in_interrupt()) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(1 + ms * HZ / 1000);
+	} else {
+		mdelay(ms);
+	}
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+
+/* MDIO access routines - used by MII standard Linux API */
+static int mdio_read (struct net_device *dev, int phy_addr, int reg_num)
+{
+	u32 addr;
+	u16 ret;
+	int count;
+	
+#ifdef DEBUG_MDIO
+	DBG_PRINT("%s: start addr %d reg %d\n", __func__, phy_addr, reg_num);
+#endif
+    /* Wait while the PHY is busy */
+	for (count = 1000; count != 0; count--) {
+		if (!(em86xx_read_reg(EM86XX_MIIAR_REG) & MiiBusy))
+			break;
+	}
+	/* Set PHY & register to read */
+	addr = ((phy_addr & 0x1F) << 11) | ((reg_num & 0x1F) << 6);
+	em86xx_write_reg(EM86XX_MIIAR_REG, addr);
+	/* Work-around Sigma-Designs MAC bug */
+	udelay(40);
+	/* Wait while PHY is busy */
+	for (count = 1000; count != 0; count--) {
+		if (!(em86xx_read_reg(EM86XX_MIIAR_REG) & MiiBusy))
+			break;
+	}
+	ret = em86xx_read_reg(EM86XX_MIIDR_REG) & 0xFFFF;
+#ifdef DEBUG_MDIO
+	DBG_PRINT(" => %04x\n", ret);
+#endif
+	
+	return ret;
+}
+
+static void mdio_write (struct net_device *dev,
+                        int phy_addr, int reg_num, int value)
+{
+	u32 addr;
+	int count;
+	
+#ifdef DEBUG_MDIO
+	DBG_PRINT("%s: start addr %d reg %d val %04x\n",
+	       __func__, phy_addr, reg_num, value);
+#endif
+	/* Wait while the PHY is busy */
+	for (count = 1000; count != 0; count--) {
+		if (!(em86xx_read_reg(EM86XX_MIIAR_REG) & MiiBusy))
+			break;
+	}
+	/* Set PHY & register to write */
+	addr = ((phy_addr & 0x1F) << 11) | ((reg_num & 0x1F) << 6) | (1 << 1);
+	em86xx_write_reg(EM86XX_MIIDR_REG, value);
+	em86xx_write_reg(EM86XX_MIIAR_REG, addr);
+
+	while (em86xx_read_reg(EM86XX_MIIAR_REG) & MiiBusy);
+
+}
+
+static int dump_ethtool_cmd(struct ethtool_cmd *ep)
+{
+
+        printk("       Speed: ");
+        switch (ep->speed) {
+        case SPEED_10:
+                printk("10Mb/s\n");
+                break;
+        case SPEED_100:
+                printk("100Mb/s\n");
+                break;
+        case SPEED_1000:
+                printk("1000Mb/s\n");
+                break;
+        default:
+                printk("Unknown! (%i)\n", ep->speed);
+                break;
+        };
+
+        printk("       Duplex: ");
+        switch (ep->duplex) {
+        case DUPLEX_HALF:
+                printk("Half\n");
+                break;
+        case DUPLEX_FULL:
+                printk("Full\n");
+                break;
+        default:
+                printk("Unknown! (%i)\n", ep->duplex);
+                break;
+        };
+
+        printk("       Auto-negotiation: %s\n",
+                (ep->autoneg == AUTONEG_DISABLE) ?
+                "off" : "on");
+        return 0;
+}
+
+
+
+/* Routine to configure the PHY */
+void setup_phy (struct mii_if_info *mii_if)
+{
+	struct net_device *dev = mii_if->dev;
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	u16 phy_cntl, phy_caps, ad_caps, status;
+	int timeout;
+	struct ethtool_cmd cmd = { ETHTOOL_GSET };
+	
+	DBG_PRINT_INOUT_FUNC("START");
+	phy_cntl = mdio_read(dev, mii_if->phy_id, MII_BMCR);
+
+	/* Avoid multiple instances */
+	if (private->autoneg_active || !(phy_cntl & BMCR_ANENABLE) )
+		return;
+
+	private->autoneg_active = 1;
+	/* Reset the PHY */
+	phy_cntl = BMCR_RESET;
+	if (private->phy_loopback)
+		phy_cntl |= BMCR_LOOPBACK;
+	DBG_PRINT("%s: Reset PHY\n", __func__);
+	mdio_write(dev, mii_if->phy_id, MII_BMCR, phy_cntl);
+	/* Wait up to 5 seconds for the reset to complete */
+	for (timeout = 10; timeout != 0; timeout--) {
+		phy_cntl = mdio_read(dev, mii_if->phy_id, MII_BMCR);
+		if (!(phy_cntl & BMCR_RESET))
+			break;
+		/* Wait 500 milliseconds */
+		wait_ms(500);
+	}
+	if (timeout == 0) {
+		DBG_PRINT("PHY reset timeout\n");
+		goto out;
+	}
+	/* Read phy & advertising capabilities */
+	DBG_PRINT("%s: set up caps\n", __func__);
+	phy_caps = mdio_read(dev, mii_if->phy_id, MII_BMSR);
+	ad_caps = ADVERTISE_CSMA;
+	if (phy_caps & BMSR_100BASE4)
+		ad_caps |= ADVERTISE_100BASE4;
+	if (phy_caps & BMSR_100FULL)
+		ad_caps |= ADVERTISE_100FULL;
+	if (phy_caps & BMSR_100HALF)
+		ad_caps |= ADVERTISE_100HALF;
+	if (phy_caps & BMSR_10FULL)
+		ad_caps |= ADVERTISE_10FULL;
+	if (phy_caps & BMSR_10HALF)
+		ad_caps |= ADVERTISE_10HALF;
+
+	/* Update auto-negociation advertisement register */
+	mdio_write(dev, mii_if->phy_id, MII_ADVERTISE, ad_caps);
+	/* Read the register back. Some (buggy) PHY won't negociate properly
+	 * if this is not done.
+	 */
+	status = mdio_read(dev, mii_if->phy_id, MII_ADVERTISE);
+	timeout = 30;
+	/* Restart auto-negociation with our new advertisement capabilities */
+	DBG_PRINT("%s: start autonegociation\n", __func__);
+ restart_autoneg:
+	phy_cntl = BMCR_ANRESTART | BMCR_ANENABLE;
+	if (private->phy_loopback)
+		phy_cntl |= BMCR_LOOPBACK;
+	mdio_write(dev, mii_if->phy_id, MII_BMCR, phy_cntl);
+	/* Wait for the auto-negociation to complete.
+	 * This can take up to 3 seconds.
+	 */
+	for (; timeout != 0; timeout--) {
+		status = mdio_read(dev, mii_if->phy_id, MII_BMSR);
+		if (status & BMSR_ANEGCOMPLETE)
+			break;
+		if (status & BMSR_RFAULT) {
+            /* In case of remote fault, restart negociation */
+			DBG_PRINT("%s: restart autonegociation\n", __func__);
+			goto restart_autoneg;
+		}
+		wait_ms(100);
+	}
+	status = mdio_read(dev, mii_if->phy_id, MII_BMSR);
+	if (!(status & BMSR_ANEGCOMPLETE))
+		DBG_PRINT("Auto-negociation timeout\n");
+	else if (status & BMSR_RFAULT)
+		DBG_PRINT("Auto-negociation remote fault\n");
+	else
+		DBG_PRINT("Auto-negociation done\n");
+
+	netdev_get_settings(dev, &cmd);
+	dump_ethtool_cmd(&cmd);
+ out:
+	private->autoneg_active = 0;
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+/* PHY detection */
+/* XXX: to be moved into mii.c */
+int phy_detect (struct net_device *dev, struct mii_if_info *mii_if)
+{
+	int phy_n;
+	int mii_status, phy_id1, phy_id2;
+	
+	DBG_PRINT_INOUT_FUNC("START");
+	mii_if->dev = dev;
+	mii_if->mdio_read = mdio_read;
+	mii_if->mdio_write = mdio_write;
+	mii_if->phy_id_mask = 0x1f;
+	mii_if->reg_num_mask = 0x1f;
+	mii_if->phy_id = -1; /* No PHY found */
+	for (phy_n = 0; phy_n < 32; phy_n++) {
+		DBG_PRINT("%s: check PHY %d\n", __func__, phy_n);
+		mii_status = mdio_read(dev, phy_n, MII_BMSR);
+		phy_id1 = mdio_read(dev, phy_n, MII_PHYSID1);
+		phy_id2 = mdio_read(dev, phy_n, MII_PHYSID2);
+		/* PHY_ID1 is zero in some realtek PHYs */
+		if (/*phy_id1 > 0 &&*/ phy_id1 < 0xFFFF && phy_id1 != 0x8000 &&
+		    phy_id2 > 0 && phy_id2 < 0xFFFF && phy_id2 != 0x8000 &&
+		    mii_status != 0xffff && mii_status != 0x0000) {
+			mii_if->advertising = mdio_read(dev, phy_n, 4);
+			mii_if->phy_id = phy_n;
+			DBG_PRINT(KERN_INFO "%s: MII PHY found at address %d, status "
+			       "0x%4.4x advertising %4.4x Link %4.4x.\n",
+			       dev->name, phy_n, mii_status, mii_if->advertising,
+			       mdio_read(dev, phy_n, 5));
+			/* set IFF_RUNNING */
+			if (mii_status & BMSR_LSTATUS) {
+				DBG_PRINT("%s: netif_carrier_on\n", __func__);
+				netif_carrier_on(dev);
+			}
+			else {
+				DBG_PRINT("%s: netif_carrier_off\n", __func__);
+				netif_carrier_off(dev);
+			}
+			break;
+		}
+	}
+	if (phy_n == 32) {
+		DBG_PRINT("failed to detect PHY\n");
+		return -1;
+	}
+	
+	DBG_PRINT_INOUT_FUNC("END");
+	return phy_n;
+}
+
+/* Getting MAC address from local RAM */
+static int get_mac_address(unsigned long *mac_lo, unsigned long *mac_hi)
+{
+	unsigned long cksum, lo, hi;
+	const unsigned char marker = 'M';
+	
+	DBG_PRINT_INOUT_FUNC("START");
+	lo = em86xx_read_reg(REG_BASE_cpu_block + LR_ETH_MAC_LO);
+	hi = em86xx_read_reg(REG_BASE_cpu_block + LR_ETH_MAC_HI);
+
+	if (((unsigned char)((hi >> 16) & 0xff)) != marker)
+		return(1); /* Not valid MAC */
+	cksum = ((lo & 0xff) + ((lo >> 8) & 0xff) + ((lo >> 16) & 0xff) + ((lo >> 24) & 0xff) + 
+		 (hi & 0xff) + ((hi >> 8) & 0xff)) & 0xff;
+	if (((hi >> 24) & 0xff) != cksum)
+		return(1); /* Not valid MAC */
+	*mac_lo = lo;
+	*mac_hi = hi & 0xffff;
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return(0); /* Got valid MAC */
+}
+
+/* Get the device mac address */
+static int em86xx_get_macaddr(unsigned char *addr)
+{
+	DBG_PRINT_INOUT_FUNC("START");
+#if defined(CONFIG_TANGOX)
+	unsigned long hi, lo;
+	if (get_mac_address(&lo, &hi) == 0) {
+		*addr++ = (hi & 0x0000ff00) >> 8;
+		*addr++ = (hi & 0x000000ff);
+		*addr++ = (lo & 0xff000000) >> 24;
+		*addr++ = (lo & 0x00ff0000) >> 16;
+		*addr++ = (lo & 0x0000ff00) >> 8;
+		*addr   = (lo & 0x000000ff);
+	} else if (tangox_ethernet_getmac(0, addr) == 0) {
+		*addr++ = (def_mac_hi & 0x0000ff00) >> 8;
+		*addr++ = (def_mac_hi & 0x000000ff);
+		*addr++ = (def_mac_lo & 0xff000000) >> 24;
+		*addr++ = (def_mac_lo & 0x00ff0000) >> 16;
+		*addr++ = (def_mac_lo & 0x0000ff00) >> 8;
+		*addr   = (def_mac_lo & 0x000000ff);
+	}
+#else
+#ifdef BOOTLOADER
+	if(	mac_read(addr) == -1) {
+		*addr++ = (def_mac_hi & 0x0000ff00) >> 8;
+		*addr++ = (def_mac_hi & 0x000000ff);
+		*addr++ = (def_mac_lo & 0xff000000) >> 24;
+		*addr++ = (def_mac_lo & 0x00ff0000) >> 16;
+		*addr++ = (def_mac_lo & 0x0000ff00) >> 8;
+		*addr   = (def_mac_lo & 0x000000ff);
+	}
+#else
+#ifdef CONFIG_SD_BOOTLOADER_INTEGRATION
+	{
+		unsigned long lo, hi;
+
+		if (get_mac_address(&lo, &hi) == 0) {
+			def_mac_hi = hi;
+			def_mac_lo = lo;
+		}
+	}
+#endif
+	*addr++ = (def_mac_hi & 0x0000ff00) >> 8;
+	*addr++ = (def_mac_hi & 0x000000ff);
+	*addr++ = (def_mac_lo & 0xff000000) >> 24;
+	*addr++ = (def_mac_lo & 0x00ff0000) >> 16;
+	*addr++ = (def_mac_lo & 0x0000ff00) >> 8;
+	*addr   = (def_mac_lo & 0x000000ff);
+#endif /* BOOTLOADER */	
+#endif /* CONFIG_TANGOX */
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+/* Setting up MAC address of ethernet PHY and device data */
+static int em86xx_set_mac(struct net_device *dev)
+{
+	unsigned long hi_mac, low_mac;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	/* Set up device mac address */
+	if (em86xx_get_macaddr(dev->dev_addr))
+		return(-EIO);
+
+	if (!is_valid_ether_addr(dev->dev_addr))
+		MSG_PRINT("%s: bogus mac address detected.\n", dev->name);
+
+	hi_mac =  (dev->dev_addr[5] << 8)  | dev->dev_addr[4];
+	low_mac = (dev->dev_addr[3] << 24) | (dev->dev_addr[2] << 16) | 
+		  (dev->dev_addr[1] << 8)  | dev->dev_addr[0];
+
+	/* Set up MAC address */
+	em86xx_write_reg(EM86XX_MACAHR_REG, hi_mac);
+	em86xx_write_reg(EM86XX_MACALR_REG, low_mac);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+#ifndef BOOTLOADER
+/* Setting customized mac address */
+static int em86xx_eth_set_macaddr(struct net_device *dev, void *addr)
+{
+	unsigned long hi_mac, low_mac;
+	struct sockaddr *sock = addr;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	/* Check if given address is valid ethernet MAC address */
+	if (!is_valid_ether_addr(sock->sa_data))
+		return(-EIO);
+
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+
+	netif_carrier_off(dev); /* Shutdown interface */
+
+	/* Save the customize mac address */
+	memcpy(dev->dev_addr, sock->sa_data, ETH_ALEN);
+	hi_mac  = (dev->dev_addr[5] << 8) | dev->dev_addr[4];
+	low_mac = (dev->dev_addr[3] << 24)| (dev->dev_addr[2] << 16) | 
+		  (dev->dev_addr[1] << 8) | dev->dev_addr[0];
+
+	def_mac_hi = hi_mac;
+	def_mac_lo = low_mac;
+
+	/* Set up MAC address */
+	em86xx_write_reg(EM86XX_MACAHR_REG, hi_mac );
+	em86xx_write_reg(EM86XX_MACALR_REG, low_mac );
+
+	netif_carrier_on(dev);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+#endif /* BOOTLOADER */
+
+/* RTL8201BL is a single-port PHY with an MII/SNI. The MAC layer device can 
+   control a maximum of 31 devices, configured with different PHY addresses
+   (00001b to 11111b). We need to find out which PHY address is using in 
+   order to obtain the mode status after the auto-neotiation is completed.
+
+   There is a module parameter phy_address to be used to override this probe,
+   to set PHY address if one already knew it.
+*/
+static int em86xx_phy_probe(void)
+{
+
+        int phy_addr 	= 0;
+	u16 phy_id 	= 0;
+        u16 phy_status 	= 0;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	if (phy_address < 0) {
+		/* search for total of 31 possible mii phy addresses */
+		for (phy_addr = 1; phy_addr < 32; phy_addr++) {
+			phy_status = em86xx_mii_read(phy_addr,GEN_sts);
+
+			if (phy_status != 0xffff && phy_status != 0x0000)
+				break;
+		}
+	} else {
+		phy_addr = phy_address;
+		phy_status = em86xx_mii_read(phy_addr,GEN_sts);
+	}
+	phy_id =  em86xx_mii_read(phy_addr,GEN_id_lo);
+	MSG_PRINT("Found PHY %04x at Addr = %d Status=0x%x\n", phy_id, phy_addr, phy_status);
+ 
+	DBG_PRINT_INOUT_FUNC("END");
+	return phy_addr;
+}
+
+/* Initialize the ethernet link status, mac, and flow control */
+static int em86xx_link_config(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	struct mii_if_info *mii = &(private->mii_if);
+	unsigned long word = 0;
+
+	DBG_PRINT_INOUT_FUNC("START");
+
+	// Turn off IRQ and stop receive/transmit 
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+
+	setup_phy(mii);
+
+	/* set the descriptor base address */
+	em86xx_write_reg(EM86XX_RLBAR_REG, PHYSADDR((u32)private->rxdsc) );
+	em86xx_write_reg(EM86XX_TLBAR_REG, PHYSADDR((u32)private->txdsc));
+
+	/* set bus mode: burst length = 32 | BLE | ~DBO */
+	word = (32 << 8) /*| (1 << 7) | (1 << 20)*/ ;
+	em86xx_write_reg(EM86XX_BMR_REG, word); 
+
+	/* enable MAC flow ctrl */
+	word = (1 << 1);
+	em86xx_write_reg(EM86XX_FCR_REG, word); 
+
+	/* configure MAC ctrller */
+	word = ETH_MAC_FLAGS;
+	word |= MacLoopbackOff; 
+        if (mii->full_duplex)
+                word |= MacFullDuplex;
+        else
+                word &= ~MacFullDuplex;
+	em86xx_write_reg(EM86XX_MACCR_REG, word);
+
+	/* Turn on the IRQ and start receive/transmit */
+	em86xx_write_reg(EM86XX_IER_REG, ETH_IRQ_FLAGS);
+	em86xx_write_reg(EM86XX_CR_REG, ETH_RXTX_FLAGS); 
+
+	netif_carrier_on(dev);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+/* Ethernet hardware initialization */
+static int em86xx_eth_hw_init(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	int rc;
+
+	DBG_PRINT_INOUT_FUNC("START");
+
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+
+	/* reset dma engine*/
+	em86xx_write_reg(EM86XX_BMR_REG, DmaResetOn);
+	em86xx_write_reg(EM86XX_BMR_REG, DmaResetOff);
+
+	if (em86xx_set_mac(dev))
+		return(-EIO);
+
+	/* stop MAC engine */
+	em86xx_write_reg(EM86XX_CR_REG, 0x0); 
+#ifndef USE_HW_FILTERING
+	/* set up multicast hash table to MCHTHR MCHTLR */
+	/* set multicast hash table to accept all */
+	em86xx_write_reg(EM86XX_MCHTHR_REG, 0xffffffff); 
+	em86xx_write_reg(EM86XX_MCHTLR_REG, 0xffffffff); 
+#else
+	/* clear hash table */
+        em86xx_write_reg( EM86XX_MCHTHR_REG, 0 );
+        em86xx_write_reg( EM86XX_MCHTLR_REG, 0 );
+
+	em86xx_eth_set_multicast_list(dev);
+#endif
+
+	/* resetting descriptors */
+#ifdef BOOTLOADER
+        if (em86xx_eth_reset_desc(dev, &private->reset_flag))
+#else
+        if (em86xx_eth_reset_desc(&em86xx_eth_dev, &private->reset_flag))
+#endif
+		return(-EIO);
+
+	/* configure PHY and speed */
+	rc = em86xx_link_config(dev);
+	DBG_PRINT_INOUT_FUNC("END");
+	return rc;
+}
+
+#ifndef BOOTLOADER
+/* Monitor the status of link, re-do link initialization if necessary. */
+#ifdef USE_KERNEL_TIMER
+static void em86xx_eth_link_monitor(unsigned long dummy)
+#else
+static int em86xx_eth_link_monitor(void *dummy)
+#endif
+{
+	struct net_device *dev = (struct net_device *)dummy;
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+        unsigned long flags;
+        int link;
+	int res;
+
+	DBG_PRINT_INOUT_FUNC("START");
+
+#ifndef USE_KERNEL_TIMER
+	daemonize("em86xx_eth");
+
+	while (private->stop_thread == 0) {
+#endif
+		spin_lock_irqsave(&private->lock, flags);
+		link = mii_link_ok(&private->mii_if);
+		spin_unlock_irqrestore(&private->lock, flags);
+		
+		if (netif_carrier_ok(dev) && !link) {			
+			MSG_PRINT("%s: detected link DOWN.\n", dev->name);
+			netif_carrier_off(dev);
+		}
+		else if (!netif_carrier_ok(dev) && link) {
+			MSG_PRINT("%s: detected link UP.\n", dev->name);
+			res = em86xx_eth_hw_init(dev);
+			netif_carrier_on(dev);
+		}
+
+#ifndef USE_KERNEL_TIMER
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(HZ);
+	}
+#endif
+
+#ifdef USE_KERNEL_TIMER
+	/* Schedule for the next time */
+	mod_timer(&private->eth_timer, jiffies + HZ); 
+	DBG_PRINT_INOUT_FUNC("END (with timer)");
+#else
+	DBG_PRINT_INOUT_FUNC("END (IRQ)");
+	return(0);
+#endif
+}
+#endif
+
+/* Setting rx/tx descriptors */
+static void em86xx_eth_setup_desc(struct net_device *dev)
+{
+	register int i;
+	struct em86xx_desc *desc_ptr = NULL;
+	unsigned long base_addr = 0;
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	/* Setup rx descriptor */
+	desc_ptr = (struct em86xx_desc *)(private->rxdsc);
+	for (i = 0; i < (private->num_rxdesc - 1); i++, desc_ptr++) {
+		desc_ptr->desc3 = PHYSADDR((unsigned long)(desc_ptr + 1));
+		desc_ptr->desc1 = (DescChain | R_BUF_SIZE);
+  		desc_ptr->desc0 = DescOwnByDma; 
+	}
+	desc_ptr->desc3 = PHYSADDR((unsigned long)(private->rxdsc));
+	desc_ptr->desc1 = (DescChain | DescEndOfRing | R_BUF_SIZE);
+	desc_ptr->desc0 = DescOwnByDma; 
+
+	/* Setup tx descriptor */
+	desc_ptr = (struct em86xx_desc *)(private->txdsc); 
+	for (i =0;  i < (private->num_txdesc - 1); i++, desc_ptr++) {
+		desc_ptr->desc3 = PHYSADDR((unsigned long)(desc_ptr + 1));
+		desc_ptr->desc1 = (TX_DESC1_FLAGS | T_BUF_SIZE);
+  		desc_ptr->desc0 = DescOwnByCPU;
+	}
+	desc_ptr->desc3 = PHYSADDR((unsigned long)(private->txdsc));
+	desc_ptr->desc1 = (TX_DESC1_FLAGS | DescEndOfRing | T_BUF_SIZE);
+	desc_ptr->desc0 = DescOwnByCPU;
+
+	/* Point rx descriptor to buffer */
+	desc_ptr = (struct em86xx_desc *)(private->rxdsc);
+#ifdef BOOTLOADER 
+      	base_addr = PHYSADDR((unsigned long)(private->rxbuf)); 
+	for (i = 0; i < private->num_rxdesc; i++, desc_ptr++, base_addr += R_BUF_SIZE) 
+		desc_ptr->desc2 = base_addr;
+#else
+        for (i = 0; i < private->num_rxdesc; i++, desc_ptr++){
+                private->rx_skb_list[i] = dev_alloc_skb(R_BUF_SIZE);
+                skb_reserve(private->rx_skb_list[i], 2);
+                desc_ptr->desc2 = PHYSADDR((u32)private->rx_skb_list[i]->data);
+#ifdef CONFIG_NONCOHERENT_IO
+		dma_cache_inv((u32)private->rx_skb_list[i]->data, R_BUF_SIZE);
+#endif
+        }
+#endif
+
+	/* Point tx descriptor to buffer */
+	desc_ptr = (struct em86xx_desc *)(private->txdsc);
+        base_addr = PHYSADDR((unsigned long)(private->txbuf));
+	for (i = 0; i < private->num_txdesc; i++, desc_ptr++, base_addr += T_BUF_SIZE) 
+		desc_ptr->desc2 = base_addr;
+
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+/* Starting up the ethernet device */
+static int em86xx_eth_open(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	DBG_PRINT_INOUT_FUNC("END");
+	if ((dev == NULL) || (private == NULL))
+		return(-EIO);
+	DBG_PRINT("%s: starting interface.\n", dev->name);
+
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+	/*Get phy address*/
+	private->phy_id = em86xx_phy_probe();
+	em86xx_eth_hw_init(dev);
+
+#ifdef BOOTLOADER
+        dev->state = NETDEV_UP;
+#else
+#ifdef USE_KERNEL_TIMER 
+	/* Schedule timer for monitoring link status */
+	init_timer(&private->eth_timer);
+	private->eth_timer.function = em86xx_eth_link_monitor;
+	private->eth_timer.data = (unsigned long)dev;
+	mod_timer(&private->eth_timer, jiffies + HZ/10);
+#else
+	private->stop_thread = 0;
+	if (kernel_thread(em86xx_eth_link_monitor, dev, CLONE_FS|CLONE_FILES) < 0)
+		return(-ENODEV);
+#endif
+	netif_start_queue(dev);
+#endif /*BOOTLOADER*/
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+/* Stopping the ethernet device */
+static int em86xx_eth_close(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	if (dev == NULL) {
+		DBG_PRINT_INOUT_FUNC("END");
+  		return(-EIO);
+	}
+
+	private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+
+#ifdef BOOTLOADER
+	dev->state = NETDEV_DOWN;
+#else
+
+#ifdef USE_KERNEL_TIMER
+	/* Kill timer */
+	del_timer_sync(&private->eth_timer);
+#else
+	private->stop_thread = 1;
+	schedule_timeout(5*HZ); /* Wait for kernel thread to terminate */
+#endif
+
+	/* Stop the transmit queue */
+	netif_stop_queue(dev);
+	netif_carrier_off(dev);
+
+#endif /*BOOTLOADER*/
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+#ifndef BOOTLOADER
+#ifdef USE_HW_FILTERING
+/* Setup multicast list */
+static void em86xx_eth_set_multicast_list(struct net_device *dev)
+{
+	/* Multicast hash filter */
+        u32 mc_filter[2] = { 0, 0 };
+        int i, rx_mode;
+ 	u8  broadcast_addr[6]  = DEFAULT_BROADCAST_ADDRESS;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	rx_mode =  em86xx_read_reg(EM86XX_MACCR_REG);  
+        DBG_PRINT(KERN_DEBUG"%s:   set_rx_mode(0x%x) done -- rx_mode=0x%x.\n",
+                           dev->name, dev->flags, rx_mode);
+
+        if (dev->flags & IFF_PROMISC) {
+                MSG_PRINT("%s: Promiscuous mode enabled.\n", dev->name);
+                rx_mode |= MacPromiscuousModeOn;
+                mc_filter[1] = mc_filter[0] = 0xffffffff;
+        } else {
+                struct dev_mc_list *mclist;
+		int n;
+                rx_mode &=  ~MacPromiscuousModeOn;
+                for (i = 0, mclist = dev->mc_list; mclist && i < dev->mc_count;
+                         i++, mclist = mclist->next){
+			n = ether_crc(ETH_ALEN, mclist->dmi_addr) >> 26;
+			mc_filter[n >> 5] |= 1 << (n & 31);
+		}
+		n = ether_crc(ETH_ALEN, broadcast_addr) >> 26;
+		mc_filter[n >> 5] |= 1 << (n & 31);
+        }
+	em86xx_write_reg(EM86XX_MACCR_REG, rx_mode );
+        em86xx_write_reg(EM86XX_MCHTLR_REG, mc_filter[0]);
+        em86xx_write_reg(EM86XX_MCHTHR_REG, mc_filter[1]);
+
+	DBG_PRINT_INOUT_FUNC("END");
+        return;
+}
+#endif
+#endif
+
+/* Transmit a packet */
+#ifdef BOOTLOADER
+static int em86xx_eth_tx(struct sk_buff *skb, struct net_device *dev, int async)
+#else
+static int em86xx_eth_tx(struct sk_buff *skb, struct net_device *dev)
+#endif
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	volatile struct em86xx_desc *desc_ptr;
+	struct net_device_stats *stats;
+	unsigned long length, err;
+	int ret = 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&private->lock, flags);
+
+	if ((length = ((ETH_ZLEN < skb->len) ? skb->len : ETH_ZLEN)) > T_BUF_SIZE) {
+      		DBG_PRINT("em86xx_eth_tx: too big\n");
+		ret = -ENOMEM; 
+		goto out_unlock;
+	}
+
+	stats = &(private->stats);
+
+	/* Send packet to device */
+	desc_ptr = (volatile struct em86xx_desc *)(&private->txdsc[private->next_txidx]);
+	if ((desc_ptr->desc0 & DescOwnByDma) != 0) {
+		stats->tx_dropped++;
+		
+		/* cannot queue anymore */
+		netif_stop_queue(dev);
+		private->need_restart_tx_queue = 1;
+
+        	ERR_PRINT("%s desc_ptr=0x%x: tx error (descriptor not owned by CPU).\n",
+				 dev->name, (u32)desc_ptr);
+		ret = -EIO;
+		goto out_unlock;
+	} 
+
+	/* Check if previous transmission has error */
+	if ((err = (desc_ptr->desc0 & TX_ERROR_FLAGS)) != 0) {
+		int i;
+		ERR_PRINT("%s: got a tx error:0x%08lx\n", dev->name, desc_ptr->desc0);
+		for (i = TX_ERRORS_START; (i < TX_ERRORS) && (err != 0); i++) {
+			int *ptr;
+			if (err & (1 << i)) {
+				err &= ~(1<<i);
+				if (tx_error_msg[i] != NULL)
+					ERR_PRINT("%s\n",tx_error_msg[i]);
+				if (tx_stat_offset[i] >= 0) {
+					ptr = (int *)(((char *)stats) + tx_stat_offset[i]);
+					*ptr++;
+				}
+			}
+		}
+
+		/* Update stats */
+ 		stats->collisions += (desc_ptr->desc0 >> 3) & 15;
+		stats->tx_errors++;
+		stats->tx_packets--;
+		stats->tx_bytes -= (desc_ptr->desc1 & DescSize1Mask);
+	}
+
+	/* Copy packet data to tx buffer */
+//	DBG_PRINT("tx copy data from skb->data=0x%x to desc2=0x%x length=0x%x\n",
+//		(u32)skb->data, (u32)desc_ptr->desc2, (u32)length );
+
+	memcpy((void *)NON_CACHED(desc_ptr->desc2), skb->data, length);
+
+	/* Setup tx descriptor */
+	desc_ptr->desc1 = ( TX_DESC1_FLAGS | length );
+	if (private->next_txidx == (private->num_txdesc - 1))
+		desc_ptr->desc1 |=  DescEndOfRing ;
+	desc_ptr->desc0 |= DescOwnByDma;
+
+	/* Start transmission (should be in suspend mode already) */
+	em86xx_write_reg(EM86XX_TPDR_REG, 0x1);
+
+#ifdef BOOTLOADER
+        private->next_txidx = imodulus((private->next_txidx + 1), private->num_txdesc);
+#else
+	private->next_txidx = ((private->next_txidx + 1) % private->num_txdesc);
+	dev->trans_start = jiffies;
+#endif
+	/* Update stats */
+	stats->tx_packets++;
+	stats->tx_bytes += length;
+
+	/* Check to see if TX queue is full */
+	desc_ptr = (volatile struct em86xx_desc *)(&private->txdsc[private->next_txidx]);
+	if ((desc_ptr->desc0 & DescOwnByDma) != 0) {
+		/* cannot queue anymore */
+		netif_stop_queue(dev);
+		private->need_restart_tx_queue = 1;
+	} 
+
+	/* Free up socket buffer */
+#ifdef BOOTLOADER
+	async = 0;
+	skb_free(skb);
+#else
+	dev_kfree_skb(skb);
+#endif
+ out_unlock:
+	spin_unlock_irqrestore(&private->lock, flags);
+	return ret;
+}
+
+
+static inline int is_sw_filtered_packet(struct net_device *dev, unsigned char *data)
+{
+#ifdef USE_SW_FILTERING
+        if (((data[0] & 0x80) == 0) && (dev->dev_addr[5] != data[5])) {
+                return 1;
+	}
+        else {
+                return 0;
+	}
+#else
+        return 0;
+#endif
+}
+
+
+/* Receiving packet(s) */
+static int em86xx_eth_rx(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private;
+#ifdef BOOTLOADER
+	struct sk_buff *skb;
+#endif
+	struct net_device_stats *stats;
+	unsigned char *data;
+	volatile struct em86xx_desc *desc_ptr;
+	unsigned long length;
+	unsigned long dsc;
+	unsigned long count=0, cnt= 0, err;
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+	volatile struct em86xx_desc *mdf_desc_ptr;
+	long mdf_start = -1;
+#endif
+//	unsigned long flags;
+
+  	private = (EM86XX_ETH_PRIV *)dev->priv;
+  	stats = &(private->stats);
+
+	/* Go thru descriptors list until we ran out or encounterred
+	   the one being processed by DMA */
+#ifdef BOOTLOADER 
+	for (cnt = 0, count = private->last_rxidx; cnt < private->num_rxdesc; cnt++, count = imodulus(count + 1, private->num_rxdesc)) {
+#else
+	for (cnt = 0, count = private->last_rxidx; cnt < private->num_rxdesc; cnt++, count = ((count + 1) % private->num_rxdesc)) {
+#endif
+
+		desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[count]);
+	 	dsc = desc_ptr->desc0;
+
+	  	if ((dsc & DescOwnByDma) != 0) {
+    			/* DMA is processing this one, break out the loop */
+			break;
+    		}
+
+		/*filter out those are not for me */
+      		data = (unsigned char *)NON_CACHED(desc_ptr->desc2);
+		if (is_sw_filtered_packet(dev, data)
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+		    && (mdf_start < 0)
+#endif
+				) {
+			ERR_PRINT("%s: mac mismatched, dropped.\n", dev->name);
+		} else	if ((err = (dsc & RX_ERROR_FLAGS)) != 0)  {
+			int i;
+
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+			 /* First check are we in MDF mode */
+			 if (mdf_start >= 0) { /* Yes, we are */
+				 MSG_PRINT("%s: rx error in MDF mode (s:0x%x,c:0x%x)\n", dev->name, mdf_start, count);
+				 /* Something is wrong, drop all MDF related descriptors */
+				 for (i = mdf_start; i != count; i = (i + 1) % private->num_rxdesc) {
+					 mdf_desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[i]);
+					 mdf_desc_ptr->desc0 = DescOwnByDma;
+					 wmb();
+				 }
+				 mdf_start = -1; /* Reset so we're out of this mode */
+			 }
+#endif
+			/*Filtering fail is valid only when Last desc bit is set, 
+			  length is 64 bytes or longer and Receive All bit is set. */
+			if (dsc & DescFilteringFail) {		
+				unsigned long len, rx_mode;
+				len = (dsc & DescFrameLengthMask) >> DescFrameLengthShift;
+				rx_mode = em86xx_read_reg(EM86XX_MACCR_REG);
+				if(!((dsc & DescRxLast) && (len >= 64) && (rx_mode & MacFilterOff)))
+					goto sync_up;
+			}
+
+      			ERR_PRINT("%s: rx error 0x%08lx:%ld desc2=0x%08x\n", 
+				dev->name, dsc, count, (u32)desc_ptr->desc2);
+
+			for (i = RX_ERRORS_START; (i < RX_ERRORS) && (err != 0); i++) {
+				int *ptr;
+				if (err & (1 << i)) {
+					err &= ~(1<<i);
+					if (rx_error_msg[i] != NULL)
+						ERR_PRINT("%s\n", rx_error_msg[i]);
+					if (rx_stat_offset[i] >= 0) {
+						ptr = (int *)(((char *)stats) + rx_stat_offset[i]);
+						*ptr++;
+					}
+				}
+			}
+
+			/* We dropped any error descriptor */
+		        stats->rx_errors++;
+		 } else if ((dsc & MD_FRAME_FLAGS) != MD_FRAME_FLAGS) {
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+			 /* We encounterred multi-descriptor frame */
+			 if (((dsc & DescRxFirst) != 0) && ((dsc & DescRxLast) == 0)) {
+				 /* First descriptor of multi-descriptor frame */
+				 if (mdf_start >= 0) { 
+					 int i;
+					 MSG_PRINT("%s: MDF mode error at beginning (s:0x%x,c:0x%x)\n", dev->name, mdf_start, count);
+					 /* Something is wrong, drop all MDF related descriptors */
+					 for (i = mdf_start; i != count; i = (i + 1) % private->num_rxdesc) {
+						 mdf_desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[i]);
+						 mdf_desc_ptr->desc0 = DescOwnByDma;
+						 wmb();
+					 }
+				 }
+				 mdf_start = (long)count;
+				 continue; /* Loop until we can get the whole frame */
+			 } else if ((dsc & MD_FRAME_FLAGS) == 0) {
+				 if (mdf_start >= 0) {
+					 /* Interim descriptor within multi-descriptor frame */
+					 continue; /* Loop until we can get the whole frame */
+				 } else {
+					 MSG_PRINT("%s: MDF mode error (c:0x%x)\n", dev->name, count);
+					 /* Bogus: drop it */
+					 goto sync_up;
+				 }
+			 } else {
+				 /* Last descriptor of multi-descriptor frame */
+				 unsigned long mdf_size, length;
+				 long i, mdf_end;
+				 char *ptr, *mdf_data;
+				 struct sk_buff *mdf_skb;
+
+				 if (mdf_start < 0) {
+					 MSG_PRINT("%s: MDF mode error at the end (c:0x%x)\n", dev->name, count);
+					 /* Bogus: drop it */
+					 goto sync_up;
+				 }
+
+				 /* First we get the size of the frame, and allocate a new skb */
+				 length = mdf_size = (dsc & DescFrameLengthMask) >> DescFrameLengthShift;
+				 mdf_end = (count + 1) % private->num_rxdesc;
+#ifdef BOOTLOADER
+				 mdf_skb = skb_alloc(mdf_size);
+#else
+				 mdf_skb = dev_alloc_skb(mdf_size);
+#endif
+				 if (mdf_skb == NULL) {
+					 /* Error: no memory available, dropping all descriptors in this frame */
+					 stats->rx_dropped += (((mdf_start + private->num_rxdesc) - mdf_end) % private->num_rxdesc);
+					 for (i = mdf_start; i != mdf_end; i = (i + 1) % private->num_rxdesc) {
+						 mdf_desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[i]);
+						 mdf_desc_ptr->desc0 = DescOwnByDma;
+						 wmb();
+					 }
+				 } else {
+#ifndef BOOTLOADER
+					 skb_reserve(mdf_skb, 2);
+#endif
+					 stats->rx_bytes += mdf_size;
+					 stats->rx_packets += (((mdf_start + private->num_rxdesc) - mdf_end) % private->num_rxdesc);
+
+					 /* Collecting all descriptors into skb  */
+					 for (ptr = mdf_skb->data, i = mdf_start; i != mdf_end; i = (i + 1) % private->num_rxdesc) {
+						 mdf_desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[i]);
+						 mdf_data = (unsigned char *)NON_CACHED(mdf_desc_ptr->desc2);
+						 memcpy(ptr, mdf_data, (length > R_BUF_SIZE) ? R_BUF_SIZE : length);
+						 ptr += R_BUF_SIZE;
+						 length -= R_BUF_SIZE;
+						 mdf_desc_ptr->desc0 = DescOwnByDma;
+						 wmb();
+					 }
+					 mdf_skb->dev = dev;
+					 mdf_skb->len = mdf_size - 4;
+
+					 /* Send the frame back up */
+#ifdef BOOTLOADER
+					 skb_put(mdf_skb);
+#else
+					 mdf_skb->protocol = eth_type_trans(mdf_skb, dev);
+					 mdf_skb->ip_summed = CHECKSUM_NONE;
+					 dev->last_rx = jiffies;
+					 netif_rx(mdf_skb);
+#endif
+				 }
+				 mdf_start = -1;
+				 continue; /* No need go to the end of the loop */
+			}
+#else
+			/* We encounterred multi-descriptor frame */
+	        	DBG_PRINT("%s: multi-descriptor frame detected 0x%08lx\n", dev->name, dsc);
+		        /* Don't handle multi-descriptor frame */
+		        stats->rx_dropped++;
+#endif /* MULTI_DESCS_FRAME_SUPPORT */
+		 } else if ((length = ((dsc & DescFrameLengthMask) >> DescFrameLengthShift)) > R_BUF_SIZE) {
+			/* Should not happen for single-descriptor frame */
+      			ERR_PRINT("%s: rx dropped (size too large: %ld)\n", dev->name, length);
+			stats->rx_length_errors++;	
+			stats->rx_dropped++;
+#ifdef BOOTLOADER
+                 } else if ((skb = skb_alloc(length)) == NULL) {
+			ERR_PRINT("%s: rx dropped (memory unavailable)\n", dev->name);
+	        	stats->rx_dropped++;
+#endif
+		 } else {
+			 /* We got single descriptor frame */
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+			 /* First check are we in MDF mode */
+			 if (mdf_start >= 0) { /* Yes, we are */
+				 int i;
+				 /* Something is wrong, drop all MDF related descriptors */
+				 for (i = mdf_start; i != count; i = (i + 1) % private->num_rxdesc) {
+					 mdf_desc_ptr = (volatile struct em86xx_desc *)(&private->rxdsc[i]);
+					 mdf_desc_ptr->desc0 = DescOwnByDma;
+				 }
+				 mdf_start = -1; /* Reset so we're out of this mode */
+			 }
+#endif
+#ifdef BOOTLOADER
+		  	 skb->dev = dev;
+                         skb->len = length - 4;
+                         memcpy(skb->data, data, length-4);
+                         skb_put(skb);
+
+                         /* Update stats */
+                         stats->rx_packets++;
+                         stats->rx_bytes += length;
+#else
+                         private->rx_skb_list[count]->dev = dev;
+                         private->rx_skb_list[count]->len = length-4;
+                         private->rx_skb_list[count]->protocol = eth_type_trans(private->rx_skb_list[count], dev);
+                         private->rx_skb_list[count]->ip_summed = CHECKSUM_NONE;
+
+                         /* Send the packet to kernel */
+                         netif_rx(private->rx_skb_list[count]);
+
+	        	 /* Update stats */
+		       	 stats->rx_packets++;
+		         stats->rx_bytes += length;
+		       	 dev->last_rx = jiffies;
+#endif /*BOOTLOADER*/
+  	 	}
+#ifndef BOOTLOADER
+                private->rx_skb_list[count] = dev_alloc_skb(R_BUF_SIZE);
+                skb_reserve(private->rx_skb_list[count], 2);
+                desc_ptr->desc2 = PHYSADDR((u32)private->rx_skb_list[count]->data);
+#ifdef CONFIG_NONCOHERENT_IO
+		dma_cache_inv((u32)private->rx_skb_list[count]->data, R_BUF_SIZE);
+#endif
+#endif
+
+sync_up:
+  		desc_ptr->desc0 = DescOwnByDma;
+		wmb();
+  	}
+
+#ifdef MULTI_DESCS_FRAME_SUPPORT
+	/* This is the last desc we read */
+	if (mdf_start >= 0)
+		/* We haven't reached the end of multi-descriptor frame, mark it here
+		 * so we can come back and pick it up again */
+		private->last_rxidx = mdf_start; 
+	else
+		private->last_rxidx = count; 
+#else
+	/* This is the last desc we read */
+	private->last_rxidx = count; 
+#endif
+	/* make sure rx is not suspended */
+	em86xx_write_reg(EM86XX_RPDR_REG, 0x1);
+  	return cnt;
+}
+
+/* Resetting rx descriptor: error recovery for "rx buf unavailable" */
+static void em86xx_eth_reset_rx_buf(struct net_device *dev)
+{
+	register int i;
+	volatile struct em86xx_desc *desc_ptr = NULL;
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	em86xx_clear_reg(EM86XX_CR_REG, DmaRxStart); 
+
+	/* Reset rx desc */
+	desc_ptr = (struct em86xx_desc *)(private->rxdsc); 
+	for (i = 0; i < private->num_rxdesc; i++, desc_ptr++) 
+		desc_ptr->desc0 = DescOwnByDma; 
+  	
+  	em86xx_write_reg(EM86XX_RPDR_REG,  0x1);
+	em86xx_set_reg(EM86XX_CR_REG, DmaRxStart); 
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+#ifndef BOOTLOADER
+/* Get the stats information */
+static struct net_device_stats *em86xx_eth_stats(struct net_device *dev)
+{
+	DBG_PRINT_INOUT_FUNC("START");
+	if (dev != NULL) {
+		DBG_PRINT_INOUT_FUNC("END");
+    		return(&(((EM86XX_ETH_PRIV *)dev->priv)->stats));
+	}
+  	else {
+		DBG_PRINT_INOUT_FUNC("END");
+    		return(NULL);
+	}
+
+}
+#endif
+
+/* Ethernet interrupt handler */
+#ifdef BOOTLOADER
+static void em86xx_eth_intr_handler(int irq, void *dev_id)
+#else
+static irqreturn_t em86xx_eth_intr_handler(int irq, void *dev_id, struct pt_regs *regs)
+#endif
+{
+	int num_rx_desc_freed = 0;
+	unsigned long status;
+	struct net_device *dev = (struct net_device *)dev_id;
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+
+#ifdef BOOTLOADER
+        if( memcmp(dev->name,DRIVER, sizeof(DRIVER)) != 0) 
+                return;
+#else
+        if (dev_id != (void *)&em86xx_eth_dev)
+                return IRQ_NONE;
+#endif
+        /* Check status */
+        status = em86xx_read_reg(EM86XX_SR_REG);
+
+        // clear all interrupt requests
+        em86xx_write_reg(EM86XX_SR_REG, status) ;
+
+        if (status & DmaIntNormal) {
+                if (status & DmaIntRxCompleted) {
+	                num_rx_desc_freed = em86xx_eth_rx(dev);
+		}
+                else if(status & DmaIntTxCompleted){
+			if(private->need_restart_tx_queue){
+				private->need_restart_tx_queue = 0;
+				netif_start_queue(dev);
+			}
+/*			else if (status & DmaIntTxCompleted ) {
+				ERR_PRINT("\t%s: DmaIntTxCompleted : Transmit completed (Normal)\n", dev->name);
+			}
+			else if (status & DmaIntTxNoBuffer ) {
+				ERR_PRINT("\t%s: DmaIntTxNoBuffer : Transmit buffer unavailable (Normal)\n", dev->name);
+			}
+			else if (status & DmaIntRxCompleted ) {
+				ERR_PRINT("\t%s: DmaIntRxCompleted : Completion of frame reception (Normal)\n", dev->name);
+			}
+			else if (status & DmaIntEarlyRx) {
+				ERR_PRINT("\t%s: DmaIntEarlyRx : Early receive interrupt (Normal)\n", dev->name);
+			}
+*/
+		}
+		else {
+                        ERR_PRINT("%s: unhandled NIS 0x%08lx\n", dev->name, status);
+		}
+	}
+ 
+	if (status & DmaIntAbnormal) { 
+                if (status & DmaIntRxNoBuffer) {
+			if (num_rx_desc_freed == 0)
+	                	num_rx_desc_freed = em86xx_eth_rx(dev);
+
+			if(num_rx_desc_freed == 0){
+                        	ERR_PRINT("%s: receive buffer unavailable 0x%08lx\n", dev->name, status);
+                        	em86xx_eth_reset_rx_buf(dev);			
+			}		
+                } else if (status & DmaIntRxStopped) {
+                        ERR_PRINT("%s: receive process stopped\n", dev->name);
+                        em86xx_set_reg(EM86XX_CR_REG, DmaRxStart); 
+                } else if (status & DmaIntTxStopped ) {
+                        ERR_PRINT("%s: transmit process stopped\n", dev->name);
+                        em86xx_write_reg(EM86XX_CR_REG, DmaTxStart); 
+                } else if (status & DmaIntTxUnderflow) {
+                        ERR_PRINT("%s: transmit underflow\n", dev->name);
+                } else if (status & DmaIntEarlyTx ) {
+                        ERR_PRINT("%s: Early transmit interrupt\n", dev->name);
+                } else if (status & DmaIntBusError ) {
+                        ERR_PRINT("%s: Fatal bus error\n", dev->name);
+			if (status & DmaRxAbort) {
+				ERR_PRINT("\t%s : DmaRxAbort : receiver bus abort\n", dev->name);
+			}
+			else if (status & DmaTxAbort) {
+				ERR_PRINT("\t%s : DmaTxAbort : transmitter bus abort\n", dev->name);
+			}
+                } else {
+                        ERR_PRINT("%s: unhandled AIS 0x%08lx\n", dev->name, status);
+                }
+        }
+ 
+	if ((status & (DmaIntAbnormal | DmaIntNormal)) == 0) {
+#ifdef DEBUG_RX_TX_STATE
+		unsigned long st;
+#endif
+                DBG_PRINT("%s: Unhandled SR 0x%08lx --> %s %s\n", dev->name, status, (status & DmaTxState)?"DmaTxState":"", (status & DmaRxState)?"DmaRxState":"");
+#ifdef DEBUG_RX_TX_STATE
+		if (status & DmaTxState) {
+			st = (status & DmaTxState);
+			ERR_PRINT("\t%s: DmaTxState : Transmit process state (status == 0x%X)\n", dev->name, st);
+			switch (st){
+			case DmaTxStopped:
+				ERR_PRINT("\t%s: DmaTxStopped : Stopped\n", dev->name);
+				break;
+			case DmaTxFetching:
+				ERR_PRINT("\t%s: DmaTxFetching : Running - fetching the descriptor\n", dev->name);
+				break;
+			case DmaTxWaiting:
+				ERR_PRINT("\t%s: DmaTxWaiting : Running - waiting for end of transmission\n", dev->name);
+				break;
+			case DmaTxReading:
+				ERR_PRINT("\t%s: DmaTxReading : Running - reading the data from memory\n", dev->name);
+				break;
+			case DmaTxSuspended:
+				ERR_PRINT("\t%s: DmaTxSuspended : Suspended\n", dev->name);
+				break;
+			case DmaTxClosing:
+				ERR_PRINT("\t%s: DmaTxClosing : Running - closing descriptor\n", dev->name);
+				break;
+			default:
+				ERR_PRINT("\t%s: UNKNOWN Tx state\n", dev->name);
+				break;
+			}
+		}
+		
+		if (status & DmaRxState) {
+			st = (status & DmaRxState);
+			ERR_PRINT("\t%s: DmaRxState : Receive process state (status == 0x%X)\n", dev->name, st);
+			switch (st){
+			case DmaRxStopped: 
+				ERR_PRINT("\t%s: DmaRxStopped : Stopped\n", dev->name); 
+				break;
+			case DmaRxFetching:
+				ERR_PRINT("\t%s: DmaRxFetching : Running - fetching the descriptor\n", dev->name); 
+				break;
+			case DmaRxChecking:
+				ERR_PRINT("\t%s: DmaRxChecking : Running - checking for end of packet \n", dev->name);
+				break;
+			case DmaRxWaiting:
+				ERR_PRINT("\t%s: DmaRxWaiting : Running - waiting for packet\n", dev->name);
+				break;
+			case DmaRxSuspended:
+				ERR_PRINT("\t%s: DmaRxSuspended : Suspended\n", dev->name);
+				break;
+			case DmaRxClosing:
+				ERR_PRINT("\t%s: DmaRxClosing : Running - closing descriptor\n", dev->name);
+				break;
+			case DmaRxFlushing:
+				ERR_PRINT("\t%s: DmaRxFlushing : Running - flushing the current frame\n", dev->name);
+				break;
+			case DmaRxQueuing:
+				ERR_PRINT("\t%s: DmaRxQueuing : Running - queuing the recieve frame into host memory\n", dev->name);
+				break;
+			default:
+				ERR_PRINT("\t%s: UNKNOWN Rx state\n", dev->name);
+				break;
+			}
+		}
+#endif
+        }
+	
+#ifdef BOOTLOADER
+	 return;
+#else
+        return IRQ_HANDLED;
+#endif
+ }
+
+static void netdev_get_drvinfo (struct net_device *dev, struct ethtool_drvinfo *info)
+{
+	DBG_PRINT_INOUT_FUNC("START");
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+	strcpy(info->bus_info, "GBUS");
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+static int netdev_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+        unsigned long flags;
+	int rc;
+
+	DBG_PRINT_INOUT_FUNC("START");
+        spin_lock_irqsave(&private->lock, flags);
+	rc = mii_ethtool_gset(&private->mii_if, cmd);
+        spin_unlock_irqrestore(&private->lock, flags);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return rc;
+}
+
+static int netdev_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+        unsigned long flags;
+	int rc;
+
+	DBG_PRINT_INOUT_FUNC("START");
+        spin_lock_irqsave(&private->lock, flags);
+	rc = mii_ethtool_sset(&private->mii_if, cmd);
+        spin_unlock_irqrestore(&private->lock, flags);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return rc;
+}
+
+static int netdev_nway_reset(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	int rc;
+	DBG_PRINT_INOUT_FUNC("START");
+	rc = mii_nway_restart(&private->mii_if);
+	DBG_PRINT_INOUT_FUNC("END");
+	return rc;
+}
+
+static u32 netdev_get_link(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+	int rc;
+	DBG_PRINT_INOUT_FUNC("START");
+	rc = mii_link_ok(&private->mii_if);
+	DBG_PRINT_INOUT_FUNC("END");
+	return rc;
+}
+
+static u32 netdev_get_msglevel(struct net_device *dev)
+{
+	DBG_PRINT_INOUT_FUNC("START");
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+static void netdev_set_msglevel(struct net_device *dev, u32 value)
+{
+}
+
+static struct ethtool_ops netdev_ethtool_ops = {
+	.get_drvinfo		= netdev_get_drvinfo,
+	.get_settings		= netdev_get_settings,
+	.set_settings		= netdev_set_settings,
+	.nway_reset		= netdev_nway_reset,
+	.get_link		= netdev_get_link,
+	.get_msglevel		= netdev_get_msglevel,
+	.set_msglevel		= netdev_set_msglevel,
+	.get_sg			= ethtool_op_get_sg,
+	.get_tx_csum		= ethtool_op_get_tx_csum,
+};
+
+#ifndef BOOTLOADER
+/* Handling ioctl call */
+//static int em86xx_eth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+static int em86xx_eth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+#if 1
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+        int ret;
+        unsigned long flags;
+
+        spin_lock_irqsave(&private->lock, flags);
+        ret = generic_mii_ioctl(&private->mii_if, if_mii(ifr), cmd, NULL);
+        spin_unlock_irqrestore(&private->lock, flags);
+
+        return ret;
+
+#else
+	EM86XX_ETH_PRIV *private = (EM86XX_ETH_PRIV *)dev->priv;
+        unsigned long flags;
+	int ret = 0;
+	struct mii_ioctl_data *data = (struct mii_ioctl_data *)&ifr->ifr_data;
+	struct ifr_data_struct
+ 	{
+		u32 unit;
+    		u32 addr;
+    		u32 data;
+  	} *req = (struct ifr_data_struct *)ifr->ifr_data;
+
+	DBG_PRINT_INOUT_FUNC("START");
+
+	if (!netif_running(dev)) {
+		DBG_PRINT( "%s : ioctl, but device not running !!\n", dev->name);
+		return -EINVAL;
+	}
+
+        spin_lock_irqsave(&private->lock, flags);
+	
+	if( req->unit == 3 ) {
+		DBG_PRINT( "em86xx::read/write MII registers(%s, cmd=%08x) unit=0x%x  reg=0x%x\n", 
+			   dev->name, cmd, req->unit, req->addr );
+		ret = generic_mii_ioctl(&private->mii_if, data, cmd, NULL);
+	}
+	else {
+		switch( cmd ) {
+		case SIOCDEVPRIVATE:  
+			DBG_PRINT( "em86xx::read registers(%s, cmd=%08x) unit=0x%x  reg=0x%x\n", 
+				   dev->name, cmd, req->unit, req->addr );
+			
+			if( req->unit == 0 ){        /* Read register */
+      				req->data = em86xx_read_reg( req->addr );
+    			}
+			else if( req->unit == 1 ){   /* Read MAC register */
+      				req->data = em86xx_read_mac_reg( req->addr );
+    			}
+    			else if( req->unit == 2 ) {   /* Read DMA register */
+      				req->data = em86xx_read_dma_reg( req->addr );
+    			}
+			else {
+				DBG_PRINT( "Unknow read request : %d\n", req->unit);
+				ret = -EOPNOTSUPP;
+			}
+    			break;
+  		case SIOCDEVPRIVATE+1:                /* Write registers */
+			DBG_PRINT( "em86xx::write registers(%s, cmd=%08x) unit=0x%x reg=0x%x data=0x%x\n", 
+				    dev->name, cmd ,req->unit, req->addr, req->data);
+
+    			if( req->unit == 0 ) {        /* Write register */
+      				em86xx_write_reg( req->addr, req->data );
+    			}
+    			else if( req->unit == 1 ) {        /* Write MAC register */
+      				em86xx_write_mac_reg( req->addr, req->data );
+    			}
+    			else if( req->unit == 2 ) {   /* Write DMA register */
+      				em86xx_write_dma_reg( req->addr, req->data );
+    			}
+			else {
+				DBG_PRINT( "Unknow write request : %d\n", req->unit);
+				ret = -EOPNOTSUPP;
+			}
+    			break;			
+		default:
+			DBG_PRINT( "Unknow cmd : %d\n", cmd);
+    			ret = -EOPNOTSUPP;
+		}
+	}
+	
+        spin_unlock_irqrestore(&private->lock, flags);
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return ret;
+#endif
+}
+#endif
+
+/* Kernel level ethernet initialization */
+static int em86xx_eth_init(struct net_device *dev)
+{
+	EM86XX_ETH_PRIV *private;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+	em86xx_write_reg(EM86XX_SR_REG, em86xx_read_reg(EM86XX_SR_REG));
+
+	if (dev == NULL)
+  		goto failed;
+
+	private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	/* Initialize private data */
+	spin_lock_init(&private->lock);
+	
+	private->rxdsc = (volatile struct em86xx_desc *)NON_CACHED((u32)private->eth_rxdsc);
+	private->txdsc = (volatile struct em86xx_desc *)NON_CACHED((u32)private->eth_txdsc);
+	private->rxbuf = (volatile unsigned char *)NON_CACHED((u32)private->eth_rxbuf);
+	private->txbuf = (volatile unsigned char *)NON_CACHED((u32)private->eth_txbuf);
+
+	/* Ethernet device initialization */
+#ifdef BOOTLOADER
+        /* Fill in the fields of the device structure with ethernet-generic values.*/
+//      dev->type               = ARPHRD_ETHER;
+        dev->mtu                = ETH_DATA_LEN; /* eth_mtu */
+        dev->addr_len           = ETH_ALEN;
+        memset(dev->broadcast, 0xff, ETH_ALEN);
+        dev->hard_header_len = ETH_HLEN;
+#else
+	ether_setup(dev);
+#endif
+
+	/* reset dma engine*/
+	em86xx_write_reg(EM86XX_BMR_REG, DmaResetOn);
+	em86xx_write_reg(EM86XX_BMR_REG, DmaResetOff);
+
+	if (em86xx_set_mac(dev))
+  		goto failed;
+
+	/* Hook up with handlers */
+#ifdef BOOTLOADER
+        dev->send_packet         = em86xx_eth_tx;
+        dev->open                = em86xx_eth_open;
+        dev->close               = em86xx_eth_close;
+#else
+	dev->get_stats		 = em86xx_eth_stats;
+	dev->hard_start_xmit	 = em86xx_eth_tx;
+	dev->open		 = em86xx_eth_open;
+	dev->stop		 = em86xx_eth_close;
+#ifdef USE_HW_FILTERING
+	dev->set_multicast_list  = em86xx_eth_set_multicast_list;
+#endif
+	dev->do_ioctl		 = em86xx_eth_ioctl;
+	dev->set_mac_address	 = em86xx_eth_set_macaddr;
+        dev->ethtool_ops         = &netdev_ethtool_ops;
+
+	dev->tx_queue_len = private->num_txdesc; 
+//	dev->flags &= ~IFF_MULTICAST;
+//	dev->flags |= IFF_DEBUG;
+#endif
+	DBG_PRINT("Detect PHY\n");
+	if (phy_detect(dev, &private->mii_if) < 0) {
+		DBG_PRINT_INOUT_FUNC("END");
+		return -ENODEV;
+	}
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+
+failed:
+	DBG_PRINT_INOUT_FUNC("END");
+	return(-EIO);
+}
+
+static int em86xx_eth_reset_desc(struct net_device *dev, int *reset)
+{
+	EM86XX_ETH_PRIV *private;
+	int i;
+
+	DBG_PRINT_INOUT_FUNC("START");
+	if (dev == NULL)
+  		return(-EIO);
+	else
+		private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	if (*reset) {
+		memset((void*)&private->stats, 0, sizeof(struct net_device_stats));
+		memset((void*)&private->mii_if, 0, sizeof(struct mii_if_info));
+		private->autoneg_active = 0;
+		private->phy_loopback = 0;	
+
+#ifndef BOOTLOADER
+
+#ifdef USE_KERNEL_TIMER 
+		memset((void*)&private->eth_timer, 0, sizeof(struct timer_list));
+#endif
+		private->need_restart_tx_queue = 0; 
+#endif
+	}
+
+	*reset = 0;
+
+	/* Clear all tx/rx buffer memory */
+	memset((void *)(private->rxbuf), 0, private->num_rxdesc * R_BUF_SIZE);
+	memset((void *)(private->txbuf), 0, private->num_txdesc * T_BUF_SIZE);
+
+	/* Initialize the indices */
+	private->last_rxidx = 0;
+	private->next_txidx = 0;
+
+#ifndef BOOTLOADER
+	if (private->rx_skb_list != NULL) {
+		for (i = 0; i < private->num_rxdesc; i++) {
+			if (private->rx_skb_list[i] != NULL)
+				dev_kfree_skb(private->rx_skb_list[i]);
+		}
+	}
+	memset((void *)private->rx_skb_list, 0, sizeof(struct skb_buff *) * private->num_rxdesc);
+#endif
+
+	/* Intialize the descriptors */
+	em86xx_eth_setup_desc(dev);
+
+	phy_detect(dev, &private->mii_if);
+
+
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+}
+
+/* Driver installation: this is where the thing starts */
+#ifdef BOOTLOADER
+int em86xx_eth_probe(struct net_device *dev)
+#else
+static int __init em86xx_eth_startup(void)
+#endif
+{
+#ifndef BOOTLOADER
+	struct net_device *dev 	= &em86xx_eth_dev;
+#endif
+	int err = 0, i;
+	EM86XX_ETH_PRIV *private= NULL;
+#ifndef STATIC_BUF_ALLOC
+	unsigned long max_num_rxdsc, max_num_txdsc;
+	unsigned long rxbuf_size, txbuf_size;
+#endif
+
+	DBG_PRINT_INOUT_FUNC("START");
+#if defined(CONFIG_TANGOX)
+        extern int tangox_ethernet_enabled(int);
+        if (tangox_ethernet_enabled(0) == 0) {
+                MSG_PRINT(KERN_WARNING "TangoX builtin ethernet is disabled.\n");
+                return(0);
+        }
+#endif
+	/* Turn off IRQ and stop receive/transmit */
+	em86xx_write_reg(EM86XX_CR_REG, 0);
+	em86xx_write_reg(EM86XX_IER_REG, 0);
+	em86xx_write_reg(EM86XX_SR_REG, em86xx_read_reg(EM86XX_SR_REG));
+
+	if(dev != NULL) {
+		if(dev->priv != NULL) {
+			private = (EM86XX_ETH_PRIV *)dev->priv;
+			if (private->dev_count != 0) {
+				err = -EIO;
+				goto failed;
+			} 
+		}
+	}
+
+	/* Allocate memory for private data */
+#ifdef BOOTLOADER
+        dev->priv = private = (EM86XX_ETH_PRIV *)malloc(sizeof(EM86XX_ETH_PRIV));//, GFP_KERNEL);
+#else
+	
+	DBG_PRINT("KMALLOC\n");
+	dev->priv = private = (EM86XX_ETH_PRIV *)kmalloc(sizeof(EM86XX_ETH_PRIV), GFP_KERNEL);
+#endif
+	if (dev->priv == NULL) {
+		err = -ENOMEM;
+		goto failed;
+	}
+
+	memset(dev->priv, 0, sizeof(EM86XX_ETH_PRIV));
+
+	private->num_rxdesc = num_rxdesc_param;;
+	private->num_txdesc = num_txdesc_param;
+
+	DBG_PRINT("private->num_rxdesc = %lu, private->num_txdesc = %lu \n", private->num_rxdesc, private->num_txdesc);
+#ifndef STATIC_BUF_ALLOC	
+	DBG_PRINT("NON STATIC_BUF_ALLOC\n");
+	/* Validating module parameters */
+	max_num_rxdsc = max_num_txdsc = PAGE_SIZE / (2 * sizeof(struct em86xx_desc));
+ #ifdef BOOTLOADER
+	DBG_PRINT("BOOTLOADER\n");
+	if (((private->num_rxdesc < MIN_NUM_RDESC) || (private->num_rxdesc > max_num_rxdsc)) ||
+	    ((private->num_txdesc < MIN_NUM_TDESC) || (private->num_txdesc > max_num_txdsc))) {
+		err = -EIO;
+		goto failed;
+	} else if ((private->desc_page = NON_CACHED(malloc(PAGE_SIZE))) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	}
+ #else
+	DBG_PRINT("NOT BOOTLOADER\n");
+	if (((private->num_rxdesc < MIN_NUM_RDESC) || (private->num_rxdesc > max_num_rxdsc)) ||
+	    ((private->num_txdesc < MIN_NUM_TDESC) || (private->num_txdesc > max_num_txdsc))) {
+		err = -EIO;
+		goto failed;
+	} else if ((private->desc_page = __get_free_page(GFP_KERNEL | GFP_DMA)) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	} else if ((private->rx_skb_list = (struct skb_buff **)kmalloc(sizeof(struct skb_buff *) 
+				                 * private->num_rxdesc, GFP_KERNEL)) == NULL) {
+		err = -ENOMEM;
+		goto failed;
+	}
+
+	memset((void *)private->rx_skb_list, 0, sizeof(struct skb_buff *) * private->num_rxdesc);
+ #endif
+
+	/* Split a page for both rx/tx descriptor */
+	private->eth_rxdsc = (struct em86xx_desc *)private->desc_page;
+	private->eth_txdsc = (struct em86xx_desc *)(private->desc_page + ((1 << PAGE_SHIFT) / 2));
+
+	/* Calculate the size needed for tx/rx -- aligned by pages */
+	rxbuf_size = private->num_rxdesc * R_BUF_SIZE;
+	txbuf_size = private->num_txdesc * T_BUF_SIZE;
+	if ((rxbuf_size & (PAGE_SIZE - 1)) != 0)
+		rxbuf_size = (rxbuf_size & PAGE_MASK) + PAGE_SIZE;
+	if ((txbuf_size & (PAGE_SIZE - 1)) != 0)
+		txbuf_size = (txbuf_size & PAGE_MASK) + PAGE_SIZE;
+	DBG_PRINT("txbuf_size = 0x%08lx, rxbuf_size = 0x%08lx\n", txbuf_size, rxbuf_size);
+
+ #ifndef BOOTLOADER
+	/* Calculate the order needed for tx/rx */
+	for (private->rxbuf_order = 0; private->rxbuf_order < MAX_ORDER; private->rxbuf_order++) {
+		if ((PAGE_SIZE * (1 << private->rxbuf_order)) >= rxbuf_size)
+			break;
+	}
+
+	for (private->txbuf_order = 0; private->txbuf_order < MAX_ORDER; private->txbuf_order++) {
+		if ((PAGE_SIZE * (1 << private->txbuf_order)) >= txbuf_size)
+			break;
+	}
+
+	if ((private->rxbuf_order >= MAX_ORDER) || (private->txbuf_order >= MAX_ORDER)) {
+		err = -ENOMEM;
+		goto failed;
+	}
+
+	DBG_PRINT("private->txbuf_order = 0x%08lx, private->rxbuf_order = 0x%08lx\n", private->txbuf_order, private->rxbuf_order);
+ #endif
+		
+ #ifdef BOOTLOADER
+	if ((private->rxbuf_pages = NON_CACHED(malloc(rxbuf_size))) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	} else if ((private->txbuf_pages = NON_CACHED(malloc(txbuf_size))) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	}
+ #else
+	if ((private->rxbuf_pages = __get_free_pages(GFP_KERNEL | GFP_DMA, private->rxbuf_order)) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	} else if ((private->txbuf_pages = __get_free_pages(GFP_KERNEL | GFP_DMA, private->txbuf_order)) == 0) {
+		err = -ENOMEM;
+		goto failed;
+	}
+ #endif
+
+	private->eth_rxbuf  = (unsigned char *)private->rxbuf_pages;
+	private->eth_txbuf  = (unsigned char *)private->txbuf_pages;
+#else
+	DBG_PRINT("STATIC_BUF_ALLOC\n");
+#endif
+
+#ifndef BOOTLOADER
+	SET_MODULE_OWNER(&em86xx_eth_dev);
+#endif
+
+	MSG_PRINT("Ethernet driver for EM86XX (v1.0)");
+        dev->irq = IRQ_ETHERNET;
+
+	private->reset_flag 	= 1;
+
+	/* Get a device name: normally it'll be eth0 */
+#ifdef BOOTLOADER
+        memcpy( dev->name, DRIVER, sizeof(DRIVER));
+
+        /* Register ISR */
+        em86xx_request_irq(IRQ_ETHERNET, em86xx_eth_intr_handler, dev);
+#else
+	if ((err = dev_alloc_name(&em86xx_eth_dev, "eth%d")) < 0)
+  		goto failed;
+
+	/* Register ISR */
+	if ((err = request_irq(IRQ_ETHERNET, em86xx_eth_intr_handler, SA_SHIRQ, "ethernet", 
+      	 	 &em86xx_eth_dev)) != 0) {
+  		err = -EIO;
+  		goto failed;
+	} else
+#endif 
+  		MSG_PRINT(" on %s (IRQ: %d)", dev->name, IRQ_ETHERNET);
+
+
+	if (em86xx_get_macaddr(dev->dev_addr)) {
+  		err = -EIO;
+  		goto failed;
+	}
+
+	MSG_PRINT("\n(MAC %02x", dev->dev_addr[0]);
+	for (i = 1; i < 6; i++)
+	  	MSG_PRINT(":%02x", dev->dev_addr[i]);
+	MSG_PRINT(", tx_desc/rx_desc = %ld/%ld), ", private->num_txdesc, private->num_rxdesc);
+	if (phy_address < 0)
+		MSG_PRINT("PHY probing enabled\n");
+	else
+		MSG_PRINT("PHY address: %d\n", phy_address);
+
+	/* Point to driver initialization routine and register the device with kernel */
+	dev->init = em86xx_eth_init;
+#ifdef BOOTLOADER
+        em86xx_eth_init(dev);
+	DBG_PRINT("AFTER em86xx_eth_init\n");
+        dev->state = NETDEV_DOWN;
+	DBG_PRINT("AFTER STATE\n");
+#else
+	if (register_netdev(dev) != 0) {
+  		err = -EIO;
+  		goto failed;
+	}
+#endif
+
+	MSG_PRINT("%s: driver installation completed.\n", dev->name);
+	private->dev_count++;
+	netif_carrier_off(dev); /* By default the carrier is off */
+	DBG_PRINT_INOUT_FUNC("END");
+	return 0;
+
+failed:
+  	if (dev->priv != NULL) {
+#ifdef BOOTLOADER
+                free(dev->priv);
+#else
+    		kfree(dev->priv);
+#endif
+    		dev->priv = NULL;
+  	}
+#ifndef STATIC_BUF_ALLOC
+#ifdef BOOTLOADER
+	if (private->desc_page   != 0)
+		free((void *)CACHED(private->desc_page));
+	if (private->rxbuf_pages != 0)
+		free((void *)CACHED(private->rxbuf_pages));
+	if (private->txbuf_pages != 0)
+		free((void *)CACHED(private->txbuf_pages));
+#else
+	if (private->desc_page   != 0)
+		free_page(private->desc_page);
+	if (private->rxbuf_pages != 0)
+		free_pages(private->rxbuf_pages, private->rxbuf_order);
+	if (private->txbuf_pages != 0)
+		free_pages(private->txbuf_pages, private->txbuf_order);
+	if (private->rx_skb_list != NULL);
+		kfree(private->rx_skb_list);
+#endif
+#endif
+  	MSG_PRINT("%s: driver installation failed.\n", dev->name);
+	DBG_PRINT_INOUT_FUNC("END");
+  	return(err);
+}
+
+#ifndef BOOTLOADER
+/* Uninstallation of drive */
+static void __exit em86xx_eth_shutdown(void)
+{
+	struct net_device *dev 	= &em86xx_eth_dev;
+	EM86XX_ETH_PRIV *private= NULL;
+#if defined(CONFIG_TANGOX)
+        extern int tangox_ethernet_enabled(int);
+        if (tangox_ethernet_enabled(0) == 0) 
+                return;
+#endif
+
+	DBG_PRINT_INOUT_FUNC("START");
+
+	if (dev == NULL)
+  		return;
+	else
+		private = (EM86XX_ETH_PRIV *)dev->priv;
+
+	if (private == NULL) {
+		return;
+	}
+
+	if (private->dev_count != 0) {
+		/* Turn off IRQ and stop receive/transmit */
+  		em86xx_write_reg(EM86XX_CR_REG, 0);
+  		em86xx_write_reg(EM86XX_IER_REG, 0);
+
+  		/* Unregister the device and ISR */
+  		free_irq(IRQ_ETHERNET, &em86xx_eth_dev);
+		unregister_netdev(&em86xx_eth_dev);
+
+		/* Set desc base address registers to 0 */
+		em86xx_write_reg(EM86XX_RLBAR_REG, 0);
+		em86xx_write_reg(EM86XX_TLBAR_REG, 0);
+#ifndef STATIC_BUF_ALLOC
+#ifdef BOOTLOADER
+		if (private->desc_page   != 0)
+			free((void *)CACHED(private->desc_page));
+		if (private->rxbuf_pages != 0)
+			free((void *)CACHED(private->rxbuf_pages));
+		if (private->txbuf_pages != 0)
+			free((void *)CACHED(private->txbuf_pages));
+#else
+		if (private->desc_page   != 0)
+			free_page(private->desc_page);
+		if (private->rxbuf_pages != 0)
+			free_pages(private->rxbuf_pages, private->rxbuf_order);
+		if (private->txbuf_pages != 0)
+			free_pages(private->txbuf_pages, private->txbuf_order);
+		if (private->rx_skb_list != NULL) {
+			int i;
+			for (i = 0; i < private->num_rxdesc; i++) {
+				if (private->rx_skb_list[i] != NULL)
+					dev_kfree_skb(private->rx_skb_list[i]);
+			}
+			kfree(private->rx_skb_list);
+		}
+#endif
+#endif
+		/* Free up memory */
+		if (em86xx_eth_dev.priv != NULL) {
+			kfree(em86xx_eth_dev.priv);
+			em86xx_eth_dev.priv = NULL;
+  		}
+	} 
+
+	DBG_PRINT_INOUT_FUNC("END");
+}
+
+/* Register startup/shutdown routines */
+module_init(em86xx_eth_startup);
+module_exit(em86xx_eth_shutdown);
+#endif
+
diff -Naur linux-2.6.30-ori/drivers/net/tango2_enet_old.h linux-2.6.30-test/drivers/net/tango2_enet_old.h
--- linux-2.6.30-ori/drivers/net/tango2_enet_old.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/net/tango2_enet_old.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,827 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+
+/*  
+ * Definitions used to for ethernet module.
+ */
+
+#ifndef __EM86XX_ETH_H__ 
+#define __EM86XX_ETH_H__ 
+
+#ifndef BOOTLOADER
+#include <asm/io.h>
+#include <linux/delay.h>
+#ifdef CONFIG_TANGOX
+#include <asm/addrspace.h>
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+#endif
+#define NON_CACHED(x)		KSEG1ADDR((u32)(x))
+#define CACHED(x)		KSEG0ADDR((u32)(x))
+#define PHYSADDR(x)		tangox_dma_address(CPHYSADDR(x))
+#define IRQ_ETHERNET 		(IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_ETH_MAC_INT)//38
+#elif defined(CONFIG_ARCH_TANGO15)
+#include <asm/arch/hardware.h>
+#define NON_CACHED(x)		em86xx_to_ncaddr((u32)(x))
+#define CACHED(x)		em86xx_to_caddr((u32)(x))
+#define PHYSADDR(x)		NON_CACHED(x)
+#else
+#error "Not support platform/architecture."
+#endif
+
+#include <asm/types.h>
+
+#else
+
+#include "config.h"
+#include "version.h"
+#include "hardware.h"
+#include "io.h"
+
+typedef unsigned int u32;
+typedef unsigned short int u16;
+typedef unsigned char u8;
+typedef int     bool;
+
+#define NON_CACHED(x)           (((u32)(x)) & 0x7fffffff)
+#define PHYSADDR(x)		NON_CACHED(x)
+
+struct net_device_stats
+{
+        unsigned long   rx_packets;             /* total packets received       */
+        unsigned long   tx_packets;             /* total packets transmitted    */
+        unsigned long   rx_bytes;               /* total bytes received         */
+        unsigned long   tx_bytes;               /* total bytes transmitted      */
+        unsigned long   rx_errors;              /* bad packets received         */
+        unsigned long   tx_errors;              /* packet transmit problems     */
+        unsigned long   rx_dropped;             /* no space in linux buffers    */
+        unsigned long   tx_dropped;             /* no space available in linux  */
+        unsigned long   multicast;              /* multicast packets received   */
+        unsigned long   collisions;
+
+        /* detailed rx_errors: */
+        unsigned long   rx_length_errors;
+        unsigned long   rx_over_errors;         /* receiver ring buff overflow  */
+        unsigned long   rx_crc_errors;          /* recved pkt with crc error    */
+        unsigned long   rx_frame_errors;        /* recv'd frame alignment error */
+        unsigned long   rx_fifo_errors;         /* recv'r fifo overrun          */
+        unsigned long   rx_missed_errors;       /* receiver missed packet       */
+
+        /* detailed tx_errors */
+        unsigned long   tx_aborted_errors;
+        unsigned long   tx_carrier_errors;
+        unsigned long   tx_fifo_errors;
+        unsigned long   tx_heartbeat_errors;
+        unsigned long   tx_window_errors;
+
+        /* for cslip etc */
+        unsigned long   rx_compressed;
+        unsigned long   tx_compressed;
+
+};
+
+static inline int is_valid_ether_addr( u8 *addr )
+{
+        const char zaddr[6] = {0,};
+
+        return !(addr[0]&1) && memcmp( addr, zaddr, 6);
+}
+
+#endif//BOOTLOADER
+
+#define EM86XX_HOST_BASE	REG_BASE_host_interface
+#define EM86XX_HOST_ETHMAC	0x00006000 
+#define EM86XX_HOST_ETHDMA	0x00007000 
+#define EM86XX_ETHDMA_BASE	CPHYSADDR(EM86XX_HOST_BASE + EM86XX_HOST_ETHDMA)
+#define EM86XX_BMR_REG		(EM86XX_ETHDMA_BASE + 0x0)
+#define EM86XX_TPDR_REG		(EM86XX_ETHDMA_BASE + 0x4)
+#define EM86XX_RPDR_REG		(EM86XX_ETHDMA_BASE + 0x8)
+#define EM86XX_RLBAR_REG	(EM86XX_ETHDMA_BASE + 0xc)
+#define EM86XX_TLBAR_REG	(EM86XX_ETHDMA_BASE + 0x10)
+#define EM86XX_SR_REG		(EM86XX_ETHDMA_BASE + 0x14)
+#define EM86XX_CR_REG		(EM86XX_ETHDMA_BASE + 0x18)
+#define EM86XX_IER_REG		(EM86XX_ETHDMA_BASE + 0x1c)
+#define EM86XX_MFCR_REG		(EM86XX_ETHDMA_BASE + 0x20)
+#define EM86XX_IFR_REG		(EM86XX_ETHDMA_BASE + 0x24) /*reserved ?*/
+#define EM86XX_TDVPAR_REG	(EM86XX_ETHDMA_BASE + 0x4c) /*reserved ?*/
+#define EM86XX_CHTBAR_REG	(EM86XX_ETHDMA_BASE + 0x50)
+#define EM86XX_CHRBAR_REG	(EM86XX_ETHDMA_BASE + 0x54)
+
+#define EM86XX_ETHMAC_BASE	CPHYSADDR(EM86XX_HOST_BASE + EM86XX_HOST_ETHMAC)
+#define EM86XX_MACCR_REG	(EM86XX_ETHMAC_BASE + 0x0)
+#define EM86XX_MACAHR_REG	(EM86XX_ETHMAC_BASE + 0x4)
+#define EM86XX_MACALR_REG	(EM86XX_ETHMAC_BASE + 0x8)
+#define EM86XX_MCHTHR_REG	(EM86XX_ETHMAC_BASE + 0xc)
+#define EM86XX_MCHTLR_REG	(EM86XX_ETHMAC_BASE + 0x10)
+#define EM86XX_MIIAR_REG	(EM86XX_ETHMAC_BASE + 0x14)
+#define EM86XX_MIIDR_REG	(EM86XX_ETHMAC_BASE + 0x18)
+#define EM86XX_FCR_REG		(EM86XX_ETHMAC_BASE + 0x1c)
+#define EM86XX_V1TR_REG		(EM86XX_ETHMAC_BASE + 0x20)
+#define EM86XX_V2TR_REG		(EM86XX_ETHMAC_BASE + 0x24)
+#define EM86XX_WUFF_REG	        (EM86XX_ETHMAC_BASE + 0x28)
+#define EM86XX_WUCS_REG		(EM86XX_ETHMAC_BASE + 0x2C)
+
+/* MII interface */
+#define MiiIfSpeed10M     	0x00000000
+#define MiiIfSpeed100M		0x00000004
+#define MiiIfExtPhyMii		0x00000000
+#define MiiIfExtPhyRmii		0x00000001
+#define MiiIfIntPhy    		0x00000002
+
+#ifndef __ASSEMBLY__ 
+
+/* Descriptor related ... */
+struct em86xx_desc {
+  volatile unsigned long desc0;
+  volatile unsigned long desc1;
+  volatile unsigned long desc2;
+  volatile unsigned long desc3;
+};
+
+/**********************************************************
+ * MAC110 Network interface registers
+ **********************************************************/
+
+enum MacControlReg      /* MAC Control register layout */
+{                                         /* Bit description                        R/W   Reset value */
+  MacFilterOff            = 0x80000000,     /* Receive all incoming packets         RW                */
+  MacFilterOn             = 0,              /* Receive filtered packets only                  0       */
+
+  MacBigEndian            = 0x40000000,     /* Big endian mode                      RW                */
+  MacLittleEndian         = 0,              /* Little endian                                  0       */
+
+  MacHeartBeatOff         = 0x10000000,     /* Heart beat signal quality disable    RW                */
+  MacHeartBeatOn          = 0,              /* Heart beat signal quality enable               0       */
+
+  MacSelectSrl            = 0x08000000,     /* Select SRL port                      RW                */
+  MacSelectMii            = 0,              /* Select MII port                                0       */
+
+  MacDisableRxOwn         = 0x00800000,     /* Disable receive own packets          RW                */
+  MacEnableRxOwn          = 0,              /* Enable receive own packets                     0       */
+
+  MacLoopbackExt          = 0x00400000,     /* External loopback                    RW                */
+  MacLoopbackInt          = 0x00200000,     /* Internal loopback                                      */
+  MacLoopbackOff          = 0,              /* Normal mode                                    00      */
+
+  MacFullDuplex           = 0x00100000,     /* Full duplex mode                     RW                */
+  MacHalfDuplex           = 0,              /* Half duplex mode                               0       */
+
+  MacMulticastFilterOff   = 0x00080000,     /* Pass all multicast packets           RW                */
+  MacMulticastFilterOn    = 0,              /* Pass filtered multicast packets                0       */
+
+  MacPromiscuousModeOn    = 0x00040000,     /* Receive all valid packets            RW        1       */
+  MacPromiscuousModeOff   = 0,              /* Receive filtered packets only                          */
+
+  MacFilterInverce        = 0x00020000,     /* Inverse filtering                    RW                */
+  MacFilterNormal         = 0,              /* Normal filtering                               0       */
+
+  MacBadFramesEnable      = 0x00010000,     /* Pass bad frames                      RW                */
+  MacBadFramesDisable     = 0,              /* Do not pass bad frames                         0       */
+
+  MacPerfectFilterOff     = 0x00008000,     /* Hash filtering only                  RW                */
+  MacPerfectFilterOn      = 0,              /* Both perfect and hash filtering                0       */
+
+  MacHashFilterOn         = 0x00002000,     /* perfom hash filtering                RW                */
+  MacHashFilterOff        = 0,              /* perfect filtering only                         0       */
+
+  MacLateCollisionOn      = 0x00001000,     /* Enable late collision control        RW                */
+  MacLateCollisionOff     = 0,              /* Disable late collision control                 0       */
+
+  MacBroadcastDisable     = 0x00000800,     /* Disable reception of broadcast frames RW               */
+  MacBroadcastEnable      = 0,              /* Enable broadcast frames                        0       */
+
+  MacRetryDisable         = 0x00000400,     /* Disable retransmission               RW                */
+  MacRetryEnable          = 0,              /* Enable retransmission                          0       */
+
+  MacPadStripEnable       = 0x00000100,     /* Pad stripping enable                 RW                */
+  MacPadStripDisable      = 0,              /* Pad stripping disable                          0       */
+
+  MacBackoff10            = 0,              /* Backoff Limit (not documented)       RW        00      */
+  MacBackoff8             = 0x00000040,     /* Backoff Limit (not documented)       RW        01      */
+  MacBackoff4             = 0x00000080,     /* Backoff Limit (not documented)       RW        10      */
+  MacBackoff1             = 0x000000c0,     /* Backoff Limit (not documented)       RW        11      */
+
+  MacDeferralCheckEnable  = 0x00000020,     /* Deferral check enable                RW                */
+  MacDeferralCheckDisable = 0,              /* Deferral check disable                         0       */
+
+  MacTxEnable             = 0x00000008,     /* Transmitter enable                   RW                */
+  MacTxDisable            = 0,              /* Transmitter disable                            0       */
+
+  MacRxEnable             = 0x00000004,     /* Receiver enable                      RW                */
+  MacRxDisable            = 0,              /* Receiver disable                               0       */
+};
+
+enum MiiRegisters
+{
+  GEN_ctl   = 0x00,	/* Basic Mode Control Register */
+			/* bit 0-7, 10: Reserved, 
+			   bit 8:  	Duplex Mode: 1=FD, 0=HD
+			   bit 9:	Restart Auto negotiation 1=restart, 0=normal operation
+			   bit11:	1=Power Down, 0=normal operation
+			   bit12:	1=enable auto-negotiation, bit13 and 8 will be ingnored
+					0=disable auto-negotiation, bit13 & 8 to determine the speed and mode
+			   bit13	1=100Mbps 0=10Mbps
+			   bit14	1=enable loopback 0=normal operation
+			   bit15	1=software reset  0=normal operation*/     	
+  GEN_sts   = 0x01,	/* Basic Mode Status Register  */
+			/* bit 0:	1=extended register capability 0=basic register capability only
+			   bit 1:	1=jabber condidtion detected 0=no jabber condition detected
+			   bit 2:	1=valid link established 0=no link
+			   bit 3:	1=Auto-negotiation ok 0=fail
+			   bit 4:	1=remote fault 0=no remote fault
+			   bit 5:	1=auto-negotiation process completed, 0=not completed
+			   bit 6:	MF Preamble suppression
+			   bit 7-10:	Reserved
+			   bit 11:	1=enable 10Base-T HD 0=suppress 10/HD
+			   bit 12:	1=enable 10Base-T FD 0=suppress 10/FD
+			   bit 13:	1=enable 100Base-T FD 0=suppress 100/FD
+			   bit 14:	1=enable 100Base-T FD 0=suppress 100/FD
+			   bit 15:	1=enable 100Base-T4 0=suppress 100-T4*/
+  GEN_id_hi = 0x02,	/* PHY Identifier Register 1   bit 0-15: High PHY identifier default=0000 for RTL8201BL*/
+  GEN_id_lo = 0x03,	/* PHY Identifier Register 2   bit 0-15: Low PHY identifier  default=8201 for RTL8201BL*/
+  AN_adv    = 0x04,	/* Auto-negotiation Advertisement Register */
+			/* bit 0-4:	Selector, only CSMA/CD<0001> is specified
+			   bit 5:	1=10Base-T is supported      0=10Base-T is not supported by local node
+			   bit 6:	1=10Base-T FD is supported   0=10Base-T FD is not supported by local node
+			   bit 7:	1=100Base-TX is supported    0=100Base-TX is not supported by local node
+			   bit 8:	1=100Base-TX FD is supported 0=100Base-TX FD is not supported by local node
+			   bit 9:	1=100Base-T4 is supported    0=100Base-T4 is not supported by local node
+			   bit10 :	1=iflow control is supported 0=flow control is not supported by local node
+			   bit11-12:	Reserved
+			   bit13:	1=advertise remote fault detectioncapability 0=do not advertise remote fault detection capability
+			   bit14:	1=ack reception of link partner capability data word 0=donot ack reception
+			   bit15:	1=transmitting the protocol specific data page 0=transmitting the primary capability data page*/
+  AN_lpa    = 0x05,	/* Auto-negotiation Link partner Ability Register */
+  AN_exp    = 0x06,	/* Auto-negotiation Expansion Register */
+  AN_np     = 0x07,	/* Auto-negotiation Next Page TX */
+  TST       = 0x19,     /* Test register, for checking link10/100 is established*/
+			/* bit 0:	1=Link 100Base Ok, 0=No 100Base link 
+			   bit 1:	1=Link 10Base Ok,  0=No 10Base link */
+
+};
+
+enum Mii_GEN_ctl
+{
+  RESET		= 0x8000,	/* Reset */
+  SPEED		= 0x2000,	/* 100 Mbit/s */
+  AUTONEG_ENB	= 0x1000,	/* Auto negotiation enabled */
+  POWER_DWN	= 0x800, 	/* Power-down enabled */
+  AUTONEG_REST	= 0x200,	/* Restart auto negotiation */
+  DUPLEX 	= 0x0100,	/* Duplex mode */
+};
+
+enum Mii_GEN_sts
+{
+  AUTOCMPLT 	= 0x0020,   	/* Autonegotiation completed */
+  LINK     	= 0x0004,   	/* Link status */
+};
+
+enum Mii_AN_adv
+{
+  CSMACD	= 0x1,		/* CSMA/CD protocol */
+  BASET10	= 0x20, 	/* 10 BaseT support */
+  BASET10FD	= 0x40, 	/* 10 BaseT full duplex support */
+  BASET100	= 0x80, 	/* 100 BaseT support */
+  BASET100FD	= 0x100, 	/* 100 BaseT full duplux support */
+  FLOWCONTROL	= 0x400, 	/* Flow control support */
+  RF		= 0x2000,	/* Remote fault support */
+};
+
+enum Mii_TST
+{
+  LINK100	= 0x1,		/* Link 100 status */
+  LINK10	= 0x2,		/* Link 10  status */
+};
+
+
+enum MacMiiAddrReg     		/* MII address register layout */
+{
+  MiiDevMask    = 0x0000F800,   /* MII device address */
+  MiiDevShift   = 11,
+
+  MiiRegMask    = 0x000007C0,   /* MII register */
+  MiiRegShift   = 6,
+
+  MiiWrite      = 0x00000002,   /* Write to register */
+  MiiRead       = 0,            /* Read from register */
+  MiiBusy       = 0x00000001,   /* MII interface is busy */
+};
+
+enum MacMiiDataReg     		/* MII address register layout */
+{
+  MiiDataMask   = 0x0000FFFF,   /* MII Data */
+};
+
+enum MacFlowControlReg 		/* MAC flow control register layout */
+{                                         /* Bit description                        R/W   Reset value */
+  MacPauseTimeMask        = 0xFFFF0000,   /* PAUSE TIME field in the control frame  RW      0000      */
+  MacPauseTimeShift       = 15,
+
+  MacControlFrameEnable   = 0x00000004,   /* Enable pass control frames to the host RW                */
+  MacControlFrameDisable  = 0,            /* Do not pass control frames to host               0       */
+
+  MacFlowControlEnable    = 0x00000002,   /* Enable flow control                    RW                */
+  MacFlowControlDisable   = 0,            /* Disable flow control                             0       */
+
+  MacSendPauseFrame       = 0x00000001,   /* send pause frame                       RW        0       */
+};
+
+/**********************************************************
+ * DMA Engine registers
+ **********************************************************/
+
+enum DmaBusModeReg         /* DMA bus mode register */
+{                                         /* Bit description                        R/W   Reset value */
+  DmaBigEndianDesc        = 0x00100000,   /* Big endian data buffer descriptors     RW                */
+  DmaLittleEndianDesc     = 0,            /* Little endian data descriptors                   0       */
+
+  DmaBurstLength32        = 0x00002000,   /* Dma burst length = 32                  RW                */
+  DmaBurstLength16        = 0x00001000,   /* Dma burst length = 16                                    */
+  DmaBurstLength8         = 0x00000800,   /* Dma burst length = 8                                     */
+  DmaBurstLength4         = 0x00000400,   /* Dma burst length = 4                                     */
+  DmaBurstLength2         = 0x00000200,   /* Dma burst length = 2                                     */
+  DmaBurstLength1         = 0x00000100,   /* Dma burst length = 1                                     */
+  DmaBurstLength0         = 0x00000000,   /* Dma burst length = 0                             0       */
+
+  DmaBigEndianData        = 0x00000080,   /* Big endian data buffers                RW                */
+  DmaLittleEndianData     = 0,            /* Little endian data buffers                       0       */
+
+  DmaDescriptorSkip16     = 0x00000040,   /* number of dwords to skip               RW                */
+  DmaDescriptorSkip8      = 0x00000020,   /* between two unchained descriptors                        */
+  DmaDescriptorSkip4      = 0x00000010,   /*                                                          */
+  DmaDescriptorSkip2      = 0x00000008,   /*                                                          */
+  DmaDescriptorSkip1      = 0x00000004,   /*                                                          */
+  DmaDescriptorSkip0      = 0,            /*                                                  0       */
+
+  DmaReceivePriorityOff   = 0x00000002,   /* equal rx and tx priorities             RW                */
+  DmaReceivePriorityOn    = 0,            /* Rx has prioryty over Tx                          0       */
+
+  DmaResetOn              = 0x00000001,   /* Reset DMA engine                       RW                */
+  DmaResetOff             = 0,            /*                                                  0       */
+};
+
+enum DmaStatusReg         /* DMA Status register */
+{                                         /* Bit description                        R/W   Reset value */
+  DmaRxAbort              = 0x01000000,   /* receiver bus abort                     R         0       */
+  DmaTxAbort              = 0x00800000,   /* transmitter bus abort                  R         0       */
+
+  DmaTxState              = 0x00700000,   /* Transmit process state                 R         000     */
+  DmaTxStopped            = 0x00000000,   /* Stopped                                                  */
+  DmaTxFetching           = 0x00100000,   /* Running - fetching the descriptor                        */
+  DmaTxWaiting            = 0x00200000,   /* Running - waiting for end of transmission                */
+  DmaTxReading            = 0x00300000,   /* Running - reading the data from memory                   */
+  DmaTxSuspended          = 0x00600000,   /* Suspended                                                */
+  DmaTxClosing            = 0x00700000,   /* Running - closing descriptor                             */
+
+  DmaRxState              = 0x000E0000,   /* Receive process state                  R         000     */
+  DmaRxStopped            = 0x00000000,   /* Stopped                                                  */
+  DmaRxFetching           = 0x00020000,   /* Running - fetching the descriptor                        */
+  DmaRxChecking           = 0x00040000,   /* Running - checking for end of packet                     */
+  DmaRxWaiting            = 0x00060000,   /* Running - waiting for packet                             */
+  DmaRxSuspended          = 0x00080000,   /* Suspended                                                */
+  DmaRxClosing            = 0x000A0000,   /* Running - closing descriptor                             */
+  DmaRxFlushing           = 0x000C0000,   /* Running - flushing the current frame                     */
+  DmaRxQueuing            = 0x000E0000,   /* Running - queuing the recieve frame into host memory     */
+
+  DmaIntNormal            = 0x00010000,   /* Normal interrupt summary               RW        0       */
+  DmaIntAbnormal          = 0x00008000,   /* Abnormal interrupt summary             RW        0       */
+
+  DmaIntEarlyRx           = 0x00004000,   /* Early receive interrupt (Normal)       RW        0       */
+  DmaIntBusError          = 0x00002000,   /* Fatal bus error (Abnormal)             RW        0       */
+  DmaIntEarlyTx           = 0x00000400,   /* Early transmit interrupt (Abnormal)    RW        0       */
+  DmaIntRxStopped         = 0x00000100,   /* Receive process stopped (Abnormal)     RW        0       */
+  DmaIntRxNoBuffer        = 0x00000080,   /* Receive buffer unavailable (Abnormal)  RW        0       */
+  DmaIntRxCompleted       = 0x00000040,   /* Completion of frame reception (Normal) RW        0       */
+  DmaIntTxUnderflow       = 0x00000020,   /* Transmit underflow (Abnormal)          RW        0       */
+  DmaIntTxNoBuffer        = 0x00000004,   /* Transmit buffer unavailable (Normal)   RW        0       */
+  DmaIntTxStopped         = 0x00000002,   /* Transmit process stopped (Abnormal)    RW        0       */
+  DmaIntTxCompleted       = 0x00000001,   /* Transmit completed (Normal)            RW        0       */
+};
+
+enum DmaControlReg        /* DMA control register */
+{                                         /* Bit description                        R/W   Reset value */
+  DmaStoreAndForward      = 0x00200000,   /* Store and forward                      RW        0       */
+  DmaTxStart              = 0x00002000,   /* Start/Stop transmission                RW        0       */
+  DmaTxSecondFrame        = 0x00000004,   /* Operate on second frame                RW        0       */
+  DmaRxStart              = 0x00000002,   /* Start/Stop reception                   RW        0       */
+};
+
+enum  DmaInterruptReg     /* DMA interrupt enable register */
+{                                         /* Bit description                        R/W   Reset value */
+  DmaIeNormal            = DmaIntNormal     ,   /* Normal interrupt enable                 RW        0       */
+  DmaIeAbnormal          = DmaIntAbnormal   ,   /* Abnormal interrupt enable               RW        0       */
+
+  DmaIeEarlyRx           = DmaIntEarlyRx    ,   /* Early receive interrupt enable          RW        0       */
+  DmaIeBusError          = DmaIntBusError   ,   /* Fatal bus error enable                  RW        0       */
+  DmaIeEarlyTx           = DmaIntEarlyTx    ,   /* Early transmit interrupt enable         RW        0       */
+  DmaIeRxStopped         = DmaIntRxStopped  ,   /* Receive process stopped enable          RW        0       */
+  DmaIeRxNoBuffer        = DmaIntRxNoBuffer ,   /* Receive buffer unavailable enable       RW        0       */
+  DmaIeRxCompleted       = DmaIntRxCompleted,   /* Completion of frame reception enable    RW        0       */
+  DmaIeTxUnderflow       = DmaIntTxUnderflow,   /* Transmit underflow enable               RW        0       */
+  DmaIeTxNoBuffer        = DmaIntTxNoBuffer ,   /* Transmit buffer unavailable enable      RW        0       */
+  DmaIeTxStopped         = DmaIntTxStopped  ,   /* Transmit process stopped enable         RW        0       */
+  DmaIeTxCompleted       = DmaIntTxCompleted,   /* Transmit completed enable               RW        0       */
+};
+
+/**********************************************************
+ * DMA Engine descriptors
+ **********************************************************/
+
+enum DmaDescriptorStatus    /* status word of DMA descriptor */
+{
+  DescOwnByDma          = 0x80000000,   /* Descriptor is owned by DMA engine  */
+  DescOwnByCPU          = 0x0,          /* Descriptor is owned by CPU  */
+
+  DescFilteringFail	= 0x40000000,   /* Filtering fail*/
+
+  DescFrameLengthMask   = 0x3FFF0000,   /* Receive descriptor frame length */
+  DescFrameLengthShift  = 16,
+
+  DescError             = 0x00008000,   /* Error summary bit  - OR of the following bits:    v  */
+
+  DescRxTruncated       = 0x00004000,   /* Rx - no more descriptors for receive frame        E  */
+  DescLengthError	= 0x00001000,   /* Rx - length doesn't match 			     E	*/
+  DescRxDamaged         = 0x00000800,   /* Rx - frame was damaged by a collision             E  */
+  DescRxMulticast       = 0x00000400,   /* Rx - received frame is multicast                     */
+  DescRxFirst           = 0x00000200,   /* Rx - first descriptor of the frame                   */
+  DescRxLast            = 0x00000100,   /* Rx - last descriptor of the frame                    */
+  DescRxLongFrame       = 0x00000080,   /* Rx - frame is longer than 1518 bytes              E  */
+  DescRxCollision       = 0x00000040,   /* Rx - frame was damaged by a collision             E  */
+  DescRxFrameEther      = 0x00000020,   /* Rx - Frame type - Ethernet, otherwise 802.3          */
+  DescRxMiiError        = 0x00000008,   /* Rx - error reported by MII interface              E  */
+  DescRxDribbling       = 0x00000004,   /* Rx - frame contains noninteger multiple of 8 bits    */
+  DescRxCrc             = 0x00000002,   /* Rx - CRC error                                    E  */
+
+  DescTxTimeout         = 0x00004000,   /* Tx - Transmit jabber timeout                      E  */
+  DescTxLostCarrier     = 0x00000800,   /* Tx - carrier lost during tramsmission             E  */
+  DescTxNoCarrier       = 0x00000400,   /* Tx - no carrier signal from the tranceiver        E  */
+  DescTxLateCollision   = 0x00000200,   /* Tx - transmission aborted due to collision        E  */
+  DescTxExcCollisions   = 0x00000100,   /* Tx - transmission aborted after 16 collisions     E  */
+  DescTxHeartbeatFail   = 0x00000080,   /* Tx - heartbeat collision check failure               */
+  DescTxCollMask        = 0x00000078,   /* Tx - Collision count                                 */
+  DescTxCollShift       = 3,
+  DescTxExcDeferral     = 0x00000004,   /* Tx - excessive deferral                           E  */
+  DescTxUnderflow       = 0x00000002,   /* Tx - late data arrival from the memory            E  */
+  DescTxDeferred        = 0x00000001,   /* Tx - frame transmision deferred                      */
+};
+
+enum DmaDescriptorLength    /* length word of DMA descriptor */
+{
+  DescTxIntEnable       = 0x80000000,   /* Tx - interrupt on completion                         */
+  DescTxLast            = 0x40000000,   /* Tx - Last segment of the frame                       */
+  DescTxFirst           = 0x20000000,   /* Tx - First segment of the frame                      */
+  DescTxDisableCrc      = 0x04000000,   /* Tx - Add CRC disabled (first segment only)           */
+
+  DescEndOfRing         = 0x02000000,   /* End of descriptors ring                              */
+  DescChain             = 0x01000000,   /* Second buffer address is chain address               */
+
+  DescSize2Mask         = 0x003FF800,   /* Buffer 2 size                                        */
+  DescSize2Shift        = 11,
+  DescSize1Mask         = 0x000007FF,   /* Buffer 1 size                                        */
+  DescSize1Shift        = 0,
+};
+
+/**********************************************************
+ * Initial register values
+ **********************************************************/
+
+enum InitialRegisters
+{
+  MacControlInitFdx       /* Full-duplex mode with perfect filter on */
+                          = MacFilterOn           | MacLittleEndian         | MacHeartBeatOn      | MacSelectMii
+                          | MacEnableRxOwn        | MacLoopbackOff          | MacFullDuplex       | MacMulticastFilterOn
+                          | MacPromiscuousModeOff | MacFilterNormal         | MacBadFramesDisable | MacPerfectFilterOn
+                          | MacHashFilterOff      | MacLateCollisionOff     | MacBroadcastEnable  | MacRetryEnable
+                          | MacPadStripDisable    | MacDeferralCheckDisable | MacTxEnable         | MacRxEnable,
+
+  MacFlowControlInitFdx   /* Full-duplex mode */
+                          = MacControlFrameDisable | MacFlowControlEnable,
+
+  MacControlInitHdx       /* Half-duplex mode with perfect filter on */
+                          = MacFilterOn           | MacLittleEndian         | MacHeartBeatOn      | MacSelectMii
+                          | MacDisableRxOwn       | MacLoopbackOff          | MacHalfDuplex       | MacMulticastFilterOn 
+                          | MacPromiscuousModeOff | MacFilterNormal         | MacBadFramesDisable | MacPerfectFilterOn
+                          | MacHashFilterOff      | MacLateCollisionOff     | MacBroadcastEnable  | MacRetryEnable
+                          | MacPadStripDisable    | MacDeferralCheckDisable | MacTxEnable         | MacRxEnable,
+
+  MacFlowControlInitHdx   /* Half-duplex mode */
+                          = MacControlFrameDisable | MacFlowControlDisable,
+
+  DmaBusModeInit          /* Little-endian mode */
+                          = DmaLittleEndianDesc   | DmaBurstLength8         | DmaLittleEndianData | DmaDescriptorSkip2
+                          | DmaReceivePriorityOn  | DmaResetOff,
+
+  DmaControlInit100       /* 100 Mb/s mode */
+                          = DmaStoreAndForward,
+
+  DmaControlInit10        /* 10 Mb/s mode */
+                          = DmaStoreAndForward,
+
+                          /* Interrupt groups */
+  DmaIntErrorMask         = DmaIntBusError,           /* Error */
+  DmaIntRxAbnMask         = DmaIntRxNoBuffer,         /* receiver abnormal interrupt */
+  DmaIntRxNormMask        = DmaIntRxCompleted,        /* receiver normal interrupt   */
+  DmaIntRxStoppedMask     = DmaIntRxStopped,          /* receiver stopped */
+  DmaIntTxAbnMask         = DmaIntTxUnderflow,        /* transmitter abnormal interrupt */
+  DmaIntTxNormMask        = DmaIntTxCompleted,        /* transmitter normal interrupt */
+  DmaIntTxStoppedMask     = DmaIntTxStopped,          /* receiver stopped */
+
+  DmaIntEnable            = DmaIeNormal | DmaIeAbnormal
+                          | DmaIntErrorMask
+                          | DmaIntRxAbnMask | DmaIntRxNormMask | DmaIntRxStoppedMask
+                          | DmaIntTxAbnMask | DmaIntTxNormMask | DmaIntTxStoppedMask,
+
+  DmaIntDisable           = 0,
+};
+
+/* some status test functions */
+static inline int em86xx_dma_rx_valid( u32 Status )
+{
+  return ( (Status & DescError) == 0 )      /* no errors, whole frame is in the buffer */
+      && ( (Status & DescRxFirst) != 0 )
+      && ( (Status & DescRxLast) != 0 );
+}
+
+static inline u32 em86xx_dma_rx_length( u32 Status )
+{
+  return (Status & DescFrameLengthMask) >> DescFrameLengthShift;
+}
+
+static inline int em86xx_dma_rx_collisions( u32 Status )
+{
+  if( Status & (DescRxDamaged | DescRxCollision) ) return 1;
+    return 0;
+}
+
+static inline int em86xx_dma_rx_crc( u32 Status )
+{
+  if( Status & DescRxCrc ) return 1;
+    return 0;
+}
+
+static inline int em86xx_dma_tx_valid( u32 Status )   /* Test the status word if the descriptor is valid */
+{
+  return ( (Status & DescError) == 0 );
+}
+
+static inline int em86xx_dma_tx_collisions( u32 Status )
+{
+  return (Status & DescTxCollMask) >> DescTxCollShift;
+}
+
+static inline int em86xx_dma_tx_aborted( u32 Status )
+{
+  if( Status & (DescTxLateCollision | DescTxExcCollisions )) return 1;
+    return 0;
+}
+
+static inline int em86xx_dma_tx_carrier( u32 Status )
+{
+  if( Status & (DescTxLostCarrier | DescTxNoCarrier )) return 1;
+    return 0;
+}
+
+static inline int em86xx_rdesc_owned_by_host(volatile struct em86xx_desc *desc)
+{
+  return((desc->desc0 & 0x80000000) ? 0 : 1);
+}
+
+static inline int em86xx_rdesc_last_desc(volatile struct em86xx_desc *desc)
+{
+  return(desc->desc0 & 0x00000100);
+}
+
+static inline int em86xx_rdesc_first_desc(volatile struct em86xx_desc *desc)
+{
+  return(desc->desc0 & 0x00000200);
+}
+
+static inline unsigned long em86xx_rdesc_frame_len(volatile struct em86xx_desc *desc)
+{
+  return((desc->desc0 & 0x3fff0000) >> 16);
+}
+
+static inline int em86xx_tdesc_owned_by_host(volatile struct em86xx_desc *desc)
+{
+  return((desc->desc0 & 0x80000000) ? 0 : 1);
+}
+
+static u32 __inline__ em86xx_read_reg( u32 Reg )
+{
+#ifdef CONFIG_TANGOX
+       u32 data = gbus_readl(Reg);
+	u32 tmp = 0;
+	extern int is_tango2_es6(void);
+	if (is_tango2_es6()) 
+		tmp = gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt);
+#else
+       u32 data = __raw_readl(Reg);
+#endif
+
+//        printk("read data=0x%08x from addr=0x%08x\n", data, Reg);
+        return data;
+}
+
+static u32 em86xx_read_mac_reg(u32 Reg)
+{
+	return em86xx_read_reg( EM86XX_ETHMAC_BASE + Reg );
+}
+
+static u32 em86xx_read_dma_reg(u32 Reg)
+{
+	return em86xx_read_reg( EM86XX_ETHDMA_BASE + Reg );
+}
+
+static void __inline__ em86xx_write_reg( u32 Reg, u32 Data )
+{
+//       printk("write data=0x%08x to addr=0x%08x\n", Data, Reg);
+#ifdef CONFIG_TANGOX
+        gbus_writel(Reg, Data);
+#else
+        __raw_writel(Data,Reg);
+#endif
+}
+
+static void em86xx_write_mac_reg(u32 Reg, u32 Data)
+{
+	em86xx_write_reg( EM86XX_ETHMAC_BASE + Reg, Data );
+}
+
+static void em86xx_write_dma_reg(u32 Reg, u32 Data)
+{
+	em86xx_write_reg( EM86XX_ETHDMA_BASE + Reg, Data );
+}
+
+
+static void __inline__ em86xx_set_reg( u32 reg, u32 data )
+{
+
+#ifdef CONFIG_TANGOX
+	data |= gbus_readl(reg);
+	gbus_writel(reg, data);
+#else
+	data |= __raw_readl(reg);
+	__raw_writel(data, reg);
+#endif
+}
+
+static void __inline__ em86xx_clear_reg( u32 reg, u32 data )
+{
+#ifdef CONFIG_TANGOX
+	gbus_writel(reg,  (gbus_readl(reg) & (~data)));
+#else
+	__raw_writel(( __raw_readl(reg) & (~data)), reg);
+#endif
+}
+
+
+/* There are two registers, MII address (EM86XX_MIIAR_REG) and 
+   MII data (EM86XX_MIIDR_REG), for accessing PHY registers.
+
+   In order to access  mii register data, one need to program the
+   MII address and wait till MII not busy.
+   
+   MII address register description:
+	bit 31-16	reserved
+	bit 15-11	PHY address
+	bit 10-6	MII Register one want to access 
+	bit 1		0:MII read 1:MII write
+	bit 0		0:MII not busy 1:MII busy
+*/
+static inline u16 em86xx_mii_read(int phy_addr, u8 Reg )
+{
+        u32 addr;
+        u16 data;
+
+#ifdef CONFIG_TANGOX
+	u32 count = 100;
+#endif
+
+        addr = ((phy_addr << MiiDevShift) & MiiDevMask) |
+        	((Reg << MiiRegShift) & MiiRegMask);
+        em86xx_write_reg(EM86XX_MIIAR_REG, addr );
+
+#ifdef CONFIG_TANGOX
+	do{
+		udelay(1);
+		count --;
+		if(count == 0) break;
+	} while( (em86xx_read_reg(EM86XX_MIIAR_REG ) & MiiBusy) == MiiBusy );
+#else
+        do{} while( (em86xx_read_reg(EM86XX_MIIAR_REG ) & MiiBusy) == MiiBusy );
+#endif
+
+        data = em86xx_read_reg(EM86XX_MIIDR_REG ) & 0xFFFF;
+/* 	printk("em86xx_mii_read: addr %d - reg %d - value: %04x\n", */
+/* 	       phy_addr, Reg, data); */
+        return data;
+}
+
+#ifndef BOOTLOADER
+static void em86xx_mii_write(int phy_addr, u8 Reg, u16 Data )
+{
+        u32 addr;
+
+#ifdef CONFIG_TANGOX
+	u32 count = 100;
+#endif
+
+        em86xx_write_reg( EM86XX_MIIDR_REG, Data );
+        addr = ((phy_addr << MiiDevShift) & MiiDevMask) |
+               ((Reg << MiiRegShift) & MiiRegMask) |
+                 MiiWrite;
+
+        em86xx_write_reg( EM86XX_MIIAR_REG, addr );
+
+#ifdef CONFIG_TANGOX
+	do{
+		udelay(1);
+		count --;
+		if(count == 0) break;
+	} while( (em86xx_read_reg(EM86XX_MIIAR_REG ) & MiiBusy) == MiiBusy );
+#else
+        do{} while( (em86xx_read_reg(EM86XX_MIIAR_REG ) & MiiBusy) == MiiBusy );
+#endif
+
+/* 	printk("em86xx_write_read: addr %d - reg %d - data: %04x\n", */
+/* 	       phy_addr, Reg, Data); */
+
+}
+#endif
+#if 0 /* for debug purpose*/
+static void mac_dump(void)
+{
+	int i;
+	u32 data, addr;
+	addr = 0;
+	printk("*********************** MAC Registers *************************\n");
+        for(i = 0; i < 12; i++) {
+		data = em86xx_read_mac_reg(addr);		
+        	if(!(i%4))
+                	printk( "0x%08x  ", addr);
+	        printk( "%08x ", data );
+        	if(!((i+1)%4))
+                	printk("\n");
+       		 addr += 4;
+	}
+}
+static void dma_dump(void)
+{
+	int i;
+	u32 data, addr;
+	addr = 0;
+	printk("*********************** DMA Registers *************************\n");
+        for(i = 0; i < 24; i++) {
+		data = em86xx_read_dma_reg(addr);		
+        	if(!(i%4))
+                	printk( "0x%08x  ", addr);
+	        printk( "%08x ", data );
+        	if(!((i+1)%4))
+                	printk("\n");
+       		 addr += 4;
+	}
+
+}
+static void rx_desc_dump(void)
+{
+	int i;
+	u32 data, addr;
+	addr = em86xx_read_reg(EM86XX_RLBAR_REG);
+	printk("*********************** RX DESC *************************\n");
+        for(i = 0; i < 128; i++) {
+		data = em86xx_read_reg(addr);		
+        	if(!(i%4))
+                	printk( "0x%08x  ", addr);
+	        printk( "%08x ", data );
+        	if(!((i+1)%4))
+                	printk("\n");
+       		 addr += 4;
+	}
+}
+static void tx_desc_dump(void) 
+{
+	int i;
+	u32 data, addr;
+	addr = em86xx_read_reg(EM86XX_TLBAR_REG);
+	printk("*********************** TX DESC *************************\n");
+        for(i = 0; i < 128; i++) {
+		data = em86xx_read_reg(addr);		
+        	if(!(i%4))
+                	printk( "0x%08x  ", addr);
+	        printk( "%08x ", data );
+        	if(!((i+1)%4))
+                	printk("\n");
+       		 addr += 4;
+	}
+}
+#endif /* #if 0*/
+#endif /* !__ASSEMBLY__ */
+#endif /* __EM86XX_ETH_H__ */
+
diff -Naur linux-2.6.30-ori/drivers/serial/8250.c linux-2.6.30-test/drivers/serial/8250.c
--- linux-2.6.30-ori/drivers/serial/8250.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/serial/8250.c	2009-06-12 18:32:43.000000000 -0400
@@ -39,6 +39,20 @@
 #include <linux/nmi.h>
 #include <linux/mutex.h>
 
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/rmdefs.h>
+#include <asm/tango2/tango2_gbus.h>
+#include <asm/tango2/tango2.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/rmdefs.h>
+#include <asm/tango3/tango3_gbus.h>
+#include <asm/tango3/tango3.h>
+#endif
+
+#ifdef CONFIG_TANGOX
+extern unsigned long tangox_get_sysclock(void);
+#endif
+
 #include <asm/io.h>
 #include <asm/irq.h>
 
@@ -388,13 +402,48 @@
 static unsigned int mem_serial_in(struct uart_port *p, int offset)
 {
 	offset = map_8250_in_reg(p, offset) << p->regshift;
+#ifdef CONFIG_TANGOX
+	{
+		unsigned long v;
+
+		/* no EFR on tango2/tango3 */
+		if (offset == (UART_EFR << p->regshift))
+			v = 0;
+		else
+			v = gbus_readl((unsigned long)p->membase +
+				       offset);
+		return v;
+	}
+#else
 	return readb(p->membase + offset);
+#endif
 }
 
 static void mem_serial_out(struct uart_port *p, int offset, int value)
 {
 	offset = map_8250_out_reg(p, offset) << p->regshift;
+#ifdef CONFIG_TANGOX
+		/*
+		 * we add  a special case for  UART_DL register, since
+		 * register content has a different meaning for us.
+		 */
+		if (offset == (UART_DL << p->regshift)) {
+			/* select right clock source */
+#ifdef CONFIG_TANGOX_UART_USE_SYSCLK
+			value = (tangox_get_sysclock() / p->uartclk);
+#else
+			value = (TANGOX_BASE_FREQUENCY / p->uartclk) + 1;
+#endif
+		}
+
+		/* no EFR on tango2/tango3 */
+		if (offset != (UART_EFR << p->regshift))
+			gbus_writel((unsigned long)p->membase +
+				    offset, value);
+		return;
+#else
 	writeb(value, p->membase + offset);
+#endif
 }
 
 static void mem32_serial_out(struct uart_port *p, int offset, int value)
@@ -547,19 +596,6 @@
 #define serial_inp(up, offset)		serial_in(up, offset)
 #define serial_outp(up, offset, value)	serial_out(up, offset, value)
 
-/* Uart divisor latch read */
-static inline int _serial_dl_read(struct uart_8250_port *up)
-{
-	return serial_inp(up, UART_DLL) | serial_inp(up, UART_DLM) << 8;
-}
-
-/* Uart divisor latch write */
-static inline void _serial_dl_write(struct uart_8250_port *up, int value)
-{
-	serial_outp(up, UART_DLL, value & 0xff);
-	serial_outp(up, UART_DLM, value >> 8 & 0xff);
-}
-
 #if defined(CONFIG_SERIAL_8250_AU1X00)
 /* Au1x00 haven't got a standard divisor latch */
 static int serial_dl_read(struct uart_8250_port *up)
@@ -595,7 +631,30 @@
 		_serial_dl_write(up, value);
 	}
 }
+#elif defined(CONFIG_TANGOX)
+static inline int serial_dl_read(struct uart_8250_port *up)
+{
+	return serial_inp(up, UART_DL);
+}
+
+/* Uart divisor latch write */
+static inline void serial_dl_write(struct uart_8250_port *up, int value)
+{
+	serial_outp(up, UART_DL, value);
+}
 #else
+/* Uart divisor latch read */
+static inline int _serial_dl_read(struct uart_8250_port *up)
+{
+	return serial_inp(up, UART_DLL) | serial_inp(up, UART_DLM) << 8;
+}
+
+/* Uart divisor latch write */
+static inline void _serial_dl_write(struct uart_8250_port *up, int value)
+{
+	serial_outp(up, UART_DLL, value & 0xff);
+	serial_outp(up, UART_DLM, value >> 8 & 0xff);
+}
 #define serial_dl_read(up) _serial_dl_read(up)
 #define serial_dl_write(up, value) _serial_dl_write(up, value)
 #endif
@@ -774,6 +833,16 @@
 	old_lcr = serial_inp(p, UART_LCR);
 	serial_outp(p, UART_LCR, UART_LCR_DLAB);
 
+#ifdef CONFIG_TANGOX
+	old_dll = serial_inp(p, UART_DL) & 0xff;
+	old_dlm = serial_inp(p, UART_DL) >> 8;
+
+	serial_outp(p, UART_DL, 0);
+
+	id = serial_inp(p, UART_DL);
+
+	serial_outp(p, UART_DL, (old_dlm << 8) | old_dll);
+#else
 	old_dll = serial_inp(p, UART_DLL);
 	old_dlm = serial_inp(p, UART_DLM);
 
@@ -784,6 +853,7 @@
 
 	serial_outp(p, UART_DLL, old_dll);
 	serial_outp(p, UART_DLM, old_dlm);
+#endif
 	serial_outp(p, UART_LCR, old_lcr);
 
 	return id;
@@ -1076,7 +1146,6 @@
 	unsigned char status1, scratch, scratch2, scratch3;
 	unsigned char save_lcr, save_mcr;
 	unsigned long flags;
-
 	if (!up->port.iobase && !up->port.mapbase && !up->port.membase)
 		return;
 
@@ -2267,7 +2336,6 @@
 	 */
 	baud = uart_get_baud_rate(port, termios, old, 0, port->uartclk/16);
 	quot = serial8250_get_divisor(port, baud);
-
 	/*
 	 * Oxford Semi 952 rev B workaround
 	 */
@@ -2636,11 +2704,11 @@
 	struct uart_8250_port *up;
 	static int first = 1;
 	int i;
-
 	if (!first)
 		return;
 	first = 0;
 
+
 	for (i = 0; i < nr_uarts; i++) {
 		struct uart_8250_port *up = &serial8250_ports[i];
 
diff -Naur linux-2.6.30-ori/drivers/serial/8250_early.c linux-2.6.30-test/drivers/serial/8250_early.c
--- linux-2.6.30-ori/drivers/serial/8250_early.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/serial/8250_early.c	2009-06-12 18:32:43.000000000 -0400
@@ -106,8 +106,13 @@
 
 	lcr = serial_in(port, UART_LCR);
 	serial_out(port, UART_LCR, lcr | UART_LCR_DLAB);
+#ifdef CONFIG_TANGOX
+	dll = serial_in(port, UART_DL) & 0xff;
+	dlm = serial_in(port, UART_DL) >> 8;
+#else
 	dll = serial_in(port, UART_DLL);
 	dlm = serial_in(port, UART_DLM);
+#endif
 	serial_out(port, UART_LCR, lcr);
 
 	quot = (dlm << 8) | dll;
@@ -128,8 +133,12 @@
 	divisor = port->uartclk / (16 * device->baud);
 	c = serial_in(port, UART_LCR);
 	serial_out(port, UART_LCR, c | UART_LCR_DLAB);
+#ifdef CONFIG_TANGOX
+	serial_out(port, UART_DL, divisor & 0xffff);
+#else
 	serial_out(port, UART_DLL, divisor & 0xff);
 	serial_out(port, UART_DLM, (divisor >> 8) & 0xff);
+#endif
 	serial_out(port, UART_LCR, c & ~UART_LCR_DLAB);
 }
 
diff -Naur linux-2.6.30-ori/drivers/serial/serial_core.c linux-2.6.30-test/drivers/serial/serial_core.c
--- linux-2.6.30-ori/drivers/serial/serial_core.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/serial/serial_core.c	2009-06-12 18:32:43.000000000 -0400
@@ -396,7 +396,8 @@
 			tty_termios_encode_baud_rate(termios, 9600, 9600);
 	}
 
-	return 0;
+//	return 0;
+	return baud;
 }
 
 EXPORT_SYMBOL(uart_get_baud_rate);
@@ -421,7 +422,8 @@
 	else
 		quot = (port->uartclk + (8 * baud)) / (16 * baud);
 
-	return quot;
+//	return quot;
+	return (quot ? quot : 1);
 }
 
 EXPORT_SYMBOL(uart_get_divisor);
diff -Naur linux-2.6.30-ori/drivers/usb/Kconfig linux-2.6.30-test/drivers/usb/Kconfig
--- linux-2.6.30-ori/drivers/usb/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -43,6 +43,7 @@
 	default y if PPC_MPC52xx
 	# MIPS:
 	default y if SOC_AU1X00
+	default y if TANGOX
 	# SH:
 	default y if CPU_SUBTYPE_SH7720
 	default y if CPU_SUBTYPE_SH7721
@@ -56,6 +57,7 @@
 	boolean
 	default y if PPC_83xx
 	default y if SOC_AU1200
+	default y if TANGOX				
 	default y if ARCH_IXP4XX
 	default PCI
 
diff -Naur linux-2.6.30-ori/drivers/usb/Makefile linux-2.6.30-test/drivers/usb/Makefile
--- linux-2.6.30-ori/drivers/usb/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -19,6 +19,8 @@
 obj-$(CONFIG_USB_R8A66597_HCD)	+= host/
 obj-$(CONFIG_USB_HWA_HCD)	+= host/
 obj-$(CONFIG_USB_ISP1760_HCD)	+= host/
+obj-$(CONFIG_TANGOX_EHCI_HCD)	+= host/
+obj-$(CONFIG_TANGOX_OHCI_HCD)	+= host/
 
 obj-$(CONFIG_USB_C67X00_HCD)	+= c67x00/
 
diff -Naur linux-2.6.30-ori/drivers/usb/Makefile.orig linux-2.6.30-test/drivers/usb/Makefile.orig
--- linux-2.6.30-ori/drivers/usb/Makefile.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/usb/Makefile.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,43 @@
+#
+# Makefile for the kernel USB device drivers.
+#
+
+# Object files in subdirectories
+
+obj-$(CONFIG_USB)		+= core/
+
+obj-$(CONFIG_USB_MON)		+= mon/
+
+obj-$(CONFIG_PCI)		+= host/
+obj-$(CONFIG_USB_EHCI_HCD)	+= host/
+obj-$(CONFIG_USB_ISP116X_HCD)	+= host/
+obj-$(CONFIG_USB_OHCI_HCD)	+= host/
+obj-$(CONFIG_USB_UHCI_HCD)	+= host/
+obj-$(CONFIG_USB_FHCI_HCD)	+= host/
+obj-$(CONFIG_USB_SL811_HCD)	+= host/
+obj-$(CONFIG_USB_U132_HCD)	+= host/
+obj-$(CONFIG_USB_R8A66597_HCD)	+= host/
+obj-$(CONFIG_USB_HWA_HCD)	+= host/
+obj-$(CONFIG_USB_ISP1760_HCD)	+= host/
+
+obj-$(CONFIG_USB_C67X00_HCD)	+= c67x00/
+
+obj-$(CONFIG_USB_WUSB)		+= wusbcore/
+
+obj-$(CONFIG_USB_ACM)		+= class/
+obj-$(CONFIG_USB_PRINTER)	+= class/
+obj-$(CONFIG_USB_WDM)		+= class/
+obj-$(CONFIG_USB_TMC)		+= class/
+
+obj-$(CONFIG_USB_STORAGE)	+= storage/
+obj-$(CONFIG_USB)		+= storage/
+
+obj-$(CONFIG_USB_MDC800)	+= image/
+obj-$(CONFIG_USB_MICROTEK)	+= image/
+
+obj-$(CONFIG_USB_SERIAL)	+= serial/
+
+obj-$(CONFIG_USB)		+= misc/
+
+obj-$(CONFIG_USB_ATM)		+= atm/
+obj-$(CONFIG_USB_SPEEDTOUCH)	+= atm/
diff -Naur linux-2.6.30-ori/drivers/usb/core/Makefile linux-2.6.30-test/drivers/usb/core/Makefile
--- linux-2.6.30-ori/drivers/usb/core/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/core/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -14,6 +14,10 @@
 	usbcore-objs	+= inode.o devices.o
 endif
 
+ifeq ($(CONFIG_TANGOX),y)
+        usbcore-objs    += tangox-usb.o
+endif
+
 obj-$(CONFIG_USB)	+= usbcore.o
 
 ifeq ($(CONFIG_USB_DEBUG),y)
diff -Naur linux-2.6.30-ori/drivers/usb/core/tangox-usb.c linux-2.6.30-test/drivers/usb/core/tangox-usb.c
--- linux-2.6.30-ori/drivers/usb/core/tangox-usb.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/usb/core/tangox-usb.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,98 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/usb.h>
+
+#include "tangox-usb.h"
+
+#undef DEBUG
+
+#ifdef DEBUG
+#define DBG(x...) printk(x)
+#else
+#define DBG(x...)
+#endif
+
+void tangox_usb_init(void)
+{
+        int  i;
+        unsigned long temp;
+#ifdef CONFIG_TANGOX_XENV_READ
+	if (!tangox_usb_enabled())
+		return;
+#endif
+	/*check see if it's inited*/
+        temp = gbus_read_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + 0x0);
+	if(temp && (1<<19)){
+		printk("TangoX USB was initialized.\n");
+		return;
+	}
+	else
+		printk("TangoX USB initializing...\n");
+
+	/*
+	1. Program the clean divider and clock multiplexer to provide 
+	   a 48 MHz reference to the USB block.
+	   This is done in bootloader.
+	*/
+
+
+#if 0   /* If you want to use external crystal at 24MHZ*/
+	printk("TangoX USB using 24MHz external crystal.\n");
+        gbus_write_uint32(pGBus , REG_BASE_system_block + SYS_hostclk_mux, 0x300);
+        gbus_write_uint32(pGBus , TANGOX_USB_CTL_STATUS_REG_BASE + 0x0, 0x70);
+	wait_ms(5);
+        gbus_write_uint32(pGBus , TANGOX_USB_CTL_STATUS_REG_BASE + 0xc, 0xf9931);
+	wait_ms(30);
+#endif
+
+        /*2. PHY software reset*/
+        DBG("Performing PHY Reseting...\n");
+        temp = gbus_read_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + 0x0);
+        gbus_write_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + 0x0, temp | 0x01);
+        udelay (30);
+        gbus_write_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + 0x0, temp);
+        wait_ms(5);
+
+	/*3. Reset Bit 1 of USB register 0x21700 to enable the USB Host controller.
+	     This is done in bootloader 
+	*/
+
+        /*4. OHCI Software reset*/
+        DBG("Performing USB OHCI Reseting...\n");
+        temp = gbus_read_uint32(pGBus, TANGOX_OHCI_BASE_ADDR + 0x08);
+        gbus_write_uint32(pGBus, TANGOX_OHCI_BASE_ADDR + 0x08,  temp | 0x01);
+        wait_ms(5);
+
+        /*5. OHCI DPLL Software reset, it says the bit is for simulation*/
+        DBG("Performing USB OHCI DPLL Reseting...\n");
+        temp = gbus_read_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + 0x0);
+        gbus_write_uint32(pGBus,  TANGOX_USB_CTL_STATUS_REG_BASE + 0x0, temp | (1<<19));
+        wait_ms(5);
+	
+	/*6. EHCI Host Software Reset*/
+        DBG("Performing USB EHCI Reseting...\n");
+        temp = gbus_read_uint32(pGBus, TANGOX_EHCI_BASE_ADDR + 0x10);
+        gbus_write_uint32(pGBus, TANGOX_EHCI_BASE_ADDR + 0x10,  temp | 0x02);
+        wait_ms(5);
+
+        for(i = 0; i < 4; i++){
+                temp = gbus_read_uint32(pGBus, TANGOX_USB_CTL_STATUS_REG_BASE + i*4);
+                DBG("TangoX USB register %d = 0x%x\n", i, temp);
+        }
+
+        return;
+}
+
+EXPORT_SYMBOL(tangox_usb_init);
+
diff -Naur linux-2.6.30-ori/drivers/usb/core/tangox-usb.h linux-2.6.30-test/drivers/usb/core/tangox-usb.h
--- linux-2.6.30-ori/drivers/usb/core/tangox-usb.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/usb/core/tangox-usb.h	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,78 @@
+/*********************************************************************
+ Copyright (C) 2001-2007
+ Sigma Designs, Inc. All Rights Reserved
+
+ This program is free software; you can redistribute it and/or modify
+ it under the terms of the GNU General Public License version 2 as
+ published by the Free Software Foundation.
+ *********************************************************************/
+#ifndef __TANGOX_USB_H
+#define __TANGOX_USB_H
+ 
+#include <asm/addrspace.h>
+
+#ifdef CONFIG_TANGO2
+#include <asm/tango2/hardware.h>
+#include <asm/tango2/tango2_gbus.h>
+#elif defined(CONFIG_TANGO3)
+#include <asm/tango3/hardware.h>
+#include <asm/tango3/tango3_gbus.h>
+#endif
+
+#define NON_CACHED(x)                   KSEG1ADDR((u32)(x))
+#define CACHED(x)                       KSEG0ADDR((u32)(x))
+
+
+#define TANGOX_EHCI_BASE_ADDR           /*NON_CACHED*/(REG_BASE_host_interface + 0x1400)
+#define TANGOX_OHCI_BASE_ADDR           /*NON_CACHED*/(REG_BASE_host_interface + 0x1500)
+#define TANGOX_USB_CTL_STATUS_REG_BASE  /*NON_CACHED*/(REG_BASE_host_interface + 0x1700)
+#define TANGOX_EHCI_IRQ                 IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_EHCI_INT
+#define TANGOX_OHCI_IRQ                 IRQ_CONTROLLER_IRQ_BASE + LOG2_CPU_USB_OHCI_INT
+
+/* tangox ehci */
+#define TANGOX_EHCI_BUS_NAME 		"tangox-ehci-bus"
+#define TANGOX_EHCI_PRODUCT_DESC 	"TangoX Integrated USB 2.0"
+#define hcd_name	 		"tangox-ehci-hcd"
+/* tangox ohci */
+#define ohci_hcd_name	 		"tangox-ohci-hcd"
+#define TANGOX_OHCI_BUS_NAME 		"tangox-ohci-bus"
+
+
+static u32 __inline__ tangox_read_reg( u32 Reg )
+{
+#ifdef CONFIG_TANGOX
+        u32 data = gbus_readl(Reg);
+#else
+        u32 data = __raw_readl(Reg);
+#endif
+
+//        printk("read data=0x%08x from addr=0x%08x\n", data, Reg);
+        return data;
+}
+
+static void __inline__ tangox_write_reg( u32 Reg, u32 Data )
+{
+//       printk("write data=0x%08x to addr=0x%08x\n", Data, Reg);
+#ifdef CONFIG_TANGOX
+        gbus_writel(Reg, Data);
+#else
+        __raw_writel(Data,Reg);
+#endif
+}
+
+static __inline__ void wait_ms(unsigned int ms)
+{
+        if(!in_interrupt()) {
+                current->state = TASK_UNINTERRUPTIBLE;
+                schedule_timeout(1 + ms * HZ / 1000);
+        }
+        else
+                mdelay(ms);
+}
+#ifdef CONFIG_TANGOX_XENV_READ
+extern int tangox_usb_enabled(void);
+#endif
+extern int is_tango2_es89(void);
+extern int is_tango3_chip(void);
+extern void tangox_usb_init (void);
+#endif
diff -Naur linux-2.6.30-ori/drivers/usb/host/Kconfig linux-2.6.30-test/drivers/usb/host/Kconfig
--- linux-2.6.30-ori/drivers/usb/host/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/host/Kconfig	2009-06-12 18:32:43.000000000 -0400
@@ -41,7 +41,7 @@
 
 config USB_EHCI_ROOT_HUB_TT
 	bool "Root Hub Transaction Translators"
-	depends on USB_EHCI_HCD
+	depends on (USB_EHCI_HCD || TANGOX_EHCI_HCD)
 	---help---
 	  Some EHCI chips have vendor-specific extensions to integrate
 	  transaction translators, so that no OHCI or UHCI companion
@@ -135,7 +135,7 @@
 
 config USB_OHCI_HCD
 	tristate "OHCI HCD support"
-	depends on USB && USB_ARCH_HAS_OHCI
+	depends on USB && (USB_ARCH_HAS_OHCI || PCI)
 	select ISP1301_OMAP if MACH_OMAP_H2 || MACH_OMAP_H3
 	select USB_OTG_UTILS if ARCH_OMAP
 	---help---
diff -Naur linux-2.6.30-ori/drivers/usb/host/ehci-hcd.c linux-2.6.30-test/drivers/usb/host/ehci-hcd.c
--- linux-2.6.30-ori/drivers/usb/host/ehci-hcd.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/host/ehci-hcd.c	2009-06-12 18:32:43.000000000 -0400
@@ -1072,6 +1072,12 @@
 #define	PLATFORM_DRIVER		ixp4xx_ehci_driver
 #endif
 
+#ifdef CONFIG_TANGOX
+#include "ehci-tangox.c"
+#define	PLATFORM_DRIVER		ehci_hcd_tangox_driver
+#endif
+
+
 #if !defined(PCI_DRIVER) && !defined(PLATFORM_DRIVER) && \
     !defined(PS3_SYSTEM_BUS_DRIVER) && !defined(OF_PLATFORM_DRIVER)
 #error "missing bus glue for ehci-hcd"
diff -Naur linux-2.6.30-ori/drivers/usb/host/ehci-hub.c linux-2.6.30-test/drivers/usb/host/ehci-hub.c
--- linux-2.6.30-ori/drivers/usb/host/ehci-hub.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/host/ehci-hub.c	2009-06-12 18:32:43.000000000 -0400
@@ -30,7 +30,7 @@
 
 #define	PORT_WAKE_BITS	(PORT_WKOC_E|PORT_WKDISC_E|PORT_WKCONN_E)
 
-#ifdef	CONFIG_PM
+#ifdef CONFIG_PM
 
 static int ehci_hub_control(
 	struct usb_hcd	*hcd,
diff -Naur linux-2.6.30-ori/drivers/usb/host/ehci-tangox.c linux-2.6.30-test/drivers/usb/host/ehci-tangox.c
--- linux-2.6.30-ori/drivers/usb/host/ehci-tangox.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/usb/host/ehci-tangox.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,207 @@
+/*
+ * Modified for SMP86XX.
+ *
+ * Copyright (c) 2004-2007 Sigma Designs, Inc.
+ *
+ * EHCI HCD (Host Controller Driver) PCI Bus Glue.
+ *
+ * Copyright (c) 2000-2004 by David Brownell
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/platform_device.h>
+#ifndef CONFIG_TANGOX
+#error "This file is TANGOX EHCI bus glue.  CONFIG_TANGOX must be defined."
+#endif
+#include "../core/tangox-usb.h"
+
+/* called during probe() after chip reset completes */
+static int ehci_tangox_setup(struct usb_hcd *hcd)
+{
+        struct ehci_hcd         *ehci = hcd_to_ehci(hcd);
+        u32                     temp;
+        int                     retval;
+
+        ehci->caps = hcd->regs;
+        ehci->regs = hcd->regs + HC_LENGTH(readl(&ehci->caps->hc_capbase));
+        dbg_hcs_params(ehci, "reset");
+        dbg_hcc_params(ehci, "reset");
+
+        /* cache this readonly data; minimize chip reads */
+        ehci->hcs_params = readl(&ehci->caps->hcs_params);
+
+        retval = ehci_halt(ehci);
+        if (retval)
+                return retval;
+
+        /* data structure init */
+        retval = ehci_init(hcd);
+        if (retval)
+                return retval;
+
+        if (ehci_is_TDI(ehci))
+                ehci_reset(ehci);
+
+        /* at least the Genesys GL880S needs fixup here */
+        temp = HCS_N_CC(ehci->hcs_params) * HCS_N_PCC(ehci->hcs_params);
+        temp &= 0x0f;
+        if (temp && HCS_N_PORTS(ehci->hcs_params) > temp) {
+                ehci_dbg(ehci, "bogus port configuration: "
+                        "cc=%d x pcc=%d < ports=%d\n",
+                        HCS_N_CC(ehci->hcs_params),
+                        HCS_N_PCC(ehci->hcs_params),
+                        HCS_N_PORTS(ehci->hcs_params));
+        }
+
+        return retval;
+}
+
+
+static const struct hc_driver ehci_tangox_hc_driver = {
+	.description =		hcd_name,
+	.product_desc =		"SMP863x/SMP865x EHCI Host Controller",
+	.hcd_priv_size =	sizeof(struct ehci_hcd),
+
+	/*
+	 * generic hardware linkage
+	 */
+	.irq =			ehci_irq,
+	.flags =		HCD_MEMORY | HCD_USB2,
+
+	/*
+	 * basic lifecycle operations
+	 */
+	.reset =		 ehci_tangox_setup,
+	.start =		ehci_run,
+	.stop =			ehci_stop,
+	.shutdown = ehci_shutdown,
+
+	/*
+	 * managing i/o requests and associated device resources
+	 */
+	.urb_enqueue =		ehci_urb_enqueue,
+	.urb_dequeue =		ehci_urb_dequeue,
+	.endpoint_disable =	ehci_endpoint_disable,
+
+	/*
+	 * scheduling support
+	 */
+	.get_frame_number =	ehci_get_frame,
+
+	/*
+	 * root hub support
+	 */
+	.hub_status_data =	ehci_hub_status_data,
+	.hub_control =		ehci_hub_control,
+	.bus_suspend =		ehci_bus_suspend,
+	.bus_resume =		ehci_bus_resume,
+	.relinquish_port = ehci_relinquish_port,
+};
+
+/*-------------------------------------------------------------------------*/
+
+int usb_ehci_tangox_probe(const struct hc_driver *driver,
+			  struct usb_hcd **hcd_out, struct platform_device *dev)
+{
+	int retval;
+	struct usb_hcd *hcd;
+	struct ehci_hcd *ehci;
+
+    tangox_usb_init();
+
+	if (dev->resource[1].flags != IORESOURCE_IRQ) {
+		pr_debug("resource[1] is not IORESOURCE_IRQ");
+		retval = -ENOMEM;
+	}
+	hcd = usb_create_hcd(driver, &dev->dev, "tangox");
+	if (!hcd)
+		return -ENOMEM;
+	hcd->rsrc_start = dev->resource[0].start;
+	hcd->rsrc_len = dev->resource[0].end - dev->resource[0].start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len, hcd_name)) {
+		pr_debug("request_mem_region failed");
+		retval = -EBUSY;
+		goto err1;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		pr_debug("ioremap failed");
+		retval = -ENOMEM;
+		goto err2;
+	}
+
+	ehci = hcd_to_ehci(hcd);
+	ehci->caps = hcd->regs;
+	ehci->regs = hcd->regs + HC_LENGTH(readl(&ehci->caps->hc_capbase));
+	/* cache this readonly data; minimize chip reads */
+	ehci->hcs_params = readl(&ehci->caps->hcs_params);
+
+	/* ehci_hcd_init(hcd_to_ehci(hcd)); */
+
+	retval =
+	    usb_add_hcd(hcd, dev->resource[1].start, IRQF_SHARED);
+	if (retval == 0)
+		return retval;
+
+	iounmap(hcd->regs);
+err2:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+err1:
+	usb_put_hcd(hcd);
+	return retval;
+}
+
+static int ehci_hcd_tangox_drv_probe(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = NULL;
+	int ret;
+
+	if (usb_disabled())
+		return -ENODEV;
+
+	ret = usb_ehci_tangox_probe(&ehci_tangox_hc_driver, &hcd, pdev);
+	return ret;
+}
+
+void usb_ehci_tangox_remove(struct usb_hcd *hcd, struct platform_device *dev)
+{
+	usb_remove_hcd(hcd);
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+static int ehci_hcd_tangox_drv_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_ehci_tangox_remove(hcd, pdev);
+	return 0;
+}
+
+MODULE_ALIAS("tangox-ehci");
+
+static struct platform_driver ehci_hcd_tangox_driver = {
+	.probe = ehci_hcd_tangox_drv_probe,
+	.remove = ehci_hcd_tangox_drv_remove,
+	.shutdown = usb_hcd_platform_shutdown,
+	.driver = {
+		.name = "tangox-ehci",
+		.bus = &platform_bus_type
+	}
+};
diff -Naur linux-2.6.30-ori/drivers/usb/host/ohci-hcd.c linux-2.6.30-test/drivers/usb/host/ohci-hcd.c
--- linux-2.6.30-ori/drivers/usb/host/ohci-hcd.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/drivers/usb/host/ohci-hcd.c	2009-06-12 18:32:43.000000000 -0400
@@ -1081,6 +1081,11 @@
 #define TMIO_OHCI_DRIVER	ohci_hcd_tmio_driver
 #endif
 
+#ifdef CONFIG_TANGOX
+#include "ohci-tangox.c"
+#define PLATFORM_DRIVER		ohci_hcd_tangox_driver
+#endif
+
 #if	!defined(PCI_DRIVER) &&		\
 	!defined(PLATFORM_DRIVER) &&	\
 	!defined(OF_PLATFORM_DRIVER) &&	\
diff -Naur linux-2.6.30-ori/drivers/usb/host/ohci-tangox.c linux-2.6.30-test/drivers/usb/host/ohci-tangox.c
--- linux-2.6.30-ori/drivers/usb/host/ohci-tangox.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/drivers/usb/host/ohci-tangox.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,204 @@
+/*
+ * OHCI HCD (Host Controller Driver) for TangoX USB 1.1.
+ *
+ * (C) Copyright 2007 Sigma Designs, Inc.
+ * (C) Copyright 1999 Roman Weissgaerber <weissg@vienna.at>
+ * (C) Copyright 2000-2002 David Brownell <dbrownell@users.sourceforge.net>
+ * (C) Copyright 2002 Hewlett-Packard Company
+ * (C) Copyright 2003-2005 MontaVista Software Inc.
+ * 
+ * Bus Glue for TANGOX OHCI driver. Sigma Designs, Inc.
+ * This file is licenced under the GPL.
+ */
+
+#include <linux/platform_device.h>
+#ifndef CONFIG_TANGOX
+#error "This file is TANGOX OHCI bus glue.  CONFIG_TANGOX must be defined."
+#endif
+
+#include "../core/tangox-usb.h"
+
+/*-------------------------------------------------------------------------*/
+
+/* configure so an HC device and id are always provided */
+/* always called with process context; sleeping is OK */
+
+
+/**
+ * usb_ohci_tangox_probe - initialize tangox-based HCDs
+ * Context: !in_interrupt()
+ *
+ * Allocates basic resources for this USB host controller, and
+ * then invokes the start() method for the HCD associated with it
+ * through the hotplug entry's driver_data.
+ *
+ */
+static int usb_ohci_tangox_probe(const struct hc_driver *driver,
+			  struct platform_device *dev)
+{
+	int retval;
+	struct usb_hcd *hcd;
+
+	if (dev->resource[1].flags != IORESOURCE_IRQ) {
+		pr_debug("resource[1] is not IORESOURCE_IRQ\n");
+		return -ENOMEM;
+	}
+
+	hcd = usb_create_hcd(driver, &dev->dev, "tangox");
+	if (!hcd)
+		return -ENOMEM;
+	hcd->rsrc_start = dev->resource[0].start;
+	hcd->rsrc_len = dev->resource[0].end - dev->resource[0].start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len, hcd_name)) {
+		pr_debug("request_mem_region failed\n");
+		retval = -EBUSY;
+		goto err1;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		pr_debug("ioremap failed\n");
+		retval = -ENOMEM;
+		goto err2;
+	}
+
+    tangox_usb_init();
+	ohci_hcd_init(hcd_to_ohci(hcd));
+
+	retval = usb_add_hcd(hcd, dev->resource[1].start, IRQF_DISABLED | IRQF_SHARED);
+	if (retval == 0)
+		return retval;
+
+	iounmap(hcd->regs);
+ err2:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+ err1:
+	usb_put_hcd(hcd);
+	return retval;
+}
+
+
+/* may be called without controller electrically present */
+/* may be called with controller, bus, and devices active */
+
+/**
+ * usb_hcd_tangox_remove - shutdown processing for tangox-based HCDs
+ * @dev: USB Host Controller being removed
+ * Context: !in_interrupt()
+ *
+ * Reverses the effect of usb_hcd_tangox_probe(), first invoking
+ * the HCD's stop() method.  It is always called from a thread
+ * context, normally "rmmod", "apmd", or something similar.
+ *
+ */
+static void usb_ohci_tangox_remove(struct usb_hcd *hcd, struct platform_device *dev)
+{
+	usb_remove_hcd(hcd);
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+/*-------------------------------------------------------------------------*/
+
+static int __devinit
+ohci_tangox_start (struct usb_hcd *hcd)
+{
+	struct ohci_hcd	*ohci = hcd_to_ohci (hcd);
+	int		ret;
+
+	ohci_dbg (ohci, "ohci_tangox_start, ohci:%p", ohci);
+
+	if ((ret = ohci_init (ohci)) < 0)
+		return ret;
+
+	if ((ret = ohci_run (ohci)) < 0) {
+		err ("can't start %s", hcd->self.bus_name);
+		ohci_stop (hcd);
+		return ret;
+	}
+
+	return 0;
+}
+
+/*-------------------------------------------------------------------------*/
+
+static const struct hc_driver ohci_tangox_hc_driver = {
+	.description =		hcd_name,
+	.product_desc =		"tangox OHCI",
+	.hcd_priv_size =	sizeof(struct ohci_hcd),
+
+	/*
+	 * generic hardware linkage
+	 */
+	.irq =			ohci_irq,
+	.flags =		HCD_USB11 | HCD_MEMORY,
+
+	/*
+	 * basic lifecycle operations
+	 */
+	.start =		ohci_tangox_start,
+	.stop =			ohci_stop,
+	.shutdown =		ohci_shutdown,
+
+	/*
+	 * managing i/o requests and associated device resources
+	 */
+	.urb_enqueue =		ohci_urb_enqueue,
+	.urb_dequeue =		ohci_urb_dequeue,
+	.endpoint_disable =	ohci_endpoint_disable,
+
+	/*
+	 * scheduling support
+	 */
+	.get_frame_number =	ohci_get_frame,
+
+	/*
+	 * root hub support
+	 */
+	.hub_status_data =	ohci_hub_status_data,
+	.hub_control =		ohci_hub_control,
+#ifdef	CONFIG_PM
+	.bus_suspend =		ohci_bus_suspend,
+	.bus_resume =		ohci_bus_resume,
+#endif
+	.start_port_reset =	ohci_start_port_reset,
+};
+
+/*-------------------------------------------------------------------------*/
+
+static int ohci_hcd_tangox_drv_probe(struct platform_device *pdev)
+{
+	int ret;
+
+	pr_debug ("In ohci_hcd_tangox_drv_probe");
+
+	if (usb_disabled())
+		return -ENODEV;
+
+	ret = usb_ohci_tangox_probe(&ohci_tangox_hc_driver, pdev);
+	return ret;
+}
+
+static int ohci_hcd_tangox_drv_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_ohci_tangox_remove(hcd, pdev);
+	return 0;
+}
+
+static struct platform_driver ohci_hcd_tangox_driver = {
+	.probe		= ohci_hcd_tangox_drv_probe,
+	.remove		= ohci_hcd_tangox_drv_remove,
+	.shutdown	= usb_hcd_platform_shutdown,
+	/*.suspend	= ohci_hcd_tangox_drv_suspend, */
+	/*.resume	= ohci_hcd_tangox_drv_resume, */
+	.driver		= {
+		.name	= "tangox-ohci",
+		.owner	= THIS_MODULE,
+	},
+};
+
+MODULE_ALIAS("platform:tangox-ohci");
diff -Naur linux-2.6.30-ori/fs/cifs/cifsfs.c linux-2.6.30-test/fs/cifs/cifsfs.c
--- linux-2.6.30-ori/fs/cifs/cifsfs.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/cifsfs.c	2009-06-12 18:32:43.000000000 -0400
@@ -68,7 +68,7 @@
 struct task_struct *oplockThread = NULL;
 /* extern struct task_struct * dnotifyThread; remove sparse warning */
 static const struct super_operations cifs_super_ops;
-unsigned int CIFSMaxBufSize = CIFS_MAX_MSGSIZE;
+unsigned int CIFSMaxBufSize = CIFS_MAX_MSGSIZE*4-4096;
 module_param(CIFSMaxBufSize, int, 0);
 MODULE_PARM_DESC(CIFSMaxBufSize, "Network buffer size (not including header). "
 				 "Default: 16384 Range: 8192 to 130048");
diff -Naur linux-2.6.30-ori/fs/cifs/cifsfs.c.orig linux-2.6.30-test/fs/cifs/cifsfs.c.orig
--- linux-2.6.30-ori/fs/cifs/cifsfs.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/cifsfs.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,1168 @@
+/*
+ *   fs/cifs/cifsfs.c
+ *
+ *   Copyright (C) International Business Machines  Corp., 2002,2008
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *
+ *   Common Internet FileSystem (CIFS) client
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+
+/* Note that BB means BUGBUG (ie something to fix eventually) */
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/mount.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/seq_file.h>
+#include <linux/vfs.h>
+#include <linux/mempool.h>
+#include <linux/delay.h>
+#include <linux/kthread.h>
+#include <linux/freezer.h>
+#include <linux/smp_lock.h>
+#include "cifsfs.h"
+#include "cifspdu.h"
+#define DECLARE_GLOBALS_HERE
+#include "cifsglob.h"
+#include "cifsproto.h"
+#include "cifs_debug.h"
+#include "cifs_fs_sb.h"
+#include <linux/mm.h>
+#include <linux/key-type.h>
+#include "dns_resolve.h"
+#include "cifs_spnego.h"
+#define CIFS_MAGIC_NUMBER 0xFF534D42	/* the first four bytes of SMB PDUs */
+
+#ifdef CONFIG_CIFS_QUOTA
+static struct quotactl_ops cifs_quotactl_ops;
+#endif /* QUOTA */
+
+int cifsFYI = 0;
+int cifsERROR = 1;
+int traceSMB = 0;
+unsigned int oplockEnabled = 1;
+unsigned int experimEnabled = 0;
+unsigned int linuxExtEnabled = 1;
+unsigned int lookupCacheEnabled = 1;
+unsigned int multiuser_mount = 0;
+unsigned int extended_security = CIFSSEC_DEF;
+/* unsigned int ntlmv2_support = 0; */
+unsigned int sign_CIFS_PDUs = 1;
+extern struct task_struct *oplockThread; /* remove sparse warning */
+struct task_struct *oplockThread = NULL;
+/* extern struct task_struct * dnotifyThread; remove sparse warning */
+static const struct super_operations cifs_super_ops;
+unsigned int CIFSMaxBufSize = CIFS_MAX_MSGSIZE;
+module_param(CIFSMaxBufSize, int, 0);
+MODULE_PARM_DESC(CIFSMaxBufSize, "Network buffer size (not including header). "
+				 "Default: 16384 Range: 8192 to 130048");
+unsigned int cifs_min_rcv = CIFS_MIN_RCV_POOL;
+module_param(cifs_min_rcv, int, 0);
+MODULE_PARM_DESC(cifs_min_rcv, "Network buffers in pool. Default: 4 Range: "
+				"1 to 64");
+unsigned int cifs_min_small = 30;
+module_param(cifs_min_small, int, 0);
+MODULE_PARM_DESC(cifs_min_small, "Small network buffers in pool. Default: 30 "
+				 "Range: 2 to 256");
+unsigned int cifs_max_pending = CIFS_MAX_REQ;
+module_param(cifs_max_pending, int, 0);
+MODULE_PARM_DESC(cifs_max_pending, "Simultaneous requests to server. "
+				   "Default: 50 Range: 2 to 256");
+
+extern mempool_t *cifs_sm_req_poolp;
+extern mempool_t *cifs_req_poolp;
+extern mempool_t *cifs_mid_poolp;
+
+extern struct kmem_cache *cifs_oplock_cachep;
+
+static int
+cifs_read_super(struct super_block *sb, void *data,
+		const char *devname, int silent)
+{
+	struct inode *inode;
+	struct cifs_sb_info *cifs_sb;
+	int rc = 0;
+
+	/* BB should we make this contingent on mount parm? */
+	sb->s_flags |= MS_NODIRATIME | MS_NOATIME;
+	sb->s_fs_info = kzalloc(sizeof(struct cifs_sb_info), GFP_KERNEL);
+	cifs_sb = CIFS_SB(sb);
+	if (cifs_sb == NULL)
+		return -ENOMEM;
+
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	/* copy mount params to sb for use in submounts */
+	/* BB: should we move this after the mount so we
+	 * do not have to do the copy on failed mounts?
+	 * BB: May be it is better to do simple copy before
+	 * complex operation (mount), and in case of fail
+	 * just exit instead of doing mount and attempting
+	 * undo it if this copy fails?*/
+	if (data) {
+		int len = strlen(data);
+		cifs_sb->mountdata = kzalloc(len + 1, GFP_KERNEL);
+		if (cifs_sb->mountdata == NULL) {
+			kfree(sb->s_fs_info);
+			sb->s_fs_info = NULL;
+			return -ENOMEM;
+		}
+		strncpy(cifs_sb->mountdata, data, len + 1);
+		cifs_sb->mountdata[len] = '\0';
+	}
+#endif
+
+	rc = cifs_mount(sb, cifs_sb, data, devname);
+
+	if (rc) {
+		if (!silent)
+			cERROR(1,
+			       ("cifs_mount failed w/return code = %d", rc));
+		goto out_mount_failed;
+	}
+
+	sb->s_magic = CIFS_MAGIC_NUMBER;
+	sb->s_op = &cifs_super_ops;
+/*	if (cifs_sb->tcon->ses->server->maxBuf > MAX_CIFS_HDR_SIZE + 512)
+	    sb->s_blocksize =
+		cifs_sb->tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE; */
+#ifdef CONFIG_CIFS_QUOTA
+	sb->s_qcop = &cifs_quotactl_ops;
+#endif
+	sb->s_blocksize = CIFS_MAX_MSGSIZE;
+	sb->s_blocksize_bits = 14;	/* default 2**14 = CIFS_MAX_MSGSIZE */
+	inode = cifs_iget(sb, ROOT_I);
+
+	if (IS_ERR(inode)) {
+		rc = PTR_ERR(inode);
+		inode = NULL;
+		goto out_no_root;
+	}
+
+	sb->s_root = d_alloc_root(inode);
+
+	if (!sb->s_root) {
+		rc = -ENOMEM;
+		goto out_no_root;
+	}
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SERVER_INUM) {
+		cFYI(1, ("export ops supported"));
+		sb->s_export_op = &cifs_export_ops;
+	}
+#endif /* EXPERIMENTAL */
+
+	return 0;
+
+out_no_root:
+	cERROR(1, ("cifs_read_super: get root inode failed"));
+	if (inode)
+		iput(inode);
+
+	cifs_umount(sb, cifs_sb);
+
+out_mount_failed:
+	if (cifs_sb) {
+#ifdef CONFIG_CIFS_DFS_UPCALL
+		if (cifs_sb->mountdata) {
+			kfree(cifs_sb->mountdata);
+			cifs_sb->mountdata = NULL;
+		}
+#endif
+		if (cifs_sb->local_nls)
+			unload_nls(cifs_sb->local_nls);
+		kfree(cifs_sb);
+	}
+	return rc;
+}
+
+static void
+cifs_put_super(struct super_block *sb)
+{
+	int rc = 0;
+	struct cifs_sb_info *cifs_sb;
+
+	cFYI(1, ("In cifs_put_super"));
+	cifs_sb = CIFS_SB(sb);
+	if (cifs_sb == NULL) {
+		cFYI(1, ("Empty cifs superblock info passed to unmount"));
+		return;
+	}
+	rc = cifs_umount(sb, cifs_sb);
+	if (rc)
+		cERROR(1, ("cifs_umount failed with return code %d", rc));
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	if (cifs_sb->mountdata) {
+		kfree(cifs_sb->mountdata);
+		cifs_sb->mountdata = NULL;
+	}
+#endif
+
+	unload_nls(cifs_sb->local_nls);
+	kfree(cifs_sb);
+	return;
+}
+
+static int
+cifs_statfs(struct dentry *dentry, struct kstatfs *buf)
+{
+	struct super_block *sb = dentry->d_sb;
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *tcon = cifs_sb->tcon;
+	int rc = -EOPNOTSUPP;
+	int xid;
+
+	xid = GetXid();
+
+	buf->f_type = CIFS_MAGIC_NUMBER;
+
+	/*
+	 * PATH_MAX may be too long - it would presumably be total path,
+	 * but note that some servers (includinng Samba 3) have a shorter
+	 * maximum path.
+	 *
+	 * Instead could get the real value via SMB_QUERY_FS_ATTRIBUTE_INFO.
+	 */
+	buf->f_namelen = PATH_MAX;
+	buf->f_files = 0;	/* undefined */
+	buf->f_ffree = 0;	/* unlimited */
+
+	/*
+	 * We could add a second check for a QFS Unix capability bit
+	 */
+	if ((tcon->ses->capabilities & CAP_UNIX) &&
+	    (CIFS_POSIX_EXTENSIONS & le64_to_cpu(tcon->fsUnixInfo.Capability)))
+		rc = CIFSSMBQFSPosixInfo(xid, tcon, buf);
+
+	/*
+	 * Only need to call the old QFSInfo if failed on newer one,
+	 * e.g. by OS/2.
+	 **/
+	if (rc && (tcon->ses->capabilities & CAP_NT_SMBS))
+		rc = CIFSSMBQFSInfo(xid, tcon, buf);
+
+	/*
+	 * Some old Windows servers also do not support level 103, retry with
+	 * older level one if old server failed the previous call or we
+	 * bypassed it because we detected that this was an older LANMAN sess
+	 */
+	if (rc)
+		rc = SMBOldQFSInfo(xid, tcon, buf);
+
+	FreeXid(xid);
+	return 0;
+}
+
+static int cifs_permission(struct inode *inode, int mask)
+{
+	struct cifs_sb_info *cifs_sb;
+
+	cifs_sb = CIFS_SB(inode->i_sb);
+
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_PERM) {
+		if ((mask & MAY_EXEC) && !execute_ok(inode))
+			return -EACCES;
+		else
+			return 0;
+	} else /* file mode might have been restricted at mount time
+		on the client (above and beyond ACL on servers) for
+		servers which do not support setting and viewing mode bits,
+		so allowing client to check permissions is useful */
+		return generic_permission(inode, mask, NULL);
+}
+
+static struct kmem_cache *cifs_inode_cachep;
+static struct kmem_cache *cifs_req_cachep;
+static struct kmem_cache *cifs_mid_cachep;
+struct kmem_cache *cifs_oplock_cachep;
+static struct kmem_cache *cifs_sm_req_cachep;
+mempool_t *cifs_sm_req_poolp;
+mempool_t *cifs_req_poolp;
+mempool_t *cifs_mid_poolp;
+
+static struct inode *
+cifs_alloc_inode(struct super_block *sb)
+{
+	struct cifsInodeInfo *cifs_inode;
+	cifs_inode = kmem_cache_alloc(cifs_inode_cachep, GFP_KERNEL);
+	if (!cifs_inode)
+		return NULL;
+	cifs_inode->cifsAttrs = 0x20;	/* default */
+	atomic_set(&cifs_inode->inUse, 0);
+	cifs_inode->time = 0;
+	cifs_inode->write_behind_rc = 0;
+	/* Until the file is open and we have gotten oplock
+	info back from the server, can not assume caching of
+	file data or metadata */
+	cifs_inode->clientCanCacheRead = false;
+	cifs_inode->clientCanCacheAll = false;
+	cifs_inode->delete_pending = false;
+	cifs_inode->vfs_inode.i_blkbits = 14;  /* 2**14 = CIFS_MAX_MSGSIZE */
+	cifs_inode->server_eof = 0;
+
+	/* Can not set i_flags here - they get immediately overwritten
+	   to zero by the VFS */
+/*	cifs_inode->vfs_inode.i_flags = S_NOATIME | S_NOCMTIME;*/
+	INIT_LIST_HEAD(&cifs_inode->openFileList);
+	return &cifs_inode->vfs_inode;
+}
+
+static void
+cifs_destroy_inode(struct inode *inode)
+{
+	kmem_cache_free(cifs_inode_cachep, CIFS_I(inode));
+}
+
+/*
+ * cifs_show_options() is for displaying mount options in /proc/mounts.
+ * Not all settable options are displayed but most of the important
+ * ones are.
+ */
+static int
+cifs_show_options(struct seq_file *s, struct vfsmount *m)
+{
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *tcon;
+	struct TCP_Server_Info *server;
+
+	cifs_sb = CIFS_SB(m->mnt_sb);
+
+	if (cifs_sb) {
+		tcon = cifs_sb->tcon;
+		if (tcon) {
+			seq_printf(s, ",unc=%s", cifs_sb->tcon->treeName);
+			if (tcon->ses) {
+				if (tcon->ses->userName)
+					seq_printf(s, ",username=%s",
+					   tcon->ses->userName);
+				if (tcon->ses->domainName)
+					seq_printf(s, ",domain=%s",
+					   tcon->ses->domainName);
+				server = tcon->ses->server;
+				if (server) {
+					seq_printf(s, ",addr=");
+					switch (server->addr.sockAddr6.
+						sin6_family) {
+					case AF_INET6:
+						seq_printf(s, "%pI6",
+							   &server->addr.sockAddr6.sin6_addr);
+						break;
+					case AF_INET:
+						seq_printf(s, "%pI4",
+							   &server->addr.sockAddr.sin_addr.s_addr);
+						break;
+					}
+				}
+			}
+			if ((cifs_sb->mnt_cifs_flags & CIFS_MOUNT_OVERR_UID) ||
+			   !(tcon->unix_ext))
+				seq_printf(s, ",uid=%d", cifs_sb->mnt_uid);
+			if ((cifs_sb->mnt_cifs_flags & CIFS_MOUNT_OVERR_GID) ||
+			   !(tcon->unix_ext))
+				seq_printf(s, ",gid=%d", cifs_sb->mnt_gid);
+			if (!tcon->unix_ext) {
+				seq_printf(s, ",file_mode=0%o,dir_mode=0%o",
+					   cifs_sb->mnt_file_mode,
+					   cifs_sb->mnt_dir_mode);
+			}
+			if (tcon->seal)
+				seq_printf(s, ",seal");
+			if (tcon->nocase)
+				seq_printf(s, ",nocase");
+			if (tcon->retry)
+				seq_printf(s, ",hard");
+		}
+		if (cifs_sb->prepath)
+			seq_printf(s, ",prepath=%s", cifs_sb->prepath);
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS)
+			seq_printf(s, ",posixpaths");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SET_UID)
+			seq_printf(s, ",setuids");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SERVER_INUM)
+			seq_printf(s, ",serverino");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DIRECT_IO)
+			seq_printf(s, ",directio");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_XATTR)
+			seq_printf(s, ",nouser_xattr");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_MAP_SPECIAL_CHR)
+			seq_printf(s, ",mapchars");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_UNX_EMUL)
+			seq_printf(s, ",sfu");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_BRL)
+			seq_printf(s, ",nobrl");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_CIFS_ACL)
+			seq_printf(s, ",cifsacl");
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DYNPERM)
+			seq_printf(s, ",dynperm");
+		if (m->mnt_sb->s_flags & MS_POSIXACL)
+			seq_printf(s, ",acl");
+
+		seq_printf(s, ",rsize=%d", cifs_sb->rsize);
+		seq_printf(s, ",wsize=%d", cifs_sb->wsize);
+	}
+	return 0;
+}
+
+#ifdef CONFIG_CIFS_QUOTA
+int cifs_xquota_set(struct super_block *sb, int quota_type, qid_t qid,
+		struct fs_disk_quota *pdquota)
+{
+	int xid;
+	int rc = 0;
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *pTcon;
+
+	if (cifs_sb)
+		pTcon = cifs_sb->tcon;
+	else
+		return -EIO;
+
+
+	xid = GetXid();
+	if (pTcon) {
+		cFYI(1, ("set type: 0x%x id: %d", quota_type, qid));
+	} else
+		rc = -EIO;
+
+	FreeXid(xid);
+	return rc;
+}
+
+int cifs_xquota_get(struct super_block *sb, int quota_type, qid_t qid,
+		    struct fs_disk_quota *pdquota)
+{
+	int xid;
+	int rc = 0;
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *pTcon;
+
+	if (cifs_sb)
+		pTcon = cifs_sb->tcon;
+	else
+		return -EIO;
+
+	xid = GetXid();
+	if (pTcon) {
+		cFYI(1, ("set type: 0x%x id: %d", quota_type, qid));
+	} else
+		rc = -EIO;
+
+	FreeXid(xid);
+	return rc;
+}
+
+int cifs_xstate_set(struct super_block *sb, unsigned int flags, int operation)
+{
+	int xid;
+	int rc = 0;
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *pTcon;
+
+	if (cifs_sb)
+		pTcon = cifs_sb->tcon;
+	else
+		return -EIO;
+
+	xid = GetXid();
+	if (pTcon) {
+		cFYI(1, ("flags: 0x%x operation: 0x%x", flags, operation));
+	} else
+		rc = -EIO;
+
+	FreeXid(xid);
+	return rc;
+}
+
+int cifs_xstate_get(struct super_block *sb, struct fs_quota_stat *qstats)
+{
+	int xid;
+	int rc = 0;
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *pTcon;
+
+	if (cifs_sb)
+		pTcon = cifs_sb->tcon;
+	else
+		return -EIO;
+
+	xid = GetXid();
+	if (pTcon) {
+		cFYI(1, ("pqstats %p", qstats));
+	} else
+		rc = -EIO;
+
+	FreeXid(xid);
+	return rc;
+}
+
+static struct quotactl_ops cifs_quotactl_ops = {
+	.set_xquota	= cifs_xquota_set,
+	.get_xquota	= cifs_xquota_get,
+	.set_xstate	= cifs_xstate_set,
+	.get_xstate	= cifs_xstate_get,
+};
+#endif
+
+static void cifs_umount_begin(struct super_block *sb)
+{
+	struct cifs_sb_info *cifs_sb = CIFS_SB(sb);
+	struct cifsTconInfo *tcon;
+
+	if (cifs_sb == NULL)
+		return;
+
+	tcon = cifs_sb->tcon;
+	if (tcon == NULL)
+		return;
+
+	lock_kernel();
+	read_lock(&cifs_tcp_ses_lock);
+	if (tcon->tc_count == 1)
+		tcon->tidStatus = CifsExiting;
+	read_unlock(&cifs_tcp_ses_lock);
+
+	/* cancel_brl_requests(tcon); */ /* BB mark all brl mids as exiting */
+	/* cancel_notify_requests(tcon); */
+	if (tcon->ses && tcon->ses->server) {
+		cFYI(1, ("wake up tasks now - umount begin not complete"));
+		wake_up_all(&tcon->ses->server->request_q);
+		wake_up_all(&tcon->ses->server->response_q);
+		msleep(1); /* yield */
+		/* we have to kick the requests once more */
+		wake_up_all(&tcon->ses->server->response_q);
+		msleep(1);
+	}
+/* BB FIXME - finish add checks for tidStatus BB */
+
+	unlock_kernel();
+	return;
+}
+
+#ifdef CONFIG_CIFS_STATS2
+static int cifs_show_stats(struct seq_file *s, struct vfsmount *mnt)
+{
+	/* BB FIXME */
+	return 0;
+}
+#endif
+
+static int cifs_remount(struct super_block *sb, int *flags, char *data)
+{
+	*flags |= MS_NODIRATIME;
+	return 0;
+}
+
+static const struct super_operations cifs_super_ops = {
+	.put_super = cifs_put_super,
+	.statfs = cifs_statfs,
+	.alloc_inode = cifs_alloc_inode,
+	.destroy_inode = cifs_destroy_inode,
+/*	.drop_inode	    = generic_delete_inode,
+	.delete_inode	= cifs_delete_inode,  */  /* Do not need above two
+	functions unless later we add lazy close of inodes or unless the
+	kernel forgets to call us with the same number of releases (closes)
+	as opens */
+	.show_options = cifs_show_options,
+	.umount_begin   = cifs_umount_begin,
+	.remount_fs = cifs_remount,
+#ifdef CONFIG_CIFS_STATS2
+	.show_stats = cifs_show_stats,
+#endif
+};
+
+static int
+cifs_get_sb(struct file_system_type *fs_type,
+	    int flags, const char *dev_name, void *data, struct vfsmount *mnt)
+{
+	int rc;
+	struct super_block *sb = sget(fs_type, NULL, set_anon_super, NULL);
+
+	cFYI(1, ("Devname: %s flags: %d ", dev_name, flags));
+
+	if (IS_ERR(sb))
+		return PTR_ERR(sb);
+
+	sb->s_flags = flags;
+
+	rc = cifs_read_super(sb, data, dev_name, flags & MS_SILENT ? 1 : 0);
+	if (rc) {
+		deactivate_locked_super(sb);
+		return rc;
+	}
+	sb->s_flags |= MS_ACTIVE;
+	simple_set_mnt(mnt, sb);
+	return 0;
+}
+
+static ssize_t cifs_file_aio_write(struct kiocb *iocb, const struct iovec *iov,
+				   unsigned long nr_segs, loff_t pos)
+{
+	struct inode *inode = iocb->ki_filp->f_path.dentry->d_inode;
+	ssize_t written;
+
+	written = generic_file_aio_write(iocb, iov, nr_segs, pos);
+	if (!CIFS_I(inode)->clientCanCacheAll)
+		filemap_fdatawrite(inode->i_mapping);
+	return written;
+}
+
+static loff_t cifs_llseek(struct file *file, loff_t offset, int origin)
+{
+	/* origin == SEEK_END => we must revalidate the cached file length */
+	if (origin == SEEK_END) {
+		int retval;
+
+		/* some applications poll for the file length in this strange
+		   way so we must seek to end on non-oplocked files by
+		   setting the revalidate time to zero */
+		CIFS_I(file->f_path.dentry->d_inode)->time = 0;
+
+		retval = cifs_revalidate(file->f_path.dentry);
+		if (retval < 0)
+			return (loff_t)retval;
+	}
+	return generic_file_llseek_unlocked(file, offset, origin);
+}
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+static int cifs_setlease(struct file *file, long arg, struct file_lock **lease)
+{
+	/* note that this is called by vfs setlease with the BKL held
+	   although I doubt that BKL is needed here in cifs */
+	struct inode *inode = file->f_path.dentry->d_inode;
+
+	if (!(S_ISREG(inode->i_mode)))
+		return -EINVAL;
+
+	/* check if file is oplocked */
+	if (((arg == F_RDLCK) &&
+		(CIFS_I(inode)->clientCanCacheRead)) ||
+	    ((arg == F_WRLCK) &&
+		(CIFS_I(inode)->clientCanCacheAll)))
+		return generic_setlease(file, arg, lease);
+	else if (CIFS_SB(inode->i_sb)->tcon->local_lease &&
+			!CIFS_I(inode)->clientCanCacheRead)
+		/* If the server claims to support oplock on this
+		   file, then we still need to check oplock even
+		   if the local_lease mount option is set, but there
+		   are servers which do not support oplock for which
+		   this mount option may be useful if the user
+		   knows that the file won't be changed on the server
+		   by anyone else */
+		return generic_setlease(file, arg, lease);
+	else
+		return -EAGAIN;
+}
+#endif
+
+struct file_system_type cifs_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "cifs",
+	.get_sb = cifs_get_sb,
+	.kill_sb = kill_anon_super,
+	/*  .fs_flags */
+};
+const struct inode_operations cifs_dir_inode_ops = {
+	.create = cifs_create,
+	.lookup = cifs_lookup,
+	.getattr = cifs_getattr,
+	.unlink = cifs_unlink,
+	.link = cifs_hardlink,
+	.mkdir = cifs_mkdir,
+	.rmdir = cifs_rmdir,
+	.rename = cifs_rename,
+	.permission = cifs_permission,
+/*	revalidate:cifs_revalidate,   */
+	.setattr = cifs_setattr,
+	.symlink = cifs_symlink,
+	.mknod   = cifs_mknod,
+#ifdef CONFIG_CIFS_XATTR
+	.setxattr = cifs_setxattr,
+	.getxattr = cifs_getxattr,
+	.listxattr = cifs_listxattr,
+	.removexattr = cifs_removexattr,
+#endif
+};
+
+const struct inode_operations cifs_file_inode_ops = {
+/*	revalidate:cifs_revalidate, */
+	.setattr = cifs_setattr,
+	.getattr = cifs_getattr, /* do we need this anymore? */
+	.rename = cifs_rename,
+	.permission = cifs_permission,
+#ifdef CONFIG_CIFS_XATTR
+	.setxattr = cifs_setxattr,
+	.getxattr = cifs_getxattr,
+	.listxattr = cifs_listxattr,
+	.removexattr = cifs_removexattr,
+#endif
+};
+
+const struct inode_operations cifs_symlink_inode_ops = {
+	.readlink = generic_readlink,
+	.follow_link = cifs_follow_link,
+	.put_link = cifs_put_link,
+	.permission = cifs_permission,
+	/* BB add the following two eventually */
+	/* revalidate: cifs_revalidate,
+	   setattr:    cifs_notify_change, *//* BB do we need notify change */
+#ifdef CONFIG_CIFS_XATTR
+	.setxattr = cifs_setxattr,
+	.getxattr = cifs_getxattr,
+	.listxattr = cifs_listxattr,
+	.removexattr = cifs_removexattr,
+#endif
+};
+
+const struct file_operations cifs_file_ops = {
+	.read = do_sync_read,
+	.write = do_sync_write,
+	.aio_read = generic_file_aio_read,
+	.aio_write = cifs_file_aio_write,
+	.open = cifs_open,
+	.release = cifs_close,
+	.lock = cifs_lock,
+	.fsync = cifs_fsync,
+	.flush = cifs_flush,
+	.mmap  = cifs_file_mmap,
+	.splice_read = generic_file_splice_read,
+	.llseek = cifs_llseek,
+#ifdef CONFIG_CIFS_POSIX
+	.unlocked_ioctl	= cifs_ioctl,
+#endif /* CONFIG_CIFS_POSIX */
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	.setlease = cifs_setlease,
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+};
+
+const struct file_operations cifs_file_direct_ops = {
+	/* no mmap, no aio, no readv -
+	   BB reevaluate whether they can be done with directio, no cache */
+	.read = cifs_user_read,
+	.write = cifs_user_write,
+	.open = cifs_open,
+	.release = cifs_close,
+	.lock = cifs_lock,
+	.fsync = cifs_fsync,
+	.flush = cifs_flush,
+	.splice_read = generic_file_splice_read,
+#ifdef CONFIG_CIFS_POSIX
+	.unlocked_ioctl  = cifs_ioctl,
+#endif /* CONFIG_CIFS_POSIX */
+	.llseek = cifs_llseek,
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	.setlease = cifs_setlease,
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+};
+const struct file_operations cifs_file_nobrl_ops = {
+	.read = do_sync_read,
+	.write = do_sync_write,
+	.aio_read = generic_file_aio_read,
+	.aio_write = cifs_file_aio_write,
+	.open = cifs_open,
+	.release = cifs_close,
+	.fsync = cifs_fsync,
+	.flush = cifs_flush,
+	.mmap  = cifs_file_mmap,
+	.splice_read = generic_file_splice_read,
+	.llseek = cifs_llseek,
+#ifdef CONFIG_CIFS_POSIX
+	.unlocked_ioctl	= cifs_ioctl,
+#endif /* CONFIG_CIFS_POSIX */
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	.setlease = cifs_setlease,
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+};
+
+const struct file_operations cifs_file_direct_nobrl_ops = {
+	/* no mmap, no aio, no readv -
+	   BB reevaluate whether they can be done with directio, no cache */
+	.read = cifs_user_read,
+	.write = cifs_user_write,
+	.open = cifs_open,
+	.release = cifs_close,
+	.fsync = cifs_fsync,
+	.flush = cifs_flush,
+	.splice_read = generic_file_splice_read,
+#ifdef CONFIG_CIFS_POSIX
+	.unlocked_ioctl  = cifs_ioctl,
+#endif /* CONFIG_CIFS_POSIX */
+	.llseek = cifs_llseek,
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	.setlease = cifs_setlease,
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+};
+
+const struct file_operations cifs_dir_ops = {
+	.readdir = cifs_readdir,
+	.release = cifs_closedir,
+	.read    = generic_read_dir,
+	.unlocked_ioctl  = cifs_ioctl,
+	.llseek = generic_file_llseek,
+};
+
+static void
+cifs_init_once(void *inode)
+{
+	struct cifsInodeInfo *cifsi = inode;
+
+	inode_init_once(&cifsi->vfs_inode);
+	INIT_LIST_HEAD(&cifsi->lockList);
+}
+
+static int
+cifs_init_inodecache(void)
+{
+	cifs_inode_cachep = kmem_cache_create("cifs_inode_cache",
+					      sizeof(struct cifsInodeInfo),
+					      0, (SLAB_RECLAIM_ACCOUNT|
+						SLAB_MEM_SPREAD),
+					      cifs_init_once);
+	if (cifs_inode_cachep == NULL)
+		return -ENOMEM;
+
+	return 0;
+}
+
+static void
+cifs_destroy_inodecache(void)
+{
+	kmem_cache_destroy(cifs_inode_cachep);
+}
+
+static int
+cifs_init_request_bufs(void)
+{
+	if (CIFSMaxBufSize < 8192) {
+	/* Buffer size can not be smaller than 2 * PATH_MAX since maximum
+	Unicode path name has to fit in any SMB/CIFS path based frames */
+		CIFSMaxBufSize = 8192;
+	} else if (CIFSMaxBufSize > 1024*127) {
+		CIFSMaxBufSize = 1024 * 127;
+	} else {
+		CIFSMaxBufSize &= 0x1FE00; /* Round size to even 512 byte mult*/
+	}
+/*	cERROR(1,("CIFSMaxBufSize %d 0x%x",CIFSMaxBufSize,CIFSMaxBufSize)); */
+	cifs_req_cachep = kmem_cache_create("cifs_request",
+					    CIFSMaxBufSize +
+					    MAX_CIFS_HDR_SIZE, 0,
+					    SLAB_HWCACHE_ALIGN, NULL);
+	if (cifs_req_cachep == NULL)
+		return -ENOMEM;
+
+	if (cifs_min_rcv < 1)
+		cifs_min_rcv = 1;
+	else if (cifs_min_rcv > 64) {
+		cifs_min_rcv = 64;
+		cERROR(1, ("cifs_min_rcv set to maximum (64)"));
+	}
+
+	cifs_req_poolp = mempool_create_slab_pool(cifs_min_rcv,
+						  cifs_req_cachep);
+
+	if (cifs_req_poolp == NULL) {
+		kmem_cache_destroy(cifs_req_cachep);
+		return -ENOMEM;
+	}
+	/* MAX_CIFS_SMALL_BUFFER_SIZE bytes is enough for most SMB responses and
+	almost all handle based requests (but not write response, nor is it
+	sufficient for path based requests).  A smaller size would have
+	been more efficient (compacting multiple slab items on one 4k page)
+	for the case in which debug was on, but this larger size allows
+	more SMBs to use small buffer alloc and is still much more
+	efficient to alloc 1 per page off the slab compared to 17K (5page)
+	alloc of large cifs buffers even when page debugging is on */
+	cifs_sm_req_cachep = kmem_cache_create("cifs_small_rq",
+			MAX_CIFS_SMALL_BUFFER_SIZE, 0, SLAB_HWCACHE_ALIGN,
+			NULL);
+	if (cifs_sm_req_cachep == NULL) {
+		mempool_destroy(cifs_req_poolp);
+		kmem_cache_destroy(cifs_req_cachep);
+		return -ENOMEM;
+	}
+
+	if (cifs_min_small < 2)
+		cifs_min_small = 2;
+	else if (cifs_min_small > 256) {
+		cifs_min_small = 256;
+		cFYI(1, ("cifs_min_small set to maximum (256)"));
+	}
+
+	cifs_sm_req_poolp = mempool_create_slab_pool(cifs_min_small,
+						     cifs_sm_req_cachep);
+
+	if (cifs_sm_req_poolp == NULL) {
+		mempool_destroy(cifs_req_poolp);
+		kmem_cache_destroy(cifs_req_cachep);
+		kmem_cache_destroy(cifs_sm_req_cachep);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void
+cifs_destroy_request_bufs(void)
+{
+	mempool_destroy(cifs_req_poolp);
+	kmem_cache_destroy(cifs_req_cachep);
+	mempool_destroy(cifs_sm_req_poolp);
+	kmem_cache_destroy(cifs_sm_req_cachep);
+}
+
+static int
+cifs_init_mids(void)
+{
+	cifs_mid_cachep = kmem_cache_create("cifs_mpx_ids",
+					    sizeof(struct mid_q_entry), 0,
+					    SLAB_HWCACHE_ALIGN, NULL);
+	if (cifs_mid_cachep == NULL)
+		return -ENOMEM;
+
+	/* 3 is a reasonable minimum number of simultaneous operations */
+	cifs_mid_poolp = mempool_create_slab_pool(3, cifs_mid_cachep);
+	if (cifs_mid_poolp == NULL) {
+		kmem_cache_destroy(cifs_mid_cachep);
+		return -ENOMEM;
+	}
+
+	cifs_oplock_cachep = kmem_cache_create("cifs_oplock_structs",
+					sizeof(struct oplock_q_entry), 0,
+					SLAB_HWCACHE_ALIGN, NULL);
+	if (cifs_oplock_cachep == NULL) {
+		mempool_destroy(cifs_mid_poolp);
+		kmem_cache_destroy(cifs_mid_cachep);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void
+cifs_destroy_mids(void)
+{
+	mempool_destroy(cifs_mid_poolp);
+	kmem_cache_destroy(cifs_mid_cachep);
+	kmem_cache_destroy(cifs_oplock_cachep);
+}
+
+static int cifs_oplock_thread(void *dummyarg)
+{
+	struct oplock_q_entry *oplock_item;
+	struct cifsTconInfo *pTcon;
+	struct inode *inode;
+	__u16  netfid;
+	int rc, waitrc = 0;
+
+	set_freezable();
+	do {
+		if (try_to_freeze())
+			continue;
+
+		spin_lock(&GlobalMid_Lock);
+		if (list_empty(&GlobalOplock_Q)) {
+			spin_unlock(&GlobalMid_Lock);
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule_timeout(39*HZ);
+		} else {
+			oplock_item = list_entry(GlobalOplock_Q.next,
+						struct oplock_q_entry, qhead);
+			cFYI(1, ("found oplock item to write out"));
+			pTcon = oplock_item->tcon;
+			inode = oplock_item->pinode;
+			netfid = oplock_item->netfid;
+			spin_unlock(&GlobalMid_Lock);
+			DeleteOplockQEntry(oplock_item);
+			/* can not grab inode sem here since it would
+				deadlock when oplock received on delete
+				since vfs_unlink holds the i_mutex across
+				the call */
+			/* mutex_lock(&inode->i_mutex);*/
+			if (S_ISREG(inode->i_mode)) {
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+				if (CIFS_I(inode)->clientCanCacheAll == 0)
+					break_lease(inode, FMODE_READ);
+				else if (CIFS_I(inode)->clientCanCacheRead == 0)
+					break_lease(inode, FMODE_WRITE);
+#endif
+				rc = filemap_fdatawrite(inode->i_mapping);
+				if (CIFS_I(inode)->clientCanCacheRead == 0) {
+					waitrc = filemap_fdatawait(
+							      inode->i_mapping);
+					invalidate_remote_inode(inode);
+				}
+				if (rc == 0)
+					rc = waitrc;
+			} else
+				rc = 0;
+			/* mutex_unlock(&inode->i_mutex);*/
+			if (rc)
+				CIFS_I(inode)->write_behind_rc = rc;
+			cFYI(1, ("Oplock flush inode %p rc %d",
+				inode, rc));
+
+				/* releasing stale oplock after recent reconnect
+				of smb session using a now incorrect file
+				handle is not a data integrity issue but do
+				not bother sending an oplock release if session
+				to server still is disconnected since oplock
+				already released by the server in that case */
+			if (!pTcon->need_reconnect) {
+				rc = CIFSSMBLock(0, pTcon, netfid,
+						0 /* len */ , 0 /* offset */, 0,
+						0, LOCKING_ANDX_OPLOCK_RELEASE,
+						false /* wait flag */);
+				cFYI(1, ("Oplock release rc = %d", rc));
+			}
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule_timeout(1);  /* yield in case q were corrupt */
+		}
+	} while (!kthread_should_stop());
+
+	return 0;
+}
+
+static int __init
+init_cifs(void)
+{
+	int rc = 0;
+	cifs_proc_init();
+	INIT_LIST_HEAD(&cifs_tcp_ses_list);
+	INIT_LIST_HEAD(&GlobalOplock_Q);
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	INIT_LIST_HEAD(&GlobalDnotifyReqList);
+	INIT_LIST_HEAD(&GlobalDnotifyRsp_Q);
+#endif
+/*
+ *  Initialize Global counters
+ */
+	atomic_set(&sesInfoAllocCount, 0);
+	atomic_set(&tconInfoAllocCount, 0);
+	atomic_set(&tcpSesAllocCount, 0);
+	atomic_set(&tcpSesReconnectCount, 0);
+	atomic_set(&tconInfoReconnectCount, 0);
+
+	atomic_set(&bufAllocCount, 0);
+	atomic_set(&smBufAllocCount, 0);
+#ifdef CONFIG_CIFS_STATS2
+	atomic_set(&totBufAllocCount, 0);
+	atomic_set(&totSmBufAllocCount, 0);
+#endif /* CONFIG_CIFS_STATS2 */
+
+	atomic_set(&midCount, 0);
+	GlobalCurrentXid = 0;
+	GlobalTotalActiveXid = 0;
+	GlobalMaxActiveXid = 0;
+	memset(Local_System_Name, 0, 15);
+	rwlock_init(&GlobalSMBSeslock);
+	rwlock_init(&cifs_tcp_ses_lock);
+	spin_lock_init(&GlobalMid_Lock);
+
+	if (cifs_max_pending < 2) {
+		cifs_max_pending = 2;
+		cFYI(1, ("cifs_max_pending set to min of 2"));
+	} else if (cifs_max_pending > 256) {
+		cifs_max_pending = 256;
+		cFYI(1, ("cifs_max_pending set to max of 256"));
+	}
+
+	rc = cifs_init_inodecache();
+	if (rc)
+		goto out_clean_proc;
+
+	rc = cifs_init_mids();
+	if (rc)
+		goto out_destroy_inodecache;
+
+	rc = cifs_init_request_bufs();
+	if (rc)
+		goto out_destroy_mids;
+
+	rc = register_filesystem(&cifs_fs_type);
+	if (rc)
+		goto out_destroy_request_bufs;
+#ifdef CONFIG_CIFS_UPCALL
+	rc = register_key_type(&cifs_spnego_key_type);
+	if (rc)
+		goto out_unregister_filesystem;
+#endif
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	rc = register_key_type(&key_type_dns_resolver);
+	if (rc)
+		goto out_unregister_key_type;
+#endif
+	oplockThread = kthread_run(cifs_oplock_thread, NULL, "cifsoplockd");
+	if (IS_ERR(oplockThread)) {
+		rc = PTR_ERR(oplockThread);
+		cERROR(1, ("error %d create oplock thread", rc));
+		goto out_unregister_dfs_key_type;
+	}
+
+	return 0;
+
+ out_unregister_dfs_key_type:
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	unregister_key_type(&key_type_dns_resolver);
+ out_unregister_key_type:
+#endif
+#ifdef CONFIG_CIFS_UPCALL
+	unregister_key_type(&cifs_spnego_key_type);
+ out_unregister_filesystem:
+#endif
+	unregister_filesystem(&cifs_fs_type);
+ out_destroy_request_bufs:
+	cifs_destroy_request_bufs();
+ out_destroy_mids:
+	cifs_destroy_mids();
+ out_destroy_inodecache:
+	cifs_destroy_inodecache();
+ out_clean_proc:
+	cifs_proc_clean();
+	return rc;
+}
+
+static void __exit
+exit_cifs(void)
+{
+	cFYI(DBG2, ("exit_cifs"));
+	cifs_proc_clean();
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	cifs_dfs_release_automount_timer();
+	unregister_key_type(&key_type_dns_resolver);
+#endif
+#ifdef CONFIG_CIFS_UPCALL
+	unregister_key_type(&cifs_spnego_key_type);
+#endif
+	unregister_filesystem(&cifs_fs_type);
+	cifs_destroy_inodecache();
+	cifs_destroy_mids();
+	cifs_destroy_request_bufs();
+	kthread_stop(oplockThread);
+}
+
+MODULE_AUTHOR("Steve French <sfrench@us.ibm.com>");
+MODULE_LICENSE("GPL");	/* combination of LGPL + GPL source behaves as GPL */
+MODULE_DESCRIPTION
+    ("VFS to access servers complying with the SNIA CIFS Specification "
+     "e.g. Samba and Windows");
+MODULE_VERSION(CIFS_VERSION);
+module_init(init_cifs)
+module_exit(exit_cifs)
diff -Naur linux-2.6.30-ori/fs/cifs/cifsglob.h linux-2.6.30-test/fs/cifs/cifsglob.h
--- linux-2.6.30-ori/fs/cifs/cifsglob.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/cifsglob.h	2009-06-12 18:32:43.000000000 -0400
@@ -422,6 +422,19 @@
 
 #endif
 
+/* FIXME remove this debug stuff eventually */
+#if 0
+#define dprintk(fmt, args...)	\
+	printk("DBG at %s:%d: "fmt, __FUNCTION__, __LINE__, ##args)
+#else
+#define dprintk(fmt, args...)	do { } while (0)
+#endif
+
+#define CIFS_NEW_READPAGES	/* use new async ->readpages() */
+
+#define CIFS_READPAGES_MAX	32 /* gives us 32*4k = 128k (just as a maximum
+				      for CIFSMaxBufSize) */
+
 /* one of these for every pending CIFS request to the server */
 struct mid_q_entry {
 	struct list_head qhead;	/* mids waiting on reply from this server */
@@ -440,6 +453,18 @@
 	bool largeBuf:1;	/* if valid response, is pointer to large buf */
 	bool multiRsp:1;	/* multiple trans2 responses for one request  */
 	bool multiEnd:1;	/* both received */
+	struct page *pages[CIFS_READPAGES_MAX]; /* pages for ->readpages() */
+	unsigned nr_pages;	/* number of pages in the request */
+	struct list_head midq_entry; /* mids linked into midq_list */
+};
+
+/* ->readpages() private data */
+struct cifs_readpages_data {
+	struct file *file;
+	struct page *pages[CIFS_READPAGES_MAX];
+	unsigned nr_pages;
+	int xid;
+	struct list_head midq_list;
 };
 
 struct oplock_q_entry {
diff -Naur linux-2.6.30-ori/fs/cifs/cifsproto.h linux-2.6.30-test/fs/cifs/cifsproto.h
--- linux-2.6.30-ori/fs/cifs/cifsproto.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/cifsproto.h	2009-06-12 18:32:43.000000000 -0400
@@ -54,6 +54,8 @@
 			int * /* bytes returned */ , const int long_op);
 extern int SendReceiveNoRsp(const unsigned int xid, struct cifsSesInfo *ses,
 			struct smb_hdr *in_buf, int flags);
+ extern int Send(const unsigned int xid, struct cifsSesInfo *ses, 
+ 	     struct kvec *iov, int n_vec, struct cifs_readpages_data *data);
 extern int SendReceive2(const unsigned int /* xid */ , struct cifsSesInfo *,
 			struct kvec *, int /* nvec to send */,
 			int * /* type of buf returned */ , const int flags);
@@ -86,6 +88,7 @@
 			     const int stage,
 			     const struct nls_table *nls_cp);
 extern __u16 GetNextMid(struct TCP_Server_Info *server);
+extern void DeleteMidQEntry(struct mid_q_entry *);
 extern struct oplock_q_entry *AllocOplockQEntry(struct inode *, u16,
 						 struct cifsTconInfo *);
 extern void DeleteOplockQEntry(struct oplock_q_entry *);
@@ -292,7 +295,7 @@
 extern int CIFSSMBRead(const int xid, struct cifsTconInfo *tcon,
 			const int netfid, unsigned int count,
 			const __u64 lseek, unsigned int *nbytes, char **buf,
-			int *return_buf_type);
+			int *return_buf_type, int async_flag);
 extern int CIFSSMBWrite(const int xid, struct cifsTconInfo *tcon,
 			const int netfid, const unsigned int count,
 			const __u64 lseek, unsigned int *nbytes,
diff -Naur linux-2.6.30-ori/fs/cifs/cifsproto.h.orig linux-2.6.30-test/fs/cifs/cifsproto.h.orig
--- linux-2.6.30-ori/fs/cifs/cifsproto.h.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/cifsproto.h.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,383 @@
+/*
+ *   fs/cifs/cifsproto.h
+ *
+ *   Copyright (c) International Business Machines  Corp., 2002,2008
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+#ifndef _CIFSPROTO_H
+#define _CIFSPROTO_H
+#include <linux/nls.h>
+
+struct statfs;
+struct smb_vol;
+
+/*
+ *****************************************************************
+ * All Prototypes
+ *****************************************************************
+ */
+
+extern struct smb_hdr *cifs_buf_get(void);
+extern void cifs_buf_release(void *);
+extern struct smb_hdr *cifs_small_buf_get(void);
+extern void cifs_small_buf_release(void *);
+extern int smb_send(struct TCP_Server_Info *, struct smb_hdr *,
+			unsigned int /* length */);
+extern unsigned int _GetXid(void);
+extern void _FreeXid(unsigned int);
+#define GetXid() (int)_GetXid(); cFYI(1,("CIFS VFS: in %s as Xid: %d with uid: %d",__func__, xid,current_fsuid()));
+#define FreeXid(curr_xid) {_FreeXid(curr_xid); cFYI(1,("CIFS VFS: leaving %s (xid = %d) rc = %d",__func__,curr_xid,(int)rc));}
+extern char *build_path_from_dentry(struct dentry *);
+extern char *cifs_build_path_to_root(struct cifs_sb_info *cifs_sb);
+extern char *build_wildcard_path_from_dentry(struct dentry *direntry);
+extern char *cifs_compose_mount_options(const char *sb_mountdata,
+		const char *fullpath, const struct dfs_info3_param *ref,
+		char **devname);
+/* extern void renew_parental_timestamps(struct dentry *direntry);*/
+extern int SendReceive(const unsigned int /* xid */ , struct cifsSesInfo *,
+			struct smb_hdr * /* input */ ,
+			struct smb_hdr * /* out */ ,
+			int * /* bytes returned */ , const int long_op);
+extern int SendReceiveNoRsp(const unsigned int xid, struct cifsSesInfo *ses,
+			struct smb_hdr *in_buf, int flags);
+extern int SendReceive2(const unsigned int /* xid */ , struct cifsSesInfo *,
+			struct kvec *, int /* nvec to send */,
+			int * /* type of buf returned */ , const int flags);
+extern int SendReceiveBlockingLock(const unsigned int xid,
+			struct cifsTconInfo *ptcon,
+			struct smb_hdr *in_buf ,
+			struct smb_hdr *out_buf,
+			int *bytes_returned);
+extern int checkSMB(struct smb_hdr *smb, __u16 mid, unsigned int length);
+extern bool is_valid_oplock_break(struct smb_hdr *smb,
+				  struct TCP_Server_Info *);
+extern bool is_size_safe_to_change(struct cifsInodeInfo *, __u64 eof);
+extern struct cifsFileInfo *find_writable_file(struct cifsInodeInfo *);
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+extern struct cifsFileInfo *find_readable_file(struct cifsInodeInfo *);
+#endif
+extern unsigned int smbCalcSize(struct smb_hdr *ptr);
+extern unsigned int smbCalcSize_LE(struct smb_hdr *ptr);
+extern int decode_negTokenInit(unsigned char *security_blob, int length,
+			enum securityEnum *secType);
+extern int cifs_inet_pton(const int, const char *source, void *dst);
+extern int map_smb_to_linux_error(struct smb_hdr *smb, int logErr);
+extern void header_assemble(struct smb_hdr *, char /* command */ ,
+			    const struct cifsTconInfo *, int /* length of
+			    fixed section (word count) in two byte units */);
+extern int small_smb_init_no_tc(const int smb_cmd, const int wct,
+				struct cifsSesInfo *ses,
+				void **request_buf);
+extern int CIFS_SessSetup(unsigned int xid, struct cifsSesInfo *ses,
+			     const int stage,
+			     const struct nls_table *nls_cp);
+extern __u16 GetNextMid(struct TCP_Server_Info *server);
+extern struct oplock_q_entry *AllocOplockQEntry(struct inode *, u16,
+						 struct cifsTconInfo *);
+extern void DeleteOplockQEntry(struct oplock_q_entry *);
+extern void DeleteTconOplockQEntries(struct cifsTconInfo *);
+extern struct timespec cifs_NTtimeToUnix(u64 utc_nanoseconds_since_1601);
+extern u64 cifs_UnixTimeToNT(struct timespec);
+extern __le64 cnvrtDosCifsTm(__u16 date, __u16 time);
+extern struct timespec cnvrtDosUnixTm(__u16 date, __u16 time);
+
+extern int cifs_posix_open(char *full_path, struct inode **pinode,
+			   struct super_block *sb, int mode, int oflags,
+			   int *poplock, __u16 *pnetfid, int xid);
+extern void posix_fill_in_inode(struct inode *tmp_inode,
+				FILE_UNIX_BASIC_INFO *pData, int isNewInode);
+extern struct inode *cifs_new_inode(struct super_block *sb, __u64 *inum);
+extern int cifs_get_inode_info(struct inode **pinode,
+			const unsigned char *search_path,
+			FILE_ALL_INFO *pfile_info,
+			struct super_block *sb, int xid, const __u16 *pfid);
+extern int cifs_get_inode_info_unix(struct inode **pinode,
+			const unsigned char *search_path,
+			struct super_block *sb, int xid);
+extern void acl_to_uid_mode(struct inode *inode, const char *path,
+			    const __u16 *pfid);
+extern int mode_to_acl(struct inode *inode, const char *path, __u64);
+
+extern int cifs_mount(struct super_block *, struct cifs_sb_info *, char *,
+			const char *);
+extern int cifs_umount(struct super_block *, struct cifs_sb_info *);
+extern void cifs_dfs_release_automount_timer(void);
+void cifs_proc_init(void);
+void cifs_proc_clean(void);
+
+extern int cifs_setup_session(unsigned int xid, struct cifsSesInfo *pSesInfo,
+			struct nls_table *nls_info);
+extern int CIFSSMBNegotiate(unsigned int xid, struct cifsSesInfo *ses);
+
+extern int CIFSTCon(unsigned int xid, struct cifsSesInfo *ses,
+			const char *tree, struct cifsTconInfo *tcon,
+			const struct nls_table *);
+
+extern int CIFSFindFirst(const int xid, struct cifsTconInfo *tcon,
+		const char *searchName, const struct nls_table *nls_codepage,
+		__u16 *searchHandle, struct cifs_search_info *psrch_inf,
+		int map, const char dirsep);
+
+extern int CIFSFindNext(const int xid, struct cifsTconInfo *tcon,
+		__u16 searchHandle, struct cifs_search_info *psrch_inf);
+
+extern int CIFSFindClose(const int, struct cifsTconInfo *tcon,
+			const __u16 search_handle);
+
+extern int CIFSSMBQPathInfo(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			FILE_ALL_INFO *findData,
+			int legacy /* whether to use old info level */,
+			const struct nls_table *nls_codepage, int remap);
+extern int SMBQueryInformation(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			FILE_ALL_INFO *findData,
+			const struct nls_table *nls_codepage, int remap);
+
+extern int CIFSSMBUnixQPathInfo(const int xid,
+			struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			FILE_UNIX_BASIC_INFO *pFindData,
+			const struct nls_table *nls_codepage, int remap);
+
+extern int CIFSGetDFSRefer(const int xid, struct cifsSesInfo *ses,
+			const unsigned char *searchName,
+			struct dfs_info3_param **target_nodes,
+			unsigned int *number_of_nodes_in_array,
+			const struct nls_table *nls_codepage, int remap);
+
+extern int get_dfs_path(int xid, struct cifsSesInfo *pSesInfo,
+			const char *old_path,
+			const struct nls_table *nls_codepage,
+			unsigned int *pnum_referrals,
+			struct dfs_info3_param **preferrals,
+			int remap);
+extern void reset_cifs_unix_caps(int xid, struct cifsTconInfo *tcon,
+				 struct super_block *sb, struct smb_vol *vol);
+extern int CIFSSMBQFSInfo(const int xid, struct cifsTconInfo *tcon,
+			struct kstatfs *FSData);
+extern int SMBOldQFSInfo(const int xid, struct cifsTconInfo *tcon,
+			struct kstatfs *FSData);
+extern int CIFSSMBSetFSUnixInfo(const int xid, struct cifsTconInfo *tcon,
+			__u64 cap);
+
+extern int CIFSSMBQFSAttributeInfo(const int xid,
+			struct cifsTconInfo *tcon);
+extern int CIFSSMBQFSDeviceInfo(const int xid, struct cifsTconInfo *tcon);
+extern int CIFSSMBQFSUnixInfo(const int xid, struct cifsTconInfo *tcon);
+extern int CIFSSMBQFSPosixInfo(const int xid, struct cifsTconInfo *tcon,
+			struct kstatfs *FSData);
+
+extern int CIFSSMBSetPathInfo(const int xid, struct cifsTconInfo *tcon,
+			const char *fileName, const FILE_BASIC_INFO *data,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBSetFileInfo(const int xid, struct cifsTconInfo *tcon,
+			const FILE_BASIC_INFO *data, __u16 fid,
+			__u32 pid_of_opener);
+extern int CIFSSMBSetFileDisposition(const int xid, struct cifsTconInfo *tcon,
+			bool delete_file, __u16 fid, __u32 pid_of_opener);
+#if 0
+extern int CIFSSMBSetAttrLegacy(int xid, struct cifsTconInfo *tcon,
+			char *fileName, __u16 dos_attributes,
+			const struct nls_table *nls_codepage);
+#endif /* possibly unneeded function */
+extern int CIFSSMBSetEOF(const int xid, struct cifsTconInfo *tcon,
+			const char *fileName, __u64 size,
+			bool setAllocationSizeFlag,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBSetFileSize(const int xid, struct cifsTconInfo *tcon,
+			 __u64 size, __u16 fileHandle, __u32 opener_pid,
+			bool AllocSizeFlag);
+
+struct cifs_unix_set_info_args {
+	__u64	ctime;
+	__u64	atime;
+	__u64	mtime;
+	__u64	mode;
+	__u64	uid;
+	__u64	gid;
+	dev_t	device;
+};
+
+extern int CIFSSMBUnixSetInfo(const int xid, struct cifsTconInfo *pTcon,
+			char *fileName,
+			const struct cifs_unix_set_info_args *args,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+
+extern int CIFSSMBMkDir(const int xid, struct cifsTconInfo *tcon,
+			const char *newName,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBRmDir(const int xid, struct cifsTconInfo *tcon,
+			const char *name, const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSPOSIXDelFile(const int xid, struct cifsTconInfo *tcon,
+			const char *name, __u16 type,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBDelFile(const int xid, struct cifsTconInfo *tcon,
+			const char *name,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBRename(const int xid, struct cifsTconInfo *tcon,
+			const char *fromName, const char *toName,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBRenameOpenFile(const int xid, struct cifsTconInfo *pTcon,
+			int netfid, const char *target_name,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSCreateHardLink(const int xid,
+			struct cifsTconInfo *tcon,
+			const char *fromName, const char *toName,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSUnixCreateHardLink(const int xid,
+			struct cifsTconInfo *tcon,
+			const char *fromName, const char *toName,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSUnixCreateSymLink(const int xid,
+			struct cifsTconInfo *tcon,
+			const char *fromName, const char *toName,
+			const struct nls_table *nls_codepage);
+extern int CIFSSMBUnixQuerySymLink(const int xid,
+			struct cifsTconInfo *tcon,
+			const unsigned char *searchName, char **syminfo,
+			const struct nls_table *nls_codepage);
+extern int CIFSSMBQueryReparseLinkInfo(const int xid,
+			struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			char *symlinkinfo, const int buflen, __u16 fid,
+			const struct nls_table *nls_codepage);
+
+extern int CIFSSMBOpen(const int xid, struct cifsTconInfo *tcon,
+			const char *fileName, const int disposition,
+			const int access_flags, const int omode,
+			__u16 *netfid, int *pOplock, FILE_ALL_INFO *,
+			const struct nls_table *nls_codepage, int remap);
+extern int SMBLegacyOpen(const int xid, struct cifsTconInfo *tcon,
+			const char *fileName, const int disposition,
+			const int access_flags, const int omode,
+			__u16 *netfid, int *pOplock, FILE_ALL_INFO *,
+			const struct nls_table *nls_codepage, int remap);
+extern int CIFSPOSIXCreate(const int xid, struct cifsTconInfo *tcon,
+			u32 posix_flags, __u64 mode, __u16 *netfid,
+			FILE_UNIX_BASIC_INFO *pRetData,
+			__u32 *pOplock, const char *name,
+			const struct nls_table *nls_codepage, int remap);
+extern int CIFSSMBClose(const int xid, struct cifsTconInfo *tcon,
+			const int smb_file_id);
+
+extern int CIFSSMBFlush(const int xid, struct cifsTconInfo *tcon,
+			const int smb_file_id);
+
+extern int CIFSSMBRead(const int xid, struct cifsTconInfo *tcon,
+			const int netfid, unsigned int count,
+			const __u64 lseek, unsigned int *nbytes, char **buf,
+			int *return_buf_type);
+extern int CIFSSMBWrite(const int xid, struct cifsTconInfo *tcon,
+			const int netfid, const unsigned int count,
+			const __u64 lseek, unsigned int *nbytes,
+			const char *buf, const char __user *ubuf,
+			const int long_op);
+extern int CIFSSMBWrite2(const int xid, struct cifsTconInfo *tcon,
+			const int netfid, const unsigned int count,
+			const __u64 offset, unsigned int *nbytes,
+			struct kvec *iov, const int nvec, const int long_op);
+extern int CIFSGetSrvInodeNumber(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName, __u64 *inode_number,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int cifsConvertToUCS(__le16 *target, const char *source, int maxlen,
+			const struct nls_table *cp, int mapChars);
+
+extern int CIFSSMBLock(const int xid, struct cifsTconInfo *tcon,
+			const __u16 netfid, const __u64 len,
+			const __u64 offset, const __u32 numUnlock,
+			const __u32 numLock, const __u8 lockType,
+			const bool waitFlag);
+extern int CIFSSMBPosixLock(const int xid, struct cifsTconInfo *tcon,
+			const __u16 smb_file_id, const int get_flag,
+			const __u64 len, struct file_lock *,
+			const __u16 lock_type, const bool waitFlag);
+extern int CIFSSMBTDis(const int xid, struct cifsTconInfo *tcon);
+extern int CIFSSMBLogoff(const int xid, struct cifsSesInfo *ses);
+
+extern struct cifsSesInfo *sesInfoAlloc(void);
+extern void sesInfoFree(struct cifsSesInfo *);
+extern struct cifsTconInfo *tconInfoAlloc(void);
+extern void tconInfoFree(struct cifsTconInfo *);
+
+extern int cifs_sign_smb(struct smb_hdr *, struct TCP_Server_Info *, __u32 *);
+extern int cifs_sign_smb2(struct kvec *iov, int n_vec, struct TCP_Server_Info *,
+			  __u32 *);
+extern int cifs_verify_signature(struct smb_hdr *,
+				 const struct mac_key *mac_key,
+				__u32 expected_sequence_number);
+extern int cifs_calculate_mac_key(struct mac_key *key, const char *rn,
+				 const char *pass);
+extern int CalcNTLMv2_partial_mac_key(struct cifsSesInfo *,
+			const struct nls_table *);
+extern void CalcNTLMv2_response(const struct cifsSesInfo *, char *);
+extern void setup_ntlmv2_rsp(struct cifsSesInfo *, char *,
+			     const struct nls_table *);
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+extern void calc_lanman_hash(const char *password, const char *cryptkey,
+				bool encrypt, char *lnm_session_key);
+#endif /* CIFS_WEAK_PW_HASH */
+extern int CIFSSMBCopy(int xid,
+			struct cifsTconInfo *source_tcon,
+			const char *fromName,
+			const __u16 target_tid,
+			const char *toName, const int flags,
+			const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern int CIFSSMBNotify(const int xid, struct cifsTconInfo *tcon,
+			const int notify_subdirs, const __u16 netfid,
+			__u32 filter, struct file *file, int multishot,
+			const struct nls_table *nls_codepage);
+extern ssize_t CIFSSMBQAllEAs(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName, char *EAData,
+			size_t bufsize, const struct nls_table *nls_codepage,
+			int remap_special_chars);
+extern ssize_t CIFSSMBQueryEA(const int xid, struct cifsTconInfo *tcon,
+		const unsigned char *searchName, const unsigned char *ea_name,
+		unsigned char *ea_value, size_t buf_size,
+		const struct nls_table *nls_codepage, int remap_special_chars);
+extern int CIFSSMBSetEA(const int xid, struct cifsTconInfo *tcon,
+		const char *fileName, const char *ea_name,
+		const void *ea_value, const __u16 ea_value_len,
+		const struct nls_table *nls_codepage, int remap_special_chars);
+extern int CIFSSMBGetCIFSACL(const int xid, struct cifsTconInfo *tcon,
+			__u16 fid, struct cifs_ntsd **acl_inf, __u32 *buflen);
+extern int CIFSSMBSetCIFSACL(const int, struct cifsTconInfo *, __u16,
+			struct cifs_ntsd *, __u32);
+extern int CIFSSMBGetPosixACL(const int xid, struct cifsTconInfo *tcon,
+		const unsigned char *searchName,
+		char *acl_inf, const int buflen, const int acl_type,
+		const struct nls_table *nls_codepage, int remap_special_chars);
+extern int CIFSSMBSetPosixACL(const int xid, struct cifsTconInfo *tcon,
+		const unsigned char *fileName,
+		const char *local_acl, const int buflen, const int acl_type,
+		const struct nls_table *nls_codepage, int remap_special_chars);
+extern int CIFSGetExtAttr(const int xid, struct cifsTconInfo *tcon,
+			const int netfid, __u64 *pExtAttrBits, __u64 *pMask);
+#endif			/* _CIFSPROTO_H */
diff -Naur linux-2.6.30-ori/fs/cifs/cifssmb.c linux-2.6.30-test/fs/cifs/cifssmb.c
--- linux-2.6.30-ori/fs/cifs/cifssmb.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/cifssmb.c	2009-06-12 18:32:43.000000000 -0400
@@ -1377,7 +1377,7 @@
 int
 CIFSSMBRead(const int xid, struct cifsTconInfo *tcon, const int netfid,
 	    const unsigned int count, const __u64 lseek, unsigned int *nbytes,
-	    char **buf, int *pbuf_type)
+	    char **buf, int *pbuf_type, int async_flag)
 {
 	int rc = -EACCES;
 	READ_REQ *pSMB = NULL;
@@ -1387,7 +1387,7 @@
 	int resp_buf_type = 0;
 	struct kvec iov[1];
 
-	cFYI(1, ("Reading %d bytes on fid %d", count, netfid));
+	cFYI(1, ("Reading %d bytes on fid %d at %lld", count, netfid, lseek));
 	if (tcon->ses->capabilities & CAP_LARGE_FILES)
 		wct = 12;
 	else {
@@ -1427,6 +1427,21 @@
 
 	iov[0].iov_base = (char *)pSMB;
 	iov[0].iov_len = pSMB->hdr.smb_buf_length + 4;
+
+	if (async_flag) {
+		/* FIXME
+		 * We treat the buf argument as a cifs_readpages data there.
+		 * Yeah, it may seem confusing, but I haven't come up with
+		 * anything better yet.
+		 */
+		struct cifs_readpages_data *data = 
+			(struct cifs_readpages_data *) *buf;
+		rc = Send(xid, tcon->ses, iov, 1, data);
+		cifs_stats_inc(&tcon->num_reads);
+		/* return immediately */
+		return rc;
+	}
+ 
 	rc = SendReceive2(xid, tcon->ses, iov, 1 /* num iovecs */,
 			 &resp_buf_type, CIFS_STD_OP | CIFS_LOG_ERROR);
 	cifs_stats_inc(&tcon->num_reads);
diff -Naur linux-2.6.30-ori/fs/cifs/cifssmb.c.orig linux-2.6.30-test/fs/cifs/cifssmb.c.orig
--- linux-2.6.30-ori/fs/cifs/cifssmb.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/cifssmb.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,5664 @@
+/*
+ *   fs/cifs/cifssmb.c
+ *
+ *   Copyright (C) International Business Machines  Corp., 2002,2009
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *
+ *   Contains the routines for constructing the SMB PDUs themselves
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+
+ /* SMB/CIFS PDU handling routines here - except for leftovers in connect.c   */
+ /* These are mostly routines that operate on a pathname, or on a tree id     */
+ /* (mounted volume), but there are eight handle based routines which must be */
+ /* treated slightly differently for reconnection purposes since we never     */
+ /* want to reuse a stale file handle and only the caller knows the file info */
+
+#include <linux/fs.h>
+#include <linux/kernel.h>
+#include <linux/vfs.h>
+#include <linux/posix_acl_xattr.h>
+#include <asm/uaccess.h>
+#include "cifspdu.h"
+#include "cifsglob.h"
+#include "cifsacl.h"
+#include "cifsproto.h"
+#include "cifs_unicode.h"
+#include "cifs_debug.h"
+
+#ifdef CONFIG_CIFS_POSIX
+static struct {
+	int index;
+	char *name;
+} protocols[] = {
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+	{LANMAN_PROT, "\2LM1.2X002"},
+	{LANMAN2_PROT, "\2LANMAN2.1"},
+#endif /* weak password hashing for legacy clients */
+	{CIFS_PROT, "\2NT LM 0.12"},
+	{POSIX_PROT, "\2POSIX 2"},
+	{BAD_PROT, "\2"}
+};
+#else
+static struct {
+	int index;
+	char *name;
+} protocols[] = {
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+	{LANMAN_PROT, "\2LM1.2X002"},
+	{LANMAN2_PROT, "\2LANMAN2.1"},
+#endif /* weak password hashing for legacy clients */
+	{CIFS_PROT, "\2NT LM 0.12"},
+	{BAD_PROT, "\2"}
+};
+#endif
+
+/* define the number of elements in the cifs dialect array */
+#ifdef CONFIG_CIFS_POSIX
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+#define CIFS_NUM_PROT 4
+#else
+#define CIFS_NUM_PROT 2
+#endif /* CIFS_WEAK_PW_HASH */
+#else /* not posix */
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+#define CIFS_NUM_PROT 3
+#else
+#define CIFS_NUM_PROT 1
+#endif /* CONFIG_CIFS_WEAK_PW_HASH */
+#endif /* CIFS_POSIX */
+
+/* Mark as invalid, all open files on tree connections since they
+   were closed when session to server was lost */
+static void mark_open_files_invalid(struct cifsTconInfo *pTcon)
+{
+	struct cifsFileInfo *open_file = NULL;
+	struct list_head *tmp;
+	struct list_head *tmp1;
+
+/* list all files open on tree connection and mark them invalid */
+	write_lock(&GlobalSMBSeslock);
+	list_for_each_safe(tmp, tmp1, &pTcon->openFileList) {
+		open_file = list_entry(tmp, struct cifsFileInfo, tlist);
+		open_file->invalidHandle = true;
+	}
+	write_unlock(&GlobalSMBSeslock);
+	/* BB Add call to invalidate_inodes(sb) for all superblocks mounted
+	   to this tcon */
+}
+
+/* Allocate and return pointer to an SMB request buffer, and set basic
+   SMB information in the SMB header.  If the return code is zero, this
+   function must have filled in request_buf pointer */
+static int
+small_smb_init(int smb_command, int wct, struct cifsTconInfo *tcon,
+		void **request_buf)
+{
+	int rc = 0;
+
+	/* SMBs NegProt, SessSetup, uLogoff do not have tcon yet so
+	   check for tcp and smb session status done differently
+	   for those three - in the calling routine */
+	if (tcon) {
+		if (tcon->tidStatus == CifsExiting) {
+			/* only tree disconnect, open, and write,
+			(and ulogoff which does not have tcon)
+			are allowed as we start force umount */
+			if ((smb_command != SMB_COM_WRITE_ANDX) &&
+			   (smb_command != SMB_COM_OPEN_ANDX) &&
+			   (smb_command != SMB_COM_TREE_DISCONNECT)) {
+				cFYI(1, ("can not send cmd %d while umounting",
+					smb_command));
+				return -ENODEV;
+			}
+		}
+		if ((tcon->ses) && (tcon->ses->status != CifsExiting) &&
+				  (tcon->ses->server)) {
+			struct nls_table *nls_codepage;
+				/* Give Demultiplex thread up to 10 seconds to
+				   reconnect, should be greater than cifs socket
+				   timeout which is 7 seconds */
+			while (tcon->ses->server->tcpStatus ==
+							 CifsNeedReconnect) {
+				wait_event_interruptible_timeout(tcon->ses->server->response_q,
+					(tcon->ses->server->tcpStatus ==
+							CifsGood), 10 * HZ);
+				if (tcon->ses->server->tcpStatus ==
+							CifsNeedReconnect) {
+					/* on "soft" mounts we wait once */
+					if (!tcon->retry ||
+					   (tcon->ses->status == CifsExiting)) {
+						cFYI(1, ("gave up waiting on "
+						      "reconnect in smb_init"));
+						return -EHOSTDOWN;
+					} /* else "hard" mount - keep retrying
+					     until process is killed or server
+					     comes back on-line */
+				} else /* TCP session is reestablished now */
+					break;
+			}
+
+			nls_codepage = load_nls_default();
+		/* need to prevent multiple threads trying to
+		simultaneously reconnect the same SMB session */
+			down(&tcon->ses->sesSem);
+			if (tcon->ses->need_reconnect)
+				rc = cifs_setup_session(0, tcon->ses,
+							nls_codepage);
+			if (!rc && (tcon->need_reconnect)) {
+				mark_open_files_invalid(tcon);
+				rc = CIFSTCon(0, tcon->ses, tcon->treeName,
+					      tcon, nls_codepage);
+				up(&tcon->ses->sesSem);
+				/* BB FIXME add code to check if wsize needs
+				   update due to negotiated smb buffer size
+				   shrinking */
+				if (rc == 0) {
+					atomic_inc(&tconInfoReconnectCount);
+					/* tell server Unix caps we support */
+					if (tcon->ses->capabilities & CAP_UNIX)
+						reset_cifs_unix_caps(
+						0 /* no xid */,
+						tcon,
+						NULL /* we do not know sb */,
+						NULL /* no vol info */);
+				}
+
+				cFYI(1, ("reconnect tcon rc = %d", rc));
+				/* Removed call to reopen open files here.
+				   It is safer (and faster) to reopen files
+				   one at a time as needed in read and write */
+
+				/* Check if handle based operation so we
+				   know whether we can continue or not without
+				   returning to caller to reset file handle */
+				switch (smb_command) {
+					case SMB_COM_READ_ANDX:
+					case SMB_COM_WRITE_ANDX:
+					case SMB_COM_CLOSE:
+					case SMB_COM_FIND_CLOSE2:
+					case SMB_COM_LOCKING_ANDX: {
+						unload_nls(nls_codepage);
+						return -EAGAIN;
+					}
+				}
+			} else {
+				up(&tcon->ses->sesSem);
+			}
+			unload_nls(nls_codepage);
+
+		} else {
+			return -EIO;
+		}
+	}
+	if (rc)
+		return rc;
+
+	*request_buf = cifs_small_buf_get();
+	if (*request_buf == NULL) {
+		/* BB should we add a retry in here if not a writepage? */
+		return -ENOMEM;
+	}
+
+	header_assemble((struct smb_hdr *) *request_buf, smb_command,
+			tcon, wct);
+
+	if (tcon != NULL)
+		cifs_stats_inc(&tcon->num_smbs_sent);
+
+	return rc;
+}
+
+int
+small_smb_init_no_tc(const int smb_command, const int wct,
+		     struct cifsSesInfo *ses, void **request_buf)
+{
+	int rc;
+	struct smb_hdr *buffer;
+
+	rc = small_smb_init(smb_command, wct, NULL, request_buf);
+	if (rc)
+		return rc;
+
+	buffer = (struct smb_hdr *)*request_buf;
+	buffer->Mid = GetNextMid(ses->server);
+	if (ses->capabilities & CAP_UNICODE)
+		buffer->Flags2 |= SMBFLG2_UNICODE;
+	if (ses->capabilities & CAP_STATUS32)
+		buffer->Flags2 |= SMBFLG2_ERR_STATUS;
+
+	/* uid, tid can stay at zero as set in header assemble */
+
+	/* BB add support for turning on the signing when
+	this function is used after 1st of session setup requests */
+
+	return rc;
+}
+
+/* If the return code is zero, this function must fill in request_buf pointer */
+static int
+smb_init(int smb_command, int wct, struct cifsTconInfo *tcon,
+	 void **request_buf /* returned */ ,
+	 void **response_buf /* returned */ )
+{
+	int rc = 0;
+
+	/* SMBs NegProt, SessSetup, uLogoff do not have tcon yet so
+	   check for tcp and smb session status done differently
+	   for those three - in the calling routine */
+	if (tcon) {
+		if (tcon->tidStatus == CifsExiting) {
+			/* only tree disconnect, open, and write,
+			  (and ulogoff which does not have tcon)
+			  are allowed as we start force umount */
+			if ((smb_command != SMB_COM_WRITE_ANDX) &&
+			   (smb_command != SMB_COM_OPEN_ANDX) &&
+			   (smb_command != SMB_COM_TREE_DISCONNECT)) {
+				cFYI(1, ("can not send cmd %d while umounting",
+					smb_command));
+				return -ENODEV;
+			}
+		}
+
+		if ((tcon->ses) && (tcon->ses->status != CifsExiting) &&
+				  (tcon->ses->server)) {
+			struct nls_table *nls_codepage;
+				/* Give Demultiplex thread up to 10 seconds to
+				   reconnect, should be greater than cifs socket
+				   timeout which is 7 seconds */
+			while (tcon->ses->server->tcpStatus ==
+							CifsNeedReconnect) {
+				wait_event_interruptible_timeout(tcon->ses->server->response_q,
+					(tcon->ses->server->tcpStatus ==
+							CifsGood), 10 * HZ);
+				if (tcon->ses->server->tcpStatus ==
+						CifsNeedReconnect) {
+					/* on "soft" mounts we wait once */
+					if (!tcon->retry ||
+					   (tcon->ses->status == CifsExiting)) {
+						cFYI(1, ("gave up waiting on "
+						      "reconnect in smb_init"));
+						return -EHOSTDOWN;
+					} /* else "hard" mount - keep retrying
+					     until process is killed or server
+					     comes on-line */
+				} else /* TCP session is reestablished now */
+					break;
+			}
+			nls_codepage = load_nls_default();
+		/* need to prevent multiple threads trying to
+		simultaneously reconnect the same SMB session */
+			down(&tcon->ses->sesSem);
+			if (tcon->ses->need_reconnect)
+				rc = cifs_setup_session(0, tcon->ses,
+							nls_codepage);
+			if (!rc && (tcon->need_reconnect)) {
+				mark_open_files_invalid(tcon);
+				rc = CIFSTCon(0, tcon->ses, tcon->treeName,
+					      tcon, nls_codepage);
+				up(&tcon->ses->sesSem);
+				/* BB FIXME add code to check if wsize needs
+				update due to negotiated smb buffer size
+				shrinking */
+				if (rc == 0) {
+					atomic_inc(&tconInfoReconnectCount);
+					/* tell server Unix caps we support */
+					if (tcon->ses->capabilities & CAP_UNIX)
+						reset_cifs_unix_caps(
+						0 /* no xid */,
+						tcon,
+						NULL /* do not know sb */,
+						NULL /* no vol info */);
+				}
+
+				cFYI(1, ("reconnect tcon rc = %d", rc));
+				/* Removed call to reopen open files here.
+				   It is safer (and faster) to reopen files
+				   one at a time as needed in read and write */
+
+				/* Check if handle based operation so we
+				   know whether we can continue or not without
+				   returning to caller to reset file handle */
+				switch (smb_command) {
+					case SMB_COM_READ_ANDX:
+					case SMB_COM_WRITE_ANDX:
+					case SMB_COM_CLOSE:
+					case SMB_COM_FIND_CLOSE2:
+					case SMB_COM_LOCKING_ANDX: {
+						unload_nls(nls_codepage);
+						return -EAGAIN;
+					}
+				}
+			} else {
+				up(&tcon->ses->sesSem);
+			}
+			unload_nls(nls_codepage);
+
+		} else {
+			return -EIO;
+		}
+	}
+	if (rc)
+		return rc;
+
+	*request_buf = cifs_buf_get();
+	if (*request_buf == NULL) {
+		/* BB should we add a retry in here if not a writepage? */
+		return -ENOMEM;
+	}
+    /* Although the original thought was we needed the response buf for  */
+    /* potential retries of smb operations it turns out we can determine */
+    /* from the mid flags when the request buffer can be resent without  */
+    /* having to use a second distinct buffer for the response */
+	if (response_buf)
+		*response_buf = *request_buf;
+
+	header_assemble((struct smb_hdr *) *request_buf, smb_command, tcon,
+			wct);
+
+	if (tcon != NULL)
+		cifs_stats_inc(&tcon->num_smbs_sent);
+
+	return rc;
+}
+
+static int validate_t2(struct smb_t2_rsp *pSMB)
+{
+	int rc = -EINVAL;
+	int total_size;
+	char *pBCC;
+
+	/* check for plausible wct, bcc and t2 data and parm sizes */
+	/* check for parm and data offset going beyond end of smb */
+	if (pSMB->hdr.WordCount >= 10) {
+		if ((le16_to_cpu(pSMB->t2_rsp.ParameterOffset) <= 1024) &&
+		   (le16_to_cpu(pSMB->t2_rsp.DataOffset) <= 1024)) {
+			/* check that bcc is at least as big as parms + data */
+			/* check that bcc is less than negotiated smb buffer */
+			total_size = le16_to_cpu(pSMB->t2_rsp.ParameterCount);
+			if (total_size < 512) {
+				total_size +=
+					le16_to_cpu(pSMB->t2_rsp.DataCount);
+				/* BCC le converted in SendReceive */
+				pBCC = (pSMB->hdr.WordCount * 2) +
+					sizeof(struct smb_hdr) +
+					(char *)pSMB;
+				if ((total_size <= (*(u16 *)pBCC)) &&
+				   (total_size <
+					CIFSMaxBufSize+MAX_CIFS_HDR_SIZE)) {
+					return 0;
+				}
+			}
+		}
+	}
+	cifs_dump_mem("Invalid transact2 SMB: ", (char *)pSMB,
+		sizeof(struct smb_t2_rsp) + 16);
+	return rc;
+}
+int
+CIFSSMBNegotiate(unsigned int xid, struct cifsSesInfo *ses)
+{
+	NEGOTIATE_REQ *pSMB;
+	NEGOTIATE_RSP *pSMBr;
+	int rc = 0;
+	int bytes_returned;
+	int i;
+	struct TCP_Server_Info *server;
+	u16 count;
+	unsigned int secFlags;
+	u16 dialect;
+
+	if (ses->server)
+		server = ses->server;
+	else {
+		rc = -EIO;
+		return rc;
+	}
+	rc = smb_init(SMB_COM_NEGOTIATE, 0, NULL /* no tcon yet */ ,
+		      (void **) &pSMB, (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	/* if any of auth flags (ie not sign or seal) are overriden use them */
+	if (ses->overrideSecFlg & (~(CIFSSEC_MUST_SIGN | CIFSSEC_MUST_SEAL)))
+		secFlags = ses->overrideSecFlg;  /* BB FIXME fix sign flags? */
+	else /* if override flags set only sign/seal OR them with global auth */
+		secFlags = extended_security | ses->overrideSecFlg;
+
+	cFYI(1, ("secFlags 0x%x", secFlags));
+
+	pSMB->hdr.Mid = GetNextMid(server);
+	pSMB->hdr.Flags2 |= (SMBFLG2_UNICODE | SMBFLG2_ERR_STATUS);
+
+	if ((secFlags & CIFSSEC_MUST_KRB5) == CIFSSEC_MUST_KRB5)
+		pSMB->hdr.Flags2 |= SMBFLG2_EXT_SEC;
+	else if ((secFlags & CIFSSEC_AUTH_MASK) == CIFSSEC_MAY_KRB5) {
+		cFYI(1, ("Kerberos only mechanism, enable extended security"));
+		pSMB->hdr.Flags2 |= SMBFLG2_EXT_SEC;
+	}
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	else if ((secFlags & CIFSSEC_MUST_NTLMSSP) == CIFSSEC_MUST_NTLMSSP)
+		pSMB->hdr.Flags2 |= SMBFLG2_EXT_SEC;
+	else if ((secFlags & CIFSSEC_AUTH_MASK) == CIFSSEC_MAY_NTLMSSP) {
+		cFYI(1, ("NTLMSSP only mechanism, enable extended security"));
+		pSMB->hdr.Flags2 |= SMBFLG2_EXT_SEC;
+	}
+#endif
+
+	count = 0;
+	for (i = 0; i < CIFS_NUM_PROT; i++) {
+		strncpy(pSMB->DialectsArray+count, protocols[i].name, 16);
+		count += strlen(protocols[i].name) + 1;
+		/* null at end of source and target buffers anyway */
+	}
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	rc = SendReceive(xid, ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc != 0)
+		goto neg_err_exit;
+
+	dialect = le16_to_cpu(pSMBr->DialectIndex);
+	cFYI(1, ("Dialect: %d", dialect));
+	/* Check wct = 1 error case */
+	if ((pSMBr->hdr.WordCount < 13) || (dialect == BAD_PROT)) {
+		/* core returns wct = 1, but we do not ask for core - otherwise
+		small wct just comes when dialect index is -1 indicating we
+		could not negotiate a common dialect */
+		rc = -EOPNOTSUPP;
+		goto neg_err_exit;
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+	} else if ((pSMBr->hdr.WordCount == 13)
+			&& ((dialect == LANMAN_PROT)
+				|| (dialect == LANMAN2_PROT))) {
+		__s16 tmp;
+		struct lanman_neg_rsp *rsp = (struct lanman_neg_rsp *)pSMBr;
+
+		if ((secFlags & CIFSSEC_MAY_LANMAN) ||
+			(secFlags & CIFSSEC_MAY_PLNTXT))
+			server->secType = LANMAN;
+		else {
+			cERROR(1, ("mount failed weak security disabled"
+				   " in /proc/fs/cifs/SecurityFlags"));
+			rc = -EOPNOTSUPP;
+			goto neg_err_exit;
+		}
+		server->secMode = (__u8)le16_to_cpu(rsp->SecurityMode);
+		server->maxReq = le16_to_cpu(rsp->MaxMpxCount);
+		server->maxBuf = min((__u32)le16_to_cpu(rsp->MaxBufSize),
+				(__u32)CIFSMaxBufSize + MAX_CIFS_HDR_SIZE);
+		server->max_vcs = le16_to_cpu(rsp->MaxNumberVcs);
+		GETU32(server->sessid) = le32_to_cpu(rsp->SessionKey);
+		/* even though we do not use raw we might as well set this
+		accurately, in case we ever find a need for it */
+		if ((le16_to_cpu(rsp->RawMode) & RAW_ENABLE) == RAW_ENABLE) {
+			server->max_rw = 0xFF00;
+			server->capabilities = CAP_MPX_MODE | CAP_RAW_MODE;
+		} else {
+			server->max_rw = 0;/* do not need to use raw anyway */
+			server->capabilities = CAP_MPX_MODE;
+		}
+		tmp = (__s16)le16_to_cpu(rsp->ServerTimeZone);
+		if (tmp == -1) {
+			/* OS/2 often does not set timezone therefore
+			 * we must use server time to calc time zone.
+			 * Could deviate slightly from the right zone.
+			 * Smallest defined timezone difference is 15 minutes
+			 * (i.e. Nepal).  Rounding up/down is done to match
+			 * this requirement.
+			 */
+			int val, seconds, remain, result;
+			struct timespec ts, utc;
+			utc = CURRENT_TIME;
+			ts = cnvrtDosUnixTm(le16_to_cpu(rsp->SrvTime.Date),
+						le16_to_cpu(rsp->SrvTime.Time));
+			cFYI(1, ("SrvTime %d sec since 1970 (utc: %d) diff: %d",
+				(int)ts.tv_sec, (int)utc.tv_sec,
+				(int)(utc.tv_sec - ts.tv_sec)));
+			val = (int)(utc.tv_sec - ts.tv_sec);
+			seconds = abs(val);
+			result = (seconds / MIN_TZ_ADJ) * MIN_TZ_ADJ;
+			remain = seconds % MIN_TZ_ADJ;
+			if (remain >= (MIN_TZ_ADJ / 2))
+				result += MIN_TZ_ADJ;
+			if (val < 0)
+				result = -result;
+			server->timeAdj = result;
+		} else {
+			server->timeAdj = (int)tmp;
+			server->timeAdj *= 60; /* also in seconds */
+		}
+		cFYI(1, ("server->timeAdj: %d seconds", server->timeAdj));
+
+
+		/* BB get server time for time conversions and add
+		code to use it and timezone since this is not UTC */
+
+		if (rsp->EncryptionKeyLength ==
+				cpu_to_le16(CIFS_CRYPTO_KEY_SIZE)) {
+			memcpy(server->cryptKey, rsp->EncryptionKey,
+				CIFS_CRYPTO_KEY_SIZE);
+		} else if (server->secMode & SECMODE_PW_ENCRYPT) {
+			rc = -EIO; /* need cryptkey unless plain text */
+			goto neg_err_exit;
+		}
+
+		cFYI(1, ("LANMAN negotiated"));
+		/* we will not end up setting signing flags - as no signing
+		was in LANMAN and server did not return the flags on */
+		goto signing_check;
+#else /* weak security disabled */
+	} else if (pSMBr->hdr.WordCount == 13) {
+		cERROR(1, ("mount failed, cifs module not built "
+			  "with CIFS_WEAK_PW_HASH support"));
+			rc = -EOPNOTSUPP;
+#endif /* WEAK_PW_HASH */
+		goto neg_err_exit;
+	} else if (pSMBr->hdr.WordCount != 17) {
+		/* unknown wct */
+		rc = -EOPNOTSUPP;
+		goto neg_err_exit;
+	}
+	/* else wct == 17 NTLM */
+	server->secMode = pSMBr->SecurityMode;
+	if ((server->secMode & SECMODE_USER) == 0)
+		cFYI(1, ("share mode security"));
+
+	if ((server->secMode & SECMODE_PW_ENCRYPT) == 0)
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+		if ((secFlags & CIFSSEC_MAY_PLNTXT) == 0)
+#endif /* CIFS_WEAK_PW_HASH */
+			cERROR(1, ("Server requests plain text password"
+				  " but client support disabled"));
+
+	if ((secFlags & CIFSSEC_MUST_NTLMV2) == CIFSSEC_MUST_NTLMV2)
+		server->secType = NTLMv2;
+	else if (secFlags & CIFSSEC_MAY_NTLM)
+		server->secType = NTLM;
+	else if (secFlags & CIFSSEC_MAY_NTLMV2)
+		server->secType = NTLMv2;
+	else if (secFlags & CIFSSEC_MAY_KRB5)
+		server->secType = Kerberos;
+	else if (secFlags & CIFSSEC_MAY_NTLMSSP)
+		server->secType = NTLMSSP;
+	else if (secFlags & CIFSSEC_MAY_LANMAN)
+		server->secType = LANMAN;
+/* #ifdef CONFIG_CIFS_EXPERIMENTAL
+	else if (secFlags & CIFSSEC_MAY_PLNTXT)
+		server->secType = ??
+#endif */
+	else {
+		rc = -EOPNOTSUPP;
+		cERROR(1, ("Invalid security type"));
+		goto neg_err_exit;
+	}
+	/* else ... any others ...? */
+
+	/* one byte, so no need to convert this or EncryptionKeyLen from
+	   little endian */
+	server->maxReq = le16_to_cpu(pSMBr->MaxMpxCount);
+	/* probably no need to store and check maxvcs */
+	server->maxBuf = min(le32_to_cpu(pSMBr->MaxBufferSize),
+			(__u32) CIFSMaxBufSize + MAX_CIFS_HDR_SIZE);
+	server->max_rw = le32_to_cpu(pSMBr->MaxRawSize);
+	cFYI(DBG2, ("Max buf = %d", ses->server->maxBuf));
+	GETU32(ses->server->sessid) = le32_to_cpu(pSMBr->SessionKey);
+	server->capabilities = le32_to_cpu(pSMBr->Capabilities);
+	server->timeAdj = (int)(__s16)le16_to_cpu(pSMBr->ServerTimeZone);
+	server->timeAdj *= 60;
+	if (pSMBr->EncryptionKeyLength == CIFS_CRYPTO_KEY_SIZE) {
+		memcpy(server->cryptKey, pSMBr->u.EncryptionKey,
+		       CIFS_CRYPTO_KEY_SIZE);
+	} else if ((pSMBr->hdr.Flags2 & SMBFLG2_EXT_SEC)
+			&& (pSMBr->EncryptionKeyLength == 0)) {
+		/* decode security blob */
+	} else if (server->secMode & SECMODE_PW_ENCRYPT) {
+		rc = -EIO; /* no crypt key only if plain text pwd */
+		goto neg_err_exit;
+	}
+
+	/* BB might be helpful to save off the domain of server here */
+
+	if ((pSMBr->hdr.Flags2 & SMBFLG2_EXT_SEC) &&
+		(server->capabilities & CAP_EXTENDED_SECURITY)) {
+		count = pSMBr->ByteCount;
+		if (count < 16) {
+			rc = -EIO;
+			goto neg_err_exit;
+		}
+		read_lock(&cifs_tcp_ses_lock);
+		if (server->srv_count > 1) {
+			read_unlock(&cifs_tcp_ses_lock);
+			if (memcmp(server->server_GUID,
+				   pSMBr->u.extended_response.
+				   GUID, 16) != 0) {
+				cFYI(1, ("server UID changed"));
+				memcpy(server->server_GUID,
+					pSMBr->u.extended_response.GUID,
+					16);
+			}
+		} else {
+			read_unlock(&cifs_tcp_ses_lock);
+			memcpy(server->server_GUID,
+			       pSMBr->u.extended_response.GUID, 16);
+		}
+
+		if (count == 16) {
+			server->secType = RawNTLMSSP;
+		} else {
+			rc = decode_negTokenInit(pSMBr->u.extended_response.
+						 SecurityBlob,
+						 count - 16,
+						 &server->secType);
+			if (rc == 1)
+				rc = 0;
+			else
+				rc = -EINVAL;
+		}
+	} else
+		server->capabilities &= ~CAP_EXTENDED_SECURITY;
+
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+signing_check:
+#endif
+	if ((secFlags & CIFSSEC_MAY_SIGN) == 0) {
+		/* MUST_SIGN already includes the MAY_SIGN FLAG
+		   so if this is zero it means that signing is disabled */
+		cFYI(1, ("Signing disabled"));
+		if (server->secMode & SECMODE_SIGN_REQUIRED) {
+			cERROR(1, ("Server requires "
+				   "packet signing to be enabled in "
+				   "/proc/fs/cifs/SecurityFlags."));
+			rc = -EOPNOTSUPP;
+		}
+		server->secMode &=
+			~(SECMODE_SIGN_ENABLED | SECMODE_SIGN_REQUIRED);
+	} else if ((secFlags & CIFSSEC_MUST_SIGN) == CIFSSEC_MUST_SIGN) {
+		/* signing required */
+		cFYI(1, ("Must sign - secFlags 0x%x", secFlags));
+		if ((server->secMode &
+			(SECMODE_SIGN_ENABLED | SECMODE_SIGN_REQUIRED)) == 0) {
+			cERROR(1,
+				("signing required but server lacks support"));
+			rc = -EOPNOTSUPP;
+		} else
+			server->secMode |= SECMODE_SIGN_REQUIRED;
+	} else {
+		/* signing optional ie CIFSSEC_MAY_SIGN */
+		if ((server->secMode & SECMODE_SIGN_REQUIRED) == 0)
+			server->secMode &=
+				~(SECMODE_SIGN_ENABLED | SECMODE_SIGN_REQUIRED);
+	}
+
+neg_err_exit:
+	cifs_buf_release(pSMB);
+
+	cFYI(1, ("negprot rc %d", rc));
+	return rc;
+}
+
+int
+CIFSSMBTDis(const int xid, struct cifsTconInfo *tcon)
+{
+	struct smb_hdr *smb_buffer;
+	int rc = 0;
+
+	cFYI(1, ("In tree disconnect"));
+
+	/* BB: do we need to check this? These should never be NULL. */
+	if ((tcon->ses == NULL) || (tcon->ses->server == NULL))
+		return -EIO;
+
+	/*
+	 * No need to return error on this operation if tid invalidated and
+	 * closed on server already e.g. due to tcp session crashing. Also,
+	 * the tcon is no longer on the list, so no need to take lock before
+	 * checking this.
+	 */
+	if (tcon->need_reconnect)
+		return 0;
+
+	rc = small_smb_init(SMB_COM_TREE_DISCONNECT, 0, tcon,
+			    (void **)&smb_buffer);
+	if (rc)
+		return rc;
+
+	rc = SendReceiveNoRsp(xid, tcon->ses, smb_buffer, 0);
+	if (rc)
+		cFYI(1, ("Tree disconnect failed %d", rc));
+
+	/* No need to return error on this operation if tid invalidated and
+	   closed on server already e.g. due to tcp session crashing */
+	if (rc == -EAGAIN)
+		rc = 0;
+
+	return rc;
+}
+
+int
+CIFSSMBLogoff(const int xid, struct cifsSesInfo *ses)
+{
+	LOGOFF_ANDX_REQ *pSMB;
+	int rc = 0;
+
+	cFYI(1, ("In SMBLogoff for session disconnect"));
+
+	/*
+	 * BB: do we need to check validity of ses and server? They should
+	 * always be valid since we have an active reference. If not, that
+	 * should probably be a BUG()
+	 */
+	if (!ses || !ses->server)
+		return -EIO;
+
+	down(&ses->sesSem);
+	if (ses->need_reconnect)
+		goto session_already_dead; /* no need to send SMBlogoff if uid
+					      already closed due to reconnect */
+	rc = small_smb_init(SMB_COM_LOGOFF_ANDX, 2, NULL, (void **)&pSMB);
+	if (rc) {
+		up(&ses->sesSem);
+		return rc;
+	}
+
+	pSMB->hdr.Mid = GetNextMid(ses->server);
+
+	if (ses->server->secMode &
+		   (SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED))
+			pSMB->hdr.Flags2 |= SMBFLG2_SECURITY_SIGNATURE;
+
+	pSMB->hdr.Uid = ses->Suid;
+
+	pSMB->AndXCommand = 0xFF;
+	rc = SendReceiveNoRsp(xid, ses, (struct smb_hdr *) pSMB, 0);
+session_already_dead:
+	up(&ses->sesSem);
+
+	/* if session dead then we do not need to do ulogoff,
+		since server closed smb session, no sense reporting
+		error */
+	if (rc == -EAGAIN)
+		rc = 0;
+	return rc;
+}
+
+int
+CIFSPOSIXDelFile(const int xid, struct cifsTconInfo *tcon, const char *fileName,
+		 __u16 type, const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	struct unlink_psx_rq *pRqD;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, offset, byte_count;
+
+	cFYI(1, ("In POSIX delete"));
+PsxDelete:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else { /* BB add path length overrun check */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+
+	params = 6 + name_len;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = 0; /* BB double check this with jra */
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+
+	/* Setup pointer to Request Data (inode type) */
+	pRqD = (struct unlink_psx_rq *)(((char *)&pSMB->hdr.Protocol) + offset);
+	pRqD->type = cpu_to_le16(type);
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + sizeof(struct unlink_psx_rq);
+
+	pSMB->DataCount = cpu_to_le16(sizeof(struct unlink_psx_rq));
+	pSMB->TotalDataCount = cpu_to_le16(sizeof(struct unlink_psx_rq));
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_POSIX_UNLINK);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("Posix delete returned %d", rc));
+	cifs_buf_release(pSMB);
+
+	cifs_stats_inc(&tcon->num_deletes);
+
+	if (rc == -EAGAIN)
+		goto PsxDelete;
+
+	return rc;
+}
+
+int
+CIFSSMBDelFile(const int xid, struct cifsTconInfo *tcon, const char *fileName,
+	       const struct nls_table *nls_codepage, int remap)
+{
+	DELETE_FILE_REQ *pSMB = NULL;
+	DELETE_FILE_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+
+DelFileRetry:
+	rc = smb_init(SMB_COM_DELETE, 1, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->fileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {		/* BB improve check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->fileName, fileName, name_len);
+	}
+	pSMB->SearchAttributes =
+	    cpu_to_le16(ATTR_READONLY | ATTR_HIDDEN | ATTR_SYSTEM);
+	pSMB->BufferFormat = 0x04;
+	pSMB->hdr.smb_buf_length += name_len + 1;
+	pSMB->ByteCount = cpu_to_le16(name_len + 1);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_deletes);
+	if (rc)
+		cFYI(1, ("Error in RMFile = %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto DelFileRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBRmDir(const int xid, struct cifsTconInfo *tcon, const char *dirName,
+	     const struct nls_table *nls_codepage, int remap)
+{
+	DELETE_DIRECTORY_REQ *pSMB = NULL;
+	DELETE_DIRECTORY_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+
+	cFYI(1, ("In CIFSSMBRmDir"));
+RmDirRetry:
+	rc = smb_init(SMB_COM_DELETE_DIRECTORY, 0, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len = cifsConvertToUCS((__le16 *) pSMB->DirName, dirName,
+					 PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {		/* BB improve check for buffer overruns BB */
+		name_len = strnlen(dirName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->DirName, dirName, name_len);
+	}
+
+	pSMB->BufferFormat = 0x04;
+	pSMB->hdr.smb_buf_length += name_len + 1;
+	pSMB->ByteCount = cpu_to_le16(name_len + 1);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_rmdirs);
+	if (rc)
+		cFYI(1, ("Error in RMDir = %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto RmDirRetry;
+	return rc;
+}
+
+int
+CIFSSMBMkDir(const int xid, struct cifsTconInfo *tcon,
+	     const char *name, const struct nls_table *nls_codepage, int remap)
+{
+	int rc = 0;
+	CREATE_DIRECTORY_REQ *pSMB = NULL;
+	CREATE_DIRECTORY_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len;
+
+	cFYI(1, ("In CIFSSMBMkDir"));
+MkDirRetry:
+	rc = smb_init(SMB_COM_CREATE_DIRECTORY, 0, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len = cifsConvertToUCS((__le16 *) pSMB->DirName, name,
+					    PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {		/* BB improve check for buffer overruns BB */
+		name_len = strnlen(name, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->DirName, name, name_len);
+	}
+
+	pSMB->BufferFormat = 0x04;
+	pSMB->hdr.smb_buf_length += name_len + 1;
+	pSMB->ByteCount = cpu_to_le16(name_len + 1);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_mkdirs);
+	if (rc)
+		cFYI(1, ("Error in Mkdir = %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto MkDirRetry;
+	return rc;
+}
+
+int
+CIFSPOSIXCreate(const int xid, struct cifsTconInfo *tcon, __u32 posix_flags,
+		__u64 mode, __u16 *netfid, FILE_UNIX_BASIC_INFO *pRetData,
+		__u32 *pOplock, const char *name,
+		const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, offset, byte_count, count;
+	OPEN_PSX_REQ *pdata;
+	OPEN_PSX_RSP *psx_rsp;
+
+	cFYI(1, ("In POSIX Create"));
+PsxCreat:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, name,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(name, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, name, name_len);
+	}
+
+	params = 6 + name_len;
+	count = sizeof(OPEN_PSX_REQ);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(1000);	/* large enough */
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	pdata = (OPEN_PSX_REQ *)(((char *)&pSMB->hdr.Protocol) + offset);
+	pdata->Level = cpu_to_le16(SMB_QUERY_FILE_UNIX_BASIC);
+	pdata->Permissions = cpu_to_le64(mode);
+	pdata->PosixOpenFlags = cpu_to_le32(posix_flags);
+	pdata->OpenFlags =  cpu_to_le32(*pOplock);
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_POSIX_OPEN);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Posix create returned %d", rc));
+		goto psx_create_err;
+	}
+
+	cFYI(1, ("copying inode info"));
+	rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+	if (rc || (pSMBr->ByteCount < sizeof(OPEN_PSX_RSP))) {
+		rc = -EIO;	/* bad smb */
+		goto psx_create_err;
+	}
+
+	/* copy return information to pRetData */
+	psx_rsp = (OPEN_PSX_RSP *)((char *) &pSMBr->hdr.Protocol
+			+ le16_to_cpu(pSMBr->t2.DataOffset));
+
+	*pOplock = le16_to_cpu(psx_rsp->OplockFlags);
+	if (netfid)
+		*netfid = psx_rsp->Fid;   /* cifs fid stays in le */
+	/* Let caller know file was created so we can set the mode. */
+	/* Do we care about the CreateAction in any other cases? */
+	if (cpu_to_le32(FILE_CREATE) == psx_rsp->CreateAction)
+		*pOplock |= CIFS_CREATE_ACTION;
+	/* check to make sure response data is there */
+	if (psx_rsp->ReturnedLevel != cpu_to_le16(SMB_QUERY_FILE_UNIX_BASIC)) {
+		pRetData->Type = cpu_to_le32(-1); /* unknown */
+		cFYI(DBG2, ("unknown type"));
+	} else {
+		if (pSMBr->ByteCount < sizeof(OPEN_PSX_RSP)
+					+ sizeof(FILE_UNIX_BASIC_INFO)) {
+			cERROR(1, ("Open response data too small"));
+			pRetData->Type = cpu_to_le32(-1);
+			goto psx_create_err;
+		}
+		memcpy((char *) pRetData,
+			(char *)psx_rsp + sizeof(OPEN_PSX_RSP),
+			sizeof(FILE_UNIX_BASIC_INFO));
+	}
+
+psx_create_err:
+	cifs_buf_release(pSMB);
+
+	cifs_stats_inc(&tcon->num_mkdirs);
+
+	if (rc == -EAGAIN)
+		goto PsxCreat;
+
+	return rc;
+}
+
+static __u16 convert_disposition(int disposition)
+{
+	__u16 ofun = 0;
+
+	switch (disposition) {
+		case FILE_SUPERSEDE:
+			ofun = SMBOPEN_OCREATE | SMBOPEN_OTRUNC;
+			break;
+		case FILE_OPEN:
+			ofun = SMBOPEN_OAPPEND;
+			break;
+		case FILE_CREATE:
+			ofun = SMBOPEN_OCREATE;
+			break;
+		case FILE_OPEN_IF:
+			ofun = SMBOPEN_OCREATE | SMBOPEN_OAPPEND;
+			break;
+		case FILE_OVERWRITE:
+			ofun = SMBOPEN_OTRUNC;
+			break;
+		case FILE_OVERWRITE_IF:
+			ofun = SMBOPEN_OCREATE | SMBOPEN_OTRUNC;
+			break;
+		default:
+			cFYI(1, ("unknown disposition %d", disposition));
+			ofun =  SMBOPEN_OAPPEND; /* regular open */
+	}
+	return ofun;
+}
+
+static int
+access_flags_to_smbopen_mode(const int access_flags)
+{
+	int masked_flags = access_flags & (GENERIC_READ | GENERIC_WRITE);
+
+	if (masked_flags == GENERIC_READ)
+		return SMBOPEN_READ;
+	else if (masked_flags == GENERIC_WRITE)
+		return SMBOPEN_WRITE;
+
+	/* just go for read/write */
+	return SMBOPEN_READWRITE;
+}
+
+int
+SMBLegacyOpen(const int xid, struct cifsTconInfo *tcon,
+	    const char *fileName, const int openDisposition,
+	    const int access_flags, const int create_options, __u16 *netfid,
+	    int *pOplock, FILE_ALL_INFO *pfile_info,
+	    const struct nls_table *nls_codepage, int remap)
+{
+	int rc = -EACCES;
+	OPENX_REQ *pSMB = NULL;
+	OPENX_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len;
+	__u16 count;
+
+OldOpenRetry:
+	rc = smb_init(SMB_COM_OPEN_ANDX, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->AndXCommand = 0xFF;       /* none */
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		count = 1;      /* account for one byte pad to word boundary */
+		name_len =
+		   cifsConvertToUCS((__le16 *) (pSMB->fileName + 1),
+				    fileName, PATH_MAX, nls_codepage, remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+	} else {                /* BB improve check for buffer overruns BB */
+		count = 0;      /* no pad */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->fileName, fileName, name_len);
+	}
+	if (*pOplock & REQ_OPLOCK)
+		pSMB->OpenFlags = cpu_to_le16(REQ_OPLOCK);
+	else if (*pOplock & REQ_BATCHOPLOCK)
+		pSMB->OpenFlags = cpu_to_le16(REQ_BATCHOPLOCK);
+
+	pSMB->OpenFlags |= cpu_to_le16(REQ_MORE_INFO);
+	pSMB->Mode = cpu_to_le16(access_flags_to_smbopen_mode(access_flags));
+	pSMB->Mode |= cpu_to_le16(0x40); /* deny none */
+	/* set file as system file if special file such
+	   as fifo and server expecting SFU style and
+	   no Unix extensions */
+
+	if (create_options & CREATE_OPTION_SPECIAL)
+		pSMB->FileAttributes = cpu_to_le16(ATTR_SYSTEM);
+	else /* BB FIXME BB */
+		pSMB->FileAttributes = cpu_to_le16(0/*ATTR_NORMAL*/);
+
+	if (create_options & CREATE_OPTION_READONLY)
+		pSMB->FileAttributes |= cpu_to_le16(ATTR_READONLY);
+
+	/* BB FIXME BB */
+/*	pSMB->CreateOptions = cpu_to_le32(create_options &
+						 CREATE_OPTIONS_MASK); */
+	/* BB FIXME END BB */
+
+	pSMB->Sattr = cpu_to_le16(ATTR_HIDDEN | ATTR_SYSTEM | ATTR_DIRECTORY);
+	pSMB->OpenFunction = cpu_to_le16(convert_disposition(openDisposition));
+	count += name_len;
+	pSMB->hdr.smb_buf_length += count;
+
+	pSMB->ByteCount = cpu_to_le16(count);
+	/* long_op set to 1 to allow for oplock break timeouts */
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			(struct smb_hdr *)pSMBr, &bytes_returned, CIFS_LONG_OP);
+	cifs_stats_inc(&tcon->num_opens);
+	if (rc) {
+		cFYI(1, ("Error in Open = %d", rc));
+	} else {
+	/* BB verify if wct == 15 */
+
+/*		*pOplock = pSMBr->OplockLevel; */ /* BB take from action field*/
+
+		*netfid = pSMBr->Fid;   /* cifs fid stays in le */
+		/* Let caller know file was created so we can set the mode. */
+		/* Do we care about the CreateAction in any other cases? */
+	/* BB FIXME BB */
+/*		if (cpu_to_le32(FILE_CREATE) == pSMBr->CreateAction)
+			*pOplock |= CIFS_CREATE_ACTION; */
+	/* BB FIXME END */
+
+		if (pfile_info) {
+			pfile_info->CreationTime = 0; /* BB convert CreateTime*/
+			pfile_info->LastAccessTime = 0; /* BB fixme */
+			pfile_info->LastWriteTime = 0; /* BB fixme */
+			pfile_info->ChangeTime = 0;  /* BB fixme */
+			pfile_info->Attributes =
+				cpu_to_le32(le16_to_cpu(pSMBr->FileAttributes));
+			/* the file_info buf is endian converted by caller */
+			pfile_info->AllocationSize =
+				cpu_to_le64(le32_to_cpu(pSMBr->EndOfFile));
+			pfile_info->EndOfFile = pfile_info->AllocationSize;
+			pfile_info->NumberOfLinks = cpu_to_le32(1);
+			pfile_info->DeletePending = 0;
+		}
+	}
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto OldOpenRetry;
+	return rc;
+}
+
+int
+CIFSSMBOpen(const int xid, struct cifsTconInfo *tcon,
+	    const char *fileName, const int openDisposition,
+	    const int access_flags, const int create_options, __u16 *netfid,
+	    int *pOplock, FILE_ALL_INFO *pfile_info,
+	    const struct nls_table *nls_codepage, int remap)
+{
+	int rc = -EACCES;
+	OPEN_REQ *pSMB = NULL;
+	OPEN_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len;
+	__u16 count;
+
+openRetry:
+	rc = smb_init(SMB_COM_NT_CREATE_ANDX, 24, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->AndXCommand = 0xFF;	/* none */
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		count = 1;	/* account for one byte pad to word boundary */
+		name_len =
+		    cifsConvertToUCS((__le16 *) (pSMB->fileName + 1),
+				     fileName, PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+		pSMB->NameLength = cpu_to_le16(name_len);
+	} else {		/* BB improve check for buffer overruns BB */
+		count = 0;	/* no pad */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		pSMB->NameLength = cpu_to_le16(name_len);
+		strncpy(pSMB->fileName, fileName, name_len);
+	}
+	if (*pOplock & REQ_OPLOCK)
+		pSMB->OpenFlags = cpu_to_le32(REQ_OPLOCK);
+	else if (*pOplock & REQ_BATCHOPLOCK)
+		pSMB->OpenFlags = cpu_to_le32(REQ_BATCHOPLOCK);
+	pSMB->DesiredAccess = cpu_to_le32(access_flags);
+	pSMB->AllocationSize = 0;
+	/* set file as system file if special file such
+	   as fifo and server expecting SFU style and
+	   no Unix extensions */
+	if (create_options & CREATE_OPTION_SPECIAL)
+		pSMB->FileAttributes = cpu_to_le32(ATTR_SYSTEM);
+	else
+		pSMB->FileAttributes = cpu_to_le32(ATTR_NORMAL);
+
+	/* XP does not handle ATTR_POSIX_SEMANTICS */
+	/* but it helps speed up case sensitive checks for other
+	servers such as Samba */
+	if (tcon->ses->capabilities & CAP_UNIX)
+		pSMB->FileAttributes |= cpu_to_le32(ATTR_POSIX_SEMANTICS);
+
+	if (create_options & CREATE_OPTION_READONLY)
+		pSMB->FileAttributes |= cpu_to_le32(ATTR_READONLY);
+
+	pSMB->ShareAccess = cpu_to_le32(FILE_SHARE_ALL);
+	pSMB->CreateDisposition = cpu_to_le32(openDisposition);
+	pSMB->CreateOptions = cpu_to_le32(create_options & CREATE_OPTIONS_MASK);
+	/* BB Expirement with various impersonation levels and verify */
+	pSMB->ImpersonationLevel = cpu_to_le32(SECURITY_IMPERSONATION);
+	pSMB->SecurityFlags =
+	    SECURITY_CONTEXT_TRACKING | SECURITY_EFFECTIVE_ONLY;
+
+	count += name_len;
+	pSMB->hdr.smb_buf_length += count;
+
+	pSMB->ByteCount = cpu_to_le16(count);
+	/* long_op set to 1 to allow for oplock break timeouts */
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			(struct smb_hdr *)pSMBr, &bytes_returned, CIFS_LONG_OP);
+	cifs_stats_inc(&tcon->num_opens);
+	if (rc) {
+		cFYI(1, ("Error in Open = %d", rc));
+	} else {
+		*pOplock = pSMBr->OplockLevel; /* 1 byte no need to le_to_cpu */
+		*netfid = pSMBr->Fid;	/* cifs fid stays in le */
+		/* Let caller know file was created so we can set the mode. */
+		/* Do we care about the CreateAction in any other cases? */
+		if (cpu_to_le32(FILE_CREATE) == pSMBr->CreateAction)
+			*pOplock |= CIFS_CREATE_ACTION;
+		if (pfile_info) {
+			memcpy((char *)pfile_info, (char *)&pSMBr->CreationTime,
+				36 /* CreationTime to Attributes */);
+			/* the file_info buf is endian converted by caller */
+			pfile_info->AllocationSize = pSMBr->AllocationSize;
+			pfile_info->EndOfFile = pSMBr->EndOfFile;
+			pfile_info->NumberOfLinks = cpu_to_le32(1);
+			pfile_info->DeletePending = 0;
+		}
+	}
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto openRetry;
+	return rc;
+}
+
+int
+CIFSSMBRead(const int xid, struct cifsTconInfo *tcon, const int netfid,
+	    const unsigned int count, const __u64 lseek, unsigned int *nbytes,
+	    char **buf, int *pbuf_type)
+{
+	int rc = -EACCES;
+	READ_REQ *pSMB = NULL;
+	READ_RSP *pSMBr = NULL;
+	char *pReadData = NULL;
+	int wct;
+	int resp_buf_type = 0;
+	struct kvec iov[1];
+
+	cFYI(1, ("Reading %d bytes on fid %d", count, netfid));
+	if (tcon->ses->capabilities & CAP_LARGE_FILES)
+		wct = 12;
+	else {
+		wct = 10; /* old style read */
+		if ((lseek >> 32) > 0)  {
+			/* can not handle this big offset for old */
+			return -EIO;
+		}
+	}
+
+	*nbytes = 0;
+	rc = small_smb_init(SMB_COM_READ_ANDX, wct, tcon, (void **) &pSMB);
+	if (rc)
+		return rc;
+
+	/* tcon and ses pointer are checked in smb_init */
+	if (tcon->ses->server == NULL)
+		return -ECONNABORTED;
+
+	pSMB->AndXCommand = 0xFF;       /* none */
+	pSMB->Fid = netfid;
+	pSMB->OffsetLow = cpu_to_le32(lseek & 0xFFFFFFFF);
+	if (wct == 12)
+		pSMB->OffsetHigh = cpu_to_le32(lseek >> 32);
+
+	pSMB->Remaining = 0;
+	pSMB->MaxCount = cpu_to_le16(count & 0xFFFF);
+	pSMB->MaxCountHigh = cpu_to_le32(count >> 16);
+	if (wct == 12)
+		pSMB->ByteCount = 0;  /* no need to do le conversion since 0 */
+	else {
+		/* old style read */
+		struct smb_com_readx_req *pSMBW =
+			(struct smb_com_readx_req *)pSMB;
+		pSMBW->ByteCount = 0;
+	}
+
+	iov[0].iov_base = (char *)pSMB;
+	iov[0].iov_len = pSMB->hdr.smb_buf_length + 4;
+	rc = SendReceive2(xid, tcon->ses, iov, 1 /* num iovecs */,
+			 &resp_buf_type, CIFS_STD_OP | CIFS_LOG_ERROR);
+	cifs_stats_inc(&tcon->num_reads);
+	pSMBr = (READ_RSP *)iov[0].iov_base;
+	if (rc) {
+		cERROR(1, ("Send error in read = %d", rc));
+	} else {
+		int data_length = le16_to_cpu(pSMBr->DataLengthHigh);
+		data_length = data_length << 16;
+		data_length += le16_to_cpu(pSMBr->DataLength);
+		*nbytes = data_length;
+
+		/*check that DataLength would not go beyond end of SMB */
+		if ((data_length > CIFSMaxBufSize)
+				|| (data_length > count)) {
+			cFYI(1, ("bad length %d for count %d",
+				 data_length, count));
+			rc = -EIO;
+			*nbytes = 0;
+		} else {
+			pReadData = (char *) (&pSMBr->hdr.Protocol) +
+					le16_to_cpu(pSMBr->DataOffset);
+/*			if (rc = copy_to_user(buf, pReadData, data_length)) {
+				cERROR(1,("Faulting on read rc = %d",rc));
+				rc = -EFAULT;
+			}*/ /* can not use copy_to_user when using page cache*/
+			if (*buf)
+				memcpy(*buf, pReadData, data_length);
+		}
+	}
+
+/*	cifs_small_buf_release(pSMB); */ /* Freed earlier now in SendReceive2 */
+	if (*buf) {
+		if (resp_buf_type == CIFS_SMALL_BUFFER)
+			cifs_small_buf_release(iov[0].iov_base);
+		else if (resp_buf_type == CIFS_LARGE_BUFFER)
+			cifs_buf_release(iov[0].iov_base);
+	} else if (resp_buf_type != CIFS_NO_BUFFER) {
+		/* return buffer to caller to free */
+		*buf = iov[0].iov_base;
+		if (resp_buf_type == CIFS_SMALL_BUFFER)
+			*pbuf_type = CIFS_SMALL_BUFFER;
+		else if (resp_buf_type == CIFS_LARGE_BUFFER)
+			*pbuf_type = CIFS_LARGE_BUFFER;
+	} /* else no valid buffer on return - leave as null */
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+	return rc;
+}
+
+
+int
+CIFSSMBWrite(const int xid, struct cifsTconInfo *tcon,
+	     const int netfid, const unsigned int count,
+	     const __u64 offset, unsigned int *nbytes, const char *buf,
+	     const char __user *ubuf, const int long_op)
+{
+	int rc = -EACCES;
+	WRITE_REQ *pSMB = NULL;
+	WRITE_RSP *pSMBr = NULL;
+	int bytes_returned, wct;
+	__u32 bytes_sent;
+	__u16 byte_count;
+
+	/* cFYI(1, ("write at %lld %d bytes", offset, count));*/
+	if (tcon->ses == NULL)
+		return -ECONNABORTED;
+
+	if (tcon->ses->capabilities & CAP_LARGE_FILES)
+		wct = 14;
+	else {
+		wct = 12;
+		if ((offset >> 32) > 0) {
+			/* can not handle big offset for old srv */
+			return -EIO;
+		}
+	}
+
+	rc = smb_init(SMB_COM_WRITE_ANDX, wct, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+	/* tcon and ses pointer are checked in smb_init */
+	if (tcon->ses->server == NULL)
+		return -ECONNABORTED;
+
+	pSMB->AndXCommand = 0xFF;	/* none */
+	pSMB->Fid = netfid;
+	pSMB->OffsetLow = cpu_to_le32(offset & 0xFFFFFFFF);
+	if (wct == 14)
+		pSMB->OffsetHigh = cpu_to_le32(offset >> 32);
+
+	pSMB->Reserved = 0xFFFFFFFF;
+	pSMB->WriteMode = 0;
+	pSMB->Remaining = 0;
+
+	/* Can increase buffer size if buffer is big enough in some cases ie we
+	can send more if LARGE_WRITE_X capability returned by the server and if
+	our buffer is big enough or if we convert to iovecs on socket writes
+	and eliminate the copy to the CIFS buffer */
+	if (tcon->ses->capabilities & CAP_LARGE_WRITE_X) {
+		bytes_sent = min_t(const unsigned int, CIFSMaxBufSize, count);
+	} else {
+		bytes_sent = (tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE)
+			 & ~0xFF;
+	}
+
+	if (bytes_sent > count)
+		bytes_sent = count;
+	pSMB->DataOffset =
+		cpu_to_le16(offsetof(struct smb_com_write_req, Data) - 4);
+	if (buf)
+		memcpy(pSMB->Data, buf, bytes_sent);
+	else if (ubuf) {
+		if (copy_from_user(pSMB->Data, ubuf, bytes_sent)) {
+			cifs_buf_release(pSMB);
+			return -EFAULT;
+		}
+	} else if (count != 0) {
+		/* No buffer */
+		cifs_buf_release(pSMB);
+		return -EINVAL;
+	} /* else setting file size with write of zero bytes */
+	if (wct == 14)
+		byte_count = bytes_sent + 1; /* pad */
+	else /* wct == 12 */
+		byte_count = bytes_sent + 5; /* bigger pad, smaller smb hdr */
+
+	pSMB->DataLengthLow = cpu_to_le16(bytes_sent & 0xFFFF);
+	pSMB->DataLengthHigh = cpu_to_le16(bytes_sent >> 16);
+	pSMB->hdr.smb_buf_length += byte_count;
+
+	if (wct == 14)
+		pSMB->ByteCount = cpu_to_le16(byte_count);
+	else { /* old style write has byte count 4 bytes earlier
+		  so 4 bytes pad  */
+		struct smb_com_writex_req *pSMBW =
+			(struct smb_com_writex_req *)pSMB;
+		pSMBW->ByteCount = cpu_to_le16(byte_count);
+	}
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, long_op);
+	cifs_stats_inc(&tcon->num_writes);
+	if (rc) {
+		cFYI(1, ("Send error in write = %d", rc));
+		*nbytes = 0;
+	} else {
+		*nbytes = le16_to_cpu(pSMBr->CountHigh);
+		*nbytes = (*nbytes) << 16;
+		*nbytes += le16_to_cpu(pSMBr->Count);
+	}
+
+	cifs_buf_release(pSMB);
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+
+int
+CIFSSMBWrite2(const int xid, struct cifsTconInfo *tcon,
+	     const int netfid, const unsigned int count,
+	     const __u64 offset, unsigned int *nbytes, struct kvec *iov,
+	     int n_vec, const int long_op)
+{
+	int rc = -EACCES;
+	WRITE_REQ *pSMB = NULL;
+	int wct;
+	int smb_hdr_len;
+	int resp_buf_type = 0;
+
+	*nbytes = 0;
+
+	cFYI(1, ("write2 at %lld %d bytes", (long long)offset, count));
+
+	if (tcon->ses->capabilities & CAP_LARGE_FILES) {
+		wct = 14;
+	} else {
+		wct = 12;
+		if ((offset >> 32) > 0) {
+			/* can not handle big offset for old srv */
+			return -EIO;
+		}
+	}
+	rc = small_smb_init(SMB_COM_WRITE_ANDX, wct, tcon, (void **) &pSMB);
+	if (rc)
+		return rc;
+	/* tcon and ses pointer are checked in smb_init */
+	if (tcon->ses->server == NULL)
+		return -ECONNABORTED;
+
+	pSMB->AndXCommand = 0xFF;	/* none */
+	pSMB->Fid = netfid;
+	pSMB->OffsetLow = cpu_to_le32(offset & 0xFFFFFFFF);
+	if (wct == 14)
+		pSMB->OffsetHigh = cpu_to_le32(offset >> 32);
+	pSMB->Reserved = 0xFFFFFFFF;
+	pSMB->WriteMode = 0;
+	pSMB->Remaining = 0;
+
+	pSMB->DataOffset =
+	    cpu_to_le16(offsetof(struct smb_com_write_req, Data) - 4);
+
+	pSMB->DataLengthLow = cpu_to_le16(count & 0xFFFF);
+	pSMB->DataLengthHigh = cpu_to_le16(count >> 16);
+	smb_hdr_len = pSMB->hdr.smb_buf_length + 1; /* hdr + 1 byte pad */
+	if (wct == 14)
+		pSMB->hdr.smb_buf_length += count+1;
+	else /* wct == 12 */
+		pSMB->hdr.smb_buf_length += count+5; /* smb data starts later */
+	if (wct == 14)
+		pSMB->ByteCount = cpu_to_le16(count + 1);
+	else /* wct == 12 */ /* bigger pad, smaller smb hdr, keep offset ok */ {
+		struct smb_com_writex_req *pSMBW =
+				(struct smb_com_writex_req *)pSMB;
+		pSMBW->ByteCount = cpu_to_le16(count + 5);
+	}
+	iov[0].iov_base = pSMB;
+	if (wct == 14)
+		iov[0].iov_len = smb_hdr_len + 4;
+	else /* wct == 12 pad bigger by four bytes */
+		iov[0].iov_len = smb_hdr_len + 8;
+
+
+	rc = SendReceive2(xid, tcon->ses, iov, n_vec + 1, &resp_buf_type,
+			  long_op);
+	cifs_stats_inc(&tcon->num_writes);
+	if (rc) {
+		cFYI(1, ("Send error Write2 = %d", rc));
+	} else if (resp_buf_type == 0) {
+		/* presumably this can not happen, but best to be safe */
+		rc = -EIO;
+	} else {
+		WRITE_RSP *pSMBr = (WRITE_RSP *)iov[0].iov_base;
+		*nbytes = le16_to_cpu(pSMBr->CountHigh);
+		*nbytes = (*nbytes) << 16;
+		*nbytes += le16_to_cpu(pSMBr->Count);
+	}
+
+/*	cifs_small_buf_release(pSMB); */ /* Freed earlier now in SendReceive2 */
+	if (resp_buf_type == CIFS_SMALL_BUFFER)
+		cifs_small_buf_release(iov[0].iov_base);
+	else if (resp_buf_type == CIFS_LARGE_BUFFER)
+		cifs_buf_release(iov[0].iov_base);
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+
+
+int
+CIFSSMBLock(const int xid, struct cifsTconInfo *tcon,
+	    const __u16 smb_file_id, const __u64 len,
+	    const __u64 offset, const __u32 numUnlock,
+	    const __u32 numLock, const __u8 lockType, const bool waitFlag)
+{
+	int rc = 0;
+	LOCK_REQ *pSMB = NULL;
+/*	LOCK_RSP *pSMBr = NULL; */ /* No response data other than rc to parse */
+	int bytes_returned;
+	int timeout = 0;
+	__u16 count;
+
+	cFYI(1, ("CIFSSMBLock timeout %d numLock %d", (int)waitFlag, numLock));
+	rc = small_smb_init(SMB_COM_LOCKING_ANDX, 8, tcon, (void **) &pSMB);
+
+	if (rc)
+		return rc;
+
+	if (lockType == LOCKING_ANDX_OPLOCK_RELEASE) {
+		timeout = CIFS_ASYNC_OP; /* no response expected */
+		pSMB->Timeout = 0;
+	} else if (waitFlag) {
+		timeout = CIFS_BLOCKING_OP; /* blocking operation, no timeout */
+		pSMB->Timeout = cpu_to_le32(-1);/* blocking - do not time out */
+	} else {
+		pSMB->Timeout = 0;
+	}
+
+	pSMB->NumberOfLocks = cpu_to_le16(numLock);
+	pSMB->NumberOfUnlocks = cpu_to_le16(numUnlock);
+	pSMB->LockType = lockType;
+	pSMB->AndXCommand = 0xFF;	/* none */
+	pSMB->Fid = smb_file_id; /* netfid stays le */
+
+	if ((numLock != 0) || (numUnlock != 0)) {
+		pSMB->Locks[0].Pid = cpu_to_le16(current->tgid);
+		/* BB where to store pid high? */
+		pSMB->Locks[0].LengthLow = cpu_to_le32((u32)len);
+		pSMB->Locks[0].LengthHigh = cpu_to_le32((u32)(len>>32));
+		pSMB->Locks[0].OffsetLow = cpu_to_le32((u32)offset);
+		pSMB->Locks[0].OffsetHigh = cpu_to_le32((u32)(offset>>32));
+		count = sizeof(LOCKING_ANDX_RANGE);
+	} else {
+		/* oplock break */
+		count = 0;
+	}
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	if (waitFlag) {
+		rc = SendReceiveBlockingLock(xid, tcon, (struct smb_hdr *) pSMB,
+			(struct smb_hdr *) pSMB, &bytes_returned);
+		cifs_small_buf_release(pSMB);
+	} else {
+		rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *)pSMB,
+				      timeout);
+		/* SMB buffer freed by function above */
+	}
+	cifs_stats_inc(&tcon->num_locks);
+	if (rc)
+		cFYI(1, ("Send error in Lock = %d", rc));
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+	since file handle passed in no longer valid */
+	return rc;
+}
+
+int
+CIFSSMBPosixLock(const int xid, struct cifsTconInfo *tcon,
+		const __u16 smb_file_id, const int get_flag, const __u64 len,
+		struct file_lock *pLockData, const __u16 lock_type,
+		const bool waitFlag)
+{
+	struct smb_com_transaction2_sfi_req *pSMB  = NULL;
+	struct smb_com_transaction2_sfi_rsp *pSMBr = NULL;
+	struct cifs_posix_lock *parm_data;
+	int rc = 0;
+	int timeout = 0;
+	int bytes_returned = 0;
+	int resp_buf_type = 0;
+	__u16 params, param_offset, offset, byte_count, count;
+	struct kvec iov[1];
+
+	cFYI(1, ("Posix Lock"));
+
+	if (pLockData == NULL)
+		return -EINVAL;
+
+	rc = small_smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB);
+
+	if (rc)
+		return rc;
+
+	pSMBr = (struct smb_com_transaction2_sfi_rsp *)pSMB;
+
+	params = 6;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_sfi_req, Fid) - 4;
+	offset = param_offset + params;
+
+	count = sizeof(struct cifs_posix_lock);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(1000); /* BB find max SMB from sess */
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	if (get_flag)
+		pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FILE_INFORMATION);
+	else
+		pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FILE_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	parm_data = (struct cifs_posix_lock *)
+			(((char *) &pSMB->hdr.Protocol) + offset);
+
+	parm_data->lock_type = cpu_to_le16(lock_type);
+	if (waitFlag) {
+		timeout = CIFS_BLOCKING_OP; /* blocking operation, no timeout */
+		parm_data->lock_flags = cpu_to_le16(1);
+		pSMB->Timeout = cpu_to_le32(-1);
+	} else
+		pSMB->Timeout = 0;
+
+	parm_data->pid = cpu_to_le32(current->tgid);
+	parm_data->start = cpu_to_le64(pLockData->fl_start);
+	parm_data->length = cpu_to_le64(len);  /* normalize negative numbers */
+
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->Fid = smb_file_id;
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_POSIX_LOCK);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	if (waitFlag) {
+		rc = SendReceiveBlockingLock(xid, tcon, (struct smb_hdr *) pSMB,
+			(struct smb_hdr *) pSMBr, &bytes_returned);
+	} else {
+		iov[0].iov_base = (char *)pSMB;
+		iov[0].iov_len = pSMB->hdr.smb_buf_length + 4;
+		rc = SendReceive2(xid, tcon->ses, iov, 1 /* num iovecs */,
+				&resp_buf_type, timeout);
+		pSMB = NULL; /* request buf already freed by SendReceive2. Do
+				not try to free it twice below on exit */
+		pSMBr = (struct smb_com_transaction2_sfi_rsp *)iov[0].iov_base;
+	}
+
+	if (rc) {
+		cFYI(1, ("Send error in Posix Lock = %d", rc));
+	} else if (get_flag) {
+		/* lock structure can be returned on get */
+		__u16 data_offset;
+		__u16 data_count;
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < sizeof(struct cifs_posix_lock))) {
+			rc = -EIO;      /* bad smb */
+			goto plk_err_exit;
+		}
+		data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+		data_count  = le16_to_cpu(pSMBr->t2.DataCount);
+		if (data_count < sizeof(struct cifs_posix_lock)) {
+			rc = -EIO;
+			goto plk_err_exit;
+		}
+		parm_data = (struct cifs_posix_lock *)
+			((char *)&pSMBr->hdr.Protocol + data_offset);
+		if (parm_data->lock_type == cpu_to_le16(CIFS_UNLCK))
+			pLockData->fl_type = F_UNLCK;
+	}
+
+plk_err_exit:
+	if (pSMB)
+		cifs_small_buf_release(pSMB);
+
+	if (resp_buf_type == CIFS_SMALL_BUFFER)
+		cifs_small_buf_release(iov[0].iov_base);
+	else if (resp_buf_type == CIFS_LARGE_BUFFER)
+		cifs_buf_release(iov[0].iov_base);
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+	   since file handle passed in no longer valid */
+
+	return rc;
+}
+
+
+int
+CIFSSMBClose(const int xid, struct cifsTconInfo *tcon, int smb_file_id)
+{
+	int rc = 0;
+	CLOSE_REQ *pSMB = NULL;
+	cFYI(1, ("In CIFSSMBClose"));
+
+/* do not retry on dead session on close */
+	rc = small_smb_init(SMB_COM_CLOSE, 3, tcon, (void **) &pSMB);
+	if (rc == -EAGAIN)
+		return 0;
+	if (rc)
+		return rc;
+
+	pSMB->FileID = (__u16) smb_file_id;
+	pSMB->LastWriteTime = 0xFFFFFFFF;
+	pSMB->ByteCount = 0;
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	cifs_stats_inc(&tcon->num_closes);
+	if (rc) {
+		if (rc != -EINTR) {
+			/* EINTR is expected when user ctl-c to kill app */
+			cERROR(1, ("Send error in Close = %d", rc));
+		}
+	}
+
+	/* Since session is dead, file will be closed on server already */
+	if (rc == -EAGAIN)
+		rc = 0;
+
+	return rc;
+}
+
+int
+CIFSSMBFlush(const int xid, struct cifsTconInfo *tcon, int smb_file_id)
+{
+	int rc = 0;
+	FLUSH_REQ *pSMB = NULL;
+	cFYI(1, ("In CIFSSMBFlush"));
+
+	rc = small_smb_init(SMB_COM_FLUSH, 1, tcon, (void **) &pSMB);
+	if (rc)
+		return rc;
+
+	pSMB->FileID = (__u16) smb_file_id;
+	pSMB->ByteCount = 0;
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	cifs_stats_inc(&tcon->num_flushes);
+	if (rc)
+		cERROR(1, ("Send error in Flush = %d", rc));
+
+	return rc;
+}
+
+int
+CIFSSMBRename(const int xid, struct cifsTconInfo *tcon,
+	      const char *fromName, const char *toName,
+	      const struct nls_table *nls_codepage, int remap)
+{
+	int rc = 0;
+	RENAME_REQ *pSMB = NULL;
+	RENAME_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len, name_len2;
+	__u16 count;
+
+	cFYI(1, ("In CIFSSMBRename"));
+renameRetry:
+	rc = smb_init(SMB_COM_RENAME, 1, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->BufferFormat = 0x04;
+	pSMB->SearchAttributes =
+	    cpu_to_le16(ATTR_READONLY | ATTR_HIDDEN | ATTR_SYSTEM |
+			ATTR_DIRECTORY);
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->OldFileName, fromName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+		pSMB->OldFileName[name_len] = 0x04;	/* pad */
+	/* protocol requires ASCII signature byte on Unicode string */
+		pSMB->OldFileName[name_len + 1] = 0x00;
+		name_len2 =
+		    cifsConvertToUCS((__le16 *)&pSMB->OldFileName[name_len + 2],
+				     toName, PATH_MAX, nls_codepage, remap);
+		name_len2 += 1 /* trailing null */  + 1 /* Signature word */ ;
+		name_len2 *= 2;	/* convert to bytes */
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fromName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->OldFileName, fromName, name_len);
+		name_len2 = strnlen(toName, PATH_MAX);
+		name_len2++;	/* trailing null */
+		pSMB->OldFileName[name_len] = 0x04;  /* 2nd buffer format */
+		strncpy(&pSMB->OldFileName[name_len + 1], toName, name_len2);
+		name_len2++;	/* trailing null */
+		name_len2++;	/* signature byte */
+	}
+
+	count = 1 /* 1st signature byte */  + name_len + name_len2;
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_renames);
+	if (rc)
+		cFYI(1, ("Send error in rename = %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto renameRetry;
+
+	return rc;
+}
+
+int CIFSSMBRenameOpenFile(const int xid, struct cifsTconInfo *pTcon,
+		int netfid, const char *target_name,
+		const struct nls_table *nls_codepage, int remap)
+{
+	struct smb_com_transaction2_sfi_req *pSMB  = NULL;
+	struct smb_com_transaction2_sfi_rsp *pSMBr = NULL;
+	struct set_file_rename *rename_info;
+	char *data_offset;
+	char dummy_string[30];
+	int rc = 0;
+	int bytes_returned = 0;
+	int len_of_str;
+	__u16 params, param_offset, offset, count, byte_count;
+
+	cFYI(1, ("Rename to File by handle"));
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, pTcon, (void **) &pSMB,
+			(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 6;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_sfi_req, Fid) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+	rename_info = (struct set_file_rename *) data_offset;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(1000); /* BB find max SMB from sess */
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FILE_INFORMATION);
+	byte_count = 3 /* pad */  + params;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	/* construct random name ".cifs_tmp<inodenum><mid>" */
+	rename_info->overwrite = cpu_to_le32(1);
+	rename_info->root_fid  = 0;
+	/* unicode only call */
+	if (target_name == NULL) {
+		sprintf(dummy_string, "cifs%x", pSMB->hdr.Mid);
+		len_of_str = cifsConvertToUCS((__le16 *)rename_info->target_name,
+					dummy_string, 24, nls_codepage, remap);
+	} else {
+		len_of_str = cifsConvertToUCS((__le16 *)rename_info->target_name,
+					target_name, PATH_MAX, nls_codepage,
+					remap);
+	}
+	rename_info->target_name_len = cpu_to_le32(2 * len_of_str);
+	count = 12 /* sizeof(struct set_file_rename) */ + (2 * len_of_str);
+	byte_count += count;
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->Fid = netfid;
+	pSMB->InformationLevel =
+		cpu_to_le16(SMB_SET_FILE_RENAME_INFORMATION);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, pTcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&pTcon->num_t2renames);
+	if (rc)
+		cFYI(1, ("Send error in Rename (by file handle) = %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+
+int
+CIFSSMBCopy(const int xid, struct cifsTconInfo *tcon, const char *fromName,
+	    const __u16 target_tid, const char *toName, const int flags,
+	    const struct nls_table *nls_codepage, int remap)
+{
+	int rc = 0;
+	COPY_REQ *pSMB = NULL;
+	COPY_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len, name_len2;
+	__u16 count;
+
+	cFYI(1, ("In CIFSSMBCopy"));
+copyRetry:
+	rc = smb_init(SMB_COM_COPY, 1, tcon, (void **) &pSMB,
+			(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->BufferFormat = 0x04;
+	pSMB->Tid2 = target_tid;
+
+	pSMB->Flags = cpu_to_le16(flags & COPY_TREE);
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len = cifsConvertToUCS((__le16 *) pSMB->OldFileName,
+					    fromName, PATH_MAX, nls_codepage,
+					    remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+		pSMB->OldFileName[name_len] = 0x04;     /* pad */
+		/* protocol requires ASCII signature byte on Unicode string */
+		pSMB->OldFileName[name_len + 1] = 0x00;
+		name_len2 =
+		    cifsConvertToUCS((__le16 *)&pSMB->OldFileName[name_len + 2],
+				toName, PATH_MAX, nls_codepage, remap);
+		name_len2 += 1 /* trailing null */  + 1 /* Signature word */ ;
+		name_len2 *= 2; /* convert to bytes */
+	} else { 	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fromName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->OldFileName, fromName, name_len);
+		name_len2 = strnlen(toName, PATH_MAX);
+		name_len2++;    /* trailing null */
+		pSMB->OldFileName[name_len] = 0x04;  /* 2nd buffer format */
+		strncpy(&pSMB->OldFileName[name_len + 1], toName, name_len2);
+		name_len2++;    /* trailing null */
+		name_len2++;    /* signature byte */
+	}
+
+	count = 1 /* 1st signature byte */  + name_len + name_len2;
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+		(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in copy = %d with %d files copied",
+			rc, le16_to_cpu(pSMBr->CopyCount)));
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto copyRetry;
+
+	return rc;
+}
+
+int
+CIFSUnixCreateSymLink(const int xid, struct cifsTconInfo *tcon,
+		      const char *fromName, const char *toName,
+		      const struct nls_table *nls_codepage)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	char *data_offset;
+	int name_len;
+	int name_len_target;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, offset, byte_count;
+
+	cFYI(1, ("In Symlink Unix style"));
+createSymLinkRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifs_strtoUCS((__le16 *) pSMB->FileName, fromName, PATH_MAX
+				  /* find define for this maxpathcomponent */
+				  , nls_codepage);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fromName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fromName, name_len);
+	}
+	params = 6 + name_len;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len_target =
+		    cifs_strtoUCS((__le16 *) data_offset, toName, PATH_MAX
+				  /* find define for this maxpathcomponent */
+				  , nls_codepage);
+		name_len_target++;	/* trailing null */
+		name_len_target *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len_target = strnlen(toName, PATH_MAX);
+		name_len_target++;	/* trailing null */
+		strncpy(data_offset, toName, name_len_target);
+	}
+
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max on data count below from sess */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + name_len_target;
+	pSMB->DataCount = cpu_to_le16(name_len_target);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_UNIX_LINK);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_symlinks);
+	if (rc)
+		cFYI(1, ("Send error in SetPathInfo create symlink = %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto createSymLinkRetry;
+
+	return rc;
+}
+
+int
+CIFSUnixCreateHardLink(const int xid, struct cifsTconInfo *tcon,
+		       const char *fromName, const char *toName,
+		       const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	char *data_offset;
+	int name_len;
+	int name_len_target;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, offset, byte_count;
+
+	cFYI(1, ("In Create Hard link Unix style"));
+createHardLinkRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len = cifsConvertToUCS((__le16 *) pSMB->FileName, toName,
+					    PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(toName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, toName, name_len);
+	}
+	params = 6 + name_len;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len_target =
+		    cifsConvertToUCS((__le16 *) data_offset, fromName, PATH_MAX,
+				     nls_codepage, remap);
+		name_len_target++;	/* trailing null */
+		name_len_target *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len_target = strnlen(fromName, PATH_MAX);
+		name_len_target++;	/* trailing null */
+		strncpy(data_offset, fromName, name_len_target);
+	}
+
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max on data count below from sess*/
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + name_len_target;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->DataCount = cpu_to_le16(name_len_target);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_UNIX_HLINK);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_hardlinks);
+	if (rc)
+		cFYI(1, ("Send error in SetPathInfo (hard link) = %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto createHardLinkRetry;
+
+	return rc;
+}
+
+int
+CIFSCreateHardLink(const int xid, struct cifsTconInfo *tcon,
+		   const char *fromName, const char *toName,
+		   const struct nls_table *nls_codepage, int remap)
+{
+	int rc = 0;
+	NT_RENAME_REQ *pSMB = NULL;
+	RENAME_RSP *pSMBr = NULL;
+	int bytes_returned;
+	int name_len, name_len2;
+	__u16 count;
+
+	cFYI(1, ("In CIFSCreateHardLink"));
+winCreateHardLinkRetry:
+
+	rc = smb_init(SMB_COM_NT_RENAME, 4, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->SearchAttributes =
+	    cpu_to_le16(ATTR_READONLY | ATTR_HIDDEN | ATTR_SYSTEM |
+			ATTR_DIRECTORY);
+	pSMB->Flags = cpu_to_le16(CREATE_HARD_LINK);
+	pSMB->ClusterCount = 0;
+
+	pSMB->BufferFormat = 0x04;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->OldFileName, fromName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+
+		/* protocol specifies ASCII buffer format (0x04) for unicode */
+		pSMB->OldFileName[name_len] = 0x04;
+		pSMB->OldFileName[name_len + 1] = 0x00; /* pad */
+		name_len2 =
+		    cifsConvertToUCS((__le16 *)&pSMB->OldFileName[name_len + 2],
+				     toName, PATH_MAX, nls_codepage, remap);
+		name_len2 += 1 /* trailing null */  + 1 /* Signature word */ ;
+		name_len2 *= 2;	/* convert to bytes */
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fromName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->OldFileName, fromName, name_len);
+		name_len2 = strnlen(toName, PATH_MAX);
+		name_len2++;	/* trailing null */
+		pSMB->OldFileName[name_len] = 0x04;	/* 2nd buffer format */
+		strncpy(&pSMB->OldFileName[name_len + 1], toName, name_len2);
+		name_len2++;	/* trailing null */
+		name_len2++;	/* signature byte */
+	}
+
+	count = 1 /* string type byte */  + name_len + name_len2;
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_hardlinks);
+	if (rc)
+		cFYI(1, ("Send error in hard link (NT rename) = %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto winCreateHardLinkRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBUnixQuerySymLink(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName, char **symlinkinfo,
+			const struct nls_table *nls_codepage)
+{
+/* SMB_QUERY_FILE_UNIX_LINK */
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	__u16 params, byte_count;
+	char *data_start;
+
+	cFYI(1, ("In QPathSymLinkInfo (Unix) for path %s", searchName));
+
+querySymLinkRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifs_strtoUCS((__le16 *) pSMB->FileName, searchName,
+				  PATH_MAX, nls_codepage);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */  + 4 /* rsrvd */  + name_len /* incl null */ ;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max data count below from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FILE_UNIX_LINK);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QuerySymLinkInfo = %d", rc));
+	} else {
+		/* decode response */
+
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		/* BB also check enough total bytes returned */
+		if (rc || (pSMBr->ByteCount < 2))
+			rc = -EIO;
+		else {
+			bool is_unicode;
+			u16 count = le16_to_cpu(pSMBr->t2.DataCount);
+
+			data_start = ((char *) &pSMBr->hdr.Protocol) +
+					   le16_to_cpu(pSMBr->t2.DataOffset);
+
+			if (pSMBr->hdr.Flags2 & SMBFLG2_UNICODE)
+				is_unicode = true;
+			else
+				is_unicode = false;
+
+			/* BB FIXME investigate remapping reserved chars here */
+			*symlinkinfo = cifs_strndup_from_ucs(data_start, count,
+						    is_unicode, nls_codepage);
+			if (!*symlinkinfo)
+				rc = -ENOMEM;
+		}
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto querySymLinkRetry;
+	return rc;
+}
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+/* Initialize NT TRANSACT SMB into small smb request buffer.
+   This assumes that all NT TRANSACTS that we init here have
+   total parm and data under about 400 bytes (to fit in small cifs
+   buffer size), which is the case so far, it easily fits. NB:
+	Setup words themselves and ByteCount
+	MaxSetupCount (size of returned setup area) and
+	MaxParameterCount (returned parms size) must be set by caller */
+static int
+smb_init_nttransact(const __u16 sub_command, const int setup_count,
+		   const int parm_len, struct cifsTconInfo *tcon,
+		   void **ret_buf)
+{
+	int rc;
+	__u32 temp_offset;
+	struct smb_com_ntransact_req *pSMB;
+
+	rc = small_smb_init(SMB_COM_NT_TRANSACT, 19 + setup_count, tcon,
+				(void **)&pSMB);
+	if (rc)
+		return rc;
+	*ret_buf = (void *)pSMB;
+	pSMB->Reserved = 0;
+	pSMB->TotalParameterCount = cpu_to_le32(parm_len);
+	pSMB->TotalDataCount  = 0;
+	pSMB->MaxDataCount = cpu_to_le32((tcon->ses->server->maxBuf -
+					  MAX_CIFS_HDR_SIZE) & 0xFFFFFF00);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->DataCount  = pSMB->TotalDataCount;
+	temp_offset = offsetof(struct smb_com_ntransact_req, Parms) +
+			(setup_count * 2) - 4 /* for rfc1001 length itself */;
+	pSMB->ParameterOffset = cpu_to_le32(temp_offset);
+	pSMB->DataOffset = cpu_to_le32(temp_offset + parm_len);
+	pSMB->SetupCount = setup_count; /* no need to le convert byte fields */
+	pSMB->SubCommand = cpu_to_le16(sub_command);
+	return 0;
+}
+
+static int
+validate_ntransact(char *buf, char **ppparm, char **ppdata,
+		   __u32 *pparmlen, __u32 *pdatalen)
+{
+	char *end_of_smb;
+	__u32 data_count, data_offset, parm_count, parm_offset;
+	struct smb_com_ntransact_rsp *pSMBr;
+
+	*pdatalen = 0;
+	*pparmlen = 0;
+
+	if (buf == NULL)
+		return -EINVAL;
+
+	pSMBr = (struct smb_com_ntransact_rsp *)buf;
+
+	/* ByteCount was converted from little endian in SendReceive */
+	end_of_smb = 2 /* sizeof byte count */ + pSMBr->ByteCount +
+			(char *)&pSMBr->ByteCount;
+
+	data_offset = le32_to_cpu(pSMBr->DataOffset);
+	data_count = le32_to_cpu(pSMBr->DataCount);
+	parm_offset = le32_to_cpu(pSMBr->ParameterOffset);
+	parm_count = le32_to_cpu(pSMBr->ParameterCount);
+
+	*ppparm = (char *)&pSMBr->hdr.Protocol + parm_offset;
+	*ppdata = (char *)&pSMBr->hdr.Protocol + data_offset;
+
+	/* should we also check that parm and data areas do not overlap? */
+	if (*ppparm > end_of_smb) {
+		cFYI(1, ("parms start after end of smb"));
+		return -EINVAL;
+	} else if (parm_count + *ppparm > end_of_smb) {
+		cFYI(1, ("parm end after end of smb"));
+		return -EINVAL;
+	} else if (*ppdata > end_of_smb) {
+		cFYI(1, ("data starts after end of smb"));
+		return -EINVAL;
+	} else if (data_count + *ppdata > end_of_smb) {
+		cFYI(1, ("data %p + count %d (%p) ends after end of smb %p start %p",
+			*ppdata, data_count, (data_count + *ppdata),
+			end_of_smb, pSMBr));
+		return -EINVAL;
+	} else if (parm_count + data_count > pSMBr->ByteCount) {
+		cFYI(1, ("parm count and data count larger than SMB"));
+		return -EINVAL;
+	}
+	*pdatalen = data_count;
+	*pparmlen = parm_count;
+	return 0;
+}
+
+int
+CIFSSMBQueryReparseLinkInfo(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			char *symlinkinfo, const int buflen, __u16 fid,
+			const struct nls_table *nls_codepage)
+{
+	int rc = 0;
+	int bytes_returned;
+	struct smb_com_transaction_ioctl_req *pSMB;
+	struct smb_com_transaction_ioctl_rsp *pSMBr;
+
+	cFYI(1, ("In Windows reparse style QueryLink for path %s", searchName));
+	rc = smb_init(SMB_COM_NT_TRANSACT, 23, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->TotalParameterCount = 0 ;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le32(2);
+	/* BB find exact data count max from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le32((tcon->ses->server->maxBuf -
+					  MAX_CIFS_HDR_SIZE) & 0xFFFFFF00);
+	pSMB->MaxSetupCount = 4;
+	pSMB->Reserved = 0;
+	pSMB->ParameterOffset = 0;
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 4;
+	pSMB->SubCommand = cpu_to_le16(NT_TRANSACT_IOCTL);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->FunctionCode = cpu_to_le32(FSCTL_GET_REPARSE_POINT);
+	pSMB->IsFsctl = 1; /* FSCTL */
+	pSMB->IsRootFlag = 0;
+	pSMB->Fid = fid; /* file handle always le */
+	pSMB->ByteCount = 0;
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QueryReparseLinkInfo = %d", rc));
+	} else {		/* decode response */
+		__u32 data_offset = le32_to_cpu(pSMBr->DataOffset);
+		__u32 data_count = le32_to_cpu(pSMBr->DataCount);
+		if ((pSMBr->ByteCount < 2) || (data_offset > 512)) {
+		/* BB also check enough total bytes returned */
+			rc = -EIO;	/* bad smb */
+			goto qreparse_out;
+		}
+		if (data_count && (data_count < 2048)) {
+			char *end_of_smb = 2 /* sizeof byte count */ +
+				pSMBr->ByteCount + (char *)&pSMBr->ByteCount;
+
+			struct reparse_data *reparse_buf =
+						(struct reparse_data *)
+						((char *)&pSMBr->hdr.Protocol
+								 + data_offset);
+			if ((char *)reparse_buf >= end_of_smb) {
+				rc = -EIO;
+				goto qreparse_out;
+			}
+			if ((reparse_buf->LinkNamesBuf +
+				reparse_buf->TargetNameOffset +
+				reparse_buf->TargetNameLen) > end_of_smb) {
+				cFYI(1, ("reparse buf beyond SMB"));
+				rc = -EIO;
+				goto qreparse_out;
+			}
+
+			if (pSMBr->hdr.Flags2 & SMBFLG2_UNICODE) {
+				cifs_from_ucs2(symlinkinfo, (__le16 *)
+						(reparse_buf->LinkNamesBuf +
+						reparse_buf->TargetNameOffset),
+						buflen,
+						reparse_buf->TargetNameLen,
+						nls_codepage, 0);
+			} else { /* ASCII names */
+				strncpy(symlinkinfo,
+					reparse_buf->LinkNamesBuf +
+					reparse_buf->TargetNameOffset,
+					min_t(const int, buflen,
+					   reparse_buf->TargetNameLen));
+			}
+		} else {
+			rc = -EIO;
+			cFYI(1, ("Invalid return data count on "
+				 "get reparse info ioctl"));
+		}
+		symlinkinfo[buflen] = 0; /* just in case so the caller
+					does not go off the end of the buffer */
+		cFYI(1, ("readlink result - %s", symlinkinfo));
+	}
+
+qreparse_out:
+	cifs_buf_release(pSMB);
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+#endif /* CIFS_EXPERIMENTAL */
+
+#ifdef CONFIG_CIFS_POSIX
+
+/*Convert an Access Control Entry from wire format to local POSIX xattr format*/
+static void cifs_convert_ace(posix_acl_xattr_entry *ace,
+			     struct cifs_posix_ace *cifs_ace)
+{
+	/* u8 cifs fields do not need le conversion */
+	ace->e_perm = cpu_to_le16(cifs_ace->cifs_e_perm);
+	ace->e_tag  = cpu_to_le16(cifs_ace->cifs_e_tag);
+	ace->e_id   = cpu_to_le32(le64_to_cpu(cifs_ace->cifs_uid));
+	/* cFYI(1,("perm %d tag %d id %d",ace->e_perm,ace->e_tag,ace->e_id)); */
+
+	return;
+}
+
+/* Convert ACL from CIFS POSIX wire format to local Linux POSIX ACL xattr */
+static int cifs_copy_posix_acl(char *trgt, char *src, const int buflen,
+			       const int acl_type, const int size_of_data_area)
+{
+	int size =  0;
+	int i;
+	__u16 count;
+	struct cifs_posix_ace *pACE;
+	struct cifs_posix_acl *cifs_acl = (struct cifs_posix_acl *)src;
+	posix_acl_xattr_header *local_acl = (posix_acl_xattr_header *)trgt;
+
+	if (le16_to_cpu(cifs_acl->version) != CIFS_ACL_VERSION)
+		return -EOPNOTSUPP;
+
+	if (acl_type & ACL_TYPE_ACCESS) {
+		count = le16_to_cpu(cifs_acl->access_entry_count);
+		pACE = &cifs_acl->ace_array[0];
+		size = sizeof(struct cifs_posix_acl);
+		size += sizeof(struct cifs_posix_ace) * count;
+		/* check if we would go beyond end of SMB */
+		if (size_of_data_area < size) {
+			cFYI(1, ("bad CIFS POSIX ACL size %d vs. %d",
+				size_of_data_area, size));
+			return -EINVAL;
+		}
+	} else if (acl_type & ACL_TYPE_DEFAULT) {
+		count = le16_to_cpu(cifs_acl->access_entry_count);
+		size = sizeof(struct cifs_posix_acl);
+		size += sizeof(struct cifs_posix_ace) * count;
+/* skip past access ACEs to get to default ACEs */
+		pACE = &cifs_acl->ace_array[count];
+		count = le16_to_cpu(cifs_acl->default_entry_count);
+		size += sizeof(struct cifs_posix_ace) * count;
+		/* check if we would go beyond end of SMB */
+		if (size_of_data_area < size)
+			return -EINVAL;
+	} else {
+		/* illegal type */
+		return -EINVAL;
+	}
+
+	size = posix_acl_xattr_size(count);
+	if ((buflen == 0) || (local_acl == NULL)) {
+		/* used to query ACL EA size */
+	} else if (size > buflen) {
+		return -ERANGE;
+	} else /* buffer big enough */ {
+		local_acl->a_version = cpu_to_le32(POSIX_ACL_XATTR_VERSION);
+		for (i = 0; i < count ; i++) {
+			cifs_convert_ace(&local_acl->a_entries[i], pACE);
+			pACE++;
+		}
+	}
+	return size;
+}
+
+static __u16 convert_ace_to_cifs_ace(struct cifs_posix_ace *cifs_ace,
+				     const posix_acl_xattr_entry *local_ace)
+{
+	__u16 rc = 0; /* 0 = ACL converted ok */
+
+	cifs_ace->cifs_e_perm = le16_to_cpu(local_ace->e_perm);
+	cifs_ace->cifs_e_tag =  le16_to_cpu(local_ace->e_tag);
+	/* BB is there a better way to handle the large uid? */
+	if (local_ace->e_id == cpu_to_le32(-1)) {
+	/* Probably no need to le convert -1 on any arch but can not hurt */
+		cifs_ace->cifs_uid = cpu_to_le64(-1);
+	} else
+		cifs_ace->cifs_uid = cpu_to_le64(le32_to_cpu(local_ace->e_id));
+	/*cFYI(1,("perm %d tag %d id %d",ace->e_perm,ace->e_tag,ace->e_id));*/
+	return rc;
+}
+
+/* Convert ACL from local Linux POSIX xattr to CIFS POSIX ACL wire format */
+static __u16 ACL_to_cifs_posix(char *parm_data, const char *pACL,
+			       const int buflen, const int acl_type)
+{
+	__u16 rc = 0;
+	struct cifs_posix_acl *cifs_acl = (struct cifs_posix_acl *)parm_data;
+	posix_acl_xattr_header *local_acl = (posix_acl_xattr_header *)pACL;
+	int count;
+	int i;
+
+	if ((buflen == 0) || (pACL == NULL) || (cifs_acl == NULL))
+		return 0;
+
+	count = posix_acl_xattr_count((size_t)buflen);
+	cFYI(1, ("setting acl with %d entries from buf of length %d and "
+		"version of %d",
+		count, buflen, le32_to_cpu(local_acl->a_version)));
+	if (le32_to_cpu(local_acl->a_version) != 2) {
+		cFYI(1, ("unknown POSIX ACL version %d",
+		     le32_to_cpu(local_acl->a_version)));
+		return 0;
+	}
+	cifs_acl->version = cpu_to_le16(1);
+	if (acl_type == ACL_TYPE_ACCESS)
+		cifs_acl->access_entry_count = cpu_to_le16(count);
+	else if (acl_type == ACL_TYPE_DEFAULT)
+		cifs_acl->default_entry_count = cpu_to_le16(count);
+	else {
+		cFYI(1, ("unknown ACL type %d", acl_type));
+		return 0;
+	}
+	for (i = 0; i < count; i++) {
+		rc = convert_ace_to_cifs_ace(&cifs_acl->ace_array[i],
+					&local_acl->a_entries[i]);
+		if (rc != 0) {
+			/* ACE not converted */
+			break;
+		}
+	}
+	if (rc == 0) {
+		rc = (__u16)(count * sizeof(struct cifs_posix_ace));
+		rc += sizeof(struct cifs_posix_acl);
+		/* BB add check to make sure ACL does not overflow SMB */
+	}
+	return rc;
+}
+
+int
+CIFSSMBGetPosixACL(const int xid, struct cifsTconInfo *tcon,
+		   const unsigned char *searchName,
+		   char *acl_inf, const int buflen, const int acl_type,
+		   const struct nls_table *nls_codepage, int remap)
+{
+/* SMB_QUERY_POSIX_ACL */
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In GetPosixACL (Unix) for path %s", searchName));
+
+queryAclRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+			cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+					 PATH_MAX, nls_codepage, remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+		pSMB->FileName[name_len] = 0;
+		pSMB->FileName[name_len+1] = 0;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */  + 4 /* rsrvd */  + name_len /* incl null */ ;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max data count below from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(
+		offsetof(struct smb_com_transaction2_qpi_req,
+			 InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_POSIX_ACL);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+		(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_acl_get);
+	if (rc) {
+		cFYI(1, ("Send error in Query POSIX ACL = %d", rc));
+	} else {
+		/* decode response */
+
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		if (rc || (pSMBr->ByteCount < 2))
+		/* BB also check enough total bytes returned */
+			rc = -EIO;      /* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			__u16 count = le16_to_cpu(pSMBr->t2.DataCount);
+			rc = cifs_copy_posix_acl(acl_inf,
+				(char *)&pSMBr->hdr.Protocol+data_offset,
+				buflen, acl_type, count);
+		}
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto queryAclRetry;
+	return rc;
+}
+
+int
+CIFSSMBSetPosixACL(const int xid, struct cifsTconInfo *tcon,
+		   const unsigned char *fileName,
+		   const char *local_acl, const int buflen,
+		   const int acl_type,
+		   const struct nls_table *nls_codepage, int remap)
+{
+	struct smb_com_transaction2_spi_req *pSMB = NULL;
+	struct smb_com_transaction2_spi_rsp *pSMBr = NULL;
+	char *parm_data;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count, data_count, param_offset, offset;
+
+	cFYI(1, ("In SetPosixACL (Unix) for path %s", fileName));
+setAclRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+			cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				      PATH_MAX, nls_codepage, remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+	params = 6 + name_len;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB size from sess */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	parm_data = ((char *) &pSMB->hdr.Protocol) + offset;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+
+	/* convert to on the wire format for POSIX ACL */
+	data_count = ACL_to_cifs_posix(parm_data, local_acl, buflen, acl_type);
+
+	if (data_count == 0) {
+		rc = -EOPNOTSUPP;
+		goto setACLerrorExit;
+	}
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_POSIX_ACL);
+	byte_count = 3 /* pad */  + params + data_count;
+	pSMB->DataCount = cpu_to_le16(data_count);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("Set POSIX ACL returned %d", rc));
+
+setACLerrorExit:
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto setAclRetry;
+	return rc;
+}
+
+/* BB fix tabs in this function FIXME BB */
+int
+CIFSGetExtAttr(const int xid, struct cifsTconInfo *tcon,
+	       const int netfid, __u64 *pExtAttrBits, __u64 *pMask)
+{
+	int rc = 0;
+	struct smb_t2_qfi_req *pSMB = NULL;
+	struct smb_t2_qfi_rsp *pSMBr = NULL;
+	int bytes_returned;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In GetExtAttr"));
+	if (tcon == NULL)
+		return -ENODEV;
+
+GetExtAttrRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+			(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2 /* level */ + 2 /* fid */;
+	pSMB->t2.TotalDataCount = 0;
+	pSMB->t2.MaxParameterCount = cpu_to_le16(4);
+	/* BB find exact max data count below from sess structure BB */
+	pSMB->t2.MaxDataCount = cpu_to_le16(4000);
+	pSMB->t2.MaxSetupCount = 0;
+	pSMB->t2.Reserved = 0;
+	pSMB->t2.Flags = 0;
+	pSMB->t2.Timeout = 0;
+	pSMB->t2.Reserved2 = 0;
+	pSMB->t2.ParameterOffset = cpu_to_le16(offsetof(struct smb_t2_qfi_req,
+					       Fid) - 4);
+	pSMB->t2.DataCount = 0;
+	pSMB->t2.DataOffset = 0;
+	pSMB->t2.SetupCount = 1;
+	pSMB->t2.Reserved3 = 0;
+	pSMB->t2.SubCommand = cpu_to_le16(TRANS2_QUERY_FILE_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->t2.TotalParameterCount = cpu_to_le16(params);
+	pSMB->t2.ParameterCount = pSMB->t2.TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_ATTR_FLAGS);
+	pSMB->Pad = 0;
+	pSMB->Fid = netfid;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->t2.ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("error %d in GetExtAttr", rc));
+	} else {
+		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		if (rc || (pSMBr->ByteCount < 2))
+		/* BB also check enough total bytes returned */
+			/* If rc should we check for EOPNOSUPP and
+			   disable the srvino flag? or in caller? */
+			rc = -EIO;      /* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			__u16 count = le16_to_cpu(pSMBr->t2.DataCount);
+			struct file_chattr_info *pfinfo;
+			/* BB Do we need a cast or hash here ? */
+			if (count != 16) {
+				cFYI(1, ("Illegal size ret in GetExtAttr"));
+				rc = -EIO;
+				goto GetExtAttrOut;
+			}
+			pfinfo = (struct file_chattr_info *)
+				 (data_offset + (char *) &pSMBr->hdr.Protocol);
+			*pExtAttrBits = le64_to_cpu(pfinfo->mode);
+			*pMask = le64_to_cpu(pfinfo->mask);
+		}
+	}
+GetExtAttrOut:
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto GetExtAttrRetry;
+	return rc;
+}
+
+#endif /* CONFIG_POSIX */
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+/* Get Security Descriptor (by handle) from remote server for a file or dir */
+int
+CIFSSMBGetCIFSACL(const int xid, struct cifsTconInfo *tcon, __u16 fid,
+		  struct cifs_ntsd **acl_inf, __u32 *pbuflen)
+{
+	int rc = 0;
+	int buf_type = 0;
+	QUERY_SEC_DESC_REQ *pSMB;
+	struct kvec iov[1];
+
+	cFYI(1, ("GetCifsACL"));
+
+	*pbuflen = 0;
+	*acl_inf = NULL;
+
+	rc = smb_init_nttransact(NT_TRANSACT_QUERY_SECURITY_DESC, 0,
+			8 /* parm len */, tcon, (void **) &pSMB);
+	if (rc)
+		return rc;
+
+	pSMB->MaxParameterCount = cpu_to_le32(4);
+	/* BB TEST with big acls that might need to be e.g. larger than 16K */
+	pSMB->MaxSetupCount = 0;
+	pSMB->Fid = fid; /* file handle always le */
+	pSMB->AclFlags = cpu_to_le32(CIFS_ACL_OWNER | CIFS_ACL_GROUP |
+				     CIFS_ACL_DACL);
+	pSMB->ByteCount = cpu_to_le16(11); /* 3 bytes pad + 8 bytes parm */
+	pSMB->hdr.smb_buf_length += 11;
+	iov[0].iov_base = (char *)pSMB;
+	iov[0].iov_len = pSMB->hdr.smb_buf_length + 4;
+
+	rc = SendReceive2(xid, tcon->ses, iov, 1 /* num iovec */, &buf_type,
+			 CIFS_STD_OP);
+	cifs_stats_inc(&tcon->num_acl_get);
+	if (rc) {
+		cFYI(1, ("Send error in QuerySecDesc = %d", rc));
+	} else {                /* decode response */
+		__le32 *parm;
+		__u32 parm_len;
+		__u32 acl_len;
+		struct smb_com_ntransact_rsp *pSMBr;
+		char *pdata;
+
+/* validate_nttransact */
+		rc = validate_ntransact(iov[0].iov_base, (char **)&parm,
+					&pdata, &parm_len, pbuflen);
+		if (rc)
+			goto qsec_out;
+		pSMBr = (struct smb_com_ntransact_rsp *)iov[0].iov_base;
+
+		cFYI(1, ("smb %p parm %p data %p", pSMBr, parm, *acl_inf));
+
+		if (le32_to_cpu(pSMBr->ParameterCount) != 4) {
+			rc = -EIO;      /* bad smb */
+			*pbuflen = 0;
+			goto qsec_out;
+		}
+
+/* BB check that data area is minimum length and as big as acl_len */
+
+		acl_len = le32_to_cpu(*parm);
+		if (acl_len != *pbuflen) {
+			cERROR(1, ("acl length %d does not match %d",
+				   acl_len, *pbuflen));
+			if (*pbuflen > acl_len)
+				*pbuflen = acl_len;
+		}
+
+		/* check if buffer is big enough for the acl
+		   header followed by the smallest SID */
+		if ((*pbuflen < sizeof(struct cifs_ntsd) + 8) ||
+		    (*pbuflen >= 64 * 1024)) {
+			cERROR(1, ("bad acl length %d", *pbuflen));
+			rc = -EINVAL;
+			*pbuflen = 0;
+		} else {
+			*acl_inf = kmalloc(*pbuflen, GFP_KERNEL);
+			if (*acl_inf == NULL) {
+				*pbuflen = 0;
+				rc = -ENOMEM;
+			}
+			memcpy(*acl_inf, pdata, *pbuflen);
+		}
+	}
+qsec_out:
+	if (buf_type == CIFS_SMALL_BUFFER)
+		cifs_small_buf_release(iov[0].iov_base);
+	else if (buf_type == CIFS_LARGE_BUFFER)
+		cifs_buf_release(iov[0].iov_base);
+/*	cifs_small_buf_release(pSMB); */ /* Freed earlier now in SendReceive2 */
+	return rc;
+}
+
+int
+CIFSSMBSetCIFSACL(const int xid, struct cifsTconInfo *tcon, __u16 fid,
+			struct cifs_ntsd *pntsd, __u32 acllen)
+{
+	__u16 byte_count, param_count, data_count, param_offset, data_offset;
+	int rc = 0;
+	int bytes_returned = 0;
+	SET_SEC_DESC_REQ *pSMB = NULL;
+	NTRANSACT_RSP *pSMBr = NULL;
+
+setCifsAclRetry:
+	rc = smb_init(SMB_COM_NT_TRANSACT, 19, tcon, (void **) &pSMB,
+			(void **) &pSMBr);
+	if (rc)
+			return (rc);
+
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+
+	param_count = 8;
+	param_offset = offsetof(struct smb_com_transaction_ssec_req, Fid) - 4;
+	data_count = acllen;
+	data_offset = param_offset + param_count;
+	byte_count = 3 /* pad */  + param_count;
+
+	pSMB->DataCount = cpu_to_le32(data_count);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->MaxParameterCount = cpu_to_le32(4);
+	pSMB->MaxDataCount = cpu_to_le32(16384);
+	pSMB->ParameterCount = cpu_to_le32(param_count);
+	pSMB->ParameterOffset = cpu_to_le32(param_offset);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->DataOffset = cpu_to_le32(data_offset);
+	pSMB->SetupCount = 0;
+	pSMB->SubCommand = cpu_to_le16(NT_TRANSACT_SET_SECURITY_DESC);
+	pSMB->ByteCount = cpu_to_le16(byte_count+data_count);
+
+	pSMB->Fid = fid; /* file handle always le */
+	pSMB->Reserved2 = 0;
+	pSMB->AclFlags = cpu_to_le32(CIFS_ACL_DACL);
+
+	if (pntsd && acllen) {
+		memcpy((char *) &pSMBr->hdr.Protocol + data_offset,
+			(char *) pntsd,
+			acllen);
+		pSMB->hdr.smb_buf_length += (byte_count + data_count);
+
+	} else
+		pSMB->hdr.smb_buf_length += byte_count;
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+		(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+
+	cFYI(1, ("SetCIFSACL bytes_returned: %d, rc: %d", bytes_returned, rc));
+	if (rc)
+		cFYI(1, ("Set CIFS ACL returned %d", rc));
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto setCifsAclRetry;
+
+	return (rc);
+}
+
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+
+/* Legacy Query Path Information call for lookup to old servers such
+   as Win9x/WinME */
+int SMBQueryInformation(const int xid, struct cifsTconInfo *tcon,
+			const unsigned char *searchName,
+			FILE_ALL_INFO *pFinfo,
+			const struct nls_table *nls_codepage, int remap)
+{
+	QUERY_INFORMATION_REQ *pSMB;
+	QUERY_INFORMATION_RSP *pSMBr;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+
+	cFYI(1, ("In SMBQPath path %s", searchName));
+QInfRetry:
+	rc = smb_init(SMB_COM_QUERY_INFORMATION, 0, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+			cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+					PATH_MAX, nls_codepage, remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+	} else {
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+	pSMB->BufferFormat = 0x04;
+	name_len++; /* account for buffer type byte */
+	pSMB->hdr.smb_buf_length += (__u16) name_len;
+	pSMB->ByteCount = cpu_to_le16(name_len);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QueryInfo = %d", rc));
+	} else if (pFinfo) {
+		struct timespec ts;
+		__u32 time = le32_to_cpu(pSMBr->last_write_time);
+
+		/* decode response */
+		/* BB FIXME - add time zone adjustment BB */
+		memset(pFinfo, 0, sizeof(FILE_ALL_INFO));
+		ts.tv_nsec = 0;
+		ts.tv_sec = time;
+		/* decode time fields */
+		pFinfo->ChangeTime = cpu_to_le64(cifs_UnixTimeToNT(ts));
+		pFinfo->LastWriteTime = pFinfo->ChangeTime;
+		pFinfo->LastAccessTime = 0;
+		pFinfo->AllocationSize =
+			cpu_to_le64(le32_to_cpu(pSMBr->size));
+		pFinfo->EndOfFile = pFinfo->AllocationSize;
+		pFinfo->Attributes =
+			cpu_to_le32(le16_to_cpu(pSMBr->attr));
+	} else
+		rc = -EIO; /* bad buffer passed in */
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QInfRetry;
+
+	return rc;
+}
+
+
+
+
+int
+CIFSSMBQPathInfo(const int xid, struct cifsTconInfo *tcon,
+		 const unsigned char *searchName,
+		 FILE_ALL_INFO *pFindData,
+		 int legacy /* old style infolevel */,
+		 const struct nls_table *nls_codepage, int remap)
+{
+/* level 263 SMB_QUERY_FILE_ALL_INFO */
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	__u16 params, byte_count;
+
+/* cFYI(1, ("In QPathInfo path %s", searchName)); */
+QPathInfoRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */ + 4 /* reserved */ + name_len /* includes NUL */;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	if (legacy)
+		pSMB->InformationLevel = cpu_to_le16(SMB_INFO_STANDARD);
+	else
+		pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FILE_ALL_INFO);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QPathInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc) /* BB add auto retry on EOPNOTSUPP? */
+			rc = -EIO;
+		else if (!legacy && (pSMBr->ByteCount < 40))
+			rc = -EIO;	/* bad smb */
+		else if (legacy && (pSMBr->ByteCount < 24))
+			rc = -EIO;  /* 24 or 26 expected but we do not read
+					last field */
+		else if (pFindData) {
+			int size;
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+
+			/* On legacy responses we do not read the last field,
+			EAsize, fortunately since it varies by subdialect and
+			also note it differs on Set vs. Get, ie two bytes or 4
+			bytes depending but we don't care here */
+			if (legacy)
+				size = sizeof(FILE_INFO_STANDARD);
+			else
+				size = sizeof(FILE_ALL_INFO);
+			memcpy((char *) pFindData,
+			       (char *) &pSMBr->hdr.Protocol +
+			       data_offset, size);
+		} else
+		    rc = -ENOMEM;
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto QPathInfoRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBUnixQPathInfo(const int xid, struct cifsTconInfo *tcon,
+		     const unsigned char *searchName,
+		     FILE_UNIX_BASIC_INFO *pFindData,
+		     const struct nls_table *nls_codepage, int remap)
+{
+/* SMB_QUERY_FILE_UNIX_BASIC */
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned = 0;
+	int name_len;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QPathInfo (Unix) the path %s", searchName));
+UnixQPathInfoRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+				  PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */ + 4 /* reserved */ + name_len /* includes NUL */;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FILE_UNIX_BASIC);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QPathInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < sizeof(FILE_UNIX_BASIC_INFO))) {
+			cERROR(1, ("Malformed FILE_UNIX_BASIC_INFO response.\n"
+				   "Unix Extensions can be disabled on mount "
+				   "by specifying the nosfu mount option."));
+			rc = -EIO;	/* bad smb */
+		} else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			memcpy((char *) pFindData,
+			       (char *) &pSMBr->hdr.Protocol +
+			       data_offset,
+			       sizeof(FILE_UNIX_BASIC_INFO));
+		}
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto UnixQPathInfoRetry;
+
+	return rc;
+}
+
+/* xid, tcon, searchName and codepage are input parms, rest are returned */
+int
+CIFSFindFirst(const int xid, struct cifsTconInfo *tcon,
+	      const char *searchName,
+	      const struct nls_table *nls_codepage,
+	      __u16 *pnetfid,
+	      struct cifs_search_info *psrch_inf, int remap, const char dirsep)
+{
+/* level 257 SMB_ */
+	TRANSACTION2_FFIRST_REQ *pSMB = NULL;
+	TRANSACTION2_FFIRST_RSP *pSMBr = NULL;
+	T2_FFIRST_RSP_PARMS *parms;
+	int rc = 0;
+	int bytes_returned = 0;
+	int name_len;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In FindFirst for %s", searchName));
+
+findFirstRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+				 PATH_MAX, nls_codepage, remap);
+		/* We can not add the asterik earlier in case
+		it got remapped to 0xF03A as if it were part of the
+		directory name instead of a wildcard */
+		name_len *= 2;
+		pSMB->FileName[name_len] = dirsep;
+		pSMB->FileName[name_len+1] = 0;
+		pSMB->FileName[name_len+2] = '*';
+		pSMB->FileName[name_len+3] = 0;
+		name_len += 4; /* now the trailing null */
+		pSMB->FileName[name_len] = 0; /* null terminate just in case */
+		pSMB->FileName[name_len+1] = 0;
+		name_len += 2;
+	} else {	/* BB add check for overrun of SMB buf BB */
+		name_len = strnlen(searchName, PATH_MAX);
+/* BB fix here and in unicode clause above ie
+		if (name_len > buffersize-header)
+			free buffer exit; BB */
+		strncpy(pSMB->FileName, searchName, name_len);
+		pSMB->FileName[name_len] = dirsep;
+		pSMB->FileName[name_len+1] = '*';
+		pSMB->FileName[name_len+2] = 0;
+		name_len += 3;
+	}
+
+	params = 12 + name_len /* includes null */ ;
+	pSMB->TotalDataCount = 0;	/* no EAs */
+	pSMB->MaxParameterCount = cpu_to_le16(10);
+	pSMB->MaxDataCount = cpu_to_le16((tcon->ses->server->maxBuf -
+					  MAX_CIFS_HDR_SIZE) & 0xFFFFFF00);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(
+	      offsetof(struct smb_com_transaction2_ffirst_req, SearchAttributes)
+		- 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;	/* one byte, no need to make endian neutral */
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_FIND_FIRST);
+	pSMB->SearchAttributes =
+	    cpu_to_le16(ATTR_READONLY | ATTR_HIDDEN | ATTR_SYSTEM |
+			ATTR_DIRECTORY);
+	pSMB->SearchCount = cpu_to_le16(CIFSMaxBufSize/sizeof(FILE_UNIX_INFO));
+	pSMB->SearchFlags = cpu_to_le16(CIFS_SEARCH_CLOSE_AT_END |
+		CIFS_SEARCH_RETURN_RESUME);
+	pSMB->InformationLevel = cpu_to_le16(psrch_inf->info_level);
+
+	/* BB what should we set StorageType to? Does it matter? BB */
+	pSMB->SearchStorageType = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_ffirst);
+
+	if (rc) {/* BB add logic to retry regular search if Unix search
+			rejected unexpectedly by server */
+		/* BB Add code to handle unsupported level rc */
+		cFYI(1, ("Error in FindFirst = %d", rc));
+
+		cifs_buf_release(pSMB);
+
+		/* BB eventually could optimize out free and realloc of buf */
+		/*    for this case */
+		if (rc == -EAGAIN)
+			goto findFirstRetry;
+	} else { /* decode response */
+		/* BB remember to free buffer if error BB */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		if (rc == 0) {
+			unsigned int lnoff;
+
+			if (pSMBr->hdr.Flags2 & SMBFLG2_UNICODE)
+				psrch_inf->unicode = true;
+			else
+				psrch_inf->unicode = false;
+
+			psrch_inf->ntwrk_buf_start = (char *)pSMBr;
+			psrch_inf->smallBuf = 0;
+			psrch_inf->srch_entries_start =
+				(char *) &pSMBr->hdr.Protocol +
+					le16_to_cpu(pSMBr->t2.DataOffset);
+			parms = (T2_FFIRST_RSP_PARMS *)((char *) &pSMBr->hdr.Protocol +
+			       le16_to_cpu(pSMBr->t2.ParameterOffset));
+
+			if (parms->EndofSearch)
+				psrch_inf->endOfSearch = true;
+			else
+				psrch_inf->endOfSearch = false;
+
+			psrch_inf->entries_in_buffer =
+					le16_to_cpu(parms->SearchCount);
+			psrch_inf->index_of_last_entry = 2 /* skip . and .. */ +
+				psrch_inf->entries_in_buffer;
+			lnoff = le16_to_cpu(parms->LastNameOffset);
+			if (tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE <
+			      lnoff) {
+				cERROR(1, ("ignoring corrupt resume name"));
+				psrch_inf->last_entry = NULL;
+				return rc;
+			}
+
+			psrch_inf->last_entry = psrch_inf->srch_entries_start +
+							lnoff;
+
+			*pnetfid = parms->SearchHandle;
+		} else {
+			cifs_buf_release(pSMB);
+		}
+	}
+
+	return rc;
+}
+
+int CIFSFindNext(const int xid, struct cifsTconInfo *tcon,
+		 __u16 searchHandle, struct cifs_search_info *psrch_inf)
+{
+	TRANSACTION2_FNEXT_REQ *pSMB = NULL;
+	TRANSACTION2_FNEXT_RSP *pSMBr = NULL;
+	T2_FNEXT_RSP_PARMS *parms;
+	char *response_data;
+	int rc = 0;
+	int bytes_returned, name_len;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In FindNext"));
+
+	if (psrch_inf->endOfSearch)
+		return -ENOENT;
+
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 14; /* includes 2 bytes of null string, converted to LE below*/
+	byte_count = 0;
+	pSMB->TotalDataCount = 0;       /* no EAs */
+	pSMB->MaxParameterCount = cpu_to_le16(8);
+	pSMB->MaxDataCount =
+		cpu_to_le16((tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE) &
+				0xFFFFFF00);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset =  cpu_to_le16(
+	      offsetof(struct smb_com_transaction2_fnext_req,SearchHandle) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_FIND_NEXT);
+	pSMB->SearchHandle = searchHandle;      /* always kept as le */
+	pSMB->SearchCount =
+		cpu_to_le16(CIFSMaxBufSize / sizeof(FILE_UNIX_INFO));
+	pSMB->InformationLevel = cpu_to_le16(psrch_inf->info_level);
+	pSMB->ResumeKey = psrch_inf->resume_key;
+	pSMB->SearchFlags =
+	      cpu_to_le16(CIFS_SEARCH_CLOSE_AT_END | CIFS_SEARCH_RETURN_RESUME);
+
+	name_len = psrch_inf->resume_name_len;
+	params += name_len;
+	if (name_len < PATH_MAX) {
+		memcpy(pSMB->ResumeFileName, psrch_inf->presume_name, name_len);
+		byte_count += name_len;
+		/* 14 byte parm len above enough for 2 byte null terminator */
+		pSMB->ResumeFileName[name_len] = 0;
+		pSMB->ResumeFileName[name_len+1] = 0;
+	} else {
+		rc = -EINVAL;
+		goto FNext2_err_exit;
+	}
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	cifs_stats_inc(&tcon->num_fnext);
+	if (rc) {
+		if (rc == -EBADF) {
+			psrch_inf->endOfSearch = true;
+			cifs_buf_release(pSMB);
+			rc = 0; /* search probably was closed at end of search*/
+		} else
+			cFYI(1, ("FindNext returned = %d", rc));
+	} else {                /* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc == 0) {
+			unsigned int lnoff;
+
+			/* BB fixme add lock for file (srch_info) struct here */
+			if (pSMBr->hdr.Flags2 & SMBFLG2_UNICODE)
+				psrch_inf->unicode = true;
+			else
+				psrch_inf->unicode = false;
+			response_data = (char *) &pSMBr->hdr.Protocol +
+			       le16_to_cpu(pSMBr->t2.ParameterOffset);
+			parms = (T2_FNEXT_RSP_PARMS *)response_data;
+			response_data = (char *)&pSMBr->hdr.Protocol +
+				le16_to_cpu(pSMBr->t2.DataOffset);
+			if (psrch_inf->smallBuf)
+				cifs_small_buf_release(
+					psrch_inf->ntwrk_buf_start);
+			else
+				cifs_buf_release(psrch_inf->ntwrk_buf_start);
+			psrch_inf->srch_entries_start = response_data;
+			psrch_inf->ntwrk_buf_start = (char *)pSMB;
+			psrch_inf->smallBuf = 0;
+			if (parms->EndofSearch)
+				psrch_inf->endOfSearch = true;
+			else
+				psrch_inf->endOfSearch = false;
+			psrch_inf->entries_in_buffer =
+						le16_to_cpu(parms->SearchCount);
+			psrch_inf->index_of_last_entry +=
+				psrch_inf->entries_in_buffer;
+			lnoff = le16_to_cpu(parms->LastNameOffset);
+			if (tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE <
+			      lnoff) {
+				cERROR(1, ("ignoring corrupt resume name"));
+				psrch_inf->last_entry = NULL;
+				return rc;
+			} else
+				psrch_inf->last_entry =
+					psrch_inf->srch_entries_start + lnoff;
+
+/*  cFYI(1,("fnxt2 entries in buf %d index_of_last %d",
+	    psrch_inf->entries_in_buffer, psrch_inf->index_of_last_entry)); */
+
+			/* BB fixme add unlock here */
+		}
+
+	}
+
+	/* BB On error, should we leave previous search buf (and count and
+	last entry fields) intact or free the previous one? */
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+	since file handle passed in no longer valid */
+FNext2_err_exit:
+	if (rc != 0)
+		cifs_buf_release(pSMB);
+	return rc;
+}
+
+int
+CIFSFindClose(const int xid, struct cifsTconInfo *tcon,
+	      const __u16 searchHandle)
+{
+	int rc = 0;
+	FINDCLOSE_REQ *pSMB = NULL;
+
+	cFYI(1, ("In CIFSSMBFindClose"));
+	rc = small_smb_init(SMB_COM_FIND_CLOSE2, 1, tcon, (void **)&pSMB);
+
+	/* no sense returning error if session restarted
+		as file handle has been closed */
+	if (rc == -EAGAIN)
+		return 0;
+	if (rc)
+		return rc;
+
+	pSMB->FileID = searchHandle;
+	pSMB->ByteCount = 0;
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	if (rc)
+		cERROR(1, ("Send error in FindClose = %d", rc));
+
+	cifs_stats_inc(&tcon->num_fclose);
+
+	/* Since session is dead, search handle closed on server already */
+	if (rc == -EAGAIN)
+		rc = 0;
+
+	return rc;
+}
+
+int
+CIFSGetSrvInodeNumber(const int xid, struct cifsTconInfo *tcon,
+		      const unsigned char *searchName,
+		      __u64 *inode_number,
+		      const struct nls_table *nls_codepage, int remap)
+{
+	int rc = 0;
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int name_len, bytes_returned;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In GetSrvInodeNum for %s", searchName));
+	if (tcon == NULL)
+		return -ENODEV;
+
+GetInodeNumberRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+			cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+					 PATH_MAX, nls_codepage, remap);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */  + 4 /* rsrvd */  + name_len /* incl null */ ;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max data count below from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+		struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FILE_INTERNAL_INFO);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+		(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("error %d in QueryInternalInfo", rc));
+	} else {
+		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		if (rc || (pSMBr->ByteCount < 2))
+		/* BB also check enough total bytes returned */
+			/* If rc should we check for EOPNOSUPP and
+			disable the srvino flag? or in caller? */
+			rc = -EIO;      /* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			__u16 count = le16_to_cpu(pSMBr->t2.DataCount);
+			struct file_internal_info *pfinfo;
+			/* BB Do we need a cast or hash here ? */
+			if (count < 8) {
+				cFYI(1, ("Illegal size ret in QryIntrnlInf"));
+				rc = -EIO;
+				goto GetInodeNumOut;
+			}
+			pfinfo = (struct file_internal_info *)
+				(data_offset + (char *) &pSMBr->hdr.Protocol);
+			*inode_number = le64_to_cpu(pfinfo->UniqueId);
+		}
+	}
+GetInodeNumOut:
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto GetInodeNumberRetry;
+	return rc;
+}
+
+/* parses DFS refferal V3 structure
+ * caller is responsible for freeing target_nodes
+ * returns:
+ * 	on success - 0
+ *	on failure - errno
+ */
+static int
+parse_DFS_referrals(TRANSACTION2_GET_DFS_REFER_RSP *pSMBr,
+		unsigned int *num_of_nodes,
+		struct dfs_info3_param **target_nodes,
+		const struct nls_table *nls_codepage, int remap,
+		const char *searchName)
+{
+	int i, rc = 0;
+	char *data_end;
+	bool is_unicode;
+	struct dfs_referral_level_3 *ref;
+
+	if (pSMBr->hdr.Flags2 & SMBFLG2_UNICODE)
+		is_unicode = true;
+	else
+		is_unicode = false;
+	*num_of_nodes = le16_to_cpu(pSMBr->NumberOfReferrals);
+
+	if (*num_of_nodes < 1) {
+		cERROR(1, ("num_referrals: must be at least > 0,"
+			"but we get num_referrals = %d\n", *num_of_nodes));
+		rc = -EINVAL;
+		goto parse_DFS_referrals_exit;
+	}
+
+	ref = (struct dfs_referral_level_3 *) &(pSMBr->referrals);
+	if (ref->VersionNumber != cpu_to_le16(3)) {
+		cERROR(1, ("Referrals of V%d version are not supported,"
+			"should be V3", le16_to_cpu(ref->VersionNumber)));
+		rc = -EINVAL;
+		goto parse_DFS_referrals_exit;
+	}
+
+	/* get the upper boundary of the resp buffer */
+	data_end = (char *)(&(pSMBr->PathConsumed)) +
+				le16_to_cpu(pSMBr->t2.DataCount);
+
+	cFYI(1, ("num_referrals: %d dfs flags: 0x%x ... \n",
+			*num_of_nodes,
+			le32_to_cpu(pSMBr->DFSFlags)));
+
+	*target_nodes = kzalloc(sizeof(struct dfs_info3_param) *
+			*num_of_nodes, GFP_KERNEL);
+	if (*target_nodes == NULL) {
+		cERROR(1, ("Failed to allocate buffer for target_nodes\n"));
+		rc = -ENOMEM;
+		goto parse_DFS_referrals_exit;
+	}
+
+	/* collect neccessary data from referrals */
+	for (i = 0; i < *num_of_nodes; i++) {
+		char *temp;
+		int max_len;
+		struct dfs_info3_param *node = (*target_nodes)+i;
+
+		node->flags = le32_to_cpu(pSMBr->DFSFlags);
+		if (is_unicode) {
+			__le16 *tmp = kmalloc(strlen(searchName)*2 + 2,
+						GFP_KERNEL);
+			cifsConvertToUCS((__le16 *) tmp, searchName,
+					PATH_MAX, nls_codepage, remap);
+			node->path_consumed = cifs_ucs2_bytes(tmp,
+					le16_to_cpu(pSMBr->PathConsumed),
+					nls_codepage);
+			kfree(tmp);
+		} else
+			node->path_consumed = le16_to_cpu(pSMBr->PathConsumed);
+
+		node->server_type = le16_to_cpu(ref->ServerType);
+		node->ref_flag = le16_to_cpu(ref->ReferralEntryFlags);
+
+		/* copy DfsPath */
+		temp = (char *)ref + le16_to_cpu(ref->DfsPathOffset);
+		max_len = data_end - temp;
+		node->path_name = cifs_strndup_from_ucs(temp, max_len,
+						      is_unicode, nls_codepage);
+		if (!node->path_name) {
+			rc = -ENOMEM;
+			goto parse_DFS_referrals_exit;
+		}
+
+		/* copy link target UNC */
+		temp = (char *)ref + le16_to_cpu(ref->NetworkAddressOffset);
+		max_len = data_end - temp;
+		node->node_name = cifs_strndup_from_ucs(temp, max_len,
+						      is_unicode, nls_codepage);
+		if (!node->node_name)
+			rc = -ENOMEM;
+	}
+
+parse_DFS_referrals_exit:
+	if (rc) {
+		free_dfs_info_array(*target_nodes, *num_of_nodes);
+		*target_nodes = NULL;
+		*num_of_nodes = 0;
+	}
+	return rc;
+}
+
+int
+CIFSGetDFSRefer(const int xid, struct cifsSesInfo *ses,
+		const unsigned char *searchName,
+		struct dfs_info3_param **target_nodes,
+		unsigned int *num_of_nodes,
+		const struct nls_table *nls_codepage, int remap)
+{
+/* TRANS2_GET_DFS_REFERRAL */
+	TRANSACTION2_GET_DFS_REFER_REQ *pSMB = NULL;
+	TRANSACTION2_GET_DFS_REFER_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	__u16 params, byte_count;
+	*num_of_nodes = 0;
+	*target_nodes = NULL;
+
+	cFYI(1, ("In GetDFSRefer the path %s", searchName));
+	if (ses == NULL)
+		return -ENODEV;
+getDFSRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, NULL, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	/* server pointer checked in called function,
+	but should never be null here anyway */
+	pSMB->hdr.Mid = GetNextMid(ses->server);
+	pSMB->hdr.Tid = ses->ipc_tid;
+	pSMB->hdr.Uid = ses->Suid;
+	if (ses->capabilities & CAP_STATUS32)
+		pSMB->hdr.Flags2 |= SMBFLG2_ERR_STATUS;
+	if (ses->capabilities & CAP_DFS)
+		pSMB->hdr.Flags2 |= SMBFLG2_DFS;
+
+	if (ses->capabilities & CAP_UNICODE) {
+		pSMB->hdr.Flags2 |= SMBFLG2_UNICODE;
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->RequestFileName,
+				     searchName, PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->RequestFileName, searchName, name_len);
+	}
+
+	if (ses->server) {
+		if (ses->server->secMode &
+		   (SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED))
+			pSMB->hdr.Flags2 |= SMBFLG2_SECURITY_SIGNATURE;
+	}
+
+	pSMB->hdr.Uid = ses->Suid;
+
+	params = 2 /* level */  + name_len /*includes null */ ;
+	pSMB->TotalDataCount = 0;
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->MaxParameterCount = 0;
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	  struct smb_com_transaction2_get_dfs_refer_req, MaxReferralLevel) - 4);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_GET_DFS_REFERRAL);
+	byte_count = params + 3 /* pad */ ;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->MaxReferralLevel = cpu_to_le16(3);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in GetDFSRefer = %d", rc));
+		goto GetDFSRefExit;
+	}
+	rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+	/* BB Also check if enough total bytes returned? */
+	if (rc || (pSMBr->ByteCount < 17)) {
+		rc = -EIO;      /* bad smb */
+		goto GetDFSRefExit;
+	}
+
+	cFYI(1, ("Decoding GetDFSRefer response BCC: %d  Offset %d",
+				pSMBr->ByteCount,
+				le16_to_cpu(pSMBr->t2.DataOffset)));
+
+	/* parse returned result into more usable form */
+	rc = parse_DFS_referrals(pSMBr, num_of_nodes,
+				 target_nodes, nls_codepage, remap,
+				 searchName);
+
+GetDFSRefExit:
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto getDFSRetry;
+
+	return rc;
+}
+
+/* Query File System Info such as free space to old servers such as Win 9x */
+int
+SMBOldQFSInfo(const int xid, struct cifsTconInfo *tcon, struct kstatfs *FSData)
+{
+/* level 0x01 SMB_QUERY_FILE_SYSTEM_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_ALLOC_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("OldQFSInfo"));
+oldQFSInfoRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		(void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;     /* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	struct smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_INFO_ALLOCATION);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+		(struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QFSInfo = %d", rc));
+	} else {                /* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < 18))
+			rc = -EIO;      /* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			cFYI(1, ("qfsinf resp BCC: %d  Offset %d",
+				 pSMBr->ByteCount, data_offset));
+
+			response_data = (FILE_SYSTEM_ALLOC_INFO *)
+				(((char *) &pSMBr->hdr.Protocol) + data_offset);
+			FSData->f_bsize =
+				le16_to_cpu(response_data->BytesPerSector) *
+				le32_to_cpu(response_data->
+					SectorsPerAllocationUnit);
+			FSData->f_blocks =
+			       le32_to_cpu(response_data->TotalAllocationUnits);
+			FSData->f_bfree = FSData->f_bavail =
+				le32_to_cpu(response_data->FreeAllocationUnits);
+			cFYI(1,
+			     ("Blocks: %lld  Free: %lld Block size %ld",
+			      (unsigned long long)FSData->f_blocks,
+			      (unsigned long long)FSData->f_bfree,
+			      FSData->f_bsize));
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto oldQFSInfoRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBQFSInfo(const int xid, struct cifsTconInfo *tcon, struct kstatfs *FSData)
+{
+/* level 0x103 SMB_QUERY_FILE_SYSTEM_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QFSInfo"));
+QFSInfoRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;	/* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+		struct smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FS_SIZE_INFO);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QFSInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < 24))
+			rc = -EIO;	/* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+
+			response_data =
+			    (FILE_SYSTEM_INFO
+			     *) (((char *) &pSMBr->hdr.Protocol) +
+				 data_offset);
+			FSData->f_bsize =
+			    le32_to_cpu(response_data->BytesPerSector) *
+			    le32_to_cpu(response_data->
+					SectorsPerAllocationUnit);
+			FSData->f_blocks =
+			    le64_to_cpu(response_data->TotalAllocationUnits);
+			FSData->f_bfree = FSData->f_bavail =
+			    le64_to_cpu(response_data->FreeAllocationUnits);
+			cFYI(1,
+			     ("Blocks: %lld  Free: %lld Block size %ld",
+			      (unsigned long long)FSData->f_blocks,
+			      (unsigned long long)FSData->f_bfree,
+			      FSData->f_bsize));
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QFSInfoRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBQFSAttributeInfo(const int xid, struct cifsTconInfo *tcon)
+{
+/* level 0x105  SMB_QUERY_FILE_SYSTEM_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_ATTRIBUTE_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QFSAttributeInfo"));
+QFSAttributeRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;	/* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+		struct smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FS_ATTRIBUTE_INFO);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cERROR(1, ("Send error in QFSAttributeInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < 13)) {
+			/* BB also check if enough bytes returned */
+			rc = -EIO;	/* bad smb */
+		} else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			response_data =
+			    (FILE_SYSTEM_ATTRIBUTE_INFO
+			     *) (((char *) &pSMBr->hdr.Protocol) +
+				 data_offset);
+			memcpy(&tcon->fsAttrInfo, response_data,
+			       sizeof(FILE_SYSTEM_ATTRIBUTE_INFO));
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QFSAttributeRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBQFSDeviceInfo(const int xid, struct cifsTconInfo *tcon)
+{
+/* level 0x104 SMB_QUERY_FILE_SYSTEM_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_DEVICE_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QFSDeviceInfo"));
+QFSDeviceRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;	/* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+		struct smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_FS_DEVICE_INFO);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QFSDeviceInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < sizeof(FILE_SYSTEM_DEVICE_INFO)))
+			rc = -EIO;	/* bad smb */
+		else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			response_data =
+			    (FILE_SYSTEM_DEVICE_INFO *)
+				(((char *) &pSMBr->hdr.Protocol) +
+				 data_offset);
+			memcpy(&tcon->fsDevInfo, response_data,
+			       sizeof(FILE_SYSTEM_DEVICE_INFO));
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QFSDeviceRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBQFSUnixInfo(const int xid, struct cifsTconInfo *tcon)
+{
+/* level 0x200  SMB_QUERY_CIFS_UNIX_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_UNIX_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QFSUnixInfo"));
+QFSUnixRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;	/* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(100);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(struct
+			smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_CIFS_UNIX_INFO);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cERROR(1, ("Send error in QFSUnixInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < 13)) {
+			rc = -EIO;	/* bad smb */
+		} else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			response_data =
+			    (FILE_SYSTEM_UNIX_INFO
+			     *) (((char *) &pSMBr->hdr.Protocol) +
+				 data_offset);
+			memcpy(&tcon->fsUnixInfo, response_data,
+			       sizeof(FILE_SYSTEM_UNIX_INFO));
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QFSUnixRetry;
+
+
+	return rc;
+}
+
+int
+CIFSSMBSetFSUnixInfo(const int xid, struct cifsTconInfo *tcon, __u64 cap)
+{
+/* level 0x200  SMB_SET_CIFS_UNIX_INFO */
+	TRANSACTION2_SETFSI_REQ *pSMB = NULL;
+	TRANSACTION2_SETFSI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, offset, byte_count;
+
+	cFYI(1, ("In SETFSUnixInfo"));
+SETFSUnixRetry:
+	/* BB switch to small buf init to save memory */
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 4;	/* 2 bytes zero followed by info level. */
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_setfsi_req, FileNum)
+				- 4;
+	offset = param_offset + params;
+
+	pSMB->MaxParameterCount = cpu_to_le16(4);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(100);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FS_INFORMATION);
+	byte_count = 1 /* pad */ + params + 12;
+
+	pSMB->DataCount = cpu_to_le16(12);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+
+	/* Params. */
+	pSMB->FileNum = 0;
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_CIFS_UNIX_INFO);
+
+	/* Data. */
+	pSMB->ClientUnixMajor = cpu_to_le16(CIFS_UNIX_MAJOR_VERSION);
+	pSMB->ClientUnixMinor = cpu_to_le16(CIFS_UNIX_MINOR_VERSION);
+	pSMB->ClientUnixCap = cpu_to_le64(cap);
+
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cERROR(1, ("Send error in SETFSUnixInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+		if (rc)
+			rc = -EIO;	/* bad smb */
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto SETFSUnixRetry;
+
+	return rc;
+}
+
+
+
+int
+CIFSSMBQFSPosixInfo(const int xid, struct cifsTconInfo *tcon,
+		   struct kstatfs *FSData)
+{
+/* level 0x201  SMB_QUERY_CIFS_POSIX_INFO */
+	TRANSACTION2_QFSI_REQ *pSMB = NULL;
+	TRANSACTION2_QFSI_RSP *pSMBr = NULL;
+	FILE_SYSTEM_POSIX_INFO *response_data;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In QFSPosixInfo"));
+QFSPosixRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	params = 2;	/* level */
+	pSMB->TotalDataCount = 0;
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(100);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	byte_count = params + 1 /* pad */ ;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(struct
+			smb_com_transaction2_qfsi_req, InformationLevel) - 4);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_FS_INFORMATION);
+	pSMB->InformationLevel = cpu_to_le16(SMB_QUERY_POSIX_FS_INFO);
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QFSUnixInfo = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		if (rc || (pSMBr->ByteCount < 13)) {
+			rc = -EIO;	/* bad smb */
+		} else {
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			response_data =
+			    (FILE_SYSTEM_POSIX_INFO
+			     *) (((char *) &pSMBr->hdr.Protocol) +
+				 data_offset);
+			FSData->f_bsize =
+					le32_to_cpu(response_data->BlockSize);
+			FSData->f_blocks =
+					le64_to_cpu(response_data->TotalBlocks);
+			FSData->f_bfree =
+			    le64_to_cpu(response_data->BlocksAvail);
+			if (response_data->UserBlocksAvail == cpu_to_le64(-1)) {
+				FSData->f_bavail = FSData->f_bfree;
+			} else {
+				FSData->f_bavail =
+				    le64_to_cpu(response_data->UserBlocksAvail);
+			}
+			if (response_data->TotalFileNodes != cpu_to_le64(-1))
+				FSData->f_files =
+				     le64_to_cpu(response_data->TotalFileNodes);
+			if (response_data->FreeFileNodes != cpu_to_le64(-1))
+				FSData->f_ffree =
+				      le64_to_cpu(response_data->FreeFileNodes);
+		}
+	}
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto QFSPosixRetry;
+
+	return rc;
+}
+
+
+/* We can not use write of zero bytes trick to
+   set file size due to need for large file support.  Also note that
+   this SetPathInfo is preferred to SetFileInfo based method in next
+   routine which is only needed to work around a sharing violation bug
+   in Samba which this routine can run into */
+
+int
+CIFSSMBSetEOF(const int xid, struct cifsTconInfo *tcon, const char *fileName,
+	      __u64 size, bool SetAllocation,
+	      const struct nls_table *nls_codepage, int remap)
+{
+	struct smb_com_transaction2_spi_req *pSMB = NULL;
+	struct smb_com_transaction2_spi_rsp *pSMBr = NULL;
+	struct file_end_of_file_info *parm_data;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, byte_count, data_count, param_offset, offset;
+
+	cFYI(1, ("In SetEOF"));
+SetEOFRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+	params = 6 + name_len;
+	data_count = sizeof(struct file_end_of_file_info);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	pSMB->MaxDataCount = cpu_to_le16(4100);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	if (SetAllocation) {
+		if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+			pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_ALLOCATION_INFO2);
+		else
+			pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_ALLOCATION_INFO);
+	} else /* Set File Size */  {
+	    if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+		    pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_END_OF_FILE_INFO2);
+	    else
+		    pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_END_OF_FILE_INFO);
+	}
+
+	parm_data =
+	    (struct file_end_of_file_info *) (((char *) &pSMB->hdr.Protocol) +
+				       offset);
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + data_count;
+	pSMB->DataCount = cpu_to_le16(data_count);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	parm_data->FileSize = cpu_to_le64(size);
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("SetPathInfo (file size) returned %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto SetEOFRetry;
+
+	return rc;
+}
+
+int
+CIFSSMBSetFileSize(const int xid, struct cifsTconInfo *tcon, __u64 size,
+		   __u16 fid, __u32 pid_of_opener, bool SetAllocation)
+{
+	struct smb_com_transaction2_sfi_req *pSMB  = NULL;
+	char *data_offset;
+	struct file_end_of_file_info *parm_data;
+	int rc = 0;
+	__u16 params, param_offset, offset, byte_count, count;
+
+	cFYI(1, ("SetFileSize (via SetFileInfo) %lld",
+			(long long)size));
+	rc = small_smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB);
+
+	if (rc)
+		return rc;
+
+	pSMB->hdr.Pid = cpu_to_le16((__u16)pid_of_opener);
+	pSMB->hdr.PidHigh = cpu_to_le16((__u16)(pid_of_opener >> 16));
+
+	params = 6;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_sfi_req, Fid) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+
+	count = sizeof(struct file_end_of_file_info);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FILE_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	parm_data =
+		(struct file_end_of_file_info *) (((char *) &pSMB->hdr.Protocol)
+				+ offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	parm_data->FileSize = cpu_to_le64(size);
+	pSMB->Fid = fid;
+	if (SetAllocation) {
+		if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+			pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_ALLOCATION_INFO2);
+		else
+			pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_ALLOCATION_INFO);
+	} else /* Set File Size */  {
+	    if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+		    pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_END_OF_FILE_INFO2);
+	    else
+		    pSMB->InformationLevel =
+				cpu_to_le16(SMB_SET_FILE_END_OF_FILE_INFO);
+	}
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	if (rc) {
+		cFYI(1,
+		     ("Send error in SetFileInfo (SetFileSize) = %d",
+		      rc));
+	}
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+
+/* Some legacy servers such as NT4 require that the file times be set on
+   an open handle, rather than by pathname - this is awkward due to
+   potential access conflicts on the open, but it is unavoidable for these
+   old servers since the only other choice is to go from 100 nanosecond DCE
+   time and resort to the original setpathinfo level which takes the ancient
+   DOS time format with 2 second granularity */
+int
+CIFSSMBSetFileInfo(const int xid, struct cifsTconInfo *tcon,
+		    const FILE_BASIC_INFO *data, __u16 fid, __u32 pid_of_opener)
+{
+	struct smb_com_transaction2_sfi_req *pSMB  = NULL;
+	char *data_offset;
+	int rc = 0;
+	__u16 params, param_offset, offset, byte_count, count;
+
+	cFYI(1, ("Set Times (via SetFileInfo)"));
+	rc = small_smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB);
+
+	if (rc)
+		return rc;
+
+	pSMB->hdr.Pid = cpu_to_le16((__u16)pid_of_opener);
+	pSMB->hdr.PidHigh = cpu_to_le16((__u16)(pid_of_opener >> 16));
+
+	params = 6;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_sfi_req, Fid) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+
+	count = sizeof(FILE_BASIC_INFO);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB PDU from sess */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FILE_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->Fid = fid;
+	if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+		pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_BASIC_INFO2);
+	else
+		pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_BASIC_INFO);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	memcpy(data_offset, data, sizeof(FILE_BASIC_INFO));
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	if (rc)
+		cFYI(1, ("Send error in Set Time (SetFileInfo) = %d", rc));
+
+	/* Note: On -EAGAIN error only caller can retry on handle based calls
+		since file handle passed in no longer valid */
+
+	return rc;
+}
+
+int
+CIFSSMBSetFileDisposition(const int xid, struct cifsTconInfo *tcon,
+			  bool delete_file, __u16 fid, __u32 pid_of_opener)
+{
+	struct smb_com_transaction2_sfi_req *pSMB  = NULL;
+	char *data_offset;
+	int rc = 0;
+	__u16 params, param_offset, offset, byte_count, count;
+
+	cFYI(1, ("Set File Disposition (via SetFileInfo)"));
+	rc = small_smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB);
+
+	if (rc)
+		return rc;
+
+	pSMB->hdr.Pid = cpu_to_le16((__u16)pid_of_opener);
+	pSMB->hdr.PidHigh = cpu_to_le16((__u16)(pid_of_opener >> 16));
+
+	params = 6;
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_sfi_req, Fid) - 4;
+	offset = param_offset + params;
+
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+
+	count = 1;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB PDU from sess */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_FILE_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->Fid = fid;
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_DISPOSITION_INFO);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	*data_offset = delete_file ? 1 : 0;
+	rc = SendReceiveNoRsp(xid, tcon->ses, (struct smb_hdr *) pSMB, 0);
+	if (rc)
+		cFYI(1, ("Send error in SetFileDisposition = %d", rc));
+
+	return rc;
+}
+
+int
+CIFSSMBSetPathInfo(const int xid, struct cifsTconInfo *tcon,
+		   const char *fileName, const FILE_BASIC_INFO *data,
+		   const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	char *data_offset;
+	__u16 params, param_offset, offset, byte_count, count;
+
+	cFYI(1, ("In SetTimes"));
+
+SetTimesRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+
+	params = 6 + name_len;
+	count = sizeof(FILE_BASIC_INFO);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	data_offset = (char *) (&pSMB->hdr.Protocol) + offset;
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	if (tcon->ses->capabilities & CAP_INFOLEVEL_PASSTHRU)
+		pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_BASIC_INFO2);
+	else
+		pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_BASIC_INFO);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	memcpy(data_offset, data, sizeof(FILE_BASIC_INFO));
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("SetPathInfo (times) returned %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto SetTimesRetry;
+
+	return rc;
+}
+
+/* Can not be used to set time stamps yet (due to old DOS time format) */
+/* Can be used to set attributes */
+#if 0  /* Possibly not needed - since it turns out that strangely NT4 has a bug
+	  handling it anyway and NT4 was what we thought it would be needed for
+	  Do not delete it until we prove whether needed for Win9x though */
+int
+CIFSSMBSetAttrLegacy(int xid, struct cifsTconInfo *tcon, char *fileName,
+		__u16 dos_attrs, const struct nls_table *nls_codepage)
+{
+	SETATTR_REQ *pSMB = NULL;
+	SETATTR_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+
+	cFYI(1, ("In SetAttrLegacy"));
+
+SetAttrLgcyRetry:
+	rc = smb_init(SMB_COM_SETATTR, 8, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+			ConvertToUCS((__le16 *) pSMB->fileName, fileName,
+				PATH_MAX, nls_codepage);
+		name_len++;     /* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;     /* trailing null */
+		strncpy(pSMB->fileName, fileName, name_len);
+	}
+	pSMB->attr = cpu_to_le16(dos_attrs);
+	pSMB->BufferFormat = 0x04;
+	pSMB->hdr.smb_buf_length += name_len + 1;
+	pSMB->ByteCount = cpu_to_le16(name_len + 1);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("Error in LegacySetAttr = %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto SetAttrLgcyRetry;
+
+	return rc;
+}
+#endif /* temporarily unneeded SetAttr legacy function */
+
+int
+CIFSSMBUnixSetInfo(const int xid, struct cifsTconInfo *tcon, char *fileName,
+		   const struct cifs_unix_set_info_args *args,
+		   const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_SPI_REQ *pSMB = NULL;
+	TRANSACTION2_SPI_RSP *pSMBr = NULL;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	FILE_UNIX_BASIC_INFO *data_offset;
+	__u16 params, param_offset, offset, count, byte_count;
+	__u64 mode = args->mode;
+
+	cFYI(1, ("In SetUID/GID/Mode"));
+setPermsRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+
+	params = 6 + name_len;
+	count = sizeof(FILE_UNIX_BASIC_INFO);
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	data_offset =
+	    (FILE_UNIX_BASIC_INFO *) ((char *) &pSMB->hdr.Protocol +
+				      offset);
+	memset(data_offset, 0, count);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->DataCount = cpu_to_le16(count);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_SET_FILE_UNIX_BASIC);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	/* Samba server ignores set of file size to zero due to bugs in some
+	older clients, but we should be precise - we use SetFileSize to
+	set file size and do not want to truncate file size to zero
+	accidently as happened on one Samba server beta by putting
+	zero instead of -1 here */
+	data_offset->EndOfFile = cpu_to_le64(NO_CHANGE_64);
+	data_offset->NumOfBytes = cpu_to_le64(NO_CHANGE_64);
+	data_offset->LastStatusChange = cpu_to_le64(args->ctime);
+	data_offset->LastAccessTime = cpu_to_le64(args->atime);
+	data_offset->LastModificationTime = cpu_to_le64(args->mtime);
+	data_offset->Uid = cpu_to_le64(args->uid);
+	data_offset->Gid = cpu_to_le64(args->gid);
+	/* better to leave device as zero when it is  */
+	data_offset->DevMajor = cpu_to_le64(MAJOR(args->device));
+	data_offset->DevMinor = cpu_to_le64(MINOR(args->device));
+	data_offset->Permissions = cpu_to_le64(mode);
+
+	if (S_ISREG(mode))
+		data_offset->Type = cpu_to_le32(UNIX_FILE);
+	else if (S_ISDIR(mode))
+		data_offset->Type = cpu_to_le32(UNIX_DIR);
+	else if (S_ISLNK(mode))
+		data_offset->Type = cpu_to_le32(UNIX_SYMLINK);
+	else if (S_ISCHR(mode))
+		data_offset->Type = cpu_to_le32(UNIX_CHARDEV);
+	else if (S_ISBLK(mode))
+		data_offset->Type = cpu_to_le32(UNIX_BLOCKDEV);
+	else if (S_ISFIFO(mode))
+		data_offset->Type = cpu_to_le32(UNIX_FIFO);
+	else if (S_ISSOCK(mode))
+		data_offset->Type = cpu_to_le32(UNIX_SOCKET);
+
+
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("SetPathInfo (perms) returned %d", rc));
+
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto setPermsRetry;
+	return rc;
+}
+
+int CIFSSMBNotify(const int xid, struct cifsTconInfo *tcon,
+		  const int notify_subdirs, const __u16 netfid,
+		  __u32 filter, struct file *pfile, int multishot,
+		  const struct nls_table *nls_codepage)
+{
+	int rc = 0;
+	struct smb_com_transaction_change_notify_req *pSMB = NULL;
+	struct smb_com_ntransaction_change_notify_rsp *pSMBr = NULL;
+	struct dir_notify_req *dnotify_req;
+	int bytes_returned;
+
+	cFYI(1, ("In CIFSSMBNotify for file handle %d", (int)netfid));
+	rc = smb_init(SMB_COM_NT_TRANSACT, 23, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	pSMB->TotalParameterCount = 0 ;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le32(2);
+	/* BB find exact data count max from sess structure BB */
+	pSMB->MaxDataCount = 0; /* same in little endian or be */
+/* BB VERIFY verify which is correct for above BB */
+	pSMB->MaxDataCount = cpu_to_le32((tcon->ses->server->maxBuf -
+					     MAX_CIFS_HDR_SIZE) & 0xFFFFFF00);
+
+	pSMB->MaxSetupCount = 4;
+	pSMB->Reserved = 0;
+	pSMB->ParameterOffset = 0;
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 4; /* single byte does not need le conversion */
+	pSMB->SubCommand = cpu_to_le16(NT_TRANSACT_NOTIFY_CHANGE);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	if (notify_subdirs)
+		pSMB->WatchTree = 1; /* one byte - no le conversion needed */
+	pSMB->Reserved2 = 0;
+	pSMB->CompletionFilter = cpu_to_le32(filter);
+	pSMB->Fid = netfid; /* file handle always le */
+	pSMB->ByteCount = 0;
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *)pSMBr, &bytes_returned,
+			 CIFS_ASYNC_OP);
+	if (rc) {
+		cFYI(1, ("Error in Notify = %d", rc));
+	} else {
+		/* Add file to outstanding requests */
+		/* BB change to kmem cache alloc */
+		dnotify_req = kmalloc(
+						sizeof(struct dir_notify_req),
+						 GFP_KERNEL);
+		if (dnotify_req) {
+			dnotify_req->Pid = pSMB->hdr.Pid;
+			dnotify_req->PidHigh = pSMB->hdr.PidHigh;
+			dnotify_req->Mid = pSMB->hdr.Mid;
+			dnotify_req->Tid = pSMB->hdr.Tid;
+			dnotify_req->Uid = pSMB->hdr.Uid;
+			dnotify_req->netfid = netfid;
+			dnotify_req->pfile = pfile;
+			dnotify_req->filter = filter;
+			dnotify_req->multishot = multishot;
+			spin_lock(&GlobalMid_Lock);
+			list_add_tail(&dnotify_req->lhead,
+					&GlobalDnotifyReqList);
+			spin_unlock(&GlobalMid_Lock);
+		} else
+			rc = -ENOMEM;
+	}
+	cifs_buf_release(pSMB);
+	return rc;
+}
+#ifdef CONFIG_CIFS_XATTR
+ssize_t
+CIFSSMBQAllEAs(const int xid, struct cifsTconInfo *tcon,
+		 const unsigned char *searchName,
+		 char *EAData, size_t buf_size,
+		 const struct nls_table *nls_codepage, int remap)
+{
+		/* BB assumes one setup word */
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	struct fea *temp_fea;
+	char *temp_ptr;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In Query All EAs path %s", searchName));
+QAllEAsRetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */ + 4 /* reserved */ + name_len /* includes NUL */;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+	struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_INFO_QUERY_ALL_EAS);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in QueryAllEAs = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		/* BB also check enough total bytes returned */
+		/* BB we need to improve the validity checking
+		of these trans2 responses */
+		if (rc || (pSMBr->ByteCount < 4))
+			rc = -EIO;	/* bad smb */
+	   /* else if (pFindData){
+			memcpy((char *) pFindData,
+			       (char *) &pSMBr->hdr.Protocol +
+			       data_offset, kl);
+		}*/ else {
+			/* check that length of list is not more than bcc */
+			/* check that each entry does not go beyond length
+			   of list */
+			/* check that each element of each entry does not
+			   go beyond end of list */
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			struct fealist *ea_response_data;
+			rc = 0;
+			/* validate_trans2_offsets() */
+			/* BB check if start of smb + data_offset > &bcc+ bcc */
+			ea_response_data = (struct fealist *)
+				(((char *) &pSMBr->hdr.Protocol) +
+				data_offset);
+			name_len = le32_to_cpu(ea_response_data->list_len);
+			cFYI(1, ("ea length %d", name_len));
+			if (name_len <= 8) {
+			/* returned EA size zeroed at top of function */
+				cFYI(1, ("empty EA list returned from server"));
+			} else {
+				/* account for ea list len */
+				name_len -= 4;
+				temp_fea = ea_response_data->list;
+				temp_ptr = (char *)temp_fea;
+				while (name_len > 0) {
+					__u16 value_len;
+					name_len -= 4;
+					temp_ptr += 4;
+					rc += temp_fea->name_len;
+				/* account for prefix user. and trailing null */
+					rc = rc + 5 + 1;
+					if (rc < (int)buf_size) {
+						memcpy(EAData, "user.", 5);
+						EAData += 5;
+						memcpy(EAData, temp_ptr,
+						       temp_fea->name_len);
+						EAData += temp_fea->name_len;
+						/* null terminate name */
+						*EAData = 0;
+						EAData = EAData + 1;
+					} else if (buf_size == 0) {
+						/* skip copy - calc size only */
+					} else {
+						/* stop before overrun buffer */
+						rc = -ERANGE;
+						break;
+					}
+					name_len -= temp_fea->name_len;
+					temp_ptr += temp_fea->name_len;
+					/* account for trailing null */
+					name_len--;
+					temp_ptr++;
+					value_len =
+					      le16_to_cpu(temp_fea->value_len);
+					name_len -= value_len;
+					temp_ptr += value_len;
+					/* BB check that temp_ptr is still
+					      within the SMB BB*/
+
+					/* no trailing null to account for
+					   in value len */
+					/* go on to next EA */
+					temp_fea = (struct fea *)temp_ptr;
+				}
+			}
+		}
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto QAllEAsRetry;
+
+	return (ssize_t)rc;
+}
+
+ssize_t CIFSSMBQueryEA(const int xid, struct cifsTconInfo *tcon,
+		const unsigned char *searchName, const unsigned char *ea_name,
+		unsigned char *ea_value, size_t buf_size,
+		const struct nls_table *nls_codepage, int remap)
+{
+	TRANSACTION2_QPI_REQ *pSMB = NULL;
+	TRANSACTION2_QPI_RSP *pSMBr = NULL;
+	int rc = 0;
+	int bytes_returned;
+	int name_len;
+	struct fea *temp_fea;
+	char *temp_ptr;
+	__u16 params, byte_count;
+
+	cFYI(1, ("In Query EA path %s", searchName));
+QEARetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, searchName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(searchName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, searchName, name_len);
+	}
+
+	params = 2 /* level */ + 4 /* reserved */ + name_len /* includes NUL */;
+	pSMB->TotalDataCount = 0;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find exact max SMB PDU from sess structure BB */
+	pSMB->MaxDataCount = cpu_to_le16(4000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	pSMB->ParameterOffset = cpu_to_le16(offsetof(
+		struct smb_com_transaction2_qpi_req, InformationLevel) - 4);
+	pSMB->DataCount = 0;
+	pSMB->DataOffset = 0;
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_QUERY_PATH_INFORMATION);
+	byte_count = params + 1 /* pad */ ;
+	pSMB->TotalParameterCount = cpu_to_le16(params);
+	pSMB->ParameterCount = pSMB->TotalParameterCount;
+	pSMB->InformationLevel = cpu_to_le16(SMB_INFO_QUERY_ALL_EAS);
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc) {
+		cFYI(1, ("Send error in Query EA = %d", rc));
+	} else {		/* decode response */
+		rc = validate_t2((struct smb_t2_rsp *)pSMBr);
+
+		/* BB also check enough total bytes returned */
+		/* BB we need to improve the validity checking
+		of these trans2 responses */
+		if (rc || (pSMBr->ByteCount < 4))
+			rc = -EIO;	/* bad smb */
+	   /* else if (pFindData){
+			memcpy((char *) pFindData,
+			       (char *) &pSMBr->hdr.Protocol +
+			       data_offset, kl);
+		}*/ else {
+			/* check that length of list is not more than bcc */
+			/* check that each entry does not go beyond length
+			   of list */
+			/* check that each element of each entry does not
+			   go beyond end of list */
+			__u16 data_offset = le16_to_cpu(pSMBr->t2.DataOffset);
+			struct fealist *ea_response_data;
+			rc = -ENODATA;
+			/* validate_trans2_offsets() */
+			/* BB check if start of smb + data_offset > &bcc+ bcc*/
+			ea_response_data = (struct fealist *)
+				(((char *) &pSMBr->hdr.Protocol) +
+				data_offset);
+			name_len = le32_to_cpu(ea_response_data->list_len);
+			cFYI(1, ("ea length %d", name_len));
+			if (name_len <= 8) {
+			/* returned EA size zeroed at top of function */
+				cFYI(1, ("empty EA list returned from server"));
+			} else {
+				/* account for ea list len */
+				name_len -= 4;
+				temp_fea = ea_response_data->list;
+				temp_ptr = (char *)temp_fea;
+				/* loop through checking if we have a matching
+				name and then return the associated value */
+				while (name_len > 0) {
+					__u16 value_len;
+					name_len -= 4;
+					temp_ptr += 4;
+					value_len =
+					      le16_to_cpu(temp_fea->value_len);
+				/* BB validate that value_len falls within SMB,
+				even though maximum for name_len is 255 */
+					if (memcmp(temp_fea->name, ea_name,
+						  temp_fea->name_len) == 0) {
+						/* found a match */
+						rc = value_len;
+				/* account for prefix user. and trailing null */
+						if (rc <= (int)buf_size) {
+							memcpy(ea_value,
+								temp_fea->name+temp_fea->name_len+1,
+								rc);
+							/* ea values, unlike ea
+							   names, are not null
+							   terminated */
+						} else if (buf_size == 0) {
+						/* skip copy - calc size only */
+						} else {
+						/* stop before overrun buffer */
+							rc = -ERANGE;
+						}
+						break;
+					}
+					name_len -= temp_fea->name_len;
+					temp_ptr += temp_fea->name_len;
+					/* account for trailing null */
+					name_len--;
+					temp_ptr++;
+					name_len -= value_len;
+					temp_ptr += value_len;
+					/* No trailing null to account for in
+					   value_len.  Go on to next EA */
+					temp_fea = (struct fea *)temp_ptr;
+				}
+			}
+		}
+	}
+	cifs_buf_release(pSMB);
+	if (rc == -EAGAIN)
+		goto QEARetry;
+
+	return (ssize_t)rc;
+}
+
+int
+CIFSSMBSetEA(const int xid, struct cifsTconInfo *tcon, const char *fileName,
+	     const char *ea_name, const void *ea_value,
+	     const __u16 ea_value_len, const struct nls_table *nls_codepage,
+	     int remap)
+{
+	struct smb_com_transaction2_spi_req *pSMB = NULL;
+	struct smb_com_transaction2_spi_rsp *pSMBr = NULL;
+	struct fealist *parm_data;
+	int name_len;
+	int rc = 0;
+	int bytes_returned = 0;
+	__u16 params, param_offset, byte_count, offset, count;
+
+	cFYI(1, ("In SetEA"));
+SetEARetry:
+	rc = smb_init(SMB_COM_TRANSACTION2, 15, tcon, (void **) &pSMB,
+		      (void **) &pSMBr);
+	if (rc)
+		return rc;
+
+	if (pSMB->hdr.Flags2 & SMBFLG2_UNICODE) {
+		name_len =
+		    cifsConvertToUCS((__le16 *) pSMB->FileName, fileName,
+				     PATH_MAX, nls_codepage, remap);
+		name_len++;	/* trailing null */
+		name_len *= 2;
+	} else {	/* BB improve the check for buffer overruns BB */
+		name_len = strnlen(fileName, PATH_MAX);
+		name_len++;	/* trailing null */
+		strncpy(pSMB->FileName, fileName, name_len);
+	}
+
+	params = 6 + name_len;
+
+	/* done calculating parms using name_len of file name,
+	now use name_len to calculate length of ea name
+	we are going to create in the inode xattrs */
+	if (ea_name == NULL)
+		name_len = 0;
+	else
+		name_len = strnlen(ea_name, 255);
+
+	count = sizeof(*parm_data) + ea_value_len + name_len;
+	pSMB->MaxParameterCount = cpu_to_le16(2);
+	/* BB find max SMB PDU from sess */
+	pSMB->MaxDataCount = cpu_to_le16(1000);
+	pSMB->MaxSetupCount = 0;
+	pSMB->Reserved = 0;
+	pSMB->Flags = 0;
+	pSMB->Timeout = 0;
+	pSMB->Reserved2 = 0;
+	param_offset = offsetof(struct smb_com_transaction2_spi_req,
+				InformationLevel) - 4;
+	offset = param_offset + params;
+	pSMB->InformationLevel =
+		cpu_to_le16(SMB_SET_FILE_EA);
+
+	parm_data =
+		(struct fealist *) (((char *) &pSMB->hdr.Protocol) +
+				       offset);
+	pSMB->ParameterOffset = cpu_to_le16(param_offset);
+	pSMB->DataOffset = cpu_to_le16(offset);
+	pSMB->SetupCount = 1;
+	pSMB->Reserved3 = 0;
+	pSMB->SubCommand = cpu_to_le16(TRANS2_SET_PATH_INFORMATION);
+	byte_count = 3 /* pad */  + params + count;
+	pSMB->DataCount = cpu_to_le16(count);
+	parm_data->list_len = cpu_to_le32(count);
+	parm_data->list[0].EA_flags = 0;
+	/* we checked above that name len is less than 255 */
+	parm_data->list[0].name_len = (__u8)name_len;
+	/* EA names are always ASCII */
+	if (ea_name)
+		strncpy(parm_data->list[0].name, ea_name, name_len);
+	parm_data->list[0].name[name_len] = 0;
+	parm_data->list[0].value_len = cpu_to_le16(ea_value_len);
+	/* caller ensures that ea_value_len is less than 64K but
+	we need to ensure that it fits within the smb */
+
+	/*BB add length check to see if it would fit in
+	     negotiated SMB buffer size BB */
+	/* if (ea_value_len > buffer_size - 512 (enough for header)) */
+	if (ea_value_len)
+		memcpy(parm_data->list[0].name+name_len+1,
+		       ea_value, ea_value_len);
+
+	pSMB->TotalDataCount = pSMB->DataCount;
+	pSMB->ParameterCount = cpu_to_le16(params);
+	pSMB->TotalParameterCount = pSMB->ParameterCount;
+	pSMB->Reserved4 = 0;
+	pSMB->hdr.smb_buf_length += byte_count;
+	pSMB->ByteCount = cpu_to_le16(byte_count);
+	rc = SendReceive(xid, tcon->ses, (struct smb_hdr *) pSMB,
+			 (struct smb_hdr *) pSMBr, &bytes_returned, 0);
+	if (rc)
+		cFYI(1, ("SetPathInfo (EA) returned %d", rc));
+
+	cifs_buf_release(pSMB);
+
+	if (rc == -EAGAIN)
+		goto SetEARetry;
+
+	return rc;
+}
+
+#endif
diff -Naur linux-2.6.30-ori/fs/cifs/connect.c linux-2.6.30-test/fs/cifs/connect.c
--- linux-2.6.30-ori/fs/cifs/connect.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/connect.c	2009-06-12 18:32:43.000000000 -0400
@@ -2472,9 +2472,9 @@
 	}
 	if (pSesInfo) {
 		if (pSesInfo->capabilities & CAP_LARGE_FILES) {
-			sb->s_maxbytes = (u64) 1 << 63;
+			sb->s_maxbytes = ((u64) (1ULL << 63)-1);
 		} else
-			sb->s_maxbytes = (u64) 1 << 31;	/* 2 GB */
+			sb->s_maxbytes = ((u64) 1 << 31ULL);
 	}
 
 	/* BB FIXME fix time_gran to be larger for LANMAN sessions */
diff -Naur linux-2.6.30-ori/fs/cifs/connect.c.orig linux-2.6.30-test/fs/cifs/connect.c.orig
--- linux-2.6.30-ori/fs/cifs/connect.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/connect.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,2841 @@
+/*
+ *   fs/cifs/connect.c
+ *
+ *   Copyright (C) International Business Machines  Corp., 2002,2009
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+#include <linux/fs.h>
+#include <linux/net.h>
+#include <linux/string.h>
+#include <linux/list.h>
+#include <linux/wait.h>
+#include <linux/pagemap.h>
+#include <linux/ctype.h>
+#include <linux/utsname.h>
+#include <linux/mempool.h>
+#include <linux/delay.h>
+#include <linux/completion.h>
+#include <linux/kthread.h>
+#include <linux/pagevec.h>
+#include <linux/freezer.h>
+#include <linux/namei.h>
+#include <asm/uaccess.h>
+#include <asm/processor.h>
+#include <net/ipv6.h>
+#include "cifspdu.h"
+#include "cifsglob.h"
+#include "cifsproto.h"
+#include "cifs_unicode.h"
+#include "cifs_debug.h"
+#include "cifs_fs_sb.h"
+#include "ntlmssp.h"
+#include "nterr.h"
+#include "rfc1002pdu.h"
+#include "cn_cifs.h"
+
+#define CIFS_PORT 445
+#define RFC1001_PORT 139
+
+extern void SMBNTencrypt(unsigned char *passwd, unsigned char *c8,
+			 unsigned char *p24);
+
+extern mempool_t *cifs_req_poolp;
+
+struct smb_vol {
+	char *username;
+	char *password;
+	char *domainname;
+	char *UNC;
+	char *UNCip;
+	char *in6_addr;   /* ipv6 address as human readable form of in6_addr */
+	char *iocharset;  /* local code page for mapping to and from Unicode */
+	char source_rfc1001_name[16]; /* netbios name of client */
+	char target_rfc1001_name[16]; /* netbios name of server for Win9x/ME */
+	uid_t linux_uid;
+	gid_t linux_gid;
+	mode_t file_mode;
+	mode_t dir_mode;
+	unsigned secFlg;
+	bool rw:1;
+	bool retry:1;
+	bool intr:1;
+	bool setuids:1;
+	bool override_uid:1;
+	bool override_gid:1;
+	bool dynperm:1;
+	bool noperm:1;
+	bool no_psx_acl:1; /* set if posix acl support should be disabled */
+	bool cifs_acl:1;
+	bool no_xattr:1;   /* set if xattr (EA) support should be disabled*/
+	bool server_ino:1; /* use inode numbers from server ie UniqueId */
+	bool direct_io:1;
+	bool remap:1;      /* set to remap seven reserved chars in filenames */
+	bool posix_paths:1; /* unset to not ask for posix pathnames. */
+	bool no_linux_ext:1;
+	bool sfu_emul:1;
+	bool nullauth:1;   /* attempt to authenticate with null user */
+	bool nocase:1;     /* request case insensitive filenames */
+	bool nobrl:1;      /* disable sending byte range locks to srv */
+	bool mand_lock:1;  /* send mandatory not posix byte range lock reqs */
+	bool seal:1;       /* request transport encryption on share */
+	bool nodfs:1;      /* Do not request DFS, even if available */
+	bool local_lease:1; /* check leases only on local system, not remote */
+	bool noblocksnd:1;
+	bool noautotune:1;
+	bool nostrictsync:1; /* do not force expensive SMBflush on every sync */
+	unsigned int rsize;
+	unsigned int wsize;
+	unsigned int sockopt;
+	unsigned short int port;
+	char *prepath;
+};
+
+static int ipv4_connect(struct TCP_Server_Info *server);
+static int ipv6_connect(struct TCP_Server_Info *server);
+
+/*
+ * cifs tcp session reconnection
+ *
+ * mark tcp session as reconnecting so temporarily locked
+ * mark all smb sessions as reconnecting for tcp session
+ * reconnect tcp session
+ * wake up waiters on reconnection? - (not needed currently)
+ */
+static int
+cifs_reconnect(struct TCP_Server_Info *server)
+{
+	int rc = 0;
+	struct list_head *tmp, *tmp2;
+	struct cifsSesInfo *ses;
+	struct cifsTconInfo *tcon;
+	struct mid_q_entry *mid_entry;
+
+	spin_lock(&GlobalMid_Lock);
+	if (server->tcpStatus == CifsExiting) {
+		/* the demux thread will exit normally
+		next time through the loop */
+		spin_unlock(&GlobalMid_Lock);
+		return rc;
+	} else
+		server->tcpStatus = CifsNeedReconnect;
+	spin_unlock(&GlobalMid_Lock);
+	server->maxBuf = 0;
+
+	cFYI(1, ("Reconnecting tcp session"));
+
+	/* before reconnecting the tcp session, mark the smb session (uid)
+		and the tid bad so they are not used until reconnected */
+	read_lock(&cifs_tcp_ses_lock);
+	list_for_each(tmp, &server->smb_ses_list) {
+		ses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);
+		ses->need_reconnect = true;
+		ses->ipc_tid = 0;
+		list_for_each(tmp2, &ses->tcon_list) {
+			tcon = list_entry(tmp2, struct cifsTconInfo, tcon_list);
+			tcon->need_reconnect = true;
+		}
+	}
+	read_unlock(&cifs_tcp_ses_lock);
+	/* do not want to be sending data on a socket we are freeing */
+	mutex_lock(&server->srv_mutex);
+	if (server->ssocket) {
+		cFYI(1, ("State: 0x%x Flags: 0x%lx", server->ssocket->state,
+			server->ssocket->flags));
+		kernel_sock_shutdown(server->ssocket, SHUT_WR);
+		cFYI(1, ("Post shutdown state: 0x%x Flags: 0x%lx",
+			server->ssocket->state,
+			server->ssocket->flags));
+		sock_release(server->ssocket);
+		server->ssocket = NULL;
+	}
+
+	spin_lock(&GlobalMid_Lock);
+	list_for_each(tmp, &server->pending_mid_q) {
+		mid_entry = list_entry(tmp, struct
+					mid_q_entry,
+					qhead);
+		if (mid_entry->midState == MID_REQUEST_SUBMITTED) {
+				/* Mark other intransit requests as needing
+				   retry so we do not immediately mark the
+				   session bad again (ie after we reconnect
+				   below) as they timeout too */
+			mid_entry->midState = MID_RETRY_NEEDED;
+		}
+	}
+	spin_unlock(&GlobalMid_Lock);
+	mutex_unlock(&server->srv_mutex);
+
+	while ((server->tcpStatus != CifsExiting) &&
+	       (server->tcpStatus != CifsGood)) {
+		try_to_freeze();
+		if (server->addr.sockAddr6.sin6_family == AF_INET6)
+			rc = ipv6_connect(server);
+		else
+			rc = ipv4_connect(server);
+		if (rc) {
+			cFYI(1, ("reconnect error %d", rc));
+			msleep(3000);
+		} else {
+			atomic_inc(&tcpSesReconnectCount);
+			spin_lock(&GlobalMid_Lock);
+			if (server->tcpStatus != CifsExiting)
+				server->tcpStatus = CifsGood;
+			server->sequence_number = 0;
+			spin_unlock(&GlobalMid_Lock);
+	/*		atomic_set(&server->inFlight,0);*/
+			wake_up(&server->response_q);
+		}
+	}
+	return rc;
+}
+
+/*
+	return codes:
+		0 	not a transact2, or all data present
+		>0 	transact2 with that much data missing
+		-EINVAL = invalid transact2
+
+ */
+static int check2ndT2(struct smb_hdr *pSMB, unsigned int maxBufSize)
+{
+	struct smb_t2_rsp *pSMBt;
+	int total_data_size;
+	int data_in_this_rsp;
+	int remaining;
+
+	if (pSMB->Command != SMB_COM_TRANSACTION2)
+		return 0;
+
+	/* check for plausible wct, bcc and t2 data and parm sizes */
+	/* check for parm and data offset going beyond end of smb */
+	if (pSMB->WordCount != 10) { /* coalesce_t2 depends on this */
+		cFYI(1, ("invalid transact2 word count"));
+		return -EINVAL;
+	}
+
+	pSMBt = (struct smb_t2_rsp *)pSMB;
+
+	total_data_size = le16_to_cpu(pSMBt->t2_rsp.TotalDataCount);
+	data_in_this_rsp = le16_to_cpu(pSMBt->t2_rsp.DataCount);
+
+	remaining = total_data_size - data_in_this_rsp;
+
+	if (remaining == 0)
+		return 0;
+	else if (remaining < 0) {
+		cFYI(1, ("total data %d smaller than data in frame %d",
+			total_data_size, data_in_this_rsp));
+		return -EINVAL;
+	} else {
+		cFYI(1, ("missing %d bytes from transact2, check next response",
+			remaining));
+		if (total_data_size > maxBufSize) {
+			cERROR(1, ("TotalDataSize %d is over maximum buffer %d",
+				total_data_size, maxBufSize));
+			return -EINVAL;
+		}
+		return remaining;
+	}
+}
+
+static int coalesce_t2(struct smb_hdr *psecond, struct smb_hdr *pTargetSMB)
+{
+	struct smb_t2_rsp *pSMB2 = (struct smb_t2_rsp *)psecond;
+	struct smb_t2_rsp *pSMBt  = (struct smb_t2_rsp *)pTargetSMB;
+	int total_data_size;
+	int total_in_buf;
+	int remaining;
+	int total_in_buf2;
+	char *data_area_of_target;
+	char *data_area_of_buf2;
+	__u16 byte_count;
+
+	total_data_size = le16_to_cpu(pSMBt->t2_rsp.TotalDataCount);
+
+	if (total_data_size != le16_to_cpu(pSMB2->t2_rsp.TotalDataCount)) {
+		cFYI(1, ("total data size of primary and secondary t2 differ"));
+	}
+
+	total_in_buf = le16_to_cpu(pSMBt->t2_rsp.DataCount);
+
+	remaining = total_data_size - total_in_buf;
+
+	if (remaining < 0)
+		return -EINVAL;
+
+	if (remaining == 0) /* nothing to do, ignore */
+		return 0;
+
+	total_in_buf2 = le16_to_cpu(pSMB2->t2_rsp.DataCount);
+	if (remaining < total_in_buf2) {
+		cFYI(1, ("transact2 2nd response contains too much data"));
+	}
+
+	/* find end of first SMB data area */
+	data_area_of_target = (char *)&pSMBt->hdr.Protocol +
+				le16_to_cpu(pSMBt->t2_rsp.DataOffset);
+	/* validate target area */
+
+	data_area_of_buf2 = (char *) &pSMB2->hdr.Protocol +
+					le16_to_cpu(pSMB2->t2_rsp.DataOffset);
+
+	data_area_of_target += total_in_buf;
+
+	/* copy second buffer into end of first buffer */
+	memcpy(data_area_of_target, data_area_of_buf2, total_in_buf2);
+	total_in_buf += total_in_buf2;
+	pSMBt->t2_rsp.DataCount = cpu_to_le16(total_in_buf);
+	byte_count = le16_to_cpu(BCC_LE(pTargetSMB));
+	byte_count += total_in_buf2;
+	BCC_LE(pTargetSMB) = cpu_to_le16(byte_count);
+
+	byte_count = pTargetSMB->smb_buf_length;
+	byte_count += total_in_buf2;
+
+	/* BB also add check that we are not beyond maximum buffer size */
+
+	pTargetSMB->smb_buf_length = byte_count;
+
+	if (remaining == total_in_buf2) {
+		cFYI(1, ("found the last secondary response"));
+		return 0; /* we are done */
+	} else /* more responses to go */
+		return 1;
+
+}
+
+static int
+cifs_demultiplex_thread(struct TCP_Server_Info *server)
+{
+	int length;
+	unsigned int pdu_length, total_read;
+	struct smb_hdr *smb_buffer = NULL;
+	struct smb_hdr *bigbuf = NULL;
+	struct smb_hdr *smallbuf = NULL;
+	struct msghdr smb_msg;
+	struct kvec iov;
+	struct socket *csocket = server->ssocket;
+	struct list_head *tmp;
+	struct cifsSesInfo *ses;
+	struct task_struct *task_to_wake = NULL;
+	struct mid_q_entry *mid_entry;
+	char temp;
+	bool isLargeBuf = false;
+	bool isMultiRsp;
+	int reconnect;
+
+	current->flags |= PF_MEMALLOC;
+	cFYI(1, ("Demultiplex PID: %d", task_pid_nr(current)));
+
+	length = atomic_inc_return(&tcpSesAllocCount);
+	if (length > 1)
+		mempool_resize(cifs_req_poolp, length + cifs_min_rcv,
+				GFP_KERNEL);
+
+	set_freezable();
+	while (server->tcpStatus != CifsExiting) {
+		if (try_to_freeze())
+			continue;
+		if (bigbuf == NULL) {
+			bigbuf = cifs_buf_get();
+			if (!bigbuf) {
+				cERROR(1, ("No memory for large SMB response"));
+				msleep(3000);
+				/* retry will check if exiting */
+				continue;
+			}
+		} else if (isLargeBuf) {
+			/* we are reusing a dirty large buf, clear its start */
+			memset(bigbuf, 0, sizeof(struct smb_hdr));
+		}
+
+		if (smallbuf == NULL) {
+			smallbuf = cifs_small_buf_get();
+			if (!smallbuf) {
+				cERROR(1, ("No memory for SMB response"));
+				msleep(1000);
+				/* retry will check if exiting */
+				continue;
+			}
+			/* beginning of smb buffer is cleared in our buf_get */
+		} else /* if existing small buf clear beginning */
+			memset(smallbuf, 0, sizeof(struct smb_hdr));
+
+		isLargeBuf = false;
+		isMultiRsp = false;
+		smb_buffer = smallbuf;
+		iov.iov_base = smb_buffer;
+		iov.iov_len = 4;
+		smb_msg.msg_control = NULL;
+		smb_msg.msg_controllen = 0;
+		pdu_length = 4; /* enough to get RFC1001 header */
+incomplete_rcv:
+		length =
+		    kernel_recvmsg(csocket, &smb_msg,
+				&iov, 1, pdu_length, 0 /* BB other flags? */);
+
+		if (server->tcpStatus == CifsExiting) {
+			break;
+		} else if (server->tcpStatus == CifsNeedReconnect) {
+			cFYI(1, ("Reconnect after server stopped responding"));
+			cifs_reconnect(server);
+			cFYI(1, ("call to reconnect done"));
+			csocket = server->ssocket;
+			continue;
+		} else if ((length == -ERESTARTSYS) || (length == -EAGAIN)) {
+			msleep(1); /* minimum sleep to prevent looping
+				allowing socket to clear and app threads to set
+				tcpStatus CifsNeedReconnect if server hung */
+			if (pdu_length < 4) {
+				iov.iov_base = (4 - pdu_length) +
+							(char *)smb_buffer;
+				iov.iov_len = pdu_length;
+				smb_msg.msg_control = NULL;
+				smb_msg.msg_controllen = 0;
+				goto incomplete_rcv;
+			} else
+				continue;
+		} else if (length <= 0) {
+			if (server->tcpStatus == CifsNew) {
+				cFYI(1, ("tcp session abend after SMBnegprot"));
+				/* some servers kill the TCP session rather than
+				   returning an SMB negprot error, in which
+				   case reconnecting here is not going to help,
+				   and so simply return error to mount */
+				break;
+			}
+			if (!try_to_freeze() && (length == -EINTR)) {
+				cFYI(1, ("cifsd thread killed"));
+				break;
+			}
+			cFYI(1, ("Reconnect after unexpected peek error %d",
+				length));
+			cifs_reconnect(server);
+			csocket = server->ssocket;
+			wake_up(&server->response_q);
+			continue;
+		} else if (length < pdu_length) {
+			cFYI(1, ("requested %d bytes but only got %d bytes",
+				  pdu_length, length));
+			pdu_length -= length;
+			msleep(1);
+			goto incomplete_rcv;
+		}
+
+		/* The right amount was read from socket - 4 bytes */
+		/* so we can now interpret the length field */
+
+		/* the first byte big endian of the length field,
+		is actually not part of the length but the type
+		with the most common, zero, as regular data */
+		temp = *((char *) smb_buffer);
+
+		/* Note that FC 1001 length is big endian on the wire,
+		but we convert it here so it is always manipulated
+		as host byte order */
+		pdu_length = be32_to_cpu((__force __be32)smb_buffer->smb_buf_length);
+		smb_buffer->smb_buf_length = pdu_length;
+
+		cFYI(1, ("rfc1002 length 0x%x", pdu_length+4));
+
+		if (temp == (char) RFC1002_SESSION_KEEP_ALIVE) {
+			continue;
+		} else if (temp == (char)RFC1002_POSITIVE_SESSION_RESPONSE) {
+			cFYI(1, ("Good RFC 1002 session rsp"));
+			continue;
+		} else if (temp == (char)RFC1002_NEGATIVE_SESSION_RESPONSE) {
+			/* we get this from Windows 98 instead of
+			   an error on SMB negprot response */
+			cFYI(1, ("Negative RFC1002 Session Response Error 0x%x)",
+				pdu_length));
+			if (server->tcpStatus == CifsNew) {
+				/* if nack on negprot (rather than
+				ret of smb negprot error) reconnecting
+				not going to help, ret error to mount */
+				break;
+			} else {
+				/* give server a second to
+				clean up before reconnect attempt */
+				msleep(1000);
+				/* always try 445 first on reconnect
+				since we get NACK on some if we ever
+				connected to port 139 (the NACK is
+				since we do not begin with RFC1001
+				session initialize frame) */
+				server->addr.sockAddr.sin_port =
+					htons(CIFS_PORT);
+				cifs_reconnect(server);
+				csocket = server->ssocket;
+				wake_up(&server->response_q);
+				continue;
+			}
+		} else if (temp != (char) 0) {
+			cERROR(1, ("Unknown RFC 1002 frame"));
+			cifs_dump_mem(" Received Data: ", (char *)smb_buffer,
+				      length);
+			cifs_reconnect(server);
+			csocket = server->ssocket;
+			continue;
+		}
+
+		/* else we have an SMB response */
+		if ((pdu_length > CIFSMaxBufSize + MAX_CIFS_HDR_SIZE - 4) ||
+			    (pdu_length < sizeof(struct smb_hdr) - 1 - 4)) {
+			cERROR(1, ("Invalid size SMB length %d pdu_length %d",
+					length, pdu_length+4));
+			cifs_reconnect(server);
+			csocket = server->ssocket;
+			wake_up(&server->response_q);
+			continue;
+		}
+
+		/* else length ok */
+		reconnect = 0;
+
+		if (pdu_length > MAX_CIFS_SMALL_BUFFER_SIZE - 4) {
+			isLargeBuf = true;
+			memcpy(bigbuf, smallbuf, 4);
+			smb_buffer = bigbuf;
+		}
+		length = 0;
+		iov.iov_base = 4 + (char *)smb_buffer;
+		iov.iov_len = pdu_length;
+		for (total_read = 0; total_read < pdu_length;
+		     total_read += length) {
+			length = kernel_recvmsg(csocket, &smb_msg, &iov, 1,
+						pdu_length - total_read, 0);
+			if ((server->tcpStatus == CifsExiting) ||
+			    (length == -EINTR)) {
+				/* then will exit */
+				reconnect = 2;
+				break;
+			} else if (server->tcpStatus == CifsNeedReconnect) {
+				cifs_reconnect(server);
+				csocket = server->ssocket;
+				/* Reconnect wakes up rspns q */
+				/* Now we will reread sock */
+				reconnect = 1;
+				break;
+			} else if ((length == -ERESTARTSYS) ||
+				   (length == -EAGAIN)) {
+				msleep(1); /* minimum sleep to prevent looping,
+					      allowing socket to clear and app
+					      threads to set tcpStatus
+					      CifsNeedReconnect if server hung*/
+				length = 0;
+				continue;
+			} else if (length <= 0) {
+				cERROR(1, ("Received no data, expecting %d",
+					      pdu_length - total_read));
+				cifs_reconnect(server);
+				csocket = server->ssocket;
+				reconnect = 1;
+				break;
+			}
+		}
+		if (reconnect == 2)
+			break;
+		else if (reconnect == 1)
+			continue;
+
+		length += 4; /* account for rfc1002 hdr */
+
+
+		dump_smb(smb_buffer, length);
+		if (checkSMB(smb_buffer, smb_buffer->Mid, total_read+4)) {
+			cifs_dump_mem("Bad SMB: ", smb_buffer, 48);
+			continue;
+		}
+
+
+		task_to_wake = NULL;
+		spin_lock(&GlobalMid_Lock);
+		list_for_each(tmp, &server->pending_mid_q) {
+			mid_entry = list_entry(tmp, struct mid_q_entry, qhead);
+
+			if ((mid_entry->mid == smb_buffer->Mid) &&
+			    (mid_entry->midState == MID_REQUEST_SUBMITTED) &&
+			    (mid_entry->command == smb_buffer->Command)) {
+				if (check2ndT2(smb_buffer,server->maxBuf) > 0) {
+					/* We have a multipart transact2 resp */
+					isMultiRsp = true;
+					if (mid_entry->resp_buf) {
+						/* merge response - fix up 1st*/
+						if (coalesce_t2(smb_buffer,
+							mid_entry->resp_buf)) {
+							mid_entry->multiRsp =
+								 true;
+							break;
+						} else {
+							/* all parts received */
+							mid_entry->multiEnd =
+								 true;
+							goto multi_t2_fnd;
+						}
+					} else {
+						if (!isLargeBuf) {
+							cERROR(1,("1st trans2 resp needs bigbuf"));
+					/* BB maybe we can fix this up,  switch
+					   to already allocated large buffer? */
+						} else {
+							/* Have first buffer */
+							mid_entry->resp_buf =
+								 smb_buffer;
+							mid_entry->largeBuf =
+								 true;
+							bigbuf = NULL;
+						}
+					}
+					break;
+				}
+				mid_entry->resp_buf = smb_buffer;
+				mid_entry->largeBuf = isLargeBuf;
+multi_t2_fnd:
+				task_to_wake = mid_entry->tsk;
+				mid_entry->midState = MID_RESPONSE_RECEIVED;
+#ifdef CONFIG_CIFS_STATS2
+				mid_entry->when_received = jiffies;
+#endif
+				/* so we do not time out requests to  server
+				which is still responding (since server could
+				be busy but not dead) */
+				server->lstrp = jiffies;
+				break;
+			}
+		}
+		spin_unlock(&GlobalMid_Lock);
+		if (task_to_wake) {
+			/* Was previous buf put in mpx struct for multi-rsp? */
+			if (!isMultiRsp) {
+				/* smb buffer will be freed by user thread */
+				if (isLargeBuf)
+					bigbuf = NULL;
+				else
+					smallbuf = NULL;
+			}
+			wake_up_process(task_to_wake);
+		} else if (!is_valid_oplock_break(smb_buffer, server) &&
+			   !isMultiRsp) {
+			cERROR(1, ("No task to wake, unknown frame received! "
+				   "NumMids %d", midCount.counter));
+			cifs_dump_mem("Received Data is: ", (char *)smb_buffer,
+				      sizeof(struct smb_hdr));
+#ifdef CONFIG_CIFS_DEBUG2
+			cifs_dump_detail(smb_buffer);
+			cifs_dump_mids(server);
+#endif /* CIFS_DEBUG2 */
+
+		}
+	} /* end while !EXITING */
+
+	/* take it off the list, if it's not already */
+	write_lock(&cifs_tcp_ses_lock);
+	list_del_init(&server->tcp_ses_list);
+	write_unlock(&cifs_tcp_ses_lock);
+
+	spin_lock(&GlobalMid_Lock);
+	server->tcpStatus = CifsExiting;
+	spin_unlock(&GlobalMid_Lock);
+	wake_up_all(&server->response_q);
+
+	/* check if we have blocked requests that need to free */
+	/* Note that cifs_max_pending is normally 50, but
+	can be set at module install time to as little as two */
+	spin_lock(&GlobalMid_Lock);
+	if (atomic_read(&server->inFlight) >= cifs_max_pending)
+		atomic_set(&server->inFlight, cifs_max_pending - 1);
+	/* We do not want to set the max_pending too low or we
+	could end up with the counter going negative */
+	spin_unlock(&GlobalMid_Lock);
+	/* Although there should not be any requests blocked on
+	this queue it can not hurt to be paranoid and try to wake up requests
+	that may haven been blocked when more than 50 at time were on the wire
+	to the same server - they now will see the session is in exit state
+	and get out of SendReceive.  */
+	wake_up_all(&server->request_q);
+	/* give those requests time to exit */
+	msleep(125);
+
+	if (server->ssocket) {
+		sock_release(csocket);
+		server->ssocket = NULL;
+	}
+	/* buffer usuallly freed in free_mid - need to free it here on exit */
+	cifs_buf_release(bigbuf);
+	if (smallbuf) /* no sense logging a debug message if NULL */
+		cifs_small_buf_release(smallbuf);
+
+	/*
+	 * BB: we shouldn't have to do any of this. It shouldn't be
+	 * possible to exit from the thread with active SMB sessions
+	 */
+	read_lock(&cifs_tcp_ses_lock);
+	if (list_empty(&server->pending_mid_q)) {
+		/* loop through server session structures attached to this and
+		    mark them dead */
+		list_for_each(tmp, &server->smb_ses_list) {
+			ses = list_entry(tmp, struct cifsSesInfo,
+					 smb_ses_list);
+			ses->status = CifsExiting;
+			ses->server = NULL;
+		}
+		read_unlock(&cifs_tcp_ses_lock);
+	} else {
+		/* although we can not zero the server struct pointer yet,
+		since there are active requests which may depnd on them,
+		mark the corresponding SMB sessions as exiting too */
+		list_for_each(tmp, &server->smb_ses_list) {
+			ses = list_entry(tmp, struct cifsSesInfo,
+					 smb_ses_list);
+			ses->status = CifsExiting;
+		}
+
+		spin_lock(&GlobalMid_Lock);
+		list_for_each(tmp, &server->pending_mid_q) {
+		mid_entry = list_entry(tmp, struct mid_q_entry, qhead);
+			if (mid_entry->midState == MID_REQUEST_SUBMITTED) {
+				cFYI(1, ("Clearing Mid 0x%x - waking up ",
+					 mid_entry->mid));
+				task_to_wake = mid_entry->tsk;
+				if (task_to_wake)
+					wake_up_process(task_to_wake);
+			}
+		}
+		spin_unlock(&GlobalMid_Lock);
+		read_unlock(&cifs_tcp_ses_lock);
+		/* 1/8th of sec is more than enough time for them to exit */
+		msleep(125);
+	}
+
+	if (!list_empty(&server->pending_mid_q)) {
+		/* mpx threads have not exited yet give them
+		at least the smb send timeout time for long ops */
+		/* due to delays on oplock break requests, we need
+		to wait at least 45 seconds before giving up
+		on a request getting a response and going ahead
+		and killing cifsd */
+		cFYI(1, ("Wait for exit from demultiplex thread"));
+		msleep(46000);
+		/* if threads still have not exited they are probably never
+		coming home not much else we can do but free the memory */
+	}
+
+	/* last chance to mark ses pointers invalid
+	if there are any pointing to this (e.g
+	if a crazy root user tried to kill cifsd
+	kernel thread explicitly this might happen) */
+	/* BB: This shouldn't be necessary, see above */
+	read_lock(&cifs_tcp_ses_lock);
+	list_for_each(tmp, &server->smb_ses_list) {
+		ses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);
+		ses->server = NULL;
+	}
+	read_unlock(&cifs_tcp_ses_lock);
+
+	kfree(server->hostname);
+	task_to_wake = xchg(&server->tsk, NULL);
+	kfree(server);
+
+	length = atomic_dec_return(&tcpSesAllocCount);
+	if (length  > 0)
+		mempool_resize(cifs_req_poolp, length + cifs_min_rcv,
+				GFP_KERNEL);
+
+	/* if server->tsk was NULL then wait for a signal before exiting */
+	if (!task_to_wake) {
+		set_current_state(TASK_INTERRUPTIBLE);
+		while (!signal_pending(current)) {
+			schedule();
+			set_current_state(TASK_INTERRUPTIBLE);
+		}
+		set_current_state(TASK_RUNNING);
+	}
+
+	module_put_and_exit(0);
+}
+
+/* extract the host portion of the UNC string */
+static char *
+extract_hostname(const char *unc)
+{
+	const char *src;
+	char *dst, *delim;
+	unsigned int len;
+
+	/* skip double chars at beginning of string */
+	/* BB: check validity of these bytes? */
+	src = unc + 2;
+
+	/* delimiter between hostname and sharename is always '\\' now */
+	delim = strchr(src, '\\');
+	if (!delim)
+		return ERR_PTR(-EINVAL);
+
+	len = delim - src;
+	dst = kmalloc((len + 1), GFP_KERNEL);
+	if (dst == NULL)
+		return ERR_PTR(-ENOMEM);
+
+	memcpy(dst, src, len);
+	dst[len] = '\0';
+
+	return dst;
+}
+
+static int
+cifs_parse_mount_options(char *options, const char *devname,
+			 struct smb_vol *vol)
+{
+	char *value;
+	char *data;
+	unsigned int  temp_len, i, j;
+	char separator[2];
+
+	separator[0] = ',';
+	separator[1] = 0;
+
+	if (Local_System_Name[0] != 0)
+		memcpy(vol->source_rfc1001_name, Local_System_Name, 15);
+	else {
+		char *nodename = utsname()->nodename;
+		int n = strnlen(nodename, 15);
+		memset(vol->source_rfc1001_name, 0x20, 15);
+		for (i = 0; i < n; i++) {
+			/* does not have to be perfect mapping since field is
+			informational, only used for servers that do not support
+			port 445 and it can be overridden at mount time */
+			vol->source_rfc1001_name[i] = toupper(nodename[i]);
+		}
+	}
+	vol->source_rfc1001_name[15] = 0;
+	/* null target name indicates to use *SMBSERVR default called name
+	   if we end up sending RFC1001 session initialize */
+	vol->target_rfc1001_name[0] = 0;
+	vol->linux_uid = current_uid();  /* use current_euid() instead? */
+	vol->linux_gid = current_gid();
+	vol->dir_mode = S_IRWXUGO;
+	/* 2767 perms indicate mandatory locking support */
+	vol->file_mode = (S_IRWXUGO | S_ISGID) & (~S_IXGRP);
+
+	/* vol->retry default is 0 (i.e. "soft" limited retry not hard retry) */
+	vol->rw = true;
+	/* default is always to request posix paths. */
+	vol->posix_paths = 1;
+
+	if (!options)
+		return 1;
+
+	if (strncmp(options, "sep=", 4) == 0) {
+		if (options[4] != 0) {
+			separator[0] = options[4];
+			options += 5;
+		} else {
+			cFYI(1, ("Null separator not allowed"));
+		}
+	}
+
+	while ((data = strsep(&options, separator)) != NULL) {
+		if (!*data)
+			continue;
+		if ((value = strchr(data, '=')) != NULL)
+			*value++ = '\0';
+
+		/* Have to parse this before we parse for "user" */
+		if (strnicmp(data, "user_xattr", 10) == 0) {
+			vol->no_xattr = 0;
+		} else if (strnicmp(data, "nouser_xattr", 12) == 0) {
+			vol->no_xattr = 1;
+		} else if (strnicmp(data, "user", 4) == 0) {
+			if (!value) {
+				printk(KERN_WARNING
+				       "CIFS: invalid or missing username\n");
+				return 1;	/* needs_arg; */
+			} else if (!*value) {
+				/* null user, ie anonymous, authentication */
+				vol->nullauth = 1;
+			}
+			if (strnlen(value, 200) < 200) {
+				vol->username = value;
+			} else {
+				printk(KERN_WARNING "CIFS: username too long\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "pass", 4) == 0) {
+			if (!value) {
+				vol->password = NULL;
+				continue;
+			} else if (value[0] == 0) {
+				/* check if string begins with double comma
+				   since that would mean the password really
+				   does start with a comma, and would not
+				   indicate an empty string */
+				if (value[1] != separator[0]) {
+					vol->password = NULL;
+					continue;
+				}
+			}
+			temp_len = strlen(value);
+			/* removed password length check, NTLM passwords
+				can be arbitrarily long */
+
+			/* if comma in password, the string will be
+			prematurely null terminated.  Commas in password are
+			specified across the cifs mount interface by a double
+			comma ie ,, and a comma used as in other cases ie ','
+			as a parameter delimiter/separator is single and due
+			to the strsep above is temporarily zeroed. */
+
+			/* NB: password legally can have multiple commas and
+			the only illegal character in a password is null */
+
+			if ((value[temp_len] == 0) &&
+			    (value[temp_len+1] == separator[0])) {
+				/* reinsert comma */
+				value[temp_len] = separator[0];
+				temp_len += 2;  /* move after second comma */
+				while (value[temp_len] != 0)  {
+					if (value[temp_len] == separator[0]) {
+						if (value[temp_len+1] ==
+						     separator[0]) {
+						/* skip second comma */
+							temp_len++;
+						} else {
+						/* single comma indicating start
+							 of next parm */
+							break;
+						}
+					}
+					temp_len++;
+				}
+				if (value[temp_len] == 0) {
+					options = NULL;
+				} else {
+					value[temp_len] = 0;
+					/* point option to start of next parm */
+					options = value + temp_len + 1;
+				}
+				/* go from value to value + temp_len condensing
+				double commas to singles. Note that this ends up
+				allocating a few bytes too many, which is ok */
+				vol->password = kzalloc(temp_len, GFP_KERNEL);
+				if (vol->password == NULL) {
+					printk(KERN_WARNING "CIFS: no memory "
+							    "for password\n");
+					return 1;
+				}
+				for (i = 0, j = 0; i < temp_len; i++, j++) {
+					vol->password[j] = value[i];
+					if (value[i] == separator[0]
+						&& value[i+1] == separator[0]) {
+						/* skip second comma */
+						i++;
+					}
+				}
+				vol->password[j] = 0;
+			} else {
+				vol->password = kzalloc(temp_len+1, GFP_KERNEL);
+				if (vol->password == NULL) {
+					printk(KERN_WARNING "CIFS: no memory "
+							    "for password\n");
+					return 1;
+				}
+				strcpy(vol->password, value);
+			}
+		} else if (strnicmp(data, "ip", 2) == 0) {
+			if (!value || !*value) {
+				vol->UNCip = NULL;
+			} else if (strnlen(value, 35) < 35) {
+				vol->UNCip = value;
+			} else {
+				printk(KERN_WARNING "CIFS: ip address "
+						    "too long\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "sec", 3) == 0) {
+			if (!value || !*value) {
+				cERROR(1, ("no security value specified"));
+				continue;
+			} else if (strnicmp(value, "krb5i", 5) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_KRB5 |
+					CIFSSEC_MUST_SIGN;
+			} else if (strnicmp(value, "krb5p", 5) == 0) {
+				/* vol->secFlg |= CIFSSEC_MUST_SEAL |
+					CIFSSEC_MAY_KRB5; */
+				cERROR(1, ("Krb5 cifs privacy not supported"));
+				return 1;
+			} else if (strnicmp(value, "krb5", 4) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_KRB5;
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+			} else if (strnicmp(value, "ntlmsspi", 8) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_NTLMSSP |
+					CIFSSEC_MUST_SIGN;
+			} else if (strnicmp(value, "ntlmssp", 7) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_NTLMSSP;
+#endif
+			} else if (strnicmp(value, "ntlmv2i", 7) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_NTLMV2 |
+					CIFSSEC_MUST_SIGN;
+			} else if (strnicmp(value, "ntlmv2", 6) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_NTLMV2;
+			} else if (strnicmp(value, "ntlmi", 5) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_NTLM |
+					CIFSSEC_MUST_SIGN;
+			} else if (strnicmp(value, "ntlm", 4) == 0) {
+				/* ntlm is default so can be turned off too */
+				vol->secFlg |= CIFSSEC_MAY_NTLM;
+			} else if (strnicmp(value, "nontlm", 6) == 0) {
+				/* BB is there a better way to do this? */
+				vol->secFlg |= CIFSSEC_MAY_NTLMV2;
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+			} else if (strnicmp(value, "lanman", 6) == 0) {
+				vol->secFlg |= CIFSSEC_MAY_LANMAN;
+#endif
+			} else if (strnicmp(value, "none", 4) == 0) {
+				vol->nullauth = 1;
+			} else {
+				cERROR(1, ("bad security option: %s", value));
+				return 1;
+			}
+		} else if ((strnicmp(data, "unc", 3) == 0)
+			   || (strnicmp(data, "target", 6) == 0)
+			   || (strnicmp(data, "path", 4) == 0)) {
+			if (!value || !*value) {
+				printk(KERN_WARNING "CIFS: invalid path to "
+						    "network resource\n");
+				return 1;	/* needs_arg; */
+			}
+			if ((temp_len = strnlen(value, 300)) < 300) {
+				vol->UNC = kmalloc(temp_len+1, GFP_KERNEL);
+				if (vol->UNC == NULL)
+					return 1;
+				strcpy(vol->UNC, value);
+				if (strncmp(vol->UNC, "//", 2) == 0) {
+					vol->UNC[0] = '\\';
+					vol->UNC[1] = '\\';
+				} else if (strncmp(vol->UNC, "\\\\", 2) != 0) {
+					printk(KERN_WARNING
+					       "CIFS: UNC Path does not begin "
+					       "with // or \\\\ \n");
+					return 1;
+				}
+			} else {
+				printk(KERN_WARNING "CIFS: UNC name too long\n");
+				return 1;
+			}
+		} else if ((strnicmp(data, "domain", 3) == 0)
+			   || (strnicmp(data, "workgroup", 5) == 0)) {
+			if (!value || !*value) {
+				printk(KERN_WARNING "CIFS: invalid domain name\n");
+				return 1;	/* needs_arg; */
+			}
+			/* BB are there cases in which a comma can be valid in
+			a domain name and need special handling? */
+			if (strnlen(value, 256) < 256) {
+				vol->domainname = value;
+				cFYI(1, ("Domain name set"));
+			} else {
+				printk(KERN_WARNING "CIFS: domain name too "
+						    "long\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "prefixpath", 10) == 0) {
+			if (!value || !*value) {
+				printk(KERN_WARNING
+					"CIFS: invalid path prefix\n");
+				return 1;       /* needs_argument */
+			}
+			if ((temp_len = strnlen(value, 1024)) < 1024) {
+				if (value[0] != '/')
+					temp_len++;  /* missing leading slash */
+				vol->prepath = kmalloc(temp_len+1, GFP_KERNEL);
+				if (vol->prepath == NULL)
+					return 1;
+				if (value[0] != '/') {
+					vol->prepath[0] = '/';
+					strcpy(vol->prepath+1, value);
+				} else
+					strcpy(vol->prepath, value);
+				cFYI(1, ("prefix path %s", vol->prepath));
+			} else {
+				printk(KERN_WARNING "CIFS: prefix too long\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "iocharset", 9) == 0) {
+			if (!value || !*value) {
+				printk(KERN_WARNING "CIFS: invalid iocharset "
+						    "specified\n");
+				return 1;	/* needs_arg; */
+			}
+			if (strnlen(value, 65) < 65) {
+				if (strnicmp(value, "default", 7))
+					vol->iocharset = value;
+				/* if iocharset not set then load_nls_default
+				   is used by caller */
+				cFYI(1, ("iocharset set to %s", value));
+			} else {
+				printk(KERN_WARNING "CIFS: iocharset name "
+						    "too long.\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "uid", 3) == 0) {
+			if (value && *value) {
+				vol->linux_uid =
+					simple_strtoul(value, &value, 0);
+				vol->override_uid = 1;
+			}
+		} else if (strnicmp(data, "gid", 3) == 0) {
+			if (value && *value) {
+				vol->linux_gid =
+					simple_strtoul(value, &value, 0);
+				vol->override_gid = 1;
+			}
+		} else if (strnicmp(data, "file_mode", 4) == 0) {
+			if (value && *value) {
+				vol->file_mode =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "dir_mode", 4) == 0) {
+			if (value && *value) {
+				vol->dir_mode =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "dirmode", 4) == 0) {
+			if (value && *value) {
+				vol->dir_mode =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "port", 4) == 0) {
+			if (value && *value) {
+				vol->port =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "rsize", 5) == 0) {
+			if (value && *value) {
+				vol->rsize =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "wsize", 5) == 0) {
+			if (value && *value) {
+				vol->wsize =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "sockopt", 5) == 0) {
+			if (value && *value) {
+				vol->sockopt =
+					simple_strtoul(value, &value, 0);
+			}
+		} else if (strnicmp(data, "netbiosname", 4) == 0) {
+			if (!value || !*value || (*value == ' ')) {
+				cFYI(1, ("invalid (empty) netbiosname"));
+			} else {
+				memset(vol->source_rfc1001_name, 0x20, 15);
+				for (i = 0; i < 15; i++) {
+				/* BB are there cases in which a comma can be
+				valid in this workstation netbios name (and need
+				special handling)? */
+
+				/* We do not uppercase netbiosname for user */
+					if (value[i] == 0)
+						break;
+					else
+						vol->source_rfc1001_name[i] =
+								value[i];
+				}
+				/* The string has 16th byte zero still from
+				set at top of the function  */
+				if ((i == 15) && (value[i] != 0))
+					printk(KERN_WARNING "CIFS: netbiosname"
+						" longer than 15 truncated.\n");
+			}
+		} else if (strnicmp(data, "servern", 7) == 0) {
+			/* servernetbiosname specified override *SMBSERVER */
+			if (!value || !*value || (*value == ' ')) {
+				cFYI(1, ("empty server netbiosname specified"));
+			} else {
+				/* last byte, type, is 0x20 for servr type */
+				memset(vol->target_rfc1001_name, 0x20, 16);
+
+				for (i = 0; i < 15; i++) {
+				/* BB are there cases in which a comma can be
+				   valid in this workstation netbios name
+				   (and need special handling)? */
+
+				/* user or mount helper must uppercase
+				   the netbiosname */
+					if (value[i] == 0)
+						break;
+					else
+						vol->target_rfc1001_name[i] =
+								value[i];
+				}
+				/* The string has 16th byte zero still from
+				   set at top of the function  */
+				if ((i == 15) && (value[i] != 0))
+					printk(KERN_WARNING "CIFS: server net"
+					"biosname longer than 15 truncated.\n");
+			}
+		} else if (strnicmp(data, "credentials", 4) == 0) {
+			/* ignore */
+		} else if (strnicmp(data, "version", 3) == 0) {
+			/* ignore */
+		} else if (strnicmp(data, "guest", 5) == 0) {
+			/* ignore */
+		} else if (strnicmp(data, "rw", 2) == 0) {
+			vol->rw = true;
+		} else if (strnicmp(data, "noblocksend", 11) == 0) {
+			vol->noblocksnd = 1;
+		} else if (strnicmp(data, "noautotune", 10) == 0) {
+			vol->noautotune = 1;
+		} else if ((strnicmp(data, "suid", 4) == 0) ||
+				   (strnicmp(data, "nosuid", 6) == 0) ||
+				   (strnicmp(data, "exec", 4) == 0) ||
+				   (strnicmp(data, "noexec", 6) == 0) ||
+				   (strnicmp(data, "nodev", 5) == 0) ||
+				   (strnicmp(data, "noauto", 6) == 0) ||
+				   (strnicmp(data, "dev", 3) == 0)) {
+			/*  The mount tool or mount.cifs helper (if present)
+			    uses these opts to set flags, and the flags are read
+			    by the kernel vfs layer before we get here (ie
+			    before read super) so there is no point trying to
+			    parse these options again and set anything and it
+			    is ok to just ignore them */
+			continue;
+		} else if (strnicmp(data, "ro", 2) == 0) {
+			vol->rw = false;
+		} else if (strnicmp(data, "hard", 4) == 0) {
+			vol->retry = 1;
+		} else if (strnicmp(data, "soft", 4) == 0) {
+			vol->retry = 0;
+		} else if (strnicmp(data, "perm", 4) == 0) {
+			vol->noperm = 0;
+		} else if (strnicmp(data, "noperm", 6) == 0) {
+			vol->noperm = 1;
+		} else if (strnicmp(data, "mapchars", 8) == 0) {
+			vol->remap = 1;
+		} else if (strnicmp(data, "nomapchars", 10) == 0) {
+			vol->remap = 0;
+		} else if (strnicmp(data, "sfu", 3) == 0) {
+			vol->sfu_emul = 1;
+		} else if (strnicmp(data, "nosfu", 5) == 0) {
+			vol->sfu_emul = 0;
+		} else if (strnicmp(data, "nodfs", 5) == 0) {
+			vol->nodfs = 1;
+		} else if (strnicmp(data, "posixpaths", 10) == 0) {
+			vol->posix_paths = 1;
+		} else if (strnicmp(data, "noposixpaths", 12) == 0) {
+			vol->posix_paths = 0;
+		} else if (strnicmp(data, "nounix", 6) == 0) {
+			vol->no_linux_ext = 1;
+		} else if (strnicmp(data, "nolinux", 7) == 0) {
+			vol->no_linux_ext = 1;
+		} else if ((strnicmp(data, "nocase", 6) == 0) ||
+			   (strnicmp(data, "ignorecase", 10)  == 0)) {
+			vol->nocase = 1;
+		} else if (strnicmp(data, "brl", 3) == 0) {
+			vol->nobrl =  0;
+		} else if ((strnicmp(data, "nobrl", 5) == 0) ||
+			   (strnicmp(data, "nolock", 6) == 0)) {
+			vol->nobrl =  1;
+			/* turn off mandatory locking in mode
+			if remote locking is turned off since the
+			local vfs will do advisory */
+			if (vol->file_mode ==
+				(S_IALLUGO & ~(S_ISUID | S_IXGRP)))
+				vol->file_mode = S_IALLUGO;
+		} else if (strnicmp(data, "forcemandatorylock", 9) == 0) {
+			/* will take the shorter form "forcemand" as well */
+			/* This mount option will force use of mandatory
+			  (DOS/Windows style) byte range locks, instead of
+			  using posix advisory byte range locks, even if the
+			  Unix extensions are available and posix locks would
+			  be supported otherwise. If Unix extensions are not
+			  negotiated this has no effect since mandatory locks
+			  would be used (mandatory locks is all that those
+			  those servers support) */
+			vol->mand_lock = 1;
+		} else if (strnicmp(data, "setuids", 7) == 0) {
+			vol->setuids = 1;
+		} else if (strnicmp(data, "nosetuids", 9) == 0) {
+			vol->setuids = 0;
+		} else if (strnicmp(data, "dynperm", 7) == 0) {
+			vol->dynperm = true;
+		} else if (strnicmp(data, "nodynperm", 9) == 0) {
+			vol->dynperm = false;
+		} else if (strnicmp(data, "nohard", 6) == 0) {
+			vol->retry = 0;
+		} else if (strnicmp(data, "nosoft", 6) == 0) {
+			vol->retry = 1;
+		} else if (strnicmp(data, "nointr", 6) == 0) {
+			vol->intr = 0;
+		} else if (strnicmp(data, "intr", 4) == 0) {
+			vol->intr = 1;
+		} else if (strnicmp(data, "nostrictsync", 12) == 0) {
+			vol->nostrictsync = 1;
+		} else if (strnicmp(data, "strictsync", 10) == 0) {
+			vol->nostrictsync = 0;
+		} else if (strnicmp(data, "serverino", 7) == 0) {
+			vol->server_ino = 1;
+		} else if (strnicmp(data, "noserverino", 9) == 0) {
+			vol->server_ino = 0;
+		} else if (strnicmp(data, "cifsacl", 7) == 0) {
+			vol->cifs_acl = 1;
+		} else if (strnicmp(data, "nocifsacl", 9) == 0) {
+			vol->cifs_acl = 0;
+		} else if (strnicmp(data, "acl", 3) == 0) {
+			vol->no_psx_acl = 0;
+		} else if (strnicmp(data, "noacl", 5) == 0) {
+			vol->no_psx_acl = 1;
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+		} else if (strnicmp(data, "locallease", 6) == 0) {
+			vol->local_lease = 1;
+#endif
+		} else if (strnicmp(data, "sign", 4) == 0) {
+			vol->secFlg |= CIFSSEC_MUST_SIGN;
+		} else if (strnicmp(data, "seal", 4) == 0) {
+			/* we do not do the following in secFlags because seal
+			   is a per tree connection (mount) not a per socket
+			   or per-smb connection option in the protocol */
+			/* vol->secFlg |= CIFSSEC_MUST_SEAL; */
+			vol->seal = 1;
+		} else if (strnicmp(data, "direct", 6) == 0) {
+			vol->direct_io = 1;
+		} else if (strnicmp(data, "forcedirectio", 13) == 0) {
+			vol->direct_io = 1;
+		} else if (strnicmp(data, "in6_addr", 8) == 0) {
+			if (!value || !*value) {
+				vol->in6_addr = NULL;
+			} else if (strnlen(value, 49) == 48) {
+				vol->in6_addr = value;
+			} else {
+				printk(KERN_WARNING "CIFS: ip v6 address not "
+						    "48 characters long\n");
+				return 1;
+			}
+		} else if (strnicmp(data, "noac", 4) == 0) {
+			printk(KERN_WARNING "CIFS: Mount option noac not "
+				"supported. Instead set "
+				"/proc/fs/cifs/LookupCacheEnabled to 0\n");
+		} else
+			printk(KERN_WARNING "CIFS: Unknown mount option %s\n",
+						data);
+	}
+	if (vol->UNC == NULL) {
+		if (devname == NULL) {
+			printk(KERN_WARNING "CIFS: Missing UNC name for mount "
+						"target\n");
+			return 1;
+		}
+		if ((temp_len = strnlen(devname, 300)) < 300) {
+			vol->UNC = kmalloc(temp_len+1, GFP_KERNEL);
+			if (vol->UNC == NULL)
+				return 1;
+			strcpy(vol->UNC, devname);
+			if (strncmp(vol->UNC, "//", 2) == 0) {
+				vol->UNC[0] = '\\';
+				vol->UNC[1] = '\\';
+			} else if (strncmp(vol->UNC, "\\\\", 2) != 0) {
+				printk(KERN_WARNING "CIFS: UNC Path does not "
+						    "begin with // or \\\\ \n");
+				return 1;
+			}
+			value = strpbrk(vol->UNC+2, "/\\");
+			if (value)
+				*value = '\\';
+		} else {
+			printk(KERN_WARNING "CIFS: UNC name too long\n");
+			return 1;
+		}
+	}
+	if (vol->UNCip == NULL)
+		vol->UNCip = &vol->UNC[2];
+
+	return 0;
+}
+
+static struct TCP_Server_Info *
+cifs_find_tcp_session(struct sockaddr_storage *addr)
+{
+	struct list_head *tmp;
+	struct TCP_Server_Info *server;
+	struct sockaddr_in *addr4 = (struct sockaddr_in *) addr;
+	struct sockaddr_in6 *addr6 = (struct sockaddr_in6 *) addr;
+
+	write_lock(&cifs_tcp_ses_lock);
+	list_for_each(tmp, &cifs_tcp_ses_list) {
+		server = list_entry(tmp, struct TCP_Server_Info,
+				    tcp_ses_list);
+		/*
+		 * the demux thread can exit on its own while still in CifsNew
+		 * so don't accept any sockets in that state. Since the
+		 * tcpStatus never changes back to CifsNew it's safe to check
+		 * for this without a lock.
+		 */
+		if (server->tcpStatus == CifsNew)
+			continue;
+
+		if (addr->ss_family == AF_INET &&
+		    (addr4->sin_addr.s_addr !=
+		     server->addr.sockAddr.sin_addr.s_addr))
+			continue;
+		else if (addr->ss_family == AF_INET6 &&
+			 !ipv6_addr_equal(&server->addr.sockAddr6.sin6_addr,
+					  &addr6->sin6_addr))
+			continue;
+
+		++server->srv_count;
+		write_unlock(&cifs_tcp_ses_lock);
+		cFYI(1, ("Existing tcp session with server found"));
+		return server;
+	}
+	write_unlock(&cifs_tcp_ses_lock);
+	return NULL;
+}
+
+static void
+cifs_put_tcp_session(struct TCP_Server_Info *server)
+{
+	struct task_struct *task;
+
+	write_lock(&cifs_tcp_ses_lock);
+	if (--server->srv_count > 0) {
+		write_unlock(&cifs_tcp_ses_lock);
+		return;
+	}
+
+	list_del_init(&server->tcp_ses_list);
+	write_unlock(&cifs_tcp_ses_lock);
+
+	spin_lock(&GlobalMid_Lock);
+	server->tcpStatus = CifsExiting;
+	spin_unlock(&GlobalMid_Lock);
+
+	task = xchg(&server->tsk, NULL);
+	if (task)
+		force_sig(SIGKILL, task);
+}
+
+static struct TCP_Server_Info *
+cifs_get_tcp_session(struct smb_vol *volume_info)
+{
+	struct TCP_Server_Info *tcp_ses = NULL;
+	struct sockaddr_storage addr;
+	struct sockaddr_in *sin_server = (struct sockaddr_in *) &addr;
+	struct sockaddr_in6 *sin_server6 = (struct sockaddr_in6 *) &addr;
+	int rc;
+
+	memset(&addr, 0, sizeof(struct sockaddr_storage));
+
+	if (volume_info->UNCip && volume_info->UNC) {
+		rc = cifs_inet_pton(AF_INET, volume_info->UNCip,
+				    &sin_server->sin_addr.s_addr);
+
+		if (rc <= 0) {
+			/* not ipv4 address, try ipv6 */
+			rc = cifs_inet_pton(AF_INET6, volume_info->UNCip,
+					    &sin_server6->sin6_addr.in6_u);
+			if (rc > 0)
+				addr.ss_family = AF_INET6;
+		} else {
+			addr.ss_family = AF_INET;
+		}
+
+		if (rc <= 0) {
+			/* we failed translating address */
+			rc = -EINVAL;
+			goto out_err;
+		}
+
+		cFYI(1, ("UNC: %s ip: %s", volume_info->UNC,
+			 volume_info->UNCip));
+	} else if (volume_info->UNCip) {
+		/* BB using ip addr as tcp_ses name to connect to the
+		   DFS root below */
+		cERROR(1, ("Connecting to DFS root not implemented yet"));
+		rc = -EINVAL;
+		goto out_err;
+	} else /* which tcp_sess DFS root would we conect to */ {
+		cERROR(1,
+		       ("CIFS mount error: No UNC path (e.g. -o "
+			"unc=//192.168.1.100/public) specified"));
+		rc = -EINVAL;
+		goto out_err;
+	}
+
+	/* see if we already have a matching tcp_ses */
+	tcp_ses = cifs_find_tcp_session(&addr);
+	if (tcp_ses)
+		return tcp_ses;
+
+	tcp_ses = kzalloc(sizeof(struct TCP_Server_Info), GFP_KERNEL);
+	if (!tcp_ses) {
+		rc = -ENOMEM;
+		goto out_err;
+	}
+
+	tcp_ses->hostname = extract_hostname(volume_info->UNC);
+	if (IS_ERR(tcp_ses->hostname)) {
+		rc = PTR_ERR(tcp_ses->hostname);
+		goto out_err;
+	}
+
+	tcp_ses->noblocksnd = volume_info->noblocksnd;
+	tcp_ses->noautotune = volume_info->noautotune;
+	atomic_set(&tcp_ses->inFlight, 0);
+	init_waitqueue_head(&tcp_ses->response_q);
+	init_waitqueue_head(&tcp_ses->request_q);
+	INIT_LIST_HEAD(&tcp_ses->pending_mid_q);
+	mutex_init(&tcp_ses->srv_mutex);
+	memcpy(tcp_ses->workstation_RFC1001_name,
+		volume_info->source_rfc1001_name, RFC1001_NAME_LEN_WITH_NULL);
+	memcpy(tcp_ses->server_RFC1001_name,
+		volume_info->target_rfc1001_name, RFC1001_NAME_LEN_WITH_NULL);
+	tcp_ses->sequence_number = 0;
+	INIT_LIST_HEAD(&tcp_ses->tcp_ses_list);
+	INIT_LIST_HEAD(&tcp_ses->smb_ses_list);
+
+	/*
+	 * at this point we are the only ones with the pointer
+	 * to the struct since the kernel thread not created yet
+	 * no need to spinlock this init of tcpStatus or srv_count
+	 */
+	tcp_ses->tcpStatus = CifsNew;
+	++tcp_ses->srv_count;
+
+	if (addr.ss_family == AF_INET6) {
+		cFYI(1, ("attempting ipv6 connect"));
+		/* BB should we allow ipv6 on port 139? */
+		/* other OS never observed in Wild doing 139 with v6 */
+		memcpy(&tcp_ses->addr.sockAddr6, sin_server6,
+			sizeof(struct sockaddr_in6));
+		sin_server6->sin6_port = htons(volume_info->port);
+		rc = ipv6_connect(tcp_ses);
+	} else {
+		memcpy(&tcp_ses->addr.sockAddr, sin_server,
+			sizeof(struct sockaddr_in));
+		sin_server->sin_port = htons(volume_info->port);
+		rc = ipv4_connect(tcp_ses);
+	}
+	if (rc < 0) {
+		cERROR(1, ("Error connecting to socket. Aborting operation"));
+		goto out_err;
+	}
+
+	/*
+	 * since we're in a cifs function already, we know that
+	 * this will succeed. No need for try_module_get().
+	 */
+	__module_get(THIS_MODULE);
+	tcp_ses->tsk = kthread_run((void *)(void *)cifs_demultiplex_thread,
+				  tcp_ses, "cifsd");
+	if (IS_ERR(tcp_ses->tsk)) {
+		rc = PTR_ERR(tcp_ses->tsk);
+		cERROR(1, ("error %d create cifsd thread", rc));
+		module_put(THIS_MODULE);
+		goto out_err;
+	}
+
+	/* thread spawned, put it on the list */
+	write_lock(&cifs_tcp_ses_lock);
+	list_add(&tcp_ses->tcp_ses_list, &cifs_tcp_ses_list);
+	write_unlock(&cifs_tcp_ses_lock);
+
+	return tcp_ses;
+
+out_err:
+	if (tcp_ses) {
+		kfree(tcp_ses->hostname);
+		if (tcp_ses->ssocket)
+			sock_release(tcp_ses->ssocket);
+		kfree(tcp_ses);
+	}
+	return ERR_PTR(rc);
+}
+
+static struct cifsSesInfo *
+cifs_find_smb_ses(struct TCP_Server_Info *server, char *username)
+{
+	struct list_head *tmp;
+	struct cifsSesInfo *ses;
+
+	write_lock(&cifs_tcp_ses_lock);
+	list_for_each(tmp, &server->smb_ses_list) {
+		ses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);
+		if (strncmp(ses->userName, username, MAX_USERNAME_SIZE))
+			continue;
+
+		++ses->ses_count;
+		write_unlock(&cifs_tcp_ses_lock);
+		return ses;
+	}
+	write_unlock(&cifs_tcp_ses_lock);
+	return NULL;
+}
+
+static void
+cifs_put_smb_ses(struct cifsSesInfo *ses)
+{
+	int xid;
+	struct TCP_Server_Info *server = ses->server;
+
+	write_lock(&cifs_tcp_ses_lock);
+	if (--ses->ses_count > 0) {
+		write_unlock(&cifs_tcp_ses_lock);
+		return;
+	}
+
+	list_del_init(&ses->smb_ses_list);
+	write_unlock(&cifs_tcp_ses_lock);
+
+	if (ses->status == CifsGood) {
+		xid = GetXid();
+		CIFSSMBLogoff(xid, ses);
+		_FreeXid(xid);
+	}
+	sesInfoFree(ses);
+	cifs_put_tcp_session(server);
+}
+
+static struct cifsTconInfo *
+cifs_find_tcon(struct cifsSesInfo *ses, const char *unc)
+{
+	struct list_head *tmp;
+	struct cifsTconInfo *tcon;
+
+	write_lock(&cifs_tcp_ses_lock);
+	list_for_each(tmp, &ses->tcon_list) {
+		tcon = list_entry(tmp, struct cifsTconInfo, tcon_list);
+		if (tcon->tidStatus == CifsExiting)
+			continue;
+		if (strncmp(tcon->treeName, unc, MAX_TREE_SIZE))
+			continue;
+
+		++tcon->tc_count;
+		write_unlock(&cifs_tcp_ses_lock);
+		return tcon;
+	}
+	write_unlock(&cifs_tcp_ses_lock);
+	return NULL;
+}
+
+static void
+cifs_put_tcon(struct cifsTconInfo *tcon)
+{
+	int xid;
+	struct cifsSesInfo *ses = tcon->ses;
+
+	write_lock(&cifs_tcp_ses_lock);
+	if (--tcon->tc_count > 0) {
+		write_unlock(&cifs_tcp_ses_lock);
+		return;
+	}
+
+	list_del_init(&tcon->tcon_list);
+	write_unlock(&cifs_tcp_ses_lock);
+
+	xid = GetXid();
+	CIFSSMBTDis(xid, tcon);
+	_FreeXid(xid);
+
+	DeleteTconOplockQEntries(tcon);
+	tconInfoFree(tcon);
+	cifs_put_smb_ses(ses);
+}
+
+int
+get_dfs_path(int xid, struct cifsSesInfo *pSesInfo, const char *old_path,
+	     const struct nls_table *nls_codepage, unsigned int *pnum_referrals,
+	     struct dfs_info3_param **preferrals, int remap)
+{
+	char *temp_unc;
+	int rc = 0;
+
+	*pnum_referrals = 0;
+	*preferrals = NULL;
+
+	if (pSesInfo->ipc_tid == 0) {
+		temp_unc = kmalloc(2 /* for slashes */ +
+			strnlen(pSesInfo->serverName,
+				SERVER_NAME_LEN_WITH_NULL * 2)
+				 + 1 + 4 /* slash IPC$ */  + 2,
+				GFP_KERNEL);
+		if (temp_unc == NULL)
+			return -ENOMEM;
+		temp_unc[0] = '\\';
+		temp_unc[1] = '\\';
+		strcpy(temp_unc + 2, pSesInfo->serverName);
+		strcpy(temp_unc + 2 + strlen(pSesInfo->serverName), "\\IPC$");
+		rc = CIFSTCon(xid, pSesInfo, temp_unc, NULL, nls_codepage);
+		cFYI(1,
+		     ("CIFS Tcon rc = %d ipc_tid = %d", rc, pSesInfo->ipc_tid));
+		kfree(temp_unc);
+	}
+	if (rc == 0)
+		rc = CIFSGetDFSRefer(xid, pSesInfo, old_path, preferrals,
+				     pnum_referrals, nls_codepage, remap);
+	/* BB map targetUNCs to dfs_info3 structures, here or
+		in CIFSGetDFSRefer BB */
+
+	return rc;
+}
+
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+static struct lock_class_key cifs_key[2];
+static struct lock_class_key cifs_slock_key[2];
+
+static inline void
+cifs_reclassify_socket4(struct socket *sock)
+{
+	struct sock *sk = sock->sk;
+	BUG_ON(sock_owned_by_user(sk));
+	sock_lock_init_class_and_name(sk, "slock-AF_INET-CIFS",
+		&cifs_slock_key[0], "sk_lock-AF_INET-CIFS", &cifs_key[0]);
+}
+
+static inline void
+cifs_reclassify_socket6(struct socket *sock)
+{
+	struct sock *sk = sock->sk;
+	BUG_ON(sock_owned_by_user(sk));
+	sock_lock_init_class_and_name(sk, "slock-AF_INET6-CIFS",
+		&cifs_slock_key[1], "sk_lock-AF_INET6-CIFS", &cifs_key[1]);
+}
+#else
+static inline void
+cifs_reclassify_socket4(struct socket *sock)
+{
+}
+
+static inline void
+cifs_reclassify_socket6(struct socket *sock)
+{
+}
+#endif
+
+/* See RFC1001 section 14 on representation of Netbios names */
+static void rfc1002mangle(char *target, char *source, unsigned int length)
+{
+	unsigned int i, j;
+
+	for (i = 0, j = 0; i < (length); i++) {
+		/* mask a nibble at a time and encode */
+		target[j] = 'A' + (0x0F & (source[i] >> 4));
+		target[j+1] = 'A' + (0x0F & source[i]);
+		j += 2;
+	}
+
+}
+
+
+static int
+ipv4_connect(struct TCP_Server_Info *server)
+{
+	int rc = 0;
+	bool connected = false;
+	__be16 orig_port = 0;
+	struct socket *socket = server->ssocket;
+
+	if (socket == NULL) {
+		rc = sock_create_kern(PF_INET, SOCK_STREAM,
+				      IPPROTO_TCP, &socket);
+		if (rc < 0) {
+			cERROR(1, ("Error %d creating socket", rc));
+			return rc;
+		}
+
+		/* BB other socket options to set KEEPALIVE, NODELAY? */
+		cFYI(1, ("Socket created"));
+		server->ssocket = socket;
+		socket->sk->sk_allocation = GFP_NOFS;
+		cifs_reclassify_socket4(socket);
+	}
+
+	/* user overrode default port */
+	if (server->addr.sockAddr.sin_port) {
+		rc = socket->ops->connect(socket, (struct sockaddr *)
+					  &server->addr.sockAddr,
+					  sizeof(struct sockaddr_in), 0);
+		if (rc >= 0)
+			connected = true;
+	}
+
+	if (!connected) {
+		/* save original port so we can retry user specified port
+			later if fall back ports fail this time  */
+		orig_port = server->addr.sockAddr.sin_port;
+
+		/* do not retry on the same port we just failed on */
+		if (server->addr.sockAddr.sin_port != htons(CIFS_PORT)) {
+			server->addr.sockAddr.sin_port = htons(CIFS_PORT);
+			rc = socket->ops->connect(socket,
+						(struct sockaddr *)
+						&server->addr.sockAddr,
+						sizeof(struct sockaddr_in), 0);
+			if (rc >= 0)
+				connected = true;
+		}
+	}
+	if (!connected) {
+		server->addr.sockAddr.sin_port = htons(RFC1001_PORT);
+		rc = socket->ops->connect(socket, (struct sockaddr *)
+					      &server->addr.sockAddr,
+					      sizeof(struct sockaddr_in), 0);
+		if (rc >= 0)
+			connected = true;
+	}
+
+	/* give up here - unless we want to retry on different
+		protocol families some day */
+	if (!connected) {
+		if (orig_port)
+			server->addr.sockAddr.sin_port = orig_port;
+		cFYI(1, ("Error %d connecting to server via ipv4", rc));
+		sock_release(socket);
+		server->ssocket = NULL;
+		return rc;
+	}
+
+
+	/*
+	 * Eventually check for other socket options to change from
+	 *  the default. sock_setsockopt not used because it expects
+	 *  user space buffer
+	 */
+	socket->sk->sk_rcvtimeo = 7 * HZ;
+	socket->sk->sk_sndtimeo = 5 * HZ;
+
+	/* make the bufsizes depend on wsize/rsize and max requests */
+	if (server->noautotune) {
+		if (socket->sk->sk_sndbuf < (200 * 1024))
+			socket->sk->sk_sndbuf = 200 * 1024;
+		if (socket->sk->sk_rcvbuf < (140 * 1024))
+			socket->sk->sk_rcvbuf = 140 * 1024;
+	}
+
+	 cFYI(1, ("sndbuf %d rcvbuf %d rcvtimeo 0x%lx",
+		 socket->sk->sk_sndbuf,
+		 socket->sk->sk_rcvbuf, socket->sk->sk_rcvtimeo));
+
+	/* send RFC1001 sessinit */
+	if (server->addr.sockAddr.sin_port == htons(RFC1001_PORT)) {
+		/* some servers require RFC1001 sessinit before sending
+		negprot - BB check reconnection in case where second
+		sessinit is sent but no second negprot */
+		struct rfc1002_session_packet *ses_init_buf;
+		struct smb_hdr *smb_buf;
+		ses_init_buf = kzalloc(sizeof(struct rfc1002_session_packet),
+				       GFP_KERNEL);
+		if (ses_init_buf) {
+			ses_init_buf->trailer.session_req.called_len = 32;
+			if (server->server_RFC1001_name &&
+			    server->server_RFC1001_name[0] != 0)
+				rfc1002mangle(ses_init_buf->trailer.
+						session_req.called_name,
+					      server->server_RFC1001_name,
+					      RFC1001_NAME_LEN_WITH_NULL);
+			else
+				rfc1002mangle(ses_init_buf->trailer.
+						session_req.called_name,
+					      DEFAULT_CIFS_CALLED_NAME,
+					      RFC1001_NAME_LEN_WITH_NULL);
+
+			ses_init_buf->trailer.session_req.calling_len = 32;
+
+			/* calling name ends in null (byte 16) from old smb
+			convention. */
+			if (server->workstation_RFC1001_name &&
+			    server->workstation_RFC1001_name[0] != 0)
+				rfc1002mangle(ses_init_buf->trailer.
+						session_req.calling_name,
+					      server->workstation_RFC1001_name,
+					      RFC1001_NAME_LEN_WITH_NULL);
+			else
+				rfc1002mangle(ses_init_buf->trailer.
+						session_req.calling_name,
+					      "LINUX_CIFS_CLNT",
+					      RFC1001_NAME_LEN_WITH_NULL);
+
+			ses_init_buf->trailer.session_req.scope1 = 0;
+			ses_init_buf->trailer.session_req.scope2 = 0;
+			smb_buf = (struct smb_hdr *)ses_init_buf;
+			/* sizeof RFC1002_SESSION_REQUEST with no scope */
+			smb_buf->smb_buf_length = 0x81000044;
+			rc = smb_send(server, smb_buf, 0x44);
+			kfree(ses_init_buf);
+			msleep(1); /* RFC1001 layer in at least one server
+				      requires very short break before negprot
+				      presumably because not expecting negprot
+				      to follow so fast.  This is a simple
+				      solution that works without
+				      complicating the code and causes no
+				      significant slowing down on mount
+				      for everyone else */
+		}
+		/* else the negprot may still work without this
+		even though malloc failed */
+
+	}
+
+	return rc;
+}
+
+static int
+ipv6_connect(struct TCP_Server_Info *server)
+{
+	int rc = 0;
+	bool connected = false;
+	__be16 orig_port = 0;
+	struct socket *socket = server->ssocket;
+
+	if (socket == NULL) {
+		rc = sock_create_kern(PF_INET6, SOCK_STREAM,
+				      IPPROTO_TCP, &socket);
+		if (rc < 0) {
+			cERROR(1, ("Error %d creating ipv6 socket", rc));
+			socket = NULL;
+			return rc;
+		}
+
+		/* BB other socket options to set KEEPALIVE, NODELAY? */
+		cFYI(1, ("ipv6 Socket created"));
+		server->ssocket = socket;
+		socket->sk->sk_allocation = GFP_NOFS;
+		cifs_reclassify_socket6(socket);
+	}
+
+	/* user overrode default port */
+	if (server->addr.sockAddr6.sin6_port) {
+		rc = socket->ops->connect(socket,
+				(struct sockaddr *) &server->addr.sockAddr6,
+				sizeof(struct sockaddr_in6), 0);
+		if (rc >= 0)
+			connected = true;
+	}
+
+	if (!connected) {
+		/* save original port so we can retry user specified port
+			later if fall back ports fail this time  */
+
+		orig_port = server->addr.sockAddr6.sin6_port;
+		/* do not retry on the same port we just failed on */
+		if (server->addr.sockAddr6.sin6_port != htons(CIFS_PORT)) {
+			server->addr.sockAddr6.sin6_port = htons(CIFS_PORT);
+			rc = socket->ops->connect(socket, (struct sockaddr *)
+					&server->addr.sockAddr6,
+					sizeof(struct sockaddr_in6), 0);
+			if (rc >= 0)
+				connected = true;
+		}
+	}
+	if (!connected) {
+		server->addr.sockAddr6.sin6_port = htons(RFC1001_PORT);
+		rc = socket->ops->connect(socket, (struct sockaddr *)
+				&server->addr.sockAddr6,
+				sizeof(struct sockaddr_in6), 0);
+		if (rc >= 0)
+			connected = true;
+	}
+
+	/* give up here - unless we want to retry on different
+		protocol families some day */
+	if (!connected) {
+		if (orig_port)
+			server->addr.sockAddr6.sin6_port = orig_port;
+		cFYI(1, ("Error %d connecting to server via ipv6", rc));
+		sock_release(socket);
+		server->ssocket = NULL;
+		return rc;
+	}
+
+	/*
+	 * Eventually check for other socket options to change from
+	 * the default. sock_setsockopt not used because it expects
+	 * user space buffer
+	 */
+	socket->sk->sk_rcvtimeo = 7 * HZ;
+	socket->sk->sk_sndtimeo = 5 * HZ;
+	server->ssocket = socket;
+
+	return rc;
+}
+
+void reset_cifs_unix_caps(int xid, struct cifsTconInfo *tcon,
+			  struct super_block *sb, struct smb_vol *vol_info)
+{
+	/* if we are reconnecting then should we check to see if
+	 * any requested capabilities changed locally e.g. via
+	 * remount but we can not do much about it here
+	 * if they have (even if we could detect it by the following)
+	 * Perhaps we could add a backpointer to array of sb from tcon
+	 * or if we change to make all sb to same share the same
+	 * sb as NFS - then we only have one backpointer to sb.
+	 * What if we wanted to mount the server share twice once with
+	 * and once without posixacls or posix paths? */
+	__u64 saved_cap = le64_to_cpu(tcon->fsUnixInfo.Capability);
+
+	if (vol_info && vol_info->no_linux_ext) {
+		tcon->fsUnixInfo.Capability = 0;
+		tcon->unix_ext = 0; /* Unix Extensions disabled */
+		cFYI(1, ("Linux protocol extensions disabled"));
+		return;
+	} else if (vol_info)
+		tcon->unix_ext = 1; /* Unix Extensions supported */
+
+	if (tcon->unix_ext == 0) {
+		cFYI(1, ("Unix extensions disabled so not set on reconnect"));
+		return;
+	}
+
+	if (!CIFSSMBQFSUnixInfo(xid, tcon)) {
+		__u64 cap = le64_to_cpu(tcon->fsUnixInfo.Capability);
+
+		/* check for reconnect case in which we do not
+		   want to change the mount behavior if we can avoid it */
+		if (vol_info == NULL) {
+			/* turn off POSIX ACL and PATHNAMES if not set
+			   originally at mount time */
+			if ((saved_cap & CIFS_UNIX_POSIX_ACL_CAP) == 0)
+				cap &= ~CIFS_UNIX_POSIX_ACL_CAP;
+			if ((saved_cap & CIFS_UNIX_POSIX_PATHNAMES_CAP) == 0) {
+				if (cap & CIFS_UNIX_POSIX_PATHNAMES_CAP)
+					cERROR(1, ("POSIXPATH support change"));
+				cap &= ~CIFS_UNIX_POSIX_PATHNAMES_CAP;
+			} else if ((cap & CIFS_UNIX_POSIX_PATHNAMES_CAP) == 0) {
+				cERROR(1, ("possible reconnect error"));
+				cERROR(1,
+					("server disabled POSIX path support"));
+			}
+		}
+
+		cap &= CIFS_UNIX_CAP_MASK;
+		if (vol_info && vol_info->no_psx_acl)
+			cap &= ~CIFS_UNIX_POSIX_ACL_CAP;
+		else if (CIFS_UNIX_POSIX_ACL_CAP & cap) {
+			cFYI(1, ("negotiated posix acl support"));
+			if (sb)
+				sb->s_flags |= MS_POSIXACL;
+		}
+
+		if (vol_info && vol_info->posix_paths == 0)
+			cap &= ~CIFS_UNIX_POSIX_PATHNAMES_CAP;
+		else if (cap & CIFS_UNIX_POSIX_PATHNAMES_CAP) {
+			cFYI(1, ("negotiate posix pathnames"));
+			if (sb)
+				CIFS_SB(sb)->mnt_cifs_flags |=
+					CIFS_MOUNT_POSIX_PATHS;
+		}
+
+		/* We might be setting the path sep back to a different
+		form if we are reconnecting and the server switched its
+		posix path capability for this share */
+		if (sb && (CIFS_SB(sb)->prepathlen > 0))
+			CIFS_SB(sb)->prepath[0] = CIFS_DIR_SEP(CIFS_SB(sb));
+
+		if (sb && (CIFS_SB(sb)->rsize > 127 * 1024)) {
+			if ((cap & CIFS_UNIX_LARGE_READ_CAP) == 0) {
+				CIFS_SB(sb)->rsize = 127 * 1024;
+				cFYI(DBG2,
+					("larger reads not supported by srv"));
+			}
+		}
+
+
+		cFYI(1, ("Negotiate caps 0x%x", (int)cap));
+#ifdef CONFIG_CIFS_DEBUG2
+		if (cap & CIFS_UNIX_FCNTL_CAP)
+			cFYI(1, ("FCNTL cap"));
+		if (cap & CIFS_UNIX_EXTATTR_CAP)
+			cFYI(1, ("EXTATTR cap"));
+		if (cap & CIFS_UNIX_POSIX_PATHNAMES_CAP)
+			cFYI(1, ("POSIX path cap"));
+		if (cap & CIFS_UNIX_XATTR_CAP)
+			cFYI(1, ("XATTR cap"));
+		if (cap & CIFS_UNIX_POSIX_ACL_CAP)
+			cFYI(1, ("POSIX ACL cap"));
+		if (cap & CIFS_UNIX_LARGE_READ_CAP)
+			cFYI(1, ("very large read cap"));
+		if (cap & CIFS_UNIX_LARGE_WRITE_CAP)
+			cFYI(1, ("very large write cap"));
+#endif /* CIFS_DEBUG2 */
+		if (CIFSSMBSetFSUnixInfo(xid, tcon, cap)) {
+			if (vol_info == NULL) {
+				cFYI(1, ("resetting capabilities failed"));
+			} else
+				cERROR(1, ("Negotiating Unix capabilities "
+					   "with the server failed.  Consider "
+					   "mounting with the Unix Extensions\n"
+					   "disabled, if problems are found, "
+					   "by specifying the nounix mount "
+					   "option."));
+
+		}
+	}
+}
+
+static void
+convert_delimiter(char *path, char delim)
+{
+	int i;
+	char old_delim;
+
+	if (path == NULL)
+		return;
+
+	if (delim == '/')
+		old_delim = '\\';
+	else
+		old_delim = '/';
+
+	for (i = 0; path[i] != '\0'; i++) {
+		if (path[i] == old_delim)
+			path[i] = delim;
+	}
+}
+
+static void setup_cifs_sb(struct smb_vol *pvolume_info,
+			  struct cifs_sb_info *cifs_sb)
+{
+	if (pvolume_info->rsize > CIFSMaxBufSize) {
+		cERROR(1, ("rsize %d too large, using MaxBufSize",
+			pvolume_info->rsize));
+		cifs_sb->rsize = CIFSMaxBufSize;
+	} else if ((pvolume_info->rsize) &&
+			(pvolume_info->rsize <= CIFSMaxBufSize))
+		cifs_sb->rsize = pvolume_info->rsize;
+	else /* default */
+		cifs_sb->rsize = CIFSMaxBufSize;
+
+	if (pvolume_info->wsize > PAGEVEC_SIZE * PAGE_CACHE_SIZE) {
+		cERROR(1, ("wsize %d too large, using 4096 instead",
+			  pvolume_info->wsize));
+		cifs_sb->wsize = 4096;
+	} else if (pvolume_info->wsize)
+		cifs_sb->wsize = pvolume_info->wsize;
+	else
+		cifs_sb->wsize = min_t(const int,
+					PAGEVEC_SIZE * PAGE_CACHE_SIZE,
+					127*1024);
+		/* old default of CIFSMaxBufSize was too small now
+		   that SMB Write2 can send multiple pages in kvec.
+		   RFC1001 does not describe what happens when frame
+		   bigger than 128K is sent so use that as max in
+		   conjunction with 52K kvec constraint on arch with 4K
+		   page size  */
+
+	if (cifs_sb->rsize < 2048) {
+		cifs_sb->rsize = 2048;
+		/* Windows ME may prefer this */
+		cFYI(1, ("readsize set to minimum: 2048"));
+	}
+	/* calculate prepath */
+	cifs_sb->prepath = pvolume_info->prepath;
+	if (cifs_sb->prepath) {
+		cifs_sb->prepathlen = strlen(cifs_sb->prepath);
+		/* we can not convert the / to \ in the path
+		separators in the prefixpath yet because we do not
+		know (until reset_cifs_unix_caps is called later)
+		whether POSIX PATH CAP is available. We normalize
+		the / to \ after reset_cifs_unix_caps is called */
+		pvolume_info->prepath = NULL;
+	} else
+		cifs_sb->prepathlen = 0;
+	cifs_sb->mnt_uid = pvolume_info->linux_uid;
+	cifs_sb->mnt_gid = pvolume_info->linux_gid;
+	cifs_sb->mnt_file_mode = pvolume_info->file_mode;
+	cifs_sb->mnt_dir_mode = pvolume_info->dir_mode;
+	cFYI(1, ("file mode: 0x%x  dir mode: 0x%x",
+		cifs_sb->mnt_file_mode, cifs_sb->mnt_dir_mode));
+
+	if (pvolume_info->noperm)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_PERM;
+	if (pvolume_info->setuids)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_SET_UID;
+	if (pvolume_info->server_ino)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_SERVER_INUM;
+	if (pvolume_info->remap)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_MAP_SPECIAL_CHR;
+	if (pvolume_info->no_xattr)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_XATTR;
+	if (pvolume_info->sfu_emul)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_UNX_EMUL;
+	if (pvolume_info->nobrl)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_BRL;
+	if (pvolume_info->nostrictsync)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NOSSYNC;
+	if (pvolume_info->mand_lock)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NOPOSIXBRL;
+	if (pvolume_info->cifs_acl)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_CIFS_ACL;
+	if (pvolume_info->override_uid)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_OVERR_UID;
+	if (pvolume_info->override_gid)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_OVERR_GID;
+	if (pvolume_info->dynperm)
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_DYNPERM;
+	if (pvolume_info->direct_io) {
+		cFYI(1, ("mounting share using direct i/o"));
+		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_DIRECT_IO;
+	}
+
+	if ((pvolume_info->cifs_acl) && (pvolume_info->dynperm))
+		cERROR(1, ("mount option dynperm ignored if cifsacl "
+			   "mount option supported"));
+}
+
+static int
+is_path_accessible(int xid, struct cifsTconInfo *tcon,
+		   struct cifs_sb_info *cifs_sb, const char *full_path)
+{
+	int rc;
+	__u64 inode_num;
+	FILE_ALL_INFO *pfile_info;
+
+	rc = CIFSGetSrvInodeNumber(xid, tcon, full_path, &inode_num,
+				   cifs_sb->local_nls,
+				   cifs_sb->mnt_cifs_flags &
+						CIFS_MOUNT_MAP_SPECIAL_CHR);
+	if (rc != -EOPNOTSUPP)
+		return rc;
+
+	pfile_info = kmalloc(sizeof(FILE_ALL_INFO), GFP_KERNEL);
+	if (pfile_info == NULL)
+		return -ENOMEM;
+
+	rc = CIFSSMBQPathInfo(xid, tcon, full_path, pfile_info,
+			      0 /* not legacy */, cifs_sb->local_nls,
+			      cifs_sb->mnt_cifs_flags &
+				CIFS_MOUNT_MAP_SPECIAL_CHR);
+	kfree(pfile_info);
+	return rc;
+}
+
+static void
+cleanup_volume_info(struct smb_vol **pvolume_info)
+{
+	struct smb_vol *volume_info;
+
+	if (!pvolume_info && !*pvolume_info)
+		return;
+
+	volume_info = *pvolume_info;
+	kzfree(volume_info->password);
+	kfree(volume_info->UNC);
+	kfree(volume_info->prepath);
+	kfree(volume_info);
+	*pvolume_info = NULL;
+	return;
+}
+
+#ifdef CONFIG_CIFS_DFS_UPCALL
+/* build_path_to_root returns full path to root when
+ * we do not have an exiting connection (tcon) */
+static char *
+build_unc_path_to_root(const struct smb_vol *volume_info,
+		const struct cifs_sb_info *cifs_sb)
+{
+	char *full_path;
+
+	int unc_len = strnlen(volume_info->UNC, MAX_TREE_SIZE + 1);
+	full_path = kmalloc(unc_len + cifs_sb->prepathlen + 1, GFP_KERNEL);
+	if (full_path == NULL)
+		return ERR_PTR(-ENOMEM);
+
+	strncpy(full_path, volume_info->UNC, unc_len);
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS) {
+		int i;
+		for (i = 0; i < unc_len; i++) {
+			if (full_path[i] == '\\')
+				full_path[i] = '/';
+		}
+	}
+
+	if (cifs_sb->prepathlen)
+		strncpy(full_path + unc_len, cifs_sb->prepath,
+				cifs_sb->prepathlen);
+
+	full_path[unc_len + cifs_sb->prepathlen] = 0; /* add trailing null */
+	return full_path;
+}
+#endif
+
+int
+cifs_mount(struct super_block *sb, struct cifs_sb_info *cifs_sb,
+		char *mount_data_global, const char *devname)
+{
+	int rc = 0;
+	int xid;
+	struct smb_vol *volume_info;
+	struct cifsSesInfo *pSesInfo = NULL;
+	struct cifsTconInfo *tcon = NULL;
+	struct TCP_Server_Info *srvTcp = NULL;
+	char   *full_path;
+	char *mount_data = mount_data_global;
+#ifdef CONFIG_CIFS_DFS_UPCALL
+	struct dfs_info3_param *referrals = NULL;
+	unsigned int num_referrals = 0;
+	int referral_walks_count = 0;
+try_mount_again:
+#endif
+	full_path = NULL;
+
+	xid = GetXid();
+
+	volume_info = kzalloc(sizeof(struct smb_vol), GFP_KERNEL);
+	if (!volume_info) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	if (cifs_parse_mount_options(mount_data, devname, volume_info)) {
+		rc = -EINVAL;
+		goto out;
+	}
+
+	if (volume_info->nullauth) {
+		cFYI(1, ("null user"));
+		volume_info->username = "";
+	} else if (volume_info->username) {
+		/* BB fixme parse for domain name here */
+		cFYI(1, ("Username: %s", volume_info->username));
+	} else {
+		cifserror("No username specified");
+	/* In userspace mount helper we can get user name from alternate
+	   locations such as env variables and files on disk */
+		rc = -EINVAL;
+		goto out;
+	}
+
+
+	/* this is needed for ASCII cp to Unicode converts */
+	if (volume_info->iocharset == NULL) {
+		cifs_sb->local_nls = load_nls_default();
+	/* load_nls_default can not return null */
+	} else {
+		cifs_sb->local_nls = load_nls(volume_info->iocharset);
+		if (cifs_sb->local_nls == NULL) {
+			cERROR(1, ("CIFS mount error: iocharset %s not found",
+				 volume_info->iocharset));
+			rc = -ELIBACC;
+			goto out;
+		}
+	}
+
+	/* get a reference to a tcp session */
+	srvTcp = cifs_get_tcp_session(volume_info);
+	if (IS_ERR(srvTcp)) {
+		rc = PTR_ERR(srvTcp);
+		goto out;
+	}
+
+	pSesInfo = cifs_find_smb_ses(srvTcp, volume_info->username);
+	if (pSesInfo) {
+		cFYI(1, ("Existing smb sess found (status=%d)",
+			pSesInfo->status));
+		/*
+		 * The existing SMB session already has a reference to srvTcp,
+		 * so we can put back the extra one we got before
+		 */
+		cifs_put_tcp_session(srvTcp);
+
+		down(&pSesInfo->sesSem);
+		if (pSesInfo->need_reconnect) {
+			cFYI(1, ("Session needs reconnect"));
+			rc = cifs_setup_session(xid, pSesInfo,
+						cifs_sb->local_nls);
+		}
+		up(&pSesInfo->sesSem);
+	} else if (!rc) {
+		cFYI(1, ("Existing smb sess not found"));
+		pSesInfo = sesInfoAlloc();
+		if (pSesInfo == NULL) {
+			rc = -ENOMEM;
+			goto mount_fail_check;
+		}
+
+		/* new SMB session uses our srvTcp ref */
+		pSesInfo->server = srvTcp;
+		if (srvTcp->addr.sockAddr6.sin6_family == AF_INET6)
+			sprintf(pSesInfo->serverName, "%pI6",
+				&srvTcp->addr.sockAddr6.sin6_addr);
+		else
+			sprintf(pSesInfo->serverName, "%pI4",
+				&srvTcp->addr.sockAddr.sin_addr.s_addr);
+
+		write_lock(&cifs_tcp_ses_lock);
+		list_add(&pSesInfo->smb_ses_list, &srvTcp->smb_ses_list);
+		write_unlock(&cifs_tcp_ses_lock);
+
+		/* volume_info->password freed at unmount */
+		if (volume_info->password) {
+			pSesInfo->password = kstrdup(volume_info->password,
+						     GFP_KERNEL);
+			if (!pSesInfo->password) {
+				rc = -ENOMEM;
+				goto mount_fail_check;
+			}
+		}
+		if (volume_info->username)
+			strncpy(pSesInfo->userName, volume_info->username,
+				MAX_USERNAME_SIZE);
+		if (volume_info->domainname) {
+			int len = strlen(volume_info->domainname);
+			pSesInfo->domainName = kmalloc(len + 1, GFP_KERNEL);
+			if (pSesInfo->domainName)
+				strcpy(pSesInfo->domainName,
+					volume_info->domainname);
+		}
+		pSesInfo->linux_uid = volume_info->linux_uid;
+		pSesInfo->overrideSecFlg = volume_info->secFlg;
+		down(&pSesInfo->sesSem);
+
+		/* BB FIXME need to pass vol->secFlgs BB */
+		rc = cifs_setup_session(xid, pSesInfo,
+					cifs_sb->local_nls);
+		up(&pSesInfo->sesSem);
+	}
+
+	/* search for existing tcon to this server share */
+	if (!rc) {
+		setup_cifs_sb(volume_info, cifs_sb);
+
+		tcon = cifs_find_tcon(pSesInfo, volume_info->UNC);
+		if (tcon) {
+			cFYI(1, ("Found match on UNC path"));
+			/* existing tcon already has a reference */
+			cifs_put_smb_ses(pSesInfo);
+			if (tcon->seal != volume_info->seal)
+				cERROR(1, ("transport encryption setting "
+					   "conflicts with existing tid"));
+		} else {
+			tcon = tconInfoAlloc();
+			if (tcon == NULL) {
+				rc = -ENOMEM;
+				goto mount_fail_check;
+			}
+
+			tcon->ses = pSesInfo;
+			if (volume_info->password) {
+				tcon->password = kstrdup(volume_info->password,
+							 GFP_KERNEL);
+				if (!tcon->password) {
+					rc = -ENOMEM;
+					goto mount_fail_check;
+				}
+			}
+
+			if ((strchr(volume_info->UNC + 3, '\\') == NULL)
+			    && (strchr(volume_info->UNC + 3, '/') == NULL)) {
+				cERROR(1, ("Missing share name"));
+				rc = -ENODEV;
+				goto mount_fail_check;
+			} else {
+				/* BB Do we need to wrap sesSem around
+				 * this TCon call and Unix SetFS as
+				 * we do on SessSetup and reconnect? */
+				rc = CIFSTCon(xid, pSesInfo, volume_info->UNC,
+					      tcon, cifs_sb->local_nls);
+				cFYI(1, ("CIFS Tcon rc = %d", rc));
+				if (volume_info->nodfs) {
+					tcon->Flags &= ~SMB_SHARE_IS_IN_DFS;
+					cFYI(1, ("DFS disabled (%d)",
+						tcon->Flags));
+				}
+			}
+			if (rc)
+				goto remote_path_check;
+			tcon->seal = volume_info->seal;
+			write_lock(&cifs_tcp_ses_lock);
+			list_add(&tcon->tcon_list, &pSesInfo->tcon_list);
+			write_unlock(&cifs_tcp_ses_lock);
+		}
+
+		/* we can have only one retry value for a connection
+		   to a share so for resources mounted more than once
+		   to the same server share the last value passed in
+		   for the retry flag is used */
+		tcon->retry = volume_info->retry;
+		tcon->nocase = volume_info->nocase;
+		tcon->local_lease = volume_info->local_lease;
+	}
+	if (pSesInfo) {
+		if (pSesInfo->capabilities & CAP_LARGE_FILES) {
+			sb->s_maxbytes = (u64) 1 << 63;
+		} else
+			sb->s_maxbytes = (u64) 1 << 31;	/* 2 GB */
+	}
+
+	/* BB FIXME fix time_gran to be larger for LANMAN sessions */
+	sb->s_time_gran = 100;
+
+	if (rc)
+		goto remote_path_check;
+
+	cifs_sb->tcon = tcon;
+
+	/* do not care if following two calls succeed - informational */
+	if (!tcon->ipc) {
+		CIFSSMBQFSDeviceInfo(xid, tcon);
+		CIFSSMBQFSAttributeInfo(xid, tcon);
+	}
+
+	/* tell server which Unix caps we support */
+	if (tcon->ses->capabilities & CAP_UNIX)
+		/* reset of caps checks mount to see if unix extensions
+		   disabled for just this mount */
+		reset_cifs_unix_caps(xid, tcon, sb, volume_info);
+	else
+		tcon->unix_ext = 0; /* server does not support them */
+
+	/* convert forward to back slashes in prepath here if needed */
+	if ((cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS) == 0)
+		convert_delimiter(cifs_sb->prepath, CIFS_DIR_SEP(cifs_sb));
+
+	if ((tcon->unix_ext == 0) && (cifs_sb->rsize > (1024 * 127))) {
+		cifs_sb->rsize = 1024 * 127;
+		cFYI(DBG2, ("no very large read support, rsize now 127K"));
+	}
+	if (!(tcon->ses->capabilities & CAP_LARGE_WRITE_X))
+		cifs_sb->wsize = min(cifs_sb->wsize,
+			       (tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE));
+	if (!(tcon->ses->capabilities & CAP_LARGE_READ_X))
+		cifs_sb->rsize = min(cifs_sb->rsize,
+			       (tcon->ses->server->maxBuf - MAX_CIFS_HDR_SIZE));
+
+remote_path_check:
+	/* check if a whole path (including prepath) is not remote */
+	if (!rc && cifs_sb->prepathlen && tcon) {
+		/* build_path_to_root works only when we have a valid tcon */
+		full_path = cifs_build_path_to_root(cifs_sb);
+		if (full_path == NULL) {
+			rc = -ENOMEM;
+			goto mount_fail_check;
+		}
+		rc = is_path_accessible(xid, tcon, cifs_sb, full_path);
+		if (rc != -EREMOTE) {
+			kfree(full_path);
+			goto mount_fail_check;
+		}
+		kfree(full_path);
+	}
+
+	/* get referral if needed */
+	if (rc == -EREMOTE) {
+#ifdef CONFIG_CIFS_DFS_UPCALL
+		if (referral_walks_count > MAX_NESTED_LINKS) {
+			/*
+			 * BB: when we implement proper loop detection,
+			 *     we will remove this check. But now we need it
+			 *     to prevent an indefinite loop if 'DFS tree' is
+			 *     misconfigured (i.e. has loops).
+			 */
+			rc = -ELOOP;
+			goto mount_fail_check;
+		}
+		/* convert forward to back slashes in prepath here if needed */
+		if ((cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS) == 0)
+			convert_delimiter(cifs_sb->prepath,
+					CIFS_DIR_SEP(cifs_sb));
+		full_path = build_unc_path_to_root(volume_info, cifs_sb);
+		if (IS_ERR(full_path)) {
+			rc = PTR_ERR(full_path);
+			goto mount_fail_check;
+		}
+
+		cFYI(1, ("Getting referral for: %s", full_path));
+		rc = get_dfs_path(xid, pSesInfo , full_path + 1,
+			cifs_sb->local_nls, &num_referrals, &referrals,
+			cifs_sb->mnt_cifs_flags & CIFS_MOUNT_MAP_SPECIAL_CHR);
+		if (!rc && num_referrals > 0) {
+			char *fake_devname = NULL;
+
+			if (mount_data != mount_data_global)
+				kfree(mount_data);
+			mount_data = cifs_compose_mount_options(
+					cifs_sb->mountdata, full_path + 1,
+					referrals, &fake_devname);
+			kfree(fake_devname);
+			free_dfs_info_array(referrals, num_referrals);
+
+			if (tcon)
+				cifs_put_tcon(tcon);
+			else if (pSesInfo)
+				cifs_put_smb_ses(pSesInfo);
+
+			cleanup_volume_info(&volume_info);
+			FreeXid(xid);
+			kfree(full_path);
+			referral_walks_count++;
+			goto try_mount_again;
+		}
+#else /* No DFS support, return error on mount */
+		rc = -EOPNOTSUPP;
+#endif
+	}
+
+mount_fail_check:
+	/* on error free sesinfo and tcon struct if needed */
+	if (rc) {
+		if (mount_data != mount_data_global)
+			kfree(mount_data);
+		/* If find_unc succeeded then rc == 0 so we can not end */
+		/* up accidently freeing someone elses tcon struct */
+		if (tcon)
+			cifs_put_tcon(tcon);
+		else if (pSesInfo)
+			cifs_put_smb_ses(pSesInfo);
+		else
+			cifs_put_tcp_session(srvTcp);
+		goto out;
+	}
+
+	/* volume_info->password is freed above when existing session found
+	(in which case it is not needed anymore) but when new sesion is created
+	the password ptr is put in the new session structure (in which case the
+	password will be freed at unmount time) */
+out:
+	/* zero out password before freeing */
+	cleanup_volume_info(&volume_info);
+	FreeXid(xid);
+	return rc;
+}
+
+int
+CIFSTCon(unsigned int xid, struct cifsSesInfo *ses,
+	 const char *tree, struct cifsTconInfo *tcon,
+	 const struct nls_table *nls_codepage)
+{
+	struct smb_hdr *smb_buffer;
+	struct smb_hdr *smb_buffer_response;
+	TCONX_REQ *pSMB;
+	TCONX_RSP *pSMBr;
+	unsigned char *bcc_ptr;
+	int rc = 0;
+	int length, bytes_left;
+	__u16 count;
+
+	if (ses == NULL)
+		return -EIO;
+
+	smb_buffer = cifs_buf_get();
+	if (smb_buffer == NULL) {
+		return -ENOMEM;
+	}
+	smb_buffer_response = smb_buffer;
+
+	header_assemble(smb_buffer, SMB_COM_TREE_CONNECT_ANDX,
+			NULL /*no tid */ , 4 /*wct */ );
+
+	smb_buffer->Mid = GetNextMid(ses->server);
+	smb_buffer->Uid = ses->Suid;
+	pSMB = (TCONX_REQ *) smb_buffer;
+	pSMBr = (TCONX_RSP *) smb_buffer_response;
+
+	pSMB->AndXCommand = 0xFF;
+	pSMB->Flags = cpu_to_le16(TCON_EXTENDED_SECINFO);
+	bcc_ptr = &pSMB->Password[0];
+	if ((ses->server->secMode) & SECMODE_USER) {
+		pSMB->PasswordLength = cpu_to_le16(1);	/* minimum */
+		*bcc_ptr = 0; /* password is null byte */
+		bcc_ptr++;              /* skip password */
+		/* already aligned so no need to do it below */
+	} else {
+		pSMB->PasswordLength = cpu_to_le16(CIFS_SESS_KEY_SIZE);
+		/* BB FIXME add code to fail this if NTLMv2 or Kerberos
+		   specified as required (when that support is added to
+		   the vfs in the future) as only NTLM or the much
+		   weaker LANMAN (which we do not send by default) is accepted
+		   by Samba (not sure whether other servers allow
+		   NTLMv2 password here) */
+#ifdef CONFIG_CIFS_WEAK_PW_HASH
+		if ((extended_security & CIFSSEC_MAY_LANMAN) &&
+		    (ses->server->secType == LANMAN))
+			calc_lanman_hash(tcon->password, ses->server->cryptKey,
+					 ses->server->secMode &
+					    SECMODE_PW_ENCRYPT ? true : false,
+					 bcc_ptr);
+		else
+#endif /* CIFS_WEAK_PW_HASH */
+		SMBNTencrypt(tcon->password, ses->server->cryptKey,
+			     bcc_ptr);
+
+		bcc_ptr += CIFS_SESS_KEY_SIZE;
+		if (ses->capabilities & CAP_UNICODE) {
+			/* must align unicode strings */
+			*bcc_ptr = 0; /* null byte password */
+			bcc_ptr++;
+		}
+	}
+
+	if (ses->server->secMode &
+			(SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED))
+		smb_buffer->Flags2 |= SMBFLG2_SECURITY_SIGNATURE;
+
+	if (ses->capabilities & CAP_STATUS32) {
+		smb_buffer->Flags2 |= SMBFLG2_ERR_STATUS;
+	}
+	if (ses->capabilities & CAP_DFS) {
+		smb_buffer->Flags2 |= SMBFLG2_DFS;
+	}
+	if (ses->capabilities & CAP_UNICODE) {
+		smb_buffer->Flags2 |= SMBFLG2_UNICODE;
+		length =
+		    cifs_strtoUCS((__le16 *) bcc_ptr, tree,
+			6 /* max utf8 char length in bytes */ *
+			(/* server len*/ + 256 /* share len */), nls_codepage);
+		bcc_ptr += 2 * length;	/* convert num 16 bit words to bytes */
+		bcc_ptr += 2;	/* skip trailing null */
+	} else {		/* ASCII */
+		strcpy(bcc_ptr, tree);
+		bcc_ptr += strlen(tree) + 1;
+	}
+	strcpy(bcc_ptr, "?????");
+	bcc_ptr += strlen("?????");
+	bcc_ptr += 1;
+	count = bcc_ptr - &pSMB->Password[0];
+	pSMB->hdr.smb_buf_length += count;
+	pSMB->ByteCount = cpu_to_le16(count);
+
+	rc = SendReceive(xid, ses, smb_buffer, smb_buffer_response, &length,
+			 CIFS_STD_OP);
+
+	/* above now done in SendReceive */
+	if ((rc == 0) && (tcon != NULL)) {
+		bool is_unicode;
+
+		tcon->tidStatus = CifsGood;
+		tcon->need_reconnect = false;
+		tcon->tid = smb_buffer_response->Tid;
+		bcc_ptr = pByteArea(smb_buffer_response);
+		bytes_left = BCC(smb_buffer_response);
+		length = strnlen(bcc_ptr, bytes_left - 2);
+		if (smb_buffer->Flags2 & SMBFLG2_UNICODE)
+			is_unicode = true;
+		else
+			is_unicode = false;
+
+
+		/* skip service field (NB: this field is always ASCII) */
+		if (length == 3) {
+			if ((bcc_ptr[0] == 'I') && (bcc_ptr[1] == 'P') &&
+			    (bcc_ptr[2] == 'C')) {
+				cFYI(1, ("IPC connection"));
+				tcon->ipc = 1;
+			}
+		} else if (length == 2) {
+			if ((bcc_ptr[0] == 'A') && (bcc_ptr[1] == ':')) {
+				/* the most common case */
+				cFYI(1, ("disk share connection"));
+			}
+		}
+		bcc_ptr += length + 1;
+		bytes_left -= (length + 1);
+		strncpy(tcon->treeName, tree, MAX_TREE_SIZE);
+
+		/* mostly informational -- no need to fail on error here */
+		tcon->nativeFileSystem = cifs_strndup_from_ucs(bcc_ptr,
+						      bytes_left, is_unicode,
+						      nls_codepage);
+
+		cFYI(1, ("nativeFileSystem=%s", tcon->nativeFileSystem));
+
+		if ((smb_buffer_response->WordCount == 3) ||
+			 (smb_buffer_response->WordCount == 7))
+			/* field is in same location */
+			tcon->Flags = le16_to_cpu(pSMBr->OptionalSupport);
+		else
+			tcon->Flags = 0;
+		cFYI(1, ("Tcon flags: 0x%x ", tcon->Flags));
+	} else if ((rc == 0) && tcon == NULL) {
+		/* all we need to save for IPC$ connection */
+		ses->ipc_tid = smb_buffer_response->Tid;
+	}
+
+	cifs_buf_release(smb_buffer);
+	return rc;
+}
+
+int
+cifs_umount(struct super_block *sb, struct cifs_sb_info *cifs_sb)
+{
+	int rc = 0;
+	char *tmp;
+
+	if (cifs_sb->tcon)
+		cifs_put_tcon(cifs_sb->tcon);
+
+	cifs_sb->tcon = NULL;
+	tmp = cifs_sb->prepath;
+	cifs_sb->prepathlen = 0;
+	cifs_sb->prepath = NULL;
+	kfree(tmp);
+
+	return rc;
+}
+
+int cifs_setup_session(unsigned int xid, struct cifsSesInfo *pSesInfo,
+					   struct nls_table *nls_info)
+{
+	int rc = 0;
+	int first_time = 0;
+	struct TCP_Server_Info *server = pSesInfo->server;
+
+	/* what if server changes its buffer size after dropping the session? */
+	if (server->maxBuf == 0) /* no need to send on reconnect */ {
+		rc = CIFSSMBNegotiate(xid, pSesInfo);
+		if (rc == -EAGAIN) {
+			/* retry only once on 1st time connection */
+			rc = CIFSSMBNegotiate(xid, pSesInfo);
+			if (rc == -EAGAIN)
+				rc = -EHOSTDOWN;
+		}
+		if (rc == 0) {
+			spin_lock(&GlobalMid_Lock);
+			if (server->tcpStatus != CifsExiting)
+				server->tcpStatus = CifsGood;
+			else
+				rc = -EHOSTDOWN;
+			spin_unlock(&GlobalMid_Lock);
+
+		}
+		first_time = 1;
+	}
+
+	if (rc)
+		goto ss_err_exit;
+
+	pSesInfo->flags = 0;
+	pSesInfo->capabilities = server->capabilities;
+	if (linuxExtEnabled == 0)
+		pSesInfo->capabilities &= (~CAP_UNIX);
+
+	cFYI(1, ("Security Mode: 0x%x Capabilities: 0x%x TimeAdjust: %d",
+		 server->secMode, server->capabilities, server->timeAdj));
+
+	rc = CIFS_SessSetup(xid, pSesInfo, first_time, nls_info);
+	if (rc) {
+		cERROR(1, ("Send error in SessSetup = %d", rc));
+	} else {
+		cFYI(1, ("CIFS Session Established successfully"));
+		spin_lock(&GlobalMid_Lock);
+		pSesInfo->status = CifsGood;
+		pSesInfo->need_reconnect = false;
+		spin_unlock(&GlobalMid_Lock);
+	}
+
+ss_err_exit:
+	return rc;
+}
+
diff -Naur linux-2.6.30-ori/fs/cifs/file.c linux-2.6.30-test/fs/cifs/file.c
--- linux-2.6.30-ori/fs/cifs/file.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/file.c	2009-06-12 18:32:43.000000000 -0400
@@ -39,6 +39,9 @@
 #include "cifs_debug.h"
 #include "cifs_fs_sb.h"
 
+// JFT Test
+extern long long em86_stats[20];
+
 static inline struct cifsFileInfo *cifs_init_private(
 	struct cifsFileInfo *private_data, struct inode *inode,
 	struct file *file, __u16 netfid)
@@ -1832,7 +1835,7 @@
 					 open_file->netfid,
 					 current_read_size, *poffset,
 					 &bytes_read, &smb_read_data,
-					 &buf_type);
+					 &buf_type, 0);
 			pSMBr = (struct smb_com_read_rsp *)smb_read_data;
 			if (smb_read_data) {
 				if (copy_to_user(current_offset,
@@ -1917,7 +1920,7 @@
 					 open_file->netfid,
 					 current_read_size, *poffset,
 					 &bytes_read, &current_offset,
-					 &buf_type);
+					 &buf_type, 0);
 		}
 		if (rc || (bytes_read == 0)) {
 			if (total_read) {
@@ -1952,6 +1955,185 @@
 	return rc;
 }
 
+#ifdef CIFS_NEW_READPAGES
+
+static int cifs_send_readpages(struct cifs_readpages_data *data)
+{
+	int rc;
+	int bogus_nbytes; /* FIXME CIFSSMBRead expects non-null nbytes arg */
+	struct cifsTconInfo *pTcon;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsFileInfo *open_file;
+	unsigned int read_size;
+	loff_t offset;
+
+	open_file = (struct cifsFileInfo *)data->file->private_data;
+	cifs_sb = CIFS_SB(data->file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+	read_size = data->nr_pages * PAGE_CACHE_SIZE;
+	offset = ((loff_t)data->pages[0]->index) << PAGE_CACHE_SHIFT;
+
+	rc = CIFSSMBRead(data->xid, pTcon, open_file->netfid, read_size,
+			offset, &bogus_nbytes, (char **)&data, 
+			NULL, 1 /* async flag */);
+	return rc;
+}
+
+/**
+ * is_response_received - check whether one or more responses came in
+ *
+ * The routine inspects the state of each of midQ entries that we wait for.
+ * Returns 1 if there is an entry in the data->midq_list that has changed 
+ * its state from MID_REQUEST_SUBMITTED.
+ * Returns 0, otherwise.
+ */
+static inline int is_response_received(struct cifs_readpages_data *data,
+		struct mid_q_entry **midQ_recv)
+{
+	struct mid_q_entry *midQ = NULL;
+
+	list_for_each_entry_reverse(midQ, &data->midq_list, midq_entry) {
+		dprintk("INFO: MIDQ mid=%d, state=%d\n",
+				midQ->mid, midQ->midState);
+		if (midQ->midState != MID_REQUEST_SUBMITTED) {
+			*midQ_recv = midQ;
+			return 1;
+		}
+	}
+	return 0;
+}
+
+static int wait_for_multiple_responses(struct cifsSesInfo *ses,
+		struct cifs_readpages_data *data)
+{
+	int timeout = 30 * HZ; /* FIXME: is that value good enough? */
+	int ret;
+	struct mid_q_entry *midQ = NULL;
+	READ_RSP *pSMBr = NULL;
+	int bytes_read;
+	char *dst, *src;
+	int i;
+
+	dprintk("NOTICE: wait_for_multiple_responses: in\n");
+	
+	while (!list_empty(&data->midq_list)) {
+		ret = wait_event_timeout(ses->server->response_q,
+				is_response_received(data, &midQ),
+				timeout);
+		if (ret == 0)
+			goto timeout;
+
+		if (midQ == NULL || midQ->resp_buf == NULL || 
+				midQ->midState != MID_RESPONSE_RECEIVED) {
+			dprintk("WARNING: bad mid state\n");
+			goto out;
+		}
+		dprintk("NOTICE: GOT MIDQ: mid=%d\n",
+				midQ->mid);
+		pSMBr = (READ_RSP *)midQ->resp_buf;
+		bytes_read = (le16_to_cpu(pSMBr->DataLengthHigh) << 16) +
+			le16_to_cpu(pSMBr->DataLength);
+		if (bytes_read > midQ->nr_pages * PAGE_CACHE_SIZE) {
+			dprintk("WARNING: response too big, bytes_read = %d\n",
+					bytes_read);
+			goto out;
+		}
+		i = 0;
+		src = (char *)pSMBr + 4 + le16_to_cpu(pSMBr->DataOffset);
+		while (bytes_read > 0) {
+			struct page *page = midQ->pages[i];
+			dst = kmap_atomic(page, KM_USER0);
+			if (PAGE_CACHE_SIZE > bytes_read) {
+				memcpy(dst, src, bytes_read);
+				/* zero the tail end of this partial page */
+				em86_stats[15]+=PAGE_CACHE_SIZE - bytes_read;
+				memset(dst + bytes_read, 0,
+						PAGE_CACHE_SIZE - bytes_read);
+				bytes_read = 0;
+			} else {
+				memcpy(dst, src, PAGE_CACHE_SIZE);
+				bytes_read -= PAGE_CACHE_SIZE;
+			}
+			kunmap_atomic(dst, KM_USER0);
+			flush_dcache_page(page);
+			SetPageUptodate(page);
+			unlock_page(page);
+			i++;
+			src += PAGE_CACHE_SIZE;
+		}
+out:
+		list_del(&midQ->midq_entry);
+		DeleteMidQEntry(midQ);
+		atomic_dec(&ses->server->inFlight);
+		wake_up(&ses->server->request_q);
+	}
+
+	return 0;
+
+timeout:
+	/* FIXME: How do we handle that ? */
+	dprintk("WARNING: wait_for_multiple_responses: timeout occurred\n");
+	return -EIO;
+}
+
+static int cifs_readpages_filler(void *_data, struct page *page)
+{
+	struct cifs_readpages_data *data = _data;
+	struct cifs_sb_info *cifs_sb;
+	int rc;
+
+	cifs_sb = CIFS_SB(data->file->f_path.dentry->d_sb);
+
+	if (data->nr_pages > 0 &&
+		(data->nr_pages == CIFS_READPAGES_MAX ||
+		 (data->nr_pages + 1) * PAGE_CACHE_SIZE > cifs_sb->rsize ||
+		 data->pages[data->nr_pages - 1]->index + 1 != page->index)) {
+		rc = cifs_send_readpages(data);
+		data->nr_pages = 0;
+		if (rc)
+			return rc;
+	}
+	data->pages[data->nr_pages] = page;
+	data->nr_pages++;
+	return 0;
+}
+
+static int cifs_readpages(struct file *file, struct address_space *mapping,
+	struct list_head *pages, unsigned nr_pages)
+{
+	int rc = -EACCES;
+	int xid;
+	struct cifs_readpages_data data;
+	struct cifsTconInfo *pTcon;
+	struct cifs_sb_info *cifs_sb;
+
+	dprintk("cifs_readpages: file=%p, nr_pages = %d\n", file, nr_pages);
+	xid = GetXid();
+	if (file->private_data == NULL) {
+		rc = -EBADF;
+		goto out;
+	}
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+	INIT_LIST_HEAD(&data.midq_list);
+	data.xid = xid;
+	data.file = file;
+	data.nr_pages = 0;
+
+	rc = read_cache_pages(mapping, pages, cifs_readpages_filler, &data);
+	if (!rc && data.nr_pages > 0) {
+		rc = cifs_send_readpages(&data);
+	}
+
+	rc = wait_for_multiple_responses(pTcon->ses, &data);
+
+out:
+	FreeXid(xid);
+	return rc;
+}
+
+#else
 
 static void cifs_copy_cache_pages(struct address_space *mapping,
 	struct list_head *pages, int bytes_read, char *data,
@@ -1981,6 +2163,7 @@
 		if (PAGE_CACHE_SIZE > bytes_read) {
 			memcpy(target, data, bytes_read);
 			/* zero the tail end of this partial page */
+			em86_stats[15]+=PAGE_CACHE_SIZE - bytes_read;
 			memset(target + bytes_read, 0,
 			       PAGE_CACHE_SIZE - bytes_read);
 			bytes_read = 0;
@@ -2075,7 +2258,7 @@
 					 open_file->netfid,
 					 read_size, offset,
 					 &bytes_read, &smb_read_data,
-					 &buf_type);
+					 &buf_type, 0);
 			/* BB more RC checks ? */
 			if (rc == -EAGAIN) {
 				if (smb_read_data) {
@@ -2143,6 +2326,8 @@
 	return rc;
 }
 
+#endif
+
 static int cifs_readpage_worker(struct file *file, struct page *page,
 	loff_t *poffset)
 {
@@ -2164,8 +2349,10 @@
 		current_fs_time(file->f_path.dentry->d_inode->i_sb);
 
 	if (PAGE_CACHE_SIZE > rc)
+	{
+		em86_stats[15]+=PAGE_CACHE_SIZE - rc;
 		memset(read_data + rc, 0, PAGE_CACHE_SIZE - rc);
-
+    }
 	flush_dcache_page(page);
 	SetPageUptodate(page);
 	rc = 0;
diff -Naur linux-2.6.30-ori/fs/cifs/file.c.orig linux-2.6.30-test/fs/cifs/file.c.orig
--- linux-2.6.30-ori/fs/cifs/file.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/file.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,2350 @@
+/*
+ *   fs/cifs/file.c
+ *
+ *   vfs operations that deal with files
+ *
+ *   Copyright (C) International Business Machines  Corp., 2002,2007
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *              Jeremy Allison (jra@samba.org)
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+#include <linux/fs.h>
+#include <linux/backing-dev.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/pagemap.h>
+#include <linux/pagevec.h>
+#include <linux/writeback.h>
+#include <linux/task_io_accounting_ops.h>
+#include <linux/delay.h>
+#include <asm/div64.h>
+#include "cifsfs.h"
+#include "cifspdu.h"
+#include "cifsglob.h"
+#include "cifsproto.h"
+#include "cifs_unicode.h"
+#include "cifs_debug.h"
+#include "cifs_fs_sb.h"
+
+static inline struct cifsFileInfo *cifs_init_private(
+	struct cifsFileInfo *private_data, struct inode *inode,
+	struct file *file, __u16 netfid)
+{
+	memset(private_data, 0, sizeof(struct cifsFileInfo));
+	private_data->netfid = netfid;
+	private_data->pid = current->tgid;
+	mutex_init(&private_data->fh_mutex);
+	mutex_init(&private_data->lock_mutex);
+	INIT_LIST_HEAD(&private_data->llist);
+	private_data->pfile = file; /* needed for writepage */
+	private_data->pInode = inode;
+	private_data->invalidHandle = false;
+	private_data->closePend = false;
+	/* we have to track num writers to the inode, since writepages
+	does not tell us which handle the write is for so there can
+	be a close (overlapping with write) of the filehandle that
+	cifs_writepages chose to use */
+	atomic_set(&private_data->wrtPending, 0);
+
+	return private_data;
+}
+
+static inline int cifs_convert_flags(unsigned int flags)
+{
+	if ((flags & O_ACCMODE) == O_RDONLY)
+		return GENERIC_READ;
+	else if ((flags & O_ACCMODE) == O_WRONLY)
+		return GENERIC_WRITE;
+	else if ((flags & O_ACCMODE) == O_RDWR) {
+		/* GENERIC_ALL is too much permission to request
+		   can cause unnecessary access denied on create */
+		/* return GENERIC_ALL; */
+		return (GENERIC_READ | GENERIC_WRITE);
+	}
+
+	return (READ_CONTROL | FILE_WRITE_ATTRIBUTES | FILE_READ_ATTRIBUTES |
+		FILE_WRITE_EA | FILE_APPEND_DATA | FILE_WRITE_DATA |
+		FILE_READ_DATA);
+}
+
+static inline fmode_t cifs_posix_convert_flags(unsigned int flags)
+{
+	fmode_t posix_flags = 0;
+
+	if ((flags & O_ACCMODE) == O_RDONLY)
+		posix_flags = FMODE_READ;
+	else if ((flags & O_ACCMODE) == O_WRONLY)
+		posix_flags = FMODE_WRITE;
+	else if ((flags & O_ACCMODE) == O_RDWR) {
+		/* GENERIC_ALL is too much permission to request
+		   can cause unnecessary access denied on create */
+		/* return GENERIC_ALL; */
+		posix_flags = FMODE_READ | FMODE_WRITE;
+	}
+	/* can not map O_CREAT or O_EXCL or O_TRUNC flags when
+	   reopening a file.  They had their effect on the original open */
+	if (flags & O_APPEND)
+		posix_flags |= (fmode_t)O_APPEND;
+	if (flags & O_SYNC)
+		posix_flags |= (fmode_t)O_SYNC;
+	if (flags & O_DIRECTORY)
+		posix_flags |= (fmode_t)O_DIRECTORY;
+	if (flags & O_NOFOLLOW)
+		posix_flags |= (fmode_t)O_NOFOLLOW;
+	if (flags & O_DIRECT)
+		posix_flags |= (fmode_t)O_DIRECT;
+
+	return posix_flags;
+}
+
+static inline int cifs_get_disposition(unsigned int flags)
+{
+	if ((flags & (O_CREAT | O_EXCL)) == (O_CREAT | O_EXCL))
+		return FILE_CREATE;
+	else if ((flags & (O_CREAT | O_TRUNC)) == (O_CREAT | O_TRUNC))
+		return FILE_OVERWRITE_IF;
+	else if ((flags & O_CREAT) == O_CREAT)
+		return FILE_OPEN_IF;
+	else if ((flags & O_TRUNC) == O_TRUNC)
+		return FILE_OVERWRITE;
+	else
+		return FILE_OPEN;
+}
+
+/* all arguments to this function must be checked for validity in caller */
+static inline int cifs_posix_open_inode_helper(struct inode *inode,
+			struct file *file, struct cifsInodeInfo *pCifsInode,
+			struct cifsFileInfo *pCifsFile, int oplock, u16 netfid)
+{
+
+	write_lock(&GlobalSMBSeslock);
+
+	pCifsInode = CIFS_I(file->f_path.dentry->d_inode);
+	if (pCifsInode == NULL) {
+		write_unlock(&GlobalSMBSeslock);
+		return -EINVAL;
+	}
+
+	if (pCifsInode->clientCanCacheRead) {
+		/* we have the inode open somewhere else
+		   no need to discard cache data */
+		goto psx_client_can_cache;
+	}
+
+	/* BB FIXME need to fix this check to move it earlier into posix_open
+	   BB  fIX following section BB FIXME */
+
+	/* if not oplocked, invalidate inode pages if mtime or file
+	   size changed */
+/*	temp = cifs_NTtimeToUnix(le64_to_cpu(buf->LastWriteTime));
+	if (timespec_equal(&file->f_path.dentry->d_inode->i_mtime, &temp) &&
+			   (file->f_path.dentry->d_inode->i_size ==
+			    (loff_t)le64_to_cpu(buf->EndOfFile))) {
+		cFYI(1, ("inode unchanged on server"));
+	} else {
+		if (file->f_path.dentry->d_inode->i_mapping) {
+			rc = filemap_write_and_wait(file->f_path.dentry->d_inode->i_mapping);
+			if (rc != 0)
+				CIFS_I(file->f_path.dentry->d_inode)->write_behind_rc = rc;
+		}
+		cFYI(1, ("invalidating remote inode since open detected it "
+			 "changed"));
+		invalidate_remote_inode(file->f_path.dentry->d_inode);
+	} */
+
+psx_client_can_cache:
+	if ((oplock & 0xF) == OPLOCK_EXCLUSIVE) {
+		pCifsInode->clientCanCacheAll = true;
+		pCifsInode->clientCanCacheRead = true;
+		cFYI(1, ("Exclusive Oplock granted on inode %p",
+			 file->f_path.dentry->d_inode));
+	} else if ((oplock & 0xF) == OPLOCK_READ)
+		pCifsInode->clientCanCacheRead = true;
+
+	/* will have to change the unlock if we reenable the
+	   filemap_fdatawrite (which does not seem necessary */
+	write_unlock(&GlobalSMBSeslock);
+	return 0;
+}
+
+static struct cifsFileInfo *
+cifs_fill_filedata(struct file *file)
+{
+	struct list_head *tmp;
+	struct cifsFileInfo *pCifsFile = NULL;
+	struct cifsInodeInfo *pCifsInode = NULL;
+
+	/* search inode for this file and fill in file->private_data */
+	pCifsInode = CIFS_I(file->f_path.dentry->d_inode);
+	read_lock(&GlobalSMBSeslock);
+	list_for_each(tmp, &pCifsInode->openFileList) {
+		pCifsFile = list_entry(tmp, struct cifsFileInfo, flist);
+		if ((pCifsFile->pfile == NULL) &&
+		    (pCifsFile->pid == current->tgid)) {
+			/* mode set in cifs_create */
+
+			/* needed for writepage */
+			pCifsFile->pfile = file;
+			file->private_data = pCifsFile;
+			break;
+		}
+	}
+	read_unlock(&GlobalSMBSeslock);
+
+	if (file->private_data != NULL) {
+		return pCifsFile;
+	} else if ((file->f_flags & O_CREAT) && (file->f_flags & O_EXCL))
+			cERROR(1, ("could not find file instance for "
+				   "new file %p", file));
+	return NULL;
+}
+
+/* all arguments to this function must be checked for validity in caller */
+static inline int cifs_open_inode_helper(struct inode *inode, struct file *file,
+	struct cifsInodeInfo *pCifsInode, struct cifsFileInfo *pCifsFile,
+	struct cifsTconInfo *pTcon, int *oplock, FILE_ALL_INFO *buf,
+	char *full_path, int xid)
+{
+	struct timespec temp;
+	int rc;
+
+	/* want handles we can use to read with first
+	   in the list so we do not have to walk the
+	   list to search for one in write_begin */
+	if ((file->f_flags & O_ACCMODE) == O_WRONLY) {
+		list_add_tail(&pCifsFile->flist,
+			      &pCifsInode->openFileList);
+	} else {
+		list_add(&pCifsFile->flist,
+			 &pCifsInode->openFileList);
+	}
+	write_unlock(&GlobalSMBSeslock);
+	if (pCifsInode->clientCanCacheRead) {
+		/* we have the inode open somewhere else
+		   no need to discard cache data */
+		goto client_can_cache;
+	}
+
+	/* BB need same check in cifs_create too? */
+	/* if not oplocked, invalidate inode pages if mtime or file
+	   size changed */
+	temp = cifs_NTtimeToUnix(le64_to_cpu(buf->LastWriteTime));
+	if (timespec_equal(&file->f_path.dentry->d_inode->i_mtime, &temp) &&
+			   (file->f_path.dentry->d_inode->i_size ==
+			    (loff_t)le64_to_cpu(buf->EndOfFile))) {
+		cFYI(1, ("inode unchanged on server"));
+	} else {
+		if (file->f_path.dentry->d_inode->i_mapping) {
+		/* BB no need to lock inode until after invalidate
+		   since namei code should already have it locked? */
+			rc = filemap_write_and_wait(file->f_path.dentry->d_inode->i_mapping);
+			if (rc != 0)
+				CIFS_I(file->f_path.dentry->d_inode)->write_behind_rc = rc;
+		}
+		cFYI(1, ("invalidating remote inode since open detected it "
+			 "changed"));
+		invalidate_remote_inode(file->f_path.dentry->d_inode);
+	}
+
+client_can_cache:
+	if (pTcon->unix_ext)
+		rc = cifs_get_inode_info_unix(&file->f_path.dentry->d_inode,
+			full_path, inode->i_sb, xid);
+	else
+		rc = cifs_get_inode_info(&file->f_path.dentry->d_inode,
+			full_path, buf, inode->i_sb, xid, NULL);
+
+	if ((*oplock & 0xF) == OPLOCK_EXCLUSIVE) {
+		pCifsInode->clientCanCacheAll = true;
+		pCifsInode->clientCanCacheRead = true;
+		cFYI(1, ("Exclusive Oplock granted on inode %p",
+			 file->f_path.dentry->d_inode));
+	} else if ((*oplock & 0xF) == OPLOCK_READ)
+		pCifsInode->clientCanCacheRead = true;
+
+	return rc;
+}
+
+int cifs_open(struct inode *inode, struct file *file)
+{
+	int rc = -EACCES;
+	int xid, oplock;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *tcon;
+	struct cifsFileInfo *pCifsFile;
+	struct cifsInodeInfo *pCifsInode;
+	char *full_path = NULL;
+	int desiredAccess;
+	int disposition;
+	__u16 netfid;
+	FILE_ALL_INFO *buf = NULL;
+
+	xid = GetXid();
+
+	cifs_sb = CIFS_SB(inode->i_sb);
+	tcon = cifs_sb->tcon;
+
+	pCifsInode = CIFS_I(file->f_path.dentry->d_inode);
+	pCifsFile = cifs_fill_filedata(file);
+	if (pCifsFile) {
+		FreeXid(xid);
+		return 0;
+	}
+
+	full_path = build_path_from_dentry(file->f_path.dentry);
+	if (full_path == NULL) {
+		FreeXid(xid);
+		return -ENOMEM;
+	}
+
+	cFYI(1, ("inode = 0x%p file flags are 0x%x for %s",
+		 inode, file->f_flags, full_path));
+
+	if (oplockEnabled)
+		oplock = REQ_OPLOCK;
+	else
+		oplock = 0;
+
+	if (!tcon->broken_posix_open && tcon->unix_ext &&
+	    (tcon->ses->capabilities & CAP_UNIX) &&
+	    (CIFS_UNIX_POSIX_PATH_OPS_CAP &
+			le64_to_cpu(tcon->fsUnixInfo.Capability))) {
+		int oflags = (int) cifs_posix_convert_flags(file->f_flags);
+		/* can not refresh inode info since size could be stale */
+		rc = cifs_posix_open(full_path, &inode, inode->i_sb,
+				     cifs_sb->mnt_file_mode /* ignored */,
+				     oflags, &oplock, &netfid, xid);
+		if (rc == 0) {
+			cFYI(1, ("posix open succeeded"));
+			/* no need for special case handling of setting mode
+			   on read only files needed here */
+
+			pCifsFile = cifs_fill_filedata(file);
+			cifs_posix_open_inode_helper(inode, file, pCifsInode,
+						     pCifsFile, oplock, netfid);
+			goto out;
+		} else if ((rc == -EINVAL) || (rc == -EOPNOTSUPP)) {
+			if (tcon->ses->serverNOS)
+				cERROR(1, ("server %s of type %s returned"
+					   " unexpected error on SMB posix open"
+					   ", disabling posix open support."
+					   " Check if server update available.",
+					   tcon->ses->serverName,
+					   tcon->ses->serverNOS));
+			tcon->broken_posix_open = true;
+		} else if ((rc != -EIO) && (rc != -EREMOTE) &&
+			 (rc != -EOPNOTSUPP)) /* path not found or net err */
+			goto out;
+		/* else fallthrough to retry open the old way on network i/o
+		   or DFS errors */
+	}
+
+	desiredAccess = cifs_convert_flags(file->f_flags);
+
+/*********************************************************************
+ *  open flag mapping table:
+ *
+ *	POSIX Flag            CIFS Disposition
+ *	----------            ----------------
+ *	O_CREAT               FILE_OPEN_IF
+ *	O_CREAT | O_EXCL      FILE_CREATE
+ *	O_CREAT | O_TRUNC     FILE_OVERWRITE_IF
+ *	O_TRUNC               FILE_OVERWRITE
+ *	none of the above     FILE_OPEN
+ *
+ *	Note that there is not a direct match between disposition
+ *	FILE_SUPERSEDE (ie create whether or not file exists although
+ *	O_CREAT | O_TRUNC is similar but truncates the existing
+ *	file rather than creating a new file as FILE_SUPERSEDE does
+ *	(which uses the attributes / metadata passed in on open call)
+ *?
+ *?  O_SYNC is a reasonable match to CIFS writethrough flag
+ *?  and the read write flags match reasonably.  O_LARGEFILE
+ *?  is irrelevant because largefile support is always used
+ *?  by this client. Flags O_APPEND, O_DIRECT, O_DIRECTORY,
+ *	 O_FASYNC, O_NOFOLLOW, O_NONBLOCK need further investigation
+ *********************************************************************/
+
+	disposition = cifs_get_disposition(file->f_flags);
+
+	/* BB pass O_SYNC flag through on file attributes .. BB */
+
+	/* Also refresh inode by passing in file_info buf returned by SMBOpen
+	   and calling get_inode_info with returned buf (at least helps
+	   non-Unix server case) */
+
+	/* BB we can not do this if this is the second open of a file
+	   and the first handle has writebehind data, we might be
+	   able to simply do a filemap_fdatawrite/filemap_fdatawait first */
+	buf = kmalloc(sizeof(FILE_ALL_INFO), GFP_KERNEL);
+	if (!buf) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	if (cifs_sb->tcon->ses->capabilities & CAP_NT_SMBS)
+		rc = CIFSSMBOpen(xid, tcon, full_path, disposition,
+			 desiredAccess, CREATE_NOT_DIR, &netfid, &oplock, buf,
+			 cifs_sb->local_nls, cifs_sb->mnt_cifs_flags
+				 & CIFS_MOUNT_MAP_SPECIAL_CHR);
+	else
+		rc = -EIO; /* no NT SMB support fall into legacy open below */
+
+	if (rc == -EIO) {
+		/* Old server, try legacy style OpenX */
+		rc = SMBLegacyOpen(xid, tcon, full_path, disposition,
+			desiredAccess, CREATE_NOT_DIR, &netfid, &oplock, buf,
+			cifs_sb->local_nls, cifs_sb->mnt_cifs_flags
+				& CIFS_MOUNT_MAP_SPECIAL_CHR);
+	}
+	if (rc) {
+		cFYI(1, ("cifs_open returned 0x%x", rc));
+		goto out;
+	}
+	file->private_data =
+		kmalloc(sizeof(struct cifsFileInfo), GFP_KERNEL);
+	if (file->private_data == NULL) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	pCifsFile = cifs_init_private(file->private_data, inode, file, netfid);
+	write_lock(&GlobalSMBSeslock);
+	list_add(&pCifsFile->tlist, &tcon->openFileList);
+
+	pCifsInode = CIFS_I(file->f_path.dentry->d_inode);
+	if (pCifsInode) {
+		rc = cifs_open_inode_helper(inode, file, pCifsInode,
+					    pCifsFile, tcon,
+					    &oplock, buf, full_path, xid);
+	} else {
+		write_unlock(&GlobalSMBSeslock);
+	}
+
+	if (oplock & CIFS_CREATE_ACTION) {
+		/* time to set mode which we can not set earlier due to
+		   problems creating new read-only files */
+		if (tcon->unix_ext) {
+			struct cifs_unix_set_info_args args = {
+				.mode	= inode->i_mode,
+				.uid	= NO_CHANGE_64,
+				.gid	= NO_CHANGE_64,
+				.ctime	= NO_CHANGE_64,
+				.atime	= NO_CHANGE_64,
+				.mtime	= NO_CHANGE_64,
+				.device	= 0,
+			};
+			CIFSSMBUnixSetInfo(xid, tcon, full_path, &args,
+					    cifs_sb->local_nls,
+					    cifs_sb->mnt_cifs_flags &
+						CIFS_MOUNT_MAP_SPECIAL_CHR);
+		}
+	}
+
+out:
+	kfree(buf);
+	kfree(full_path);
+	FreeXid(xid);
+	return rc;
+}
+
+/* Try to reacquire byte range locks that were released when session */
+/* to server was lost */
+static int cifs_relock_file(struct cifsFileInfo *cifsFile)
+{
+	int rc = 0;
+
+/* BB list all locks open on this file and relock */
+
+	return rc;
+}
+
+static int cifs_reopen_file(struct file *file, bool can_flush)
+{
+	int rc = -EACCES;
+	int xid, oplock;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *tcon;
+	struct cifsFileInfo *pCifsFile;
+	struct cifsInodeInfo *pCifsInode;
+	struct inode *inode;
+	char *full_path = NULL;
+	int desiredAccess;
+	int disposition = FILE_OPEN;
+	__u16 netfid;
+
+	if (file->private_data)
+		pCifsFile = (struct cifsFileInfo *)file->private_data;
+	else
+		return -EBADF;
+
+	xid = GetXid();
+	mutex_unlock(&pCifsFile->fh_mutex);
+	if (!pCifsFile->invalidHandle) {
+		mutex_lock(&pCifsFile->fh_mutex);
+		FreeXid(xid);
+		return 0;
+	}
+
+	if (file->f_path.dentry == NULL) {
+		cERROR(1, ("no valid name if dentry freed"));
+		dump_stack();
+		rc = -EBADF;
+		goto reopen_error_exit;
+	}
+
+	inode = file->f_path.dentry->d_inode;
+	if (inode == NULL) {
+		cERROR(1, ("inode not valid"));
+		dump_stack();
+		rc = -EBADF;
+		goto reopen_error_exit;
+	}
+
+	cifs_sb = CIFS_SB(inode->i_sb);
+	tcon = cifs_sb->tcon;
+
+/* can not grab rename sem here because various ops, including
+   those that already have the rename sem can end up causing writepage
+   to get called and if the server was down that means we end up here,
+   and we can never tell if the caller already has the rename_sem */
+	full_path = build_path_from_dentry(file->f_path.dentry);
+	if (full_path == NULL) {
+		rc = -ENOMEM;
+reopen_error_exit:
+		mutex_lock(&pCifsFile->fh_mutex);
+		FreeXid(xid);
+		return rc;
+	}
+
+	cFYI(1, ("inode = 0x%p file flags 0x%x for %s",
+		 inode, file->f_flags, full_path));
+
+	if (oplockEnabled)
+		oplock = REQ_OPLOCK;
+	else
+		oplock = 0;
+
+	if (tcon->unix_ext && (tcon->ses->capabilities & CAP_UNIX) &&
+	    (CIFS_UNIX_POSIX_PATH_OPS_CAP &
+			le64_to_cpu(tcon->fsUnixInfo.Capability))) {
+		int oflags = (int) cifs_posix_convert_flags(file->f_flags);
+		/* can not refresh inode info since size could be stale */
+		rc = cifs_posix_open(full_path, NULL, inode->i_sb,
+				     cifs_sb->mnt_file_mode /* ignored */,
+				     oflags, &oplock, &netfid, xid);
+		if (rc == 0) {
+			cFYI(1, ("posix reopen succeeded"));
+			goto reopen_success;
+		}
+		/* fallthrough to retry open the old way on errors, especially
+		   in the reconnect path it is important to retry hard */
+	}
+
+	desiredAccess = cifs_convert_flags(file->f_flags);
+
+	/* Can not refresh inode by passing in file_info buf to be returned
+	   by SMBOpen and then calling get_inode_info with returned buf
+	   since file might have write behind data that needs to be flushed
+	   and server version of file size can be stale. If we knew for sure
+	   that inode was not dirty locally we could do this */
+
+	rc = CIFSSMBOpen(xid, tcon, full_path, disposition, desiredAccess,
+			 CREATE_NOT_DIR, &netfid, &oplock, NULL,
+			 cifs_sb->local_nls, cifs_sb->mnt_cifs_flags &
+				CIFS_MOUNT_MAP_SPECIAL_CHR);
+	if (rc) {
+		mutex_lock(&pCifsFile->fh_mutex);
+		cFYI(1, ("cifs_open returned 0x%x", rc));
+		cFYI(1, ("oplock: %d", oplock));
+	} else {
+reopen_success:
+		pCifsFile->netfid = netfid;
+		pCifsFile->invalidHandle = false;
+		mutex_lock(&pCifsFile->fh_mutex);
+		pCifsInode = CIFS_I(inode);
+		if (pCifsInode) {
+			if (can_flush) {
+				rc = filemap_write_and_wait(inode->i_mapping);
+				if (rc != 0)
+					CIFS_I(inode)->write_behind_rc = rc;
+			/* temporarily disable caching while we
+			   go to server to get inode info */
+				pCifsInode->clientCanCacheAll = false;
+				pCifsInode->clientCanCacheRead = false;
+				if (tcon->unix_ext)
+					rc = cifs_get_inode_info_unix(&inode,
+						full_path, inode->i_sb, xid);
+				else
+					rc = cifs_get_inode_info(&inode,
+						full_path, NULL, inode->i_sb,
+						xid, NULL);
+			} /* else we are writing out data to server already
+			     and could deadlock if we tried to flush data, and
+			     since we do not know if we have data that would
+			     invalidate the current end of file on the server
+			     we can not go to the server to get the new inod
+			     info */
+			if ((oplock & 0xF) == OPLOCK_EXCLUSIVE) {
+				pCifsInode->clientCanCacheAll = true;
+				pCifsInode->clientCanCacheRead = true;
+				cFYI(1, ("Exclusive Oplock granted on inode %p",
+					 file->f_path.dentry->d_inode));
+			} else if ((oplock & 0xF) == OPLOCK_READ) {
+				pCifsInode->clientCanCacheRead = true;
+				pCifsInode->clientCanCacheAll = false;
+			} else {
+				pCifsInode->clientCanCacheRead = false;
+				pCifsInode->clientCanCacheAll = false;
+			}
+			cifs_relock_file(pCifsFile);
+		}
+	}
+	kfree(full_path);
+	FreeXid(xid);
+	return rc;
+}
+
+int cifs_close(struct inode *inode, struct file *file)
+{
+	int rc = 0;
+	int xid, timeout;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	struct cifsFileInfo *pSMBFile =
+		(struct cifsFileInfo *)file->private_data;
+
+	xid = GetXid();
+
+	cifs_sb = CIFS_SB(inode->i_sb);
+	pTcon = cifs_sb->tcon;
+	if (pSMBFile) {
+		struct cifsLockInfo *li, *tmp;
+		write_lock(&GlobalSMBSeslock);
+		pSMBFile->closePend = true;
+		if (pTcon) {
+			/* no sense reconnecting to close a file that is
+			   already closed */
+			if (!pTcon->need_reconnect) {
+				write_unlock(&GlobalSMBSeslock);
+				timeout = 2;
+				while ((atomic_read(&pSMBFile->wrtPending) != 0)
+					&& (timeout <= 2048)) {
+					/* Give write a better chance to get to
+					server ahead of the close.  We do not
+					want to add a wait_q here as it would
+					increase the memory utilization as
+					the struct would be in each open file,
+					but this should give enough time to
+					clear the socket */
+					cFYI(DBG2,
+						("close delay, write pending"));
+					msleep(timeout);
+					timeout *= 4;
+				}
+				if (atomic_read(&pSMBFile->wrtPending))
+					cERROR(1, ("close with pending write"));
+				if (!pTcon->need_reconnect &&
+				    !pSMBFile->invalidHandle)
+					rc = CIFSSMBClose(xid, pTcon,
+						  pSMBFile->netfid);
+			} else
+				write_unlock(&GlobalSMBSeslock);
+		} else
+			write_unlock(&GlobalSMBSeslock);
+
+		/* Delete any outstanding lock records.
+		   We'll lose them when the file is closed anyway. */
+		mutex_lock(&pSMBFile->lock_mutex);
+		list_for_each_entry_safe(li, tmp, &pSMBFile->llist, llist) {
+			list_del(&li->llist);
+			kfree(li);
+		}
+		mutex_unlock(&pSMBFile->lock_mutex);
+
+		write_lock(&GlobalSMBSeslock);
+		list_del(&pSMBFile->flist);
+		list_del(&pSMBFile->tlist);
+		write_unlock(&GlobalSMBSeslock);
+		timeout = 10;
+		/* We waited above to give the SMBWrite a chance to issue
+		   on the wire (so we do not get SMBWrite returning EBADF
+		   if writepages is racing with close.  Note that writepages
+		   does not specify a file handle, so it is possible for a file
+		   to be opened twice, and the application close the "wrong"
+		   file handle - in these cases we delay long enough to allow
+		   the SMBWrite to get on the wire before the SMB Close.
+		   We allow total wait here over 45 seconds, more than
+		   oplock break time, and more than enough to allow any write
+		   to complete on the server, or to time out on the client */
+		while ((atomic_read(&pSMBFile->wrtPending) != 0)
+				&& (timeout <= 50000)) {
+			cERROR(1, ("writes pending, delay free of handle"));
+			msleep(timeout);
+			timeout *= 8;
+		}
+		kfree(file->private_data);
+		file->private_data = NULL;
+	} else
+		rc = -EBADF;
+
+	read_lock(&GlobalSMBSeslock);
+	if (list_empty(&(CIFS_I(inode)->openFileList))) {
+		cFYI(1, ("closing last open instance for inode %p", inode));
+		/* if the file is not open we do not know if we can cache info
+		   on this inode, much less write behind and read ahead */
+		CIFS_I(inode)->clientCanCacheRead = false;
+		CIFS_I(inode)->clientCanCacheAll  = false;
+	}
+	read_unlock(&GlobalSMBSeslock);
+	if ((rc == 0) && CIFS_I(inode)->write_behind_rc)
+		rc = CIFS_I(inode)->write_behind_rc;
+	FreeXid(xid);
+	return rc;
+}
+
+int cifs_closedir(struct inode *inode, struct file *file)
+{
+	int rc = 0;
+	int xid;
+	struct cifsFileInfo *pCFileStruct =
+	    (struct cifsFileInfo *)file->private_data;
+	char *ptmp;
+
+	cFYI(1, ("Closedir inode = 0x%p", inode));
+
+	xid = GetXid();
+
+	if (pCFileStruct) {
+		struct cifsTconInfo *pTcon;
+		struct cifs_sb_info *cifs_sb =
+			CIFS_SB(file->f_path.dentry->d_sb);
+
+		pTcon = cifs_sb->tcon;
+
+		cFYI(1, ("Freeing private data in close dir"));
+		write_lock(&GlobalSMBSeslock);
+		if (!pCFileStruct->srch_inf.endOfSearch &&
+		    !pCFileStruct->invalidHandle) {
+			pCFileStruct->invalidHandle = true;
+			write_unlock(&GlobalSMBSeslock);
+			rc = CIFSFindClose(xid, pTcon, pCFileStruct->netfid);
+			cFYI(1, ("Closing uncompleted readdir with rc %d",
+				 rc));
+			/* not much we can do if it fails anyway, ignore rc */
+			rc = 0;
+		} else
+			write_unlock(&GlobalSMBSeslock);
+		ptmp = pCFileStruct->srch_inf.ntwrk_buf_start;
+		if (ptmp) {
+			cFYI(1, ("closedir free smb buf in srch struct"));
+			pCFileStruct->srch_inf.ntwrk_buf_start = NULL;
+			if (pCFileStruct->srch_inf.smallBuf)
+				cifs_small_buf_release(ptmp);
+			else
+				cifs_buf_release(ptmp);
+		}
+		kfree(file->private_data);
+		file->private_data = NULL;
+	}
+	/* BB can we lock the filestruct while this is going on? */
+	FreeXid(xid);
+	return rc;
+}
+
+static int store_file_lock(struct cifsFileInfo *fid, __u64 len,
+				__u64 offset, __u8 lockType)
+{
+	struct cifsLockInfo *li =
+		kmalloc(sizeof(struct cifsLockInfo), GFP_KERNEL);
+	if (li == NULL)
+		return -ENOMEM;
+	li->offset = offset;
+	li->length = len;
+	li->type = lockType;
+	mutex_lock(&fid->lock_mutex);
+	list_add(&li->llist, &fid->llist);
+	mutex_unlock(&fid->lock_mutex);
+	return 0;
+}
+
+int cifs_lock(struct file *file, int cmd, struct file_lock *pfLock)
+{
+	int rc, xid;
+	__u32 numLock = 0;
+	__u32 numUnlock = 0;
+	__u64 length;
+	bool wait_flag = false;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *tcon;
+	__u16 netfid;
+	__u8 lockType = LOCKING_ANDX_LARGE_FILES;
+	bool posix_locking = 0;
+
+	length = 1 + pfLock->fl_end - pfLock->fl_start;
+	rc = -EACCES;
+	xid = GetXid();
+
+	cFYI(1, ("Lock parm: 0x%x flockflags: "
+		 "0x%x flocktype: 0x%x start: %lld end: %lld",
+		cmd, pfLock->fl_flags, pfLock->fl_type, pfLock->fl_start,
+		pfLock->fl_end));
+
+	if (pfLock->fl_flags & FL_POSIX)
+		cFYI(1, ("Posix"));
+	if (pfLock->fl_flags & FL_FLOCK)
+		cFYI(1, ("Flock"));
+	if (pfLock->fl_flags & FL_SLEEP) {
+		cFYI(1, ("Blocking lock"));
+		wait_flag = true;
+	}
+	if (pfLock->fl_flags & FL_ACCESS)
+		cFYI(1, ("Process suspended by mandatory locking - "
+			 "not implemented yet"));
+	if (pfLock->fl_flags & FL_LEASE)
+		cFYI(1, ("Lease on file - not implemented yet"));
+	if (pfLock->fl_flags &
+	    (~(FL_POSIX | FL_FLOCK | FL_SLEEP | FL_ACCESS | FL_LEASE)))
+		cFYI(1, ("Unknown lock flags 0x%x", pfLock->fl_flags));
+
+	if (pfLock->fl_type == F_WRLCK) {
+		cFYI(1, ("F_WRLCK "));
+		numLock = 1;
+	} else if (pfLock->fl_type == F_UNLCK) {
+		cFYI(1, ("F_UNLCK"));
+		numUnlock = 1;
+		/* Check if unlock includes more than
+		one lock range */
+	} else if (pfLock->fl_type == F_RDLCK) {
+		cFYI(1, ("F_RDLCK"));
+		lockType |= LOCKING_ANDX_SHARED_LOCK;
+		numLock = 1;
+	} else if (pfLock->fl_type == F_EXLCK) {
+		cFYI(1, ("F_EXLCK"));
+		numLock = 1;
+	} else if (pfLock->fl_type == F_SHLCK) {
+		cFYI(1, ("F_SHLCK"));
+		lockType |= LOCKING_ANDX_SHARED_LOCK;
+		numLock = 1;
+	} else
+		cFYI(1, ("Unknown type of lock"));
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	tcon = cifs_sb->tcon;
+
+	if (file->private_data == NULL) {
+		FreeXid(xid);
+		return -EBADF;
+	}
+	netfid = ((struct cifsFileInfo *)file->private_data)->netfid;
+
+	if ((tcon->ses->capabilities & CAP_UNIX) &&
+	    (CIFS_UNIX_FCNTL_CAP & le64_to_cpu(tcon->fsUnixInfo.Capability)) &&
+	    ((cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NOPOSIXBRL) == 0))
+		posix_locking = 1;
+	/* BB add code here to normalize offset and length to
+	account for negative length which we can not accept over the
+	wire */
+	if (IS_GETLK(cmd)) {
+		if (posix_locking) {
+			int posix_lock_type;
+			if (lockType & LOCKING_ANDX_SHARED_LOCK)
+				posix_lock_type = CIFS_RDLCK;
+			else
+				posix_lock_type = CIFS_WRLCK;
+			rc = CIFSSMBPosixLock(xid, tcon, netfid, 1 /* get */,
+					length,	pfLock,
+					posix_lock_type, wait_flag);
+			FreeXid(xid);
+			return rc;
+		}
+
+		/* BB we could chain these into one lock request BB */
+		rc = CIFSSMBLock(xid, tcon, netfid, length, pfLock->fl_start,
+				 0, 1, lockType, 0 /* wait flag */ );
+		if (rc == 0) {
+			rc = CIFSSMBLock(xid, tcon, netfid, length,
+					 pfLock->fl_start, 1 /* numUnlock */ ,
+					 0 /* numLock */ , lockType,
+					 0 /* wait flag */ );
+			pfLock->fl_type = F_UNLCK;
+			if (rc != 0)
+				cERROR(1, ("Error unlocking previously locked "
+					   "range %d during test of lock", rc));
+			rc = 0;
+
+		} else {
+			/* if rc == ERR_SHARING_VIOLATION ? */
+			rc = 0;	/* do not change lock type to unlock
+				   since range in use */
+		}
+
+		FreeXid(xid);
+		return rc;
+	}
+
+	if (!numLock && !numUnlock) {
+		/* if no lock or unlock then nothing
+		to do since we do not know what it is */
+		FreeXid(xid);
+		return -EOPNOTSUPP;
+	}
+
+	if (posix_locking) {
+		int posix_lock_type;
+		if (lockType & LOCKING_ANDX_SHARED_LOCK)
+			posix_lock_type = CIFS_RDLCK;
+		else
+			posix_lock_type = CIFS_WRLCK;
+
+		if (numUnlock == 1)
+			posix_lock_type = CIFS_UNLCK;
+
+		rc = CIFSSMBPosixLock(xid, tcon, netfid, 0 /* set */,
+				      length, pfLock,
+				      posix_lock_type, wait_flag);
+	} else {
+		struct cifsFileInfo *fid =
+			(struct cifsFileInfo *)file->private_data;
+
+		if (numLock) {
+			rc = CIFSSMBLock(xid, tcon, netfid, length,
+					pfLock->fl_start,
+					0, numLock, lockType, wait_flag);
+
+			if (rc == 0) {
+				/* For Windows locks we must store them. */
+				rc = store_file_lock(fid, length,
+						pfLock->fl_start, lockType);
+			}
+		} else if (numUnlock) {
+			/* For each stored lock that this unlock overlaps
+			   completely, unlock it. */
+			int stored_rc = 0;
+			struct cifsLockInfo *li, *tmp;
+
+			rc = 0;
+			mutex_lock(&fid->lock_mutex);
+			list_for_each_entry_safe(li, tmp, &fid->llist, llist) {
+				if (pfLock->fl_start <= li->offset &&
+						(pfLock->fl_start + length) >=
+						(li->offset + li->length)) {
+					stored_rc = CIFSSMBLock(xid, tcon,
+							netfid,
+							li->length, li->offset,
+							1, 0, li->type, false);
+					if (stored_rc)
+						rc = stored_rc;
+
+					list_del(&li->llist);
+					kfree(li);
+				}
+			}
+			mutex_unlock(&fid->lock_mutex);
+		}
+	}
+
+	if (pfLock->fl_flags & FL_POSIX)
+		posix_lock_file_wait(file, pfLock);
+	FreeXid(xid);
+	return rc;
+}
+
+/*
+ * Set the timeout on write requests past EOF. For some servers (Windows)
+ * these calls can be very long.
+ *
+ * If we're writing >10M past the EOF we give a 180s timeout. Anything less
+ * than that gets a 45s timeout. Writes not past EOF get 15s timeouts.
+ * The 10M cutoff is totally arbitrary. A better scheme for this would be
+ * welcome if someone wants to suggest one.
+ *
+ * We may be able to do a better job with this if there were some way to
+ * declare that a file should be sparse.
+ */
+static int
+cifs_write_timeout(struct cifsInodeInfo *cifsi, loff_t offset)
+{
+	if (offset <= cifsi->server_eof)
+		return CIFS_STD_OP;
+	else if (offset > (cifsi->server_eof + (10 * 1024 * 1024)))
+		return CIFS_VLONG_OP;
+	else
+		return CIFS_LONG_OP;
+}
+
+/* update the file size (if needed) after a write */
+static void
+cifs_update_eof(struct cifsInodeInfo *cifsi, loff_t offset,
+		      unsigned int bytes_written)
+{
+	loff_t end_of_write = offset + bytes_written;
+
+	if (end_of_write > cifsi->server_eof)
+		cifsi->server_eof = end_of_write;
+}
+
+ssize_t cifs_user_write(struct file *file, const char __user *write_data,
+	size_t write_size, loff_t *poffset)
+{
+	int rc = 0;
+	unsigned int bytes_written = 0;
+	unsigned int total_written;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	int xid, long_op;
+	struct cifsFileInfo *open_file;
+	struct cifsInodeInfo *cifsi = CIFS_I(file->f_path.dentry->d_inode);
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+
+	pTcon = cifs_sb->tcon;
+
+	/* cFYI(1,
+	   (" write %d bytes to offset %lld of %s", write_size,
+	   *poffset, file->f_path.dentry->d_name.name)); */
+
+	if (file->private_data == NULL)
+		return -EBADF;
+	open_file = (struct cifsFileInfo *) file->private_data;
+
+	rc = generic_write_checks(file, poffset, &write_size, 0);
+	if (rc)
+		return rc;
+
+	xid = GetXid();
+
+	long_op = cifs_write_timeout(cifsi, *poffset);
+	for (total_written = 0; write_size > total_written;
+	     total_written += bytes_written) {
+		rc = -EAGAIN;
+		while (rc == -EAGAIN) {
+			if (file->private_data == NULL) {
+				/* file has been closed on us */
+				FreeXid(xid);
+			/* if we have gotten here we have written some data
+			   and blocked, and the file has been freed on us while
+			   we blocked so return what we managed to write */
+				return total_written;
+			}
+			if (open_file->closePend) {
+				FreeXid(xid);
+				if (total_written)
+					return total_written;
+				else
+					return -EBADF;
+			}
+			if (open_file->invalidHandle) {
+				/* we could deadlock if we called
+				   filemap_fdatawait from here so tell
+				   reopen_file not to flush data to server
+				   now */
+				rc = cifs_reopen_file(file, false);
+				if (rc != 0)
+					break;
+			}
+
+			rc = CIFSSMBWrite(xid, pTcon,
+				open_file->netfid,
+				min_t(const int, cifs_sb->wsize,
+				      write_size - total_written),
+				*poffset, &bytes_written,
+				NULL, write_data + total_written, long_op);
+		}
+		if (rc || (bytes_written == 0)) {
+			if (total_written)
+				break;
+			else {
+				FreeXid(xid);
+				return rc;
+			}
+		} else {
+			cifs_update_eof(cifsi, *poffset, bytes_written);
+			*poffset += bytes_written;
+		}
+		long_op = CIFS_STD_OP; /* subsequent writes fast -
+				    15 seconds is plenty */
+	}
+
+	cifs_stats_bytes_written(pTcon, total_written);
+
+	/* since the write may have blocked check these pointers again */
+	if ((file->f_path.dentry) && (file->f_path.dentry->d_inode)) {
+		struct inode *inode = file->f_path.dentry->d_inode;
+/* Do not update local mtime - server will set its actual value on write
+ *		inode->i_ctime = inode->i_mtime =
+ * 			current_fs_time(inode->i_sb);*/
+		if (total_written > 0) {
+			spin_lock(&inode->i_lock);
+			if (*poffset > file->f_path.dentry->d_inode->i_size)
+				i_size_write(file->f_path.dentry->d_inode,
+					*poffset);
+			spin_unlock(&inode->i_lock);
+		}
+		mark_inode_dirty_sync(file->f_path.dentry->d_inode);
+	}
+	FreeXid(xid);
+	return total_written;
+}
+
+static ssize_t cifs_write(struct file *file, const char *write_data,
+			  size_t write_size, loff_t *poffset)
+{
+	int rc = 0;
+	unsigned int bytes_written = 0;
+	unsigned int total_written;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	int xid, long_op;
+	struct cifsFileInfo *open_file;
+	struct cifsInodeInfo *cifsi = CIFS_I(file->f_path.dentry->d_inode);
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+
+	pTcon = cifs_sb->tcon;
+
+	cFYI(1, ("write %zd bytes to offset %lld of %s", write_size,
+	   *poffset, file->f_path.dentry->d_name.name));
+
+	if (file->private_data == NULL)
+		return -EBADF;
+	open_file = (struct cifsFileInfo *)file->private_data;
+
+	xid = GetXid();
+
+	long_op = cifs_write_timeout(cifsi, *poffset);
+	for (total_written = 0; write_size > total_written;
+	     total_written += bytes_written) {
+		rc = -EAGAIN;
+		while (rc == -EAGAIN) {
+			if (file->private_data == NULL) {
+				/* file has been closed on us */
+				FreeXid(xid);
+			/* if we have gotten here we have written some data
+			   and blocked, and the file has been freed on us
+			   while we blocked so return what we managed to
+			   write */
+				return total_written;
+			}
+			if (open_file->closePend) {
+				FreeXid(xid);
+				if (total_written)
+					return total_written;
+				else
+					return -EBADF;
+			}
+			if (open_file->invalidHandle) {
+				/* we could deadlock if we called
+				   filemap_fdatawait from here so tell
+				   reopen_file not to flush data to
+				   server now */
+				rc = cifs_reopen_file(file, false);
+				if (rc != 0)
+					break;
+			}
+			if (experimEnabled || (pTcon->ses->server &&
+				((pTcon->ses->server->secMode &
+				(SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED))
+				== 0))) {
+				struct kvec iov[2];
+				unsigned int len;
+
+				len = min((size_t)cifs_sb->wsize,
+					  write_size - total_written);
+				/* iov[0] is reserved for smb header */
+				iov[1].iov_base = (char *)write_data +
+						  total_written;
+				iov[1].iov_len = len;
+				rc = CIFSSMBWrite2(xid, pTcon,
+						open_file->netfid, len,
+						*poffset, &bytes_written,
+						iov, 1, long_op);
+			} else
+				rc = CIFSSMBWrite(xid, pTcon,
+					 open_file->netfid,
+					 min_t(const int, cifs_sb->wsize,
+					       write_size - total_written),
+					 *poffset, &bytes_written,
+					 write_data + total_written,
+					 NULL, long_op);
+		}
+		if (rc || (bytes_written == 0)) {
+			if (total_written)
+				break;
+			else {
+				FreeXid(xid);
+				return rc;
+			}
+		} else {
+			cifs_update_eof(cifsi, *poffset, bytes_written);
+			*poffset += bytes_written;
+		}
+		long_op = CIFS_STD_OP; /* subsequent writes fast -
+				    15 seconds is plenty */
+	}
+
+	cifs_stats_bytes_written(pTcon, total_written);
+
+	/* since the write may have blocked check these pointers again */
+	if ((file->f_path.dentry) && (file->f_path.dentry->d_inode)) {
+/*BB We could make this contingent on superblock ATIME flag too */
+/*		file->f_path.dentry->d_inode->i_ctime =
+		file->f_path.dentry->d_inode->i_mtime = CURRENT_TIME;*/
+		if (total_written > 0) {
+			spin_lock(&file->f_path.dentry->d_inode->i_lock);
+			if (*poffset > file->f_path.dentry->d_inode->i_size)
+				i_size_write(file->f_path.dentry->d_inode,
+					     *poffset);
+			spin_unlock(&file->f_path.dentry->d_inode->i_lock);
+		}
+		mark_inode_dirty_sync(file->f_path.dentry->d_inode);
+	}
+	FreeXid(xid);
+	return total_written;
+}
+
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+struct cifsFileInfo *find_readable_file(struct cifsInodeInfo *cifs_inode)
+{
+	struct cifsFileInfo *open_file = NULL;
+
+	read_lock(&GlobalSMBSeslock);
+	/* we could simply get the first_list_entry since write-only entries
+	   are always at the end of the list but since the first entry might
+	   have a close pending, we go through the whole list */
+	list_for_each_entry(open_file, &cifs_inode->openFileList, flist) {
+		if (open_file->closePend)
+			continue;
+		if (open_file->pfile && ((open_file->pfile->f_flags & O_RDWR) ||
+		    (open_file->pfile->f_flags & O_RDONLY))) {
+			if (!open_file->invalidHandle) {
+				/* found a good file */
+				/* lock it so it will not be closed on us */
+				atomic_inc(&open_file->wrtPending);
+				read_unlock(&GlobalSMBSeslock);
+				return open_file;
+			} /* else might as well continue, and look for
+			     another, or simply have the caller reopen it
+			     again rather than trying to fix this handle */
+		} else /* write only file */
+			break; /* write only files are last so must be done */
+	}
+	read_unlock(&GlobalSMBSeslock);
+	return NULL;
+}
+#endif
+
+struct cifsFileInfo *find_writable_file(struct cifsInodeInfo *cifs_inode)
+{
+	struct cifsFileInfo *open_file;
+	bool any_available = false;
+	int rc;
+
+	/* Having a null inode here (because mapping->host was set to zero by
+	the VFS or MM) should not happen but we had reports of on oops (due to
+	it being zero) during stress testcases so we need to check for it */
+
+	if (cifs_inode == NULL) {
+		cERROR(1, ("Null inode passed to cifs_writeable_file"));
+		dump_stack();
+		return NULL;
+	}
+
+	read_lock(&GlobalSMBSeslock);
+refind_writable:
+	list_for_each_entry(open_file, &cifs_inode->openFileList, flist) {
+		if (open_file->closePend ||
+		    (!any_available && open_file->pid != current->tgid))
+			continue;
+
+		if (open_file->pfile &&
+		    ((open_file->pfile->f_flags & O_RDWR) ||
+		     (open_file->pfile->f_flags & O_WRONLY))) {
+			atomic_inc(&open_file->wrtPending);
+
+			if (!open_file->invalidHandle) {
+				/* found a good writable file */
+				read_unlock(&GlobalSMBSeslock);
+				return open_file;
+			}
+
+			read_unlock(&GlobalSMBSeslock);
+			/* Had to unlock since following call can block */
+			rc = cifs_reopen_file(open_file->pfile, false);
+			if (!rc) {
+				if (!open_file->closePend)
+					return open_file;
+				else { /* start over in case this was deleted */
+				       /* since the list could be modified */
+					read_lock(&GlobalSMBSeslock);
+					atomic_dec(&open_file->wrtPending);
+					goto refind_writable;
+				}
+			}
+
+			/* if it fails, try another handle if possible -
+			(we can not do this if closePending since
+			loop could be modified - in which case we
+			have to start at the beginning of the list
+			again. Note that it would be bad
+			to hold up writepages here (rather than
+			in caller) with continuous retries */
+			cFYI(1, ("wp failed on reopen file"));
+			read_lock(&GlobalSMBSeslock);
+			/* can not use this handle, no write
+			   pending on this one after all */
+			atomic_dec(&open_file->wrtPending);
+
+			if (open_file->closePend) /* list could have changed */
+				goto refind_writable;
+			/* else we simply continue to the next entry. Thus
+			   we do not loop on reopen errors.  If we
+			   can not reopen the file, for example if we
+			   reconnected to a server with another client
+			   racing to delete or lock the file we would not
+			   make progress if we restarted before the beginning
+			   of the loop here. */
+		}
+	}
+	/* couldn't find useable FH with same pid, try any available */
+	if (!any_available) {
+		any_available = true;
+		goto refind_writable;
+	}
+	read_unlock(&GlobalSMBSeslock);
+	return NULL;
+}
+
+static int cifs_partialpagewrite(struct page *page, unsigned from, unsigned to)
+{
+	struct address_space *mapping = page->mapping;
+	loff_t offset = (loff_t)page->index << PAGE_CACHE_SHIFT;
+	char *write_data;
+	int rc = -EFAULT;
+	int bytes_written = 0;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	struct inode *inode;
+	struct cifsFileInfo *open_file;
+
+	if (!mapping || !mapping->host)
+		return -EFAULT;
+
+	inode = page->mapping->host;
+	cifs_sb = CIFS_SB(inode->i_sb);
+	pTcon = cifs_sb->tcon;
+
+	offset += (loff_t)from;
+	write_data = kmap(page);
+	write_data += from;
+
+	if ((to > PAGE_CACHE_SIZE) || (from > to)) {
+		kunmap(page);
+		return -EIO;
+	}
+
+	/* racing with truncate? */
+	if (offset > mapping->host->i_size) {
+		kunmap(page);
+		return 0; /* don't care */
+	}
+
+	/* check to make sure that we are not extending the file */
+	if (mapping->host->i_size - offset < (loff_t)to)
+		to = (unsigned)(mapping->host->i_size - offset);
+
+	open_file = find_writable_file(CIFS_I(mapping->host));
+	if (open_file) {
+		bytes_written = cifs_write(open_file->pfile, write_data,
+					   to-from, &offset);
+		atomic_dec(&open_file->wrtPending);
+		/* Does mm or vfs already set times? */
+		inode->i_atime = inode->i_mtime = current_fs_time(inode->i_sb);
+		if ((bytes_written > 0) && (offset))
+			rc = 0;
+		else if (bytes_written < 0)
+			rc = bytes_written;
+	} else {
+		cFYI(1, ("No writeable filehandles for inode"));
+		rc = -EIO;
+	}
+
+	kunmap(page);
+	return rc;
+}
+
+static int cifs_writepages(struct address_space *mapping,
+			   struct writeback_control *wbc)
+{
+	struct backing_dev_info *bdi = mapping->backing_dev_info;
+	unsigned int bytes_to_write;
+	unsigned int bytes_written;
+	struct cifs_sb_info *cifs_sb;
+	int done = 0;
+	pgoff_t end;
+	pgoff_t index;
+	int range_whole = 0;
+	struct kvec *iov;
+	int len;
+	int n_iov = 0;
+	pgoff_t next;
+	int nr_pages;
+	__u64 offset = 0;
+	struct cifsFileInfo *open_file;
+	struct cifsInodeInfo *cifsi = CIFS_I(mapping->host);
+	struct page *page;
+	struct pagevec pvec;
+	int rc = 0;
+	int scanned = 0;
+	int xid, long_op;
+
+	cifs_sb = CIFS_SB(mapping->host->i_sb);
+
+	/*
+	 * If wsize is smaller that the page cache size, default to writing
+	 * one page at a time via cifs_writepage
+	 */
+	if (cifs_sb->wsize < PAGE_CACHE_SIZE)
+		return generic_writepages(mapping, wbc);
+
+	if ((cifs_sb->tcon->ses) && (cifs_sb->tcon->ses->server))
+		if (cifs_sb->tcon->ses->server->secMode &
+				(SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED))
+			if (!experimEnabled)
+				return generic_writepages(mapping, wbc);
+
+	iov = kmalloc(32 * sizeof(struct kvec), GFP_KERNEL);
+	if (iov == NULL)
+		return generic_writepages(mapping, wbc);
+
+
+	/*
+	 * BB: Is this meaningful for a non-block-device file system?
+	 * If it is, we should test it again after we do I/O
+	 */
+	if (wbc->nonblocking && bdi_write_congested(bdi)) {
+		wbc->encountered_congestion = 1;
+		kfree(iov);
+		return 0;
+	}
+
+	xid = GetXid();
+
+	pagevec_init(&pvec, 0);
+	if (wbc->range_cyclic) {
+		index = mapping->writeback_index; /* Start from prev offset */
+		end = -1;
+	} else {
+		index = wbc->range_start >> PAGE_CACHE_SHIFT;
+		end = wbc->range_end >> PAGE_CACHE_SHIFT;
+		if (wbc->range_start == 0 && wbc->range_end == LLONG_MAX)
+			range_whole = 1;
+		scanned = 1;
+	}
+retry:
+	while (!done && (index <= end) &&
+	       (nr_pages = pagevec_lookup_tag(&pvec, mapping, &index,
+			PAGECACHE_TAG_DIRTY,
+			min(end - index, (pgoff_t)PAGEVEC_SIZE - 1) + 1))) {
+		int first;
+		unsigned int i;
+
+		first = -1;
+		next = 0;
+		n_iov = 0;
+		bytes_to_write = 0;
+
+		for (i = 0; i < nr_pages; i++) {
+			page = pvec.pages[i];
+			/*
+			 * At this point we hold neither mapping->tree_lock nor
+			 * lock on the page itself: the page may be truncated or
+			 * invalidated (changing page->mapping to NULL), or even
+			 * swizzled back from swapper_space to tmpfs file
+			 * mapping
+			 */
+
+			if (first < 0)
+				lock_page(page);
+			else if (!trylock_page(page))
+				break;
+
+			if (unlikely(page->mapping != mapping)) {
+				unlock_page(page);
+				break;
+			}
+
+			if (!wbc->range_cyclic && page->index > end) {
+				done = 1;
+				unlock_page(page);
+				break;
+			}
+
+			if (next && (page->index != next)) {
+				/* Not next consecutive page */
+				unlock_page(page);
+				break;
+			}
+
+			if (wbc->sync_mode != WB_SYNC_NONE)
+				wait_on_page_writeback(page);
+
+			if (PageWriteback(page) ||
+					!clear_page_dirty_for_io(page)) {
+				unlock_page(page);
+				break;
+			}
+
+			/*
+			 * This actually clears the dirty bit in the radix tree.
+			 * See cifs_writepage() for more commentary.
+			 */
+			set_page_writeback(page);
+
+			if (page_offset(page) >= mapping->host->i_size) {
+				done = 1;
+				unlock_page(page);
+				end_page_writeback(page);
+				break;
+			}
+
+			/*
+			 * BB can we get rid of this?  pages are held by pvec
+			 */
+			page_cache_get(page);
+
+			len = min(mapping->host->i_size - page_offset(page),
+				  (loff_t)PAGE_CACHE_SIZE);
+
+			/* reserve iov[0] for the smb header */
+			n_iov++;
+			iov[n_iov].iov_base = kmap(page);
+			iov[n_iov].iov_len = len;
+			bytes_to_write += len;
+
+			if (first < 0) {
+				first = i;
+				offset = page_offset(page);
+			}
+			next = page->index + 1;
+			if (bytes_to_write + PAGE_CACHE_SIZE > cifs_sb->wsize)
+				break;
+		}
+		if (n_iov) {
+			/* Search for a writable handle every time we call
+			 * CIFSSMBWrite2.  We can't rely on the last handle
+			 * we used to still be valid
+			 */
+			open_file = find_writable_file(CIFS_I(mapping->host));
+			if (!open_file) {
+				cERROR(1, ("No writable handles for inode"));
+				rc = -EBADF;
+			} else {
+				long_op = cifs_write_timeout(cifsi, offset);
+				rc = CIFSSMBWrite2(xid, cifs_sb->tcon,
+						   open_file->netfid,
+						   bytes_to_write, offset,
+						   &bytes_written, iov, n_iov,
+						   long_op);
+				atomic_dec(&open_file->wrtPending);
+				cifs_update_eof(cifsi, offset, bytes_written);
+
+				if (rc || bytes_written < bytes_to_write) {
+					cERROR(1, ("Write2 ret %d, wrote %d",
+						  rc, bytes_written));
+					/* BB what if continued retry is
+					   requested via mount flags? */
+					if (rc == -ENOSPC)
+						set_bit(AS_ENOSPC, &mapping->flags);
+					else
+						set_bit(AS_EIO, &mapping->flags);
+				} else {
+					cifs_stats_bytes_written(cifs_sb->tcon,
+								 bytes_written);
+				}
+			}
+			for (i = 0; i < n_iov; i++) {
+				page = pvec.pages[first + i];
+				/* Should we also set page error on
+				success rc but too little data written? */
+				/* BB investigate retry logic on temporary
+				server crash cases and how recovery works
+				when page marked as error */
+				if (rc)
+					SetPageError(page);
+				kunmap(page);
+				unlock_page(page);
+				end_page_writeback(page);
+				page_cache_release(page);
+			}
+			if ((wbc->nr_to_write -= n_iov) <= 0)
+				done = 1;
+			index = next;
+		} else
+			/* Need to re-find the pages we skipped */
+			index = pvec.pages[0]->index + 1;
+
+		pagevec_release(&pvec);
+	}
+	if (!scanned && !done) {
+		/*
+		 * We hit the last page and there is more work to be done: wrap
+		 * back to the start of the file
+		 */
+		scanned = 1;
+		index = 0;
+		goto retry;
+	}
+	if (wbc->range_cyclic || (range_whole && wbc->nr_to_write > 0))
+		mapping->writeback_index = index;
+
+	FreeXid(xid);
+	kfree(iov);
+	return rc;
+}
+
+static int cifs_writepage(struct page *page, struct writeback_control *wbc)
+{
+	int rc = -EFAULT;
+	int xid;
+
+	xid = GetXid();
+/* BB add check for wbc flags */
+	page_cache_get(page);
+	if (!PageUptodate(page))
+		cFYI(1, ("ppw - page not up to date"));
+
+	/*
+	 * Set the "writeback" flag, and clear "dirty" in the radix tree.
+	 *
+	 * A writepage() implementation always needs to do either this,
+	 * or re-dirty the page with "redirty_page_for_writepage()" in
+	 * the case of a failure.
+	 *
+	 * Just unlocking the page will cause the radix tree tag-bits
+	 * to fail to update with the state of the page correctly.
+	 */
+	set_page_writeback(page);
+	rc = cifs_partialpagewrite(page, 0, PAGE_CACHE_SIZE);
+	SetPageUptodate(page); /* BB add check for error and Clearuptodate? */
+	unlock_page(page);
+	end_page_writeback(page);
+	page_cache_release(page);
+	FreeXid(xid);
+	return rc;
+}
+
+static int cifs_write_end(struct file *file, struct address_space *mapping,
+			loff_t pos, unsigned len, unsigned copied,
+			struct page *page, void *fsdata)
+{
+	int rc;
+	struct inode *inode = mapping->host;
+
+	cFYI(1, ("write_end for page %p from pos %lld with %d bytes",
+		 page, pos, copied));
+
+	if (PageChecked(page)) {
+		if (copied == len)
+			SetPageUptodate(page);
+		ClearPageChecked(page);
+	} else if (!PageUptodate(page) && copied == PAGE_CACHE_SIZE)
+		SetPageUptodate(page);
+
+	if (!PageUptodate(page)) {
+		char *page_data;
+		unsigned offset = pos & (PAGE_CACHE_SIZE - 1);
+		int xid;
+
+		xid = GetXid();
+		/* this is probably better than directly calling
+		   partialpage_write since in this function the file handle is
+		   known which we might as well	leverage */
+		/* BB check if anything else missing out of ppw
+		   such as updating last write time */
+		page_data = kmap(page);
+		rc = cifs_write(file, page_data + offset, copied, &pos);
+		/* if (rc < 0) should we set writebehind rc? */
+		kunmap(page);
+
+		FreeXid(xid);
+	} else {
+		rc = copied;
+		pos += copied;
+		set_page_dirty(page);
+	}
+
+	if (rc > 0) {
+		spin_lock(&inode->i_lock);
+		if (pos > inode->i_size)
+			i_size_write(inode, pos);
+		spin_unlock(&inode->i_lock);
+	}
+
+	unlock_page(page);
+	page_cache_release(page);
+
+	return rc;
+}
+
+int cifs_fsync(struct file *file, struct dentry *dentry, int datasync)
+{
+	int xid;
+	int rc = 0;
+	struct cifsTconInfo *tcon;
+	struct cifsFileInfo *smbfile =
+		(struct cifsFileInfo *)file->private_data;
+	struct inode *inode = file->f_path.dentry->d_inode;
+
+	xid = GetXid();
+
+	cFYI(1, ("Sync file - name: %s datasync: 0x%x",
+		dentry->d_name.name, datasync));
+
+	rc = filemap_write_and_wait(inode->i_mapping);
+	if (rc == 0) {
+		rc = CIFS_I(inode)->write_behind_rc;
+		CIFS_I(inode)->write_behind_rc = 0;
+		tcon = CIFS_SB(inode->i_sb)->tcon;
+		if (!rc && tcon && smbfile &&
+		   !(CIFS_SB(inode->i_sb)->mnt_cifs_flags & CIFS_MOUNT_NOSSYNC))
+			rc = CIFSSMBFlush(xid, tcon, smbfile->netfid);
+	}
+
+	FreeXid(xid);
+	return rc;
+}
+
+/* static void cifs_sync_page(struct page *page)
+{
+	struct address_space *mapping;
+	struct inode *inode;
+	unsigned long index = page->index;
+	unsigned int rpages = 0;
+	int rc = 0;
+
+	cFYI(1, ("sync page %p",page));
+	mapping = page->mapping;
+	if (!mapping)
+		return 0;
+	inode = mapping->host;
+	if (!inode)
+		return; */
+
+/*	fill in rpages then
+	result = cifs_pagein_inode(inode, index, rpages); */ /* BB finish */
+
+/*	cFYI(1, ("rpages is %d for sync page of Index %ld", rpages, index));
+
+#if 0
+	if (rc < 0)
+		return rc;
+	return 0;
+#endif
+} */
+
+/*
+ * As file closes, flush all cached write data for this inode checking
+ * for write behind errors.
+ */
+int cifs_flush(struct file *file, fl_owner_t id)
+{
+	struct inode *inode = file->f_path.dentry->d_inode;
+	int rc = 0;
+
+	/* Rather than do the steps manually:
+	   lock the inode for writing
+	   loop through pages looking for write behind data (dirty pages)
+	   coalesce into contiguous 16K (or smaller) chunks to write to server
+	   send to server (prefer in parallel)
+	   deal with writebehind errors
+	   unlock inode for writing
+	   filemapfdatawrite appears easier for the time being */
+
+	rc = filemap_fdatawrite(inode->i_mapping);
+	/* reset wb rc if we were able to write out dirty pages */
+	if (!rc) {
+		rc = CIFS_I(inode)->write_behind_rc;
+		CIFS_I(inode)->write_behind_rc = 0;
+	}
+
+	cFYI(1, ("Flush inode %p file %p rc %d", inode, file, rc));
+
+	return rc;
+}
+
+ssize_t cifs_user_read(struct file *file, char __user *read_data,
+	size_t read_size, loff_t *poffset)
+{
+	int rc = -EACCES;
+	unsigned int bytes_read = 0;
+	unsigned int total_read = 0;
+	unsigned int current_read_size;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	int xid;
+	struct cifsFileInfo *open_file;
+	char *smb_read_data;
+	char __user *current_offset;
+	struct smb_com_read_rsp *pSMBr;
+
+	xid = GetXid();
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+
+	if (file->private_data == NULL) {
+		FreeXid(xid);
+		return -EBADF;
+	}
+	open_file = (struct cifsFileInfo *)file->private_data;
+
+	if ((file->f_flags & O_ACCMODE) == O_WRONLY)
+		cFYI(1, ("attempting read on write only file instance"));
+
+	for (total_read = 0, current_offset = read_data;
+	     read_size > total_read;
+	     total_read += bytes_read, current_offset += bytes_read) {
+		current_read_size = min_t(const int, read_size - total_read,
+					  cifs_sb->rsize);
+		rc = -EAGAIN;
+		smb_read_data = NULL;
+		while (rc == -EAGAIN) {
+			int buf_type = CIFS_NO_BUFFER;
+			if ((open_file->invalidHandle) &&
+			    (!open_file->closePend)) {
+				rc = cifs_reopen_file(file, true);
+				if (rc != 0)
+					break;
+			}
+			rc = CIFSSMBRead(xid, pTcon,
+					 open_file->netfid,
+					 current_read_size, *poffset,
+					 &bytes_read, &smb_read_data,
+					 &buf_type);
+			pSMBr = (struct smb_com_read_rsp *)smb_read_data;
+			if (smb_read_data) {
+				if (copy_to_user(current_offset,
+						smb_read_data +
+						4 /* RFC1001 length field */ +
+						le16_to_cpu(pSMBr->DataOffset),
+						bytes_read))
+					rc = -EFAULT;
+
+				if (buf_type == CIFS_SMALL_BUFFER)
+					cifs_small_buf_release(smb_read_data);
+				else if (buf_type == CIFS_LARGE_BUFFER)
+					cifs_buf_release(smb_read_data);
+				smb_read_data = NULL;
+			}
+		}
+		if (rc || (bytes_read == 0)) {
+			if (total_read) {
+				break;
+			} else {
+				FreeXid(xid);
+				return rc;
+			}
+		} else {
+			cifs_stats_bytes_read(pTcon, bytes_read);
+			*poffset += bytes_read;
+		}
+	}
+	FreeXid(xid);
+	return total_read;
+}
+
+
+static ssize_t cifs_read(struct file *file, char *read_data, size_t read_size,
+	loff_t *poffset)
+{
+	int rc = -EACCES;
+	unsigned int bytes_read = 0;
+	unsigned int total_read;
+	unsigned int current_read_size;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	int xid;
+	char *current_offset;
+	struct cifsFileInfo *open_file;
+	int buf_type = CIFS_NO_BUFFER;
+
+	xid = GetXid();
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+
+	if (file->private_data == NULL) {
+		FreeXid(xid);
+		return -EBADF;
+	}
+	open_file = (struct cifsFileInfo *)file->private_data;
+
+	if ((file->f_flags & O_ACCMODE) == O_WRONLY)
+		cFYI(1, ("attempting read on write only file instance"));
+
+	for (total_read = 0, current_offset = read_data;
+	     read_size > total_read;
+	     total_read += bytes_read, current_offset += bytes_read) {
+		current_read_size = min_t(const int, read_size - total_read,
+					  cifs_sb->rsize);
+		/* For windows me and 9x we do not want to request more
+		than it negotiated since it will refuse the read then */
+		if ((pTcon->ses) &&
+			!(pTcon->ses->capabilities & CAP_LARGE_FILES)) {
+			current_read_size = min_t(const int, current_read_size,
+					pTcon->ses->server->maxBuf - 128);
+		}
+		rc = -EAGAIN;
+		while (rc == -EAGAIN) {
+			if ((open_file->invalidHandle) &&
+			    (!open_file->closePend)) {
+				rc = cifs_reopen_file(file, true);
+				if (rc != 0)
+					break;
+			}
+			rc = CIFSSMBRead(xid, pTcon,
+					 open_file->netfid,
+					 current_read_size, *poffset,
+					 &bytes_read, &current_offset,
+					 &buf_type);
+		}
+		if (rc || (bytes_read == 0)) {
+			if (total_read) {
+				break;
+			} else {
+				FreeXid(xid);
+				return rc;
+			}
+		} else {
+			cifs_stats_bytes_read(pTcon, total_read);
+			*poffset += bytes_read;
+		}
+	}
+	FreeXid(xid);
+	return total_read;
+}
+
+int cifs_file_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	int rc, xid;
+
+	xid = GetXid();
+	rc = cifs_revalidate(dentry);
+	if (rc) {
+		cFYI(1, ("Validation prior to mmap failed, error=%d", rc));
+		FreeXid(xid);
+		return rc;
+	}
+	rc = generic_file_mmap(file, vma);
+	FreeXid(xid);
+	return rc;
+}
+
+
+static void cifs_copy_cache_pages(struct address_space *mapping,
+	struct list_head *pages, int bytes_read, char *data,
+	struct pagevec *plru_pvec)
+{
+	struct page *page;
+	char *target;
+
+	while (bytes_read > 0) {
+		if (list_empty(pages))
+			break;
+
+		page = list_entry(pages->prev, struct page, lru);
+		list_del(&page->lru);
+
+		if (add_to_page_cache(page, mapping, page->index,
+				      GFP_KERNEL)) {
+			page_cache_release(page);
+			cFYI(1, ("Add page cache failed"));
+			data += PAGE_CACHE_SIZE;
+			bytes_read -= PAGE_CACHE_SIZE;
+			continue;
+		}
+
+		target = kmap_atomic(page, KM_USER0);
+
+		if (PAGE_CACHE_SIZE > bytes_read) {
+			memcpy(target, data, bytes_read);
+			/* zero the tail end of this partial page */
+			memset(target + bytes_read, 0,
+			       PAGE_CACHE_SIZE - bytes_read);
+			bytes_read = 0;
+		} else {
+			memcpy(target, data, PAGE_CACHE_SIZE);
+			bytes_read -= PAGE_CACHE_SIZE;
+		}
+		kunmap_atomic(target, KM_USER0);
+
+		flush_dcache_page(page);
+		SetPageUptodate(page);
+		unlock_page(page);
+		if (!pagevec_add(plru_pvec, page))
+			__pagevec_lru_add_file(plru_pvec);
+		data += PAGE_CACHE_SIZE;
+	}
+	return;
+}
+
+static int cifs_readpages(struct file *file, struct address_space *mapping,
+	struct list_head *page_list, unsigned num_pages)
+{
+	int rc = -EACCES;
+	int xid;
+	loff_t offset;
+	struct page *page;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	unsigned int bytes_read = 0;
+	unsigned int read_size, i;
+	char *smb_read_data = NULL;
+	struct smb_com_read_rsp *pSMBr;
+	struct pagevec lru_pvec;
+	struct cifsFileInfo *open_file;
+	int buf_type = CIFS_NO_BUFFER;
+
+	xid = GetXid();
+	if (file->private_data == NULL) {
+		FreeXid(xid);
+		return -EBADF;
+	}
+	open_file = (struct cifsFileInfo *)file->private_data;
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+
+	pagevec_init(&lru_pvec, 0);
+	cFYI(DBG2, ("rpages: num pages %d", num_pages));
+	for (i = 0; i < num_pages; ) {
+		unsigned contig_pages;
+		struct page *tmp_page;
+		unsigned long expected_index;
+
+		if (list_empty(page_list))
+			break;
+
+		page = list_entry(page_list->prev, struct page, lru);
+		offset = (loff_t)page->index << PAGE_CACHE_SHIFT;
+
+		/* count adjacent pages that we will read into */
+		contig_pages = 0;
+		expected_index =
+			list_entry(page_list->prev, struct page, lru)->index;
+		list_for_each_entry_reverse(tmp_page, page_list, lru) {
+			if (tmp_page->index == expected_index) {
+				contig_pages++;
+				expected_index++;
+			} else
+				break;
+		}
+		if (contig_pages + i >  num_pages)
+			contig_pages = num_pages - i;
+
+		/* for reads over a certain size could initiate async
+		   read ahead */
+
+		read_size = contig_pages * PAGE_CACHE_SIZE;
+		/* Read size needs to be in multiples of one page */
+		read_size = min_t(const unsigned int, read_size,
+				  cifs_sb->rsize & PAGE_CACHE_MASK);
+		cFYI(DBG2, ("rpages: read size 0x%x  contiguous pages %d",
+				read_size, contig_pages));
+		rc = -EAGAIN;
+		while (rc == -EAGAIN) {
+			if ((open_file->invalidHandle) &&
+			    (!open_file->closePend)) {
+				rc = cifs_reopen_file(file, true);
+				if (rc != 0)
+					break;
+			}
+
+			rc = CIFSSMBRead(xid, pTcon,
+					 open_file->netfid,
+					 read_size, offset,
+					 &bytes_read, &smb_read_data,
+					 &buf_type);
+			/* BB more RC checks ? */
+			if (rc == -EAGAIN) {
+				if (smb_read_data) {
+					if (buf_type == CIFS_SMALL_BUFFER)
+						cifs_small_buf_release(smb_read_data);
+					else if (buf_type == CIFS_LARGE_BUFFER)
+						cifs_buf_release(smb_read_data);
+					smb_read_data = NULL;
+				}
+			}
+		}
+		if ((rc < 0) || (smb_read_data == NULL)) {
+			cFYI(1, ("Read error in readpages: %d", rc));
+			break;
+		} else if (bytes_read > 0) {
+			task_io_account_read(bytes_read);
+			pSMBr = (struct smb_com_read_rsp *)smb_read_data;
+			cifs_copy_cache_pages(mapping, page_list, bytes_read,
+				smb_read_data + 4 /* RFC1001 hdr */ +
+				le16_to_cpu(pSMBr->DataOffset), &lru_pvec);
+
+			i +=  bytes_read >> PAGE_CACHE_SHIFT;
+			cifs_stats_bytes_read(pTcon, bytes_read);
+			if ((bytes_read & PAGE_CACHE_MASK) != bytes_read) {
+				i++; /* account for partial page */
+
+				/* server copy of file can have smaller size
+				   than client */
+				/* BB do we need to verify this common case ?
+				   this case is ok - if we are at server EOF
+				   we will hit it on next read */
+
+				/* break; */
+			}
+		} else {
+			cFYI(1, ("No bytes read (%d) at offset %lld . "
+				 "Cleaning remaining pages from readahead list",
+				 bytes_read, offset));
+			/* BB turn off caching and do new lookup on
+			   file size at server? */
+			break;
+		}
+		if (smb_read_data) {
+			if (buf_type == CIFS_SMALL_BUFFER)
+				cifs_small_buf_release(smb_read_data);
+			else if (buf_type == CIFS_LARGE_BUFFER)
+				cifs_buf_release(smb_read_data);
+			smb_read_data = NULL;
+		}
+		bytes_read = 0;
+	}
+
+	pagevec_lru_add_file(&lru_pvec);
+
+/* need to free smb_read_data buf before exit */
+	if (smb_read_data) {
+		if (buf_type == CIFS_SMALL_BUFFER)
+			cifs_small_buf_release(smb_read_data);
+		else if (buf_type == CIFS_LARGE_BUFFER)
+			cifs_buf_release(smb_read_data);
+		smb_read_data = NULL;
+	}
+
+	FreeXid(xid);
+	return rc;
+}
+
+static int cifs_readpage_worker(struct file *file, struct page *page,
+	loff_t *poffset)
+{
+	char *read_data;
+	int rc;
+
+	page_cache_get(page);
+	read_data = kmap(page);
+	/* for reads over a certain size could initiate async read ahead */
+
+	rc = cifs_read(file, read_data, PAGE_CACHE_SIZE, poffset);
+
+	if (rc < 0)
+		goto io_error;
+	else
+		cFYI(1, ("Bytes read %d", rc));
+
+	file->f_path.dentry->d_inode->i_atime =
+		current_fs_time(file->f_path.dentry->d_inode->i_sb);
+
+	if (PAGE_CACHE_SIZE > rc)
+		memset(read_data + rc, 0, PAGE_CACHE_SIZE - rc);
+
+	flush_dcache_page(page);
+	SetPageUptodate(page);
+	rc = 0;
+
+io_error:
+	kunmap(page);
+	page_cache_release(page);
+	return rc;
+}
+
+static int cifs_readpage(struct file *file, struct page *page)
+{
+	loff_t offset = (loff_t)page->index << PAGE_CACHE_SHIFT;
+	int rc = -EACCES;
+	int xid;
+
+	xid = GetXid();
+
+	if (file->private_data == NULL) {
+		FreeXid(xid);
+		return -EBADF;
+	}
+
+	cFYI(1, ("readpage %p at offset %d 0x%x\n",
+		 page, (int)offset, (int)offset));
+
+	rc = cifs_readpage_worker(file, page, &offset);
+
+	unlock_page(page);
+
+	FreeXid(xid);
+	return rc;
+}
+
+static int is_inode_writable(struct cifsInodeInfo *cifs_inode)
+{
+	struct cifsFileInfo *open_file;
+
+	read_lock(&GlobalSMBSeslock);
+	list_for_each_entry(open_file, &cifs_inode->openFileList, flist) {
+		if (open_file->closePend)
+			continue;
+		if (open_file->pfile &&
+		    ((open_file->pfile->f_flags & O_RDWR) ||
+		     (open_file->pfile->f_flags & O_WRONLY))) {
+			read_unlock(&GlobalSMBSeslock);
+			return 1;
+		}
+	}
+	read_unlock(&GlobalSMBSeslock);
+	return 0;
+}
+
+/* We do not want to update the file size from server for inodes
+   open for write - to avoid races with writepage extending
+   the file - in the future we could consider allowing
+   refreshing the inode only on increases in the file size
+   but this is tricky to do without racing with writebehind
+   page caching in the current Linux kernel design */
+bool is_size_safe_to_change(struct cifsInodeInfo *cifsInode, __u64 end_of_file)
+{
+	if (!cifsInode)
+		return true;
+
+	if (is_inode_writable(cifsInode)) {
+		/* This inode is open for write at least once */
+		struct cifs_sb_info *cifs_sb;
+
+		cifs_sb = CIFS_SB(cifsInode->vfs_inode.i_sb);
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DIRECT_IO) {
+			/* since no page cache to corrupt on directio
+			we can change size safely */
+			return true;
+		}
+
+		if (i_size_read(&cifsInode->vfs_inode) < end_of_file)
+			return true;
+
+		return false;
+	} else
+		return true;
+}
+
+static int cifs_write_begin(struct file *file, struct address_space *mapping,
+			loff_t pos, unsigned len, unsigned flags,
+			struct page **pagep, void **fsdata)
+{
+	pgoff_t index = pos >> PAGE_CACHE_SHIFT;
+	loff_t offset = pos & (PAGE_CACHE_SIZE - 1);
+	loff_t page_start = pos & PAGE_MASK;
+	loff_t i_size;
+	struct page *page;
+	int rc = 0;
+
+	cFYI(1, ("write_begin from %lld len %d", (long long)pos, len));
+
+	page = grab_cache_page_write_begin(mapping, index, flags);
+	if (!page) {
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	if (PageUptodate(page))
+		goto out;
+
+	/*
+	 * If we write a full page it will be up to date, no need to read from
+	 * the server. If the write is short, we'll end up doing a sync write
+	 * instead.
+	 */
+	if (len == PAGE_CACHE_SIZE)
+		goto out;
+
+	/*
+	 * optimize away the read when we have an oplock, and we're not
+	 * expecting to use any of the data we'd be reading in. That
+	 * is, when the page lies beyond the EOF, or straddles the EOF
+	 * and the write will cover all of the existing data.
+	 */
+	if (CIFS_I(mapping->host)->clientCanCacheRead) {
+		i_size = i_size_read(mapping->host);
+		if (page_start >= i_size ||
+		    (offset == 0 && (pos + len) >= i_size)) {
+			zero_user_segments(page, 0, offset,
+					   offset + len,
+					   PAGE_CACHE_SIZE);
+			/*
+			 * PageChecked means that the parts of the page
+			 * to which we're not writing are considered up
+			 * to date. Once the data is copied to the
+			 * page, it can be set uptodate.
+			 */
+			SetPageChecked(page);
+			goto out;
+		}
+	}
+
+	if ((file->f_flags & O_ACCMODE) != O_WRONLY) {
+		/*
+		 * might as well read a page, it is fast enough. If we get
+		 * an error, we don't need to return it. cifs_write_end will
+		 * do a sync write instead since PG_uptodate isn't set.
+		 */
+		cifs_readpage_worker(file, page, &page_start);
+	} else {
+		/* we could try using another file handle if there is one -
+		   but how would we lock it to prevent close of that handle
+		   racing with this read? In any case
+		   this will be written out by write_end so is fine */
+	}
+out:
+	*pagep = page;
+	return rc;
+}
+
+const struct address_space_operations cifs_addr_ops = {
+	.readpage = cifs_readpage,
+	.readpages = cifs_readpages,
+	.writepage = cifs_writepage,
+	.writepages = cifs_writepages,
+	.write_begin = cifs_write_begin,
+	.write_end = cifs_write_end,
+	.set_page_dirty = __set_page_dirty_nobuffers,
+	/* .sync_page = cifs_sync_page, */
+	/* .direct_IO = */
+};
+
+/*
+ * cifs_readpages requires the server to support a buffer large enough to
+ * contain the header plus one complete page of data.  Otherwise, we need
+ * to leave cifs_readpages out of the address space operations.
+ */
+const struct address_space_operations cifs_addr_ops_smallbuf = {
+	.readpage = cifs_readpage,
+	.writepage = cifs_writepage,
+	.writepages = cifs_writepages,
+	.write_begin = cifs_write_begin,
+	.write_end = cifs_write_end,
+	.set_page_dirty = __set_page_dirty_nobuffers,
+	/* .sync_page = cifs_sync_page, */
+	/* .direct_IO = */
+};
diff -Naur linux-2.6.30-ori/fs/cifs/inode.c linux-2.6.30-test/fs/cifs/inode.c
--- linux-2.6.30-ori/fs/cifs/inode.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/inode.c	2009-06-12 18:32:43.000000000 -0400
@@ -51,7 +51,9 @@
 
 		/* check if server can support readpages */
 		if (cifs_sb->tcon->ses->server->maxBuf <
-				PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE)
+				PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE 
+			// Test JFT
+			&& ! (cifs_sb->tcon->ses->capabilities & CAP_LARGE_FILES))
 			inode->i_data.a_ops = &cifs_addr_ops_smallbuf;
 		else
 			inode->i_data.a_ops = &cifs_addr_ops;
@@ -339,7 +341,7 @@
 		rc = CIFSSMBRead(xid, pTcon,
 				 netfid,
 				 24 /* length */, 0 /* offset */,
-				 &bytes_read, &pbuf, &buf_type);
+				 &bytes_read, &pbuf, &buf_type, 0);
 		if ((rc == 0) && (bytes_read >= 8)) {
 			if (memcmp("IntxBLK", pbuf, 8) == 0) {
 				cFYI(1, ("Block device"));
diff -Naur linux-2.6.30-ori/fs/cifs/readdir.c linux-2.6.30-test/fs/cifs/readdir.c
--- linux-2.6.30-ori/fs/cifs/readdir.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/readdir.c	2009-06-12 18:32:43.000000000 -0400
@@ -279,7 +279,9 @@
 
 		if ((cifs_sb->tcon) && (cifs_sb->tcon->ses) &&
 		   (cifs_sb->tcon->ses->server->maxBuf <
-			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE))
+			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE)
+			// Test JFT
+			&& ! (cifs_sb->tcon->ses->capabilities & CAP_LARGE_FILES))
 			tmp_inode->i_data.a_ops = &cifs_addr_ops_smallbuf;
 		else
 			tmp_inode->i_data.a_ops = &cifs_addr_ops;
@@ -412,7 +414,9 @@
 
 		if ((cifs_sb->tcon) && (cifs_sb->tcon->ses) &&
 		   (cifs_sb->tcon->ses->server->maxBuf <
-			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE))
+			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE)
+			// Test JFT
+			&& ! (cifs_sb->tcon->ses->capabilities & CAP_LARGE_FILES))
 			tmp_inode->i_data.a_ops = &cifs_addr_ops_smallbuf;
 		else
 			tmp_inode->i_data.a_ops = &cifs_addr_ops;
diff -Naur linux-2.6.30-ori/fs/cifs/readdir.c.orig linux-2.6.30-test/fs/cifs/readdir.c.orig
--- linux-2.6.30-ori/fs/cifs/readdir.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/cifs/readdir.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,1149 @@
+/*
+ *   fs/cifs/readdir.c
+ *
+ *   Directory search handling
+ *
+ *   Copyright (C) International Business Machines  Corp., 2004, 2008
+ *   Author(s): Steve French (sfrench@us.ibm.com)
+ *
+ *   This library is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU Lesser General Public License as published
+ *   by the Free Software Foundation; either version 2.1 of the License, or
+ *   (at your option) any later version.
+ *
+ *   This library is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+ *   the GNU Lesser General Public License for more details.
+ *
+ *   You should have received a copy of the GNU Lesser General Public License
+ *   along with this library; if not, write to the Free Software
+ *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+#include <linux/fs.h>
+#include <linux/pagemap.h>
+#include <linux/stat.h>
+#include "cifspdu.h"
+#include "cifsglob.h"
+#include "cifsproto.h"
+#include "cifs_unicode.h"
+#include "cifs_debug.h"
+#include "cifs_fs_sb.h"
+#include "cifsfs.h"
+
+/*
+ * To be safe - for UCS to UTF-8 with strings loaded with the rare long
+ * characters alloc more to account for such multibyte target UTF-8
+ * characters.
+ */
+#define UNICODE_NAME_MAX ((4 * NAME_MAX) + 2)
+
+#ifdef CONFIG_CIFS_DEBUG2
+static void dump_cifs_file_struct(struct file *file, char *label)
+{
+	struct cifsFileInfo *cf;
+
+	if (file) {
+		cf = file->private_data;
+		if (cf == NULL) {
+			cFYI(1, ("empty cifs private file data"));
+			return;
+		}
+		if (cf->invalidHandle)
+			cFYI(1, ("invalid handle"));
+		if (cf->srch_inf.endOfSearch)
+			cFYI(1, ("end of search"));
+		if (cf->srch_inf.emptyDir)
+			cFYI(1, ("empty dir"));
+	}
+}
+#else
+static inline void dump_cifs_file_struct(struct file *file, char *label)
+{
+}
+#endif /* DEBUG2 */
+
+/* Returns 1 if new inode created, 2 if both dentry and inode were */
+/* Might check in the future if inode number changed so we can rehash inode */
+static int
+construct_dentry(struct qstr *qstring, struct file *file,
+		 struct inode **ptmp_inode, struct dentry **pnew_dentry,
+		 __u64 *inum)
+{
+	struct dentry *tmp_dentry = NULL;
+	struct super_block *sb = file->f_path.dentry->d_sb;
+	int rc = 0;
+
+	cFYI(1, ("For %s", qstring->name));
+
+	qstring->hash = full_name_hash(qstring->name, qstring->len);
+	tmp_dentry = d_lookup(file->f_path.dentry, qstring);
+	if (tmp_dentry) {
+		/* BB: overwrite old name? i.e. tmp_dentry->d_name and
+		 * tmp_dentry->d_name.len??
+		 */
+		cFYI(0, ("existing dentry with inode 0x%p",
+			 tmp_dentry->d_inode));
+		*ptmp_inode = tmp_dentry->d_inode;
+		if (*ptmp_inode == NULL) {
+			*ptmp_inode = cifs_new_inode(sb, inum);
+			if (*ptmp_inode == NULL)
+				return rc;
+			rc = 1;
+		}
+	} else {
+		tmp_dentry = d_alloc(file->f_path.dentry, qstring);
+		if (tmp_dentry == NULL) {
+			cERROR(1, ("Failed allocating dentry"));
+			*ptmp_inode = NULL;
+			return rc;
+		}
+
+		if (CIFS_SB(sb)->tcon->nocase)
+			tmp_dentry->d_op = &cifs_ci_dentry_ops;
+		else
+			tmp_dentry->d_op = &cifs_dentry_ops;
+
+		*ptmp_inode = cifs_new_inode(sb, inum);
+		if (*ptmp_inode == NULL)
+			return rc;
+		rc = 2;
+	}
+
+	tmp_dentry->d_time = jiffies;
+	*pnew_dentry = tmp_dentry;
+	return rc;
+}
+
+static void AdjustForTZ(struct cifsTconInfo *tcon, struct inode *inode)
+{
+	if ((tcon) && (tcon->ses) && (tcon->ses->server)) {
+		inode->i_ctime.tv_sec += tcon->ses->server->timeAdj;
+		inode->i_mtime.tv_sec += tcon->ses->server->timeAdj;
+		inode->i_atime.tv_sec += tcon->ses->server->timeAdj;
+	}
+	return;
+}
+
+
+static void fill_in_inode(struct inode *tmp_inode, int new_buf_type,
+			  char *buf, unsigned int *pobject_type, int isNewInode)
+{
+	loff_t local_size;
+	struct timespec local_mtime;
+
+	struct cifsInodeInfo *cifsInfo = CIFS_I(tmp_inode);
+	struct cifs_sb_info *cifs_sb = CIFS_SB(tmp_inode->i_sb);
+	__u32 attr;
+	__u64 allocation_size;
+	__u64 end_of_file;
+	umode_t default_mode;
+
+	/* save mtime and size */
+	local_mtime = tmp_inode->i_mtime;
+	local_size  = tmp_inode->i_size;
+
+	if (new_buf_type) {
+		FILE_DIRECTORY_INFO *pfindData = (FILE_DIRECTORY_INFO *)buf;
+
+		attr = le32_to_cpu(pfindData->ExtFileAttributes);
+		allocation_size = le64_to_cpu(pfindData->AllocationSize);
+		end_of_file = le64_to_cpu(pfindData->EndOfFile);
+		tmp_inode->i_atime =
+		      cifs_NTtimeToUnix(le64_to_cpu(pfindData->LastAccessTime));
+		tmp_inode->i_mtime =
+		      cifs_NTtimeToUnix(le64_to_cpu(pfindData->LastWriteTime));
+		tmp_inode->i_ctime =
+		      cifs_NTtimeToUnix(le64_to_cpu(pfindData->ChangeTime));
+	} else { /* legacy, OS2 and DOS style */
+/*		struct timespec ts;*/
+		FIND_FILE_STANDARD_INFO *pfindData =
+			(FIND_FILE_STANDARD_INFO *)buf;
+
+		tmp_inode->i_mtime = cnvrtDosUnixTm(
+				le16_to_cpu(pfindData->LastWriteDate),
+				le16_to_cpu(pfindData->LastWriteTime));
+		tmp_inode->i_atime = cnvrtDosUnixTm(
+				le16_to_cpu(pfindData->LastAccessDate),
+				le16_to_cpu(pfindData->LastAccessTime));
+		tmp_inode->i_ctime = cnvrtDosUnixTm(
+				le16_to_cpu(pfindData->LastWriteDate),
+				le16_to_cpu(pfindData->LastWriteTime));
+		AdjustForTZ(cifs_sb->tcon, tmp_inode);
+		attr = le16_to_cpu(pfindData->Attributes);
+		allocation_size = le32_to_cpu(pfindData->AllocationSize);
+		end_of_file = le32_to_cpu(pfindData->DataSize);
+	}
+
+	/* Linux can not store file creation time unfortunately so ignore it */
+
+	cifsInfo->cifsAttrs = attr;
+#ifdef CONFIG_CIFS_EXPERIMENTAL
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_CIFS_ACL) {
+		/* get more accurate mode via ACL - so force inode refresh */
+		cifsInfo->time = 0;
+	} else
+#endif /* CONFIG_CIFS_EXPERIMENTAL */
+		cifsInfo->time = jiffies;
+
+	/* treat dos attribute of read-only as read-only mode bit e.g. 555? */
+	/* 2767 perms - indicate mandatory locking */
+		/* BB fill in uid and gid here? with help from winbind?
+		   or retrieve from NTFS stream extended attribute */
+	if (atomic_read(&cifsInfo->inUse) == 0) {
+		tmp_inode->i_uid = cifs_sb->mnt_uid;
+		tmp_inode->i_gid = cifs_sb->mnt_gid;
+	}
+
+	if (attr & ATTR_DIRECTORY)
+		default_mode = cifs_sb->mnt_dir_mode;
+	else
+		default_mode = cifs_sb->mnt_file_mode;
+
+	/* set initial permissions */
+	if ((atomic_read(&cifsInfo->inUse) == 0) ||
+	    (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DYNPERM) == 0)
+		tmp_inode->i_mode = default_mode;
+	else {
+		/* just reenable write bits if !ATTR_READONLY */
+		if ((tmp_inode->i_mode & S_IWUGO) == 0 &&
+		    (attr & ATTR_READONLY) == 0)
+			tmp_inode->i_mode |= (S_IWUGO & default_mode);
+
+		tmp_inode->i_mode &= ~S_IFMT;
+	}
+
+	/* clear write bits if ATTR_READONLY is set */
+	if (attr & ATTR_READONLY)
+		tmp_inode->i_mode &= ~S_IWUGO;
+
+	/* set inode type */
+	if ((attr & ATTR_SYSTEM) &&
+	    (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_UNX_EMUL)) {
+		if (end_of_file == 0)  {
+			tmp_inode->i_mode |= S_IFIFO;
+			*pobject_type = DT_FIFO;
+		} else {
+			/*
+			 * trying to get the type can be slow, so just call
+			 * this a regular file for now, and mark for reval
+			 */
+			tmp_inode->i_mode |= S_IFREG;
+			*pobject_type = DT_REG;
+			cifsInfo->time = 0;
+		}
+	} else {
+		if (attr & ATTR_DIRECTORY) {
+			tmp_inode->i_mode |= S_IFDIR;
+			*pobject_type = DT_DIR;
+		} else {
+			tmp_inode->i_mode |= S_IFREG;
+			*pobject_type = DT_REG;
+		}
+	}
+
+	/* can not fill in nlink here as in qpathinfo version and Unx search */
+	if (atomic_read(&cifsInfo->inUse) == 0)
+		atomic_set(&cifsInfo->inUse, 1);
+
+	cifsInfo->server_eof = end_of_file;
+	spin_lock(&tmp_inode->i_lock);
+	if (is_size_safe_to_change(cifsInfo, end_of_file)) {
+		/* can not safely change the file size here if the
+		client is writing to it due to potential races */
+		i_size_write(tmp_inode, end_of_file);
+
+	/* 512 bytes (2**9) is the fake blocksize that must be used */
+	/* for this calculation, even though the reported blocksize is larger */
+		tmp_inode->i_blocks = (512 - 1 + allocation_size) >> 9;
+	}
+	spin_unlock(&tmp_inode->i_lock);
+
+	if (allocation_size < end_of_file)
+		cFYI(1, ("May be sparse file, allocation less than file size"));
+	cFYI(1, ("File Size %ld and blocks %llu",
+		(unsigned long)tmp_inode->i_size,
+		(unsigned long long)tmp_inode->i_blocks));
+	if (S_ISREG(tmp_inode->i_mode)) {
+		cFYI(1, ("File inode"));
+		tmp_inode->i_op = &cifs_file_inode_ops;
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DIRECT_IO) {
+			if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_BRL)
+				tmp_inode->i_fop = &cifs_file_direct_nobrl_ops;
+			else
+				tmp_inode->i_fop = &cifs_file_direct_ops;
+		} else if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_BRL)
+			tmp_inode->i_fop = &cifs_file_nobrl_ops;
+		else
+			tmp_inode->i_fop = &cifs_file_ops;
+
+		if ((cifs_sb->tcon) && (cifs_sb->tcon->ses) &&
+		   (cifs_sb->tcon->ses->server->maxBuf <
+			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE))
+			tmp_inode->i_data.a_ops = &cifs_addr_ops_smallbuf;
+		else
+			tmp_inode->i_data.a_ops = &cifs_addr_ops;
+
+		if (isNewInode)
+			return; /* No sense invalidating pages for new inode
+				   since have not started caching readahead file
+				   data yet */
+
+		if (timespec_equal(&tmp_inode->i_mtime, &local_mtime) &&
+			(local_size == tmp_inode->i_size)) {
+			cFYI(1, ("inode exists but unchanged"));
+		} else {
+			/* file may have changed on server */
+			cFYI(1, ("invalidate inode, readdir detected change"));
+			invalidate_remote_inode(tmp_inode);
+		}
+	} else if (S_ISDIR(tmp_inode->i_mode)) {
+		cFYI(1, ("Directory inode"));
+		tmp_inode->i_op = &cifs_dir_inode_ops;
+		tmp_inode->i_fop = &cifs_dir_ops;
+	} else if (S_ISLNK(tmp_inode->i_mode)) {
+		cFYI(1, ("Symbolic Link inode"));
+		tmp_inode->i_op = &cifs_symlink_inode_ops;
+	} else {
+		cFYI(1, ("Init special inode"));
+		init_special_inode(tmp_inode, tmp_inode->i_mode,
+				   tmp_inode->i_rdev);
+	}
+}
+
+static void unix_fill_in_inode(struct inode *tmp_inode,
+	FILE_UNIX_INFO *pfindData, unsigned int *pobject_type, int isNewInode)
+{
+	loff_t local_size;
+	struct timespec local_mtime;
+
+	struct cifsInodeInfo *cifsInfo = CIFS_I(tmp_inode);
+	struct cifs_sb_info *cifs_sb = CIFS_SB(tmp_inode->i_sb);
+
+	__u32 type = le32_to_cpu(pfindData->Type);
+	__u64 num_of_bytes = le64_to_cpu(pfindData->NumOfBytes);
+	__u64 end_of_file = le64_to_cpu(pfindData->EndOfFile);
+	cifsInfo->time = jiffies;
+	atomic_inc(&cifsInfo->inUse);
+
+	/* save mtime and size */
+	local_mtime = tmp_inode->i_mtime;
+	local_size  = tmp_inode->i_size;
+
+	tmp_inode->i_atime =
+	    cifs_NTtimeToUnix(le64_to_cpu(pfindData->LastAccessTime));
+	tmp_inode->i_mtime =
+	    cifs_NTtimeToUnix(le64_to_cpu(pfindData->LastModificationTime));
+	tmp_inode->i_ctime =
+	    cifs_NTtimeToUnix(le64_to_cpu(pfindData->LastStatusChange));
+
+	tmp_inode->i_mode = le64_to_cpu(pfindData->Permissions);
+	/* since we set the inode type below we need to mask off type
+	   to avoid strange results if bits above were corrupt */
+	tmp_inode->i_mode &= ~S_IFMT;
+	if (type == UNIX_FILE) {
+		*pobject_type = DT_REG;
+		tmp_inode->i_mode |= S_IFREG;
+	} else if (type == UNIX_SYMLINK) {
+		*pobject_type = DT_LNK;
+		tmp_inode->i_mode |= S_IFLNK;
+	} else if (type == UNIX_DIR) {
+		*pobject_type = DT_DIR;
+		tmp_inode->i_mode |= S_IFDIR;
+	} else if (type == UNIX_CHARDEV) {
+		*pobject_type = DT_CHR;
+		tmp_inode->i_mode |= S_IFCHR;
+		tmp_inode->i_rdev = MKDEV(le64_to_cpu(pfindData->DevMajor),
+				le64_to_cpu(pfindData->DevMinor) & MINORMASK);
+	} else if (type == UNIX_BLOCKDEV) {
+		*pobject_type = DT_BLK;
+		tmp_inode->i_mode |= S_IFBLK;
+		tmp_inode->i_rdev = MKDEV(le64_to_cpu(pfindData->DevMajor),
+				le64_to_cpu(pfindData->DevMinor) & MINORMASK);
+	} else if (type == UNIX_FIFO) {
+		*pobject_type = DT_FIFO;
+		tmp_inode->i_mode |= S_IFIFO;
+	} else if (type == UNIX_SOCKET) {
+		*pobject_type = DT_SOCK;
+		tmp_inode->i_mode |= S_IFSOCK;
+	} else {
+		/* safest to just call it a file */
+		*pobject_type = DT_REG;
+		tmp_inode->i_mode |= S_IFREG;
+		cFYI(1, ("unknown inode type %d", type));
+	}
+
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_OVERR_UID)
+		tmp_inode->i_uid = cifs_sb->mnt_uid;
+	else
+		tmp_inode->i_uid = le64_to_cpu(pfindData->Uid);
+	if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_OVERR_GID)
+		tmp_inode->i_gid = cifs_sb->mnt_gid;
+	else
+		tmp_inode->i_gid = le64_to_cpu(pfindData->Gid);
+	tmp_inode->i_nlink = le64_to_cpu(pfindData->Nlinks);
+
+	cifsInfo->server_eof = end_of_file;
+	spin_lock(&tmp_inode->i_lock);
+	if (is_size_safe_to_change(cifsInfo, end_of_file)) {
+		/* can not safely change the file size here if the
+		client is writing to it due to potential races */
+		i_size_write(tmp_inode, end_of_file);
+
+	/* 512 bytes (2**9) is the fake blocksize that must be used */
+	/* for this calculation, not the real blocksize */
+		tmp_inode->i_blocks = (512 - 1 + num_of_bytes) >> 9;
+	}
+	spin_unlock(&tmp_inode->i_lock);
+
+	if (S_ISREG(tmp_inode->i_mode)) {
+		cFYI(1, ("File inode"));
+		tmp_inode->i_op = &cifs_file_inode_ops;
+
+		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_DIRECT_IO) {
+			if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_BRL)
+				tmp_inode->i_fop = &cifs_file_direct_nobrl_ops;
+			else
+				tmp_inode->i_fop = &cifs_file_direct_ops;
+		} else if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_NO_BRL)
+			tmp_inode->i_fop = &cifs_file_nobrl_ops;
+		else
+			tmp_inode->i_fop = &cifs_file_ops;
+
+		if ((cifs_sb->tcon) && (cifs_sb->tcon->ses) &&
+		   (cifs_sb->tcon->ses->server->maxBuf <
+			PAGE_CACHE_SIZE + MAX_CIFS_HDR_SIZE))
+			tmp_inode->i_data.a_ops = &cifs_addr_ops_smallbuf;
+		else
+			tmp_inode->i_data.a_ops = &cifs_addr_ops;
+
+		if (isNewInode)
+			return; /* No sense invalidating pages for new inode
+				   since we have not started caching readahead
+				   file data for it yet */
+
+		if (timespec_equal(&tmp_inode->i_mtime, &local_mtime) &&
+			(local_size == tmp_inode->i_size)) {
+			cFYI(1, ("inode exists but unchanged"));
+		} else {
+			/* file may have changed on server */
+			cFYI(1, ("invalidate inode, readdir detected change"));
+			invalidate_remote_inode(tmp_inode);
+		}
+	} else if (S_ISDIR(tmp_inode->i_mode)) {
+		cFYI(1, ("Directory inode"));
+		tmp_inode->i_op = &cifs_dir_inode_ops;
+		tmp_inode->i_fop = &cifs_dir_ops;
+	} else if (S_ISLNK(tmp_inode->i_mode)) {
+		cFYI(1, ("Symbolic Link inode"));
+		tmp_inode->i_op = &cifs_symlink_inode_ops;
+/* tmp_inode->i_fop = *//* do not need to set to anything */
+	} else {
+		cFYI(1, ("Special inode"));
+		init_special_inode(tmp_inode, tmp_inode->i_mode,
+				   tmp_inode->i_rdev);
+	}
+}
+
+/* BB eventually need to add the following helper function to
+      resolve NT_STATUS_STOPPED_ON_SYMLINK return code when
+      we try to do FindFirst on (NTFS) directory symlinks */
+/*
+int get_symlink_reparse_path(char *full_path, struct cifs_sb_info *cifs_sb,
+			     int xid)
+{
+	__u16 fid;
+	int len;
+	int oplock = 0;
+	int rc;
+	struct cifsTconInfo *ptcon = cifs_sb->tcon;
+	char *tmpbuffer;
+
+	rc = CIFSSMBOpen(xid, ptcon, full_path, FILE_OPEN, GENERIC_READ,
+			OPEN_REPARSE_POINT, &fid, &oplock, NULL,
+			cifs_sb->local_nls,
+			cifs_sb->mnt_cifs_flags & CIFS_MOUNT_MAP_SPECIAL_CHR);
+	if (!rc) {
+		tmpbuffer = kmalloc(maxpath);
+		rc = CIFSSMBQueryReparseLinkInfo(xid, ptcon, full_path,
+				tmpbuffer,
+				maxpath -1,
+				fid,
+				cifs_sb->local_nls);
+		if (CIFSSMBClose(xid, ptcon, fid)) {
+			cFYI(1, ("Error closing temporary reparsepoint open)"));
+		}
+	}
+}
+ */
+
+static int initiate_cifs_search(const int xid, struct file *file)
+{
+	int rc = 0;
+	char *full_path;
+	struct cifsFileInfo *cifsFile;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+
+	if (file->private_data == NULL) {
+		file->private_data =
+			kzalloc(sizeof(struct cifsFileInfo), GFP_KERNEL);
+	}
+
+	if (file->private_data == NULL)
+		return -ENOMEM;
+	cifsFile = file->private_data;
+	cifsFile->invalidHandle = true;
+	cifsFile->srch_inf.endOfSearch = false;
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	if (cifs_sb == NULL)
+		return -EINVAL;
+
+	pTcon = cifs_sb->tcon;
+	if (pTcon == NULL)
+		return -EINVAL;
+
+	full_path = build_path_from_dentry(file->f_path.dentry);
+
+	if (full_path == NULL)
+		return -ENOMEM;
+
+	cFYI(1, ("Full path: %s start at: %lld", full_path, file->f_pos));
+
+ffirst_retry:
+	/* test for Unix extensions */
+	/* but now check for them on the share/mount not on the SMB session */
+/*	if (pTcon->ses->capabilities & CAP_UNIX) { */
+	if (pTcon->unix_ext)
+		cifsFile->srch_inf.info_level = SMB_FIND_FILE_UNIX;
+	else if ((pTcon->ses->capabilities &
+			(CAP_NT_SMBS | CAP_NT_FIND)) == 0) {
+		cifsFile->srch_inf.info_level = SMB_FIND_FILE_INFO_STANDARD;
+	} else if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SERVER_INUM) {
+		cifsFile->srch_inf.info_level = SMB_FIND_FILE_ID_FULL_DIR_INFO;
+	} else /* not srvinos - BB fixme add check for backlevel? */ {
+		cifsFile->srch_inf.info_level = SMB_FIND_FILE_DIRECTORY_INFO;
+	}
+
+	rc = CIFSFindFirst(xid, pTcon, full_path, cifs_sb->local_nls,
+		&cifsFile->netfid, &cifsFile->srch_inf,
+		cifs_sb->mnt_cifs_flags &
+			CIFS_MOUNT_MAP_SPECIAL_CHR, CIFS_DIR_SEP(cifs_sb));
+	if (rc == 0)
+		cifsFile->invalidHandle = false;
+	/* BB add following call to handle readdir on new NTFS symlink errors
+	else if STATUS_STOPPED_ON_SYMLINK
+		call get_symlink_reparse_path and retry with new path */
+	else if ((rc == -EOPNOTSUPP) &&
+		(cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SERVER_INUM)) {
+		cifs_sb->mnt_cifs_flags &= ~CIFS_MOUNT_SERVER_INUM;
+		goto ffirst_retry;
+	}
+	kfree(full_path);
+	return rc;
+}
+
+/* return length of unicode string in bytes */
+static int cifs_unicode_bytelen(char *str)
+{
+	int len;
+	__le16 *ustr = (__le16 *)str;
+
+	for (len = 0; len <= PATH_MAX; len++) {
+		if (ustr[len] == 0)
+			return len << 1;
+	}
+	cFYI(1, ("Unicode string longer than PATH_MAX found"));
+	return len << 1;
+}
+
+static char *nxt_dir_entry(char *old_entry, char *end_of_smb, int level)
+{
+	char *new_entry;
+	FILE_DIRECTORY_INFO *pDirInfo = (FILE_DIRECTORY_INFO *)old_entry;
+
+	if (level == SMB_FIND_FILE_INFO_STANDARD) {
+		FIND_FILE_STANDARD_INFO *pfData;
+		pfData = (FIND_FILE_STANDARD_INFO *)pDirInfo;
+
+		new_entry = old_entry + sizeof(FIND_FILE_STANDARD_INFO) +
+				pfData->FileNameLength;
+	} else
+		new_entry = old_entry + le32_to_cpu(pDirInfo->NextEntryOffset);
+	cFYI(1, ("new entry %p old entry %p", new_entry, old_entry));
+	/* validate that new_entry is not past end of SMB */
+	if (new_entry >= end_of_smb) {
+		cERROR(1,
+		      ("search entry %p began after end of SMB %p old entry %p",
+			new_entry, end_of_smb, old_entry));
+		return NULL;
+	} else if (((level == SMB_FIND_FILE_INFO_STANDARD) &&
+		    (new_entry + sizeof(FIND_FILE_STANDARD_INFO) > end_of_smb))
+		  || ((level != SMB_FIND_FILE_INFO_STANDARD) &&
+		   (new_entry + sizeof(FILE_DIRECTORY_INFO) > end_of_smb)))  {
+		cERROR(1, ("search entry %p extends after end of SMB %p",
+			new_entry, end_of_smb));
+		return NULL;
+	} else
+		return new_entry;
+
+}
+
+#define UNICODE_DOT cpu_to_le16(0x2e)
+
+/* return 0 if no match and 1 for . (current directory) and 2 for .. (parent) */
+static int cifs_entry_is_dot(char *current_entry, struct cifsFileInfo *cfile)
+{
+	int rc = 0;
+	char *filename = NULL;
+	int len = 0;
+
+	if (cfile->srch_inf.info_level == SMB_FIND_FILE_UNIX) {
+		FILE_UNIX_INFO *pFindData = (FILE_UNIX_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		if (cfile->srch_inf.unicode) {
+			len = cifs_unicode_bytelen(filename);
+		} else {
+			/* BB should we make this strnlen of PATH_MAX? */
+			len = strnlen(filename, 5);
+		}
+	} else if (cfile->srch_inf.info_level == SMB_FIND_FILE_DIRECTORY_INFO) {
+		FILE_DIRECTORY_INFO *pFindData =
+			(FILE_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (cfile->srch_inf.info_level ==
+			SMB_FIND_FILE_FULL_DIRECTORY_INFO) {
+		FILE_FULL_DIRECTORY_INFO *pFindData =
+			(FILE_FULL_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (cfile->srch_inf.info_level ==
+			SMB_FIND_FILE_ID_FULL_DIR_INFO) {
+		SEARCH_ID_FULL_DIR_INFO *pFindData =
+			(SEARCH_ID_FULL_DIR_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (cfile->srch_inf.info_level ==
+			SMB_FIND_FILE_BOTH_DIRECTORY_INFO) {
+		FILE_BOTH_DIRECTORY_INFO *pFindData =
+			(FILE_BOTH_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (cfile->srch_inf.info_level == SMB_FIND_FILE_INFO_STANDARD) {
+		FIND_FILE_STANDARD_INFO *pFindData =
+			(FIND_FILE_STANDARD_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = pFindData->FileNameLength;
+	} else {
+		cFYI(1, ("Unknown findfirst level %d",
+			 cfile->srch_inf.info_level));
+	}
+
+	if (filename) {
+		if (cfile->srch_inf.unicode) {
+			__le16 *ufilename = (__le16 *)filename;
+			if (len == 2) {
+				/* check for . */
+				if (ufilename[0] == UNICODE_DOT)
+					rc = 1;
+			} else if (len == 4) {
+				/* check for .. */
+				if ((ufilename[0] == UNICODE_DOT)
+				   && (ufilename[1] == UNICODE_DOT))
+					rc = 2;
+			}
+		} else /* ASCII */ {
+			if (len == 1) {
+				if (filename[0] == '.')
+					rc = 1;
+			} else if (len == 2) {
+				if ((filename[0] == '.') && (filename[1] == '.'))
+					rc = 2;
+			}
+		}
+	}
+
+	return rc;
+}
+
+/* Check if directory that we are searching has changed so we can decide
+   whether we can use the cached search results from the previous search */
+static int is_dir_changed(struct file *file)
+{
+	struct inode *inode = file->f_path.dentry->d_inode;
+	struct cifsInodeInfo *cifsInfo = CIFS_I(inode);
+
+	if (cifsInfo->time == 0)
+		return 1; /* directory was changed, perhaps due to unlink */
+	else
+		return 0;
+
+}
+
+static int cifs_save_resume_key(const char *current_entry,
+	struct cifsFileInfo *cifsFile)
+{
+	int rc = 0;
+	unsigned int len = 0;
+	__u16 level;
+	char *filename;
+
+	if ((cifsFile == NULL) || (current_entry == NULL))
+		return -EINVAL;
+
+	level = cifsFile->srch_inf.info_level;
+
+	if (level == SMB_FIND_FILE_UNIX) {
+		FILE_UNIX_INFO *pFindData = (FILE_UNIX_INFO *)current_entry;
+
+		filename = &pFindData->FileName[0];
+		if (cifsFile->srch_inf.unicode) {
+			len = cifs_unicode_bytelen(filename);
+		} else {
+			/* BB should we make this strnlen of PATH_MAX? */
+			len = strnlen(filename, PATH_MAX);
+		}
+		cifsFile->srch_inf.resume_key = pFindData->ResumeKey;
+	} else if (level == SMB_FIND_FILE_DIRECTORY_INFO) {
+		FILE_DIRECTORY_INFO *pFindData =
+			(FILE_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+		cifsFile->srch_inf.resume_key = pFindData->FileIndex;
+	} else if (level == SMB_FIND_FILE_FULL_DIRECTORY_INFO) {
+		FILE_FULL_DIRECTORY_INFO *pFindData =
+			(FILE_FULL_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+		cifsFile->srch_inf.resume_key = pFindData->FileIndex;
+	} else if (level == SMB_FIND_FILE_ID_FULL_DIR_INFO) {
+		SEARCH_ID_FULL_DIR_INFO *pFindData =
+			(SEARCH_ID_FULL_DIR_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+		cifsFile->srch_inf.resume_key = pFindData->FileIndex;
+	} else if (level == SMB_FIND_FILE_BOTH_DIRECTORY_INFO) {
+		FILE_BOTH_DIRECTORY_INFO *pFindData =
+			(FILE_BOTH_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+		cifsFile->srch_inf.resume_key = pFindData->FileIndex;
+	} else if (level == SMB_FIND_FILE_INFO_STANDARD) {
+		FIND_FILE_STANDARD_INFO *pFindData =
+			(FIND_FILE_STANDARD_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		/* one byte length, no name conversion */
+		len = (unsigned int)pFindData->FileNameLength;
+		cifsFile->srch_inf.resume_key = pFindData->ResumeKey;
+	} else {
+		cFYI(1, ("Unknown findfirst level %d", level));
+		return -EINVAL;
+	}
+	cifsFile->srch_inf.resume_name_len = len;
+	cifsFile->srch_inf.presume_name = filename;
+	return rc;
+}
+
+/* find the corresponding entry in the search */
+/* Note that the SMB server returns search entries for . and .. which
+   complicates logic here if we choose to parse for them and we do not
+   assume that they are located in the findfirst return buffer.*/
+/* We start counting in the buffer with entry 2 and increment for every
+   entry (do not increment for . or .. entry) */
+static int find_cifs_entry(const int xid, struct cifsTconInfo *pTcon,
+	struct file *file, char **ppCurrentEntry, int *num_to_ret)
+{
+	int rc = 0;
+	int pos_in_buf = 0;
+	loff_t first_entry_in_buffer;
+	loff_t index_to_find = file->f_pos;
+	struct cifsFileInfo *cifsFile = file->private_data;
+	/* check if index in the buffer */
+
+	if ((cifsFile == NULL) || (ppCurrentEntry == NULL) ||
+	   (num_to_ret == NULL))
+		return -ENOENT;
+
+	*ppCurrentEntry = NULL;
+	first_entry_in_buffer =
+		cifsFile->srch_inf.index_of_last_entry -
+			cifsFile->srch_inf.entries_in_buffer;
+
+	/* if first entry in buf is zero then is first buffer
+	in search response data which means it is likely . and ..
+	will be in this buffer, although some servers do not return
+	. and .. for the root of a drive and for those we need
+	to start two entries earlier */
+
+	dump_cifs_file_struct(file, "In fce ");
+	if (((index_to_find < cifsFile->srch_inf.index_of_last_entry) &&
+	     is_dir_changed(file)) ||
+	   (index_to_find < first_entry_in_buffer)) {
+		/* close and restart search */
+		cFYI(1, ("search backing up - close and restart search"));
+		write_lock(&GlobalSMBSeslock);
+		if (!cifsFile->srch_inf.endOfSearch &&
+		    !cifsFile->invalidHandle) {
+			cifsFile->invalidHandle = true;
+			write_unlock(&GlobalSMBSeslock);
+			CIFSFindClose(xid, pTcon, cifsFile->netfid);
+		} else
+			write_unlock(&GlobalSMBSeslock);
+		if (cifsFile->srch_inf.ntwrk_buf_start) {
+			cFYI(1, ("freeing SMB ff cache buf on search rewind"));
+			if (cifsFile->srch_inf.smallBuf)
+				cifs_small_buf_release(cifsFile->srch_inf.
+						ntwrk_buf_start);
+			else
+				cifs_buf_release(cifsFile->srch_inf.
+						ntwrk_buf_start);
+			cifsFile->srch_inf.ntwrk_buf_start = NULL;
+		}
+		rc = initiate_cifs_search(xid, file);
+		if (rc) {
+			cFYI(1, ("error %d reinitiating a search on rewind",
+				 rc));
+			return rc;
+		}
+		cifs_save_resume_key(cifsFile->srch_inf.last_entry, cifsFile);
+	}
+
+	while ((index_to_find >= cifsFile->srch_inf.index_of_last_entry) &&
+	      (rc == 0) && !cifsFile->srch_inf.endOfSearch) {
+		cFYI(1, ("calling findnext2"));
+		rc = CIFSFindNext(xid, pTcon, cifsFile->netfid,
+				  &cifsFile->srch_inf);
+		cifs_save_resume_key(cifsFile->srch_inf.last_entry, cifsFile);
+		if (rc)
+			return -ENOENT;
+	}
+	if (index_to_find < cifsFile->srch_inf.index_of_last_entry) {
+		/* we found the buffer that contains the entry */
+		/* scan and find it */
+		int i;
+		char *current_entry;
+		char *end_of_smb = cifsFile->srch_inf.ntwrk_buf_start +
+			smbCalcSize((struct smb_hdr *)
+				cifsFile->srch_inf.ntwrk_buf_start);
+
+		current_entry = cifsFile->srch_inf.srch_entries_start;
+		first_entry_in_buffer = cifsFile->srch_inf.index_of_last_entry
+					- cifsFile->srch_inf.entries_in_buffer;
+		pos_in_buf = index_to_find - first_entry_in_buffer;
+		cFYI(1, ("found entry - pos_in_buf %d", pos_in_buf));
+
+		for (i = 0; (i < (pos_in_buf)) && (current_entry != NULL); i++) {
+			/* go entry by entry figuring out which is first */
+			current_entry = nxt_dir_entry(current_entry, end_of_smb,
+						cifsFile->srch_inf.info_level);
+		}
+		if ((current_entry == NULL) && (i < pos_in_buf)) {
+			/* BB fixme - check if we should flag this error */
+			cERROR(1, ("reached end of buf searching for pos in buf"
+			  " %d index to find %lld rc %d",
+			  pos_in_buf, index_to_find, rc));
+		}
+		rc = 0;
+		*ppCurrentEntry = current_entry;
+	} else {
+		cFYI(1, ("index not in buffer - could not findnext into it"));
+		return 0;
+	}
+
+	if (pos_in_buf >= cifsFile->srch_inf.entries_in_buffer) {
+		cFYI(1, ("can not return entries pos_in_buf beyond last"));
+		*num_to_ret = 0;
+	} else
+		*num_to_ret = cifsFile->srch_inf.entries_in_buffer - pos_in_buf;
+
+	return rc;
+}
+
+/* inode num, inode type and filename returned */
+static int cifs_get_name_from_search_buf(struct qstr *pqst,
+	char *current_entry, __u16 level, unsigned int unicode,
+	struct cifs_sb_info *cifs_sb, unsigned int max_len, __u64 *pinum)
+{
+	int rc = 0;
+	unsigned int len = 0;
+	char *filename;
+	struct nls_table *nlt = cifs_sb->local_nls;
+
+	*pinum = 0;
+
+	if (level == SMB_FIND_FILE_UNIX) {
+		FILE_UNIX_INFO *pFindData = (FILE_UNIX_INFO *)current_entry;
+
+		filename = &pFindData->FileName[0];
+		if (unicode) {
+			len = cifs_unicode_bytelen(filename);
+		} else {
+			/* BB should we make this strnlen of PATH_MAX? */
+			len = strnlen(filename, PATH_MAX);
+		}
+
+		*pinum = le64_to_cpu(pFindData->UniqueId);
+	} else if (level == SMB_FIND_FILE_DIRECTORY_INFO) {
+		FILE_DIRECTORY_INFO *pFindData =
+			(FILE_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (level == SMB_FIND_FILE_FULL_DIRECTORY_INFO) {
+		FILE_FULL_DIRECTORY_INFO *pFindData =
+			(FILE_FULL_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (level == SMB_FIND_FILE_ID_FULL_DIR_INFO) {
+		SEARCH_ID_FULL_DIR_INFO *pFindData =
+			(SEARCH_ID_FULL_DIR_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+		*pinum = le64_to_cpu(pFindData->UniqueId);
+	} else if (level == SMB_FIND_FILE_BOTH_DIRECTORY_INFO) {
+		FILE_BOTH_DIRECTORY_INFO *pFindData =
+			(FILE_BOTH_DIRECTORY_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		len = le32_to_cpu(pFindData->FileNameLength);
+	} else if (level == SMB_FIND_FILE_INFO_STANDARD) {
+		FIND_FILE_STANDARD_INFO *pFindData =
+			(FIND_FILE_STANDARD_INFO *)current_entry;
+		filename = &pFindData->FileName[0];
+		/* one byte length, no name conversion */
+		len = (unsigned int)pFindData->FileNameLength;
+	} else {
+		cFYI(1, ("Unknown findfirst level %d", level));
+		return -EINVAL;
+	}
+
+	if (len > max_len) {
+		cERROR(1, ("bad search response length %d past smb end", len));
+		return -EINVAL;
+	}
+
+	if (unicode) {
+		pqst->len = cifs_from_ucs2((char *) pqst->name,
+					   (__le16 *) filename,
+					   UNICODE_NAME_MAX,
+					   min(len, max_len), nlt,
+					   cifs_sb->mnt_cifs_flags &
+						CIFS_MOUNT_MAP_SPECIAL_CHR);
+	} else {
+		pqst->name = filename;
+		pqst->len = len;
+	}
+	pqst->hash = full_name_hash(pqst->name, pqst->len);
+/*	cFYI(1, ("filldir on %s",pqst->name));  */
+	return rc;
+}
+
+static int cifs_filldir(char *pfindEntry, struct file *file, filldir_t filldir,
+			void *direntry, char *scratch_buf, unsigned int max_len)
+{
+	int rc = 0;
+	struct qstr qstring;
+	struct cifsFileInfo *pCifsF;
+	unsigned int obj_type;
+	__u64  inum;
+	struct cifs_sb_info *cifs_sb;
+	struct inode *tmp_inode;
+	struct dentry *tmp_dentry;
+
+	/* get filename and len into qstring */
+	/* get dentry */
+	/* decide whether to create and populate ionde */
+	if ((direntry == NULL) || (file == NULL))
+		return -EINVAL;
+
+	pCifsF = file->private_data;
+
+	if ((scratch_buf == NULL) || (pfindEntry == NULL) || (pCifsF == NULL))
+		return -ENOENT;
+
+	rc = cifs_entry_is_dot(pfindEntry, pCifsF);
+	/* skip . and .. since we added them first */
+	if (rc != 0)
+		return 0;
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+
+	qstring.name = scratch_buf;
+	rc = cifs_get_name_from_search_buf(&qstring, pfindEntry,
+			pCifsF->srch_inf.info_level,
+			pCifsF->srch_inf.unicode, cifs_sb,
+			max_len,
+			&inum /* returned */);
+
+	if (rc)
+		return rc;
+
+	/* only these two infolevels return valid inode numbers */
+	if (pCifsF->srch_inf.info_level == SMB_FIND_FILE_UNIX ||
+	    pCifsF->srch_inf.info_level == SMB_FIND_FILE_ID_FULL_DIR_INFO)
+		rc = construct_dentry(&qstring, file, &tmp_inode, &tmp_dentry,
+					&inum);
+	else
+		rc = construct_dentry(&qstring, file, &tmp_inode, &tmp_dentry,
+					NULL);
+
+	if ((tmp_inode == NULL) || (tmp_dentry == NULL))
+		return -ENOMEM;
+
+	/* we pass in rc below, indicating whether it is a new inode,
+	   so we can figure out whether to invalidate the inode cached
+	   data if the file has changed */
+	if (pCifsF->srch_inf.info_level == SMB_FIND_FILE_UNIX)
+		unix_fill_in_inode(tmp_inode,
+				   (FILE_UNIX_INFO *)pfindEntry,
+				   &obj_type, rc);
+	else if (pCifsF->srch_inf.info_level == SMB_FIND_FILE_INFO_STANDARD)
+		fill_in_inode(tmp_inode, 0 /* old level 1 buffer type */,
+				pfindEntry, &obj_type, rc);
+	else
+		fill_in_inode(tmp_inode, 1 /* NT */, pfindEntry, &obj_type, rc);
+
+	if (rc) /* new inode - needs to be tied to dentry */ {
+		d_instantiate(tmp_dentry, tmp_inode);
+		if (rc == 2)
+			d_rehash(tmp_dentry);
+	}
+
+
+	rc = filldir(direntry, qstring.name, qstring.len, file->f_pos,
+		     tmp_inode->i_ino, obj_type);
+	if (rc) {
+		cFYI(1, ("filldir rc = %d", rc));
+		/* we can not return filldir errors to the caller
+		since they are "normal" when the stat blocksize
+		is too small - we return remapped error instead */
+		rc = -EOVERFLOW;
+	}
+
+	dput(tmp_dentry);
+	return rc;
+}
+
+
+int cifs_readdir(struct file *file, void *direntry, filldir_t filldir)
+{
+	int rc = 0;
+	int xid, i;
+	struct cifs_sb_info *cifs_sb;
+	struct cifsTconInfo *pTcon;
+	struct cifsFileInfo *cifsFile = NULL;
+	char *current_entry;
+	int num_to_fill = 0;
+	char *tmp_buf = NULL;
+	char *end_of_smb;
+	unsigned int max_len;
+
+	xid = GetXid();
+
+	cifs_sb = CIFS_SB(file->f_path.dentry->d_sb);
+	pTcon = cifs_sb->tcon;
+	if (pTcon == NULL)
+		return -EINVAL;
+
+	switch ((int) file->f_pos) {
+	case 0:
+		if (filldir(direntry, ".", 1, file->f_pos,
+		     file->f_path.dentry->d_inode->i_ino, DT_DIR) < 0) {
+			cERROR(1, ("Filldir for current dir failed"));
+			rc = -ENOMEM;
+			break;
+		}
+		file->f_pos++;
+	case 1:
+		if (filldir(direntry, "..", 2, file->f_pos,
+		     file->f_path.dentry->d_parent->d_inode->i_ino, DT_DIR) < 0) {
+			cERROR(1, ("Filldir for parent dir failed"));
+			rc = -ENOMEM;
+			break;
+		}
+		file->f_pos++;
+	default:
+		/* 1) If search is active,
+			is in current search buffer?
+			if it before then restart search
+			if after then keep searching till find it */
+
+		if (file->private_data == NULL) {
+			rc = initiate_cifs_search(xid, file);
+			cFYI(1, ("initiate cifs search rc %d", rc));
+			if (rc) {
+				FreeXid(xid);
+				return rc;
+			}
+		}
+		if (file->private_data == NULL) {
+			rc = -EINVAL;
+			FreeXid(xid);
+			return rc;
+		}
+		cifsFile = file->private_data;
+		if (cifsFile->srch_inf.endOfSearch) {
+			if (cifsFile->srch_inf.emptyDir) {
+				cFYI(1, ("End of search, empty dir"));
+				rc = 0;
+				break;
+			}
+		} /* else {
+			cifsFile->invalidHandle = true;
+			CIFSFindClose(xid, pTcon, cifsFile->netfid);
+		} */
+
+		rc = find_cifs_entry(xid, pTcon, file,
+				&current_entry, &num_to_fill);
+		if (rc) {
+			cFYI(1, ("fce error %d", rc));
+			goto rddir2_exit;
+		} else if (current_entry != NULL) {
+			cFYI(1, ("entry %lld found", file->f_pos));
+		} else {
+			cFYI(1, ("could not find entry"));
+			goto rddir2_exit;
+		}
+		cFYI(1, ("loop through %d times filling dir for net buf %p",
+			num_to_fill, cifsFile->srch_inf.ntwrk_buf_start));
+		max_len = smbCalcSize((struct smb_hdr *)
+				cifsFile->srch_inf.ntwrk_buf_start);
+		end_of_smb = cifsFile->srch_inf.ntwrk_buf_start + max_len;
+
+		tmp_buf = kmalloc(UNICODE_NAME_MAX, GFP_KERNEL);
+		for (i = 0; (i < num_to_fill) && (rc == 0); i++) {
+			if (current_entry == NULL) {
+				/* evaluate whether this case is an error */
+				cERROR(1, ("past SMB end,  num to fill %d i %d",
+					  num_to_fill, i));
+				break;
+			}
+			/* if buggy server returns . and .. late do
+			we want to check for that here? */
+			rc = cifs_filldir(current_entry, file,
+					filldir, direntry, tmp_buf, max_len);
+			if (rc == -EOVERFLOW) {
+				rc = 0;
+				break;
+			}
+
+			file->f_pos++;
+			if (file->f_pos ==
+				cifsFile->srch_inf.index_of_last_entry) {
+				cFYI(1, ("last entry in buf at pos %lld %s",
+					file->f_pos, tmp_buf));
+				cifs_save_resume_key(current_entry, cifsFile);
+				break;
+			} else
+				current_entry =
+					nxt_dir_entry(current_entry, end_of_smb,
+						cifsFile->srch_inf.info_level);
+		}
+		kfree(tmp_buf);
+		break;
+	} /* end switch */
+
+rddir2_exit:
+	FreeXid(xid);
+	return rc;
+}
diff -Naur linux-2.6.30-ori/fs/cifs/transport.c linux-2.6.30-test/fs/cifs/transport.c
--- linux-2.6.30-ori/fs/cifs/transport.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/cifs/transport.c	2009-06-12 18:32:43.000000000 -0400
@@ -69,7 +69,7 @@
 	return temp;
 }
 
-static void
+void
 DeleteMidQEntry(struct mid_q_entry *midEntry)
 {
 #ifdef CONFIG_CIFS_STATS2
@@ -434,6 +434,80 @@
 	return rc;
 }
 
+  int
+Send(const unsigned int xid, struct cifsSesInfo *ses, 
+	     struct kvec *iov, int n_vec, struct cifs_readpages_data *data)
+{
+	int rc = 0;
+	struct mid_q_entry *midQ;
+	struct smb_hdr *in_buf = iov[0].iov_base;
+	int i;
+	
+	if ((ses == NULL) || (ses->server == NULL)) {
+		cifs_small_buf_release(in_buf);
+		cERROR(1,("Null session"));
+		return -EIO;
+	}
+
+	if(ses->server->tcpStatus == CifsExiting) {
+		cifs_small_buf_release(in_buf);
+		return -ENOENT;
+	}
+
+	/* Ensure that we do not send more than 50 overlapping requests 
+	   to the same server. We may make this configurable later or
+	   use ses->maxReq */
+
+	rc = wait_for_free_request(ses, 0);
+	if (rc) {
+		cifs_small_buf_release(in_buf);
+		return rc;
+	}
+
+	/* make sure that we sign in the same order that we send on this socket 
+	   and avoid races inside tcp sendmsg code that could cause corruption
+	   of smb data */
+
+	mutex_lock(&ses->server->srv_mutex); 
+
+	rc = allocate_mid(ses, in_buf, &midQ);
+	if (rc) {
+		mutex_unlock(&ses->server->srv_mutex);
+		cifs_small_buf_release(in_buf);
+		/* Update # of requests on wire to server */
+		atomic_dec(&ses->server->inFlight); 
+		wake_up(&ses->server->request_q);
+		return rc;
+	}
+
+	for (i = 0; i < data->nr_pages; i++) {
+		midQ->pages[i] = data->pages[i];
+	}
+	midQ->nr_pages = data->nr_pages;
+	list_add_tail(&midQ->midq_entry, &data->midq_list);
+
+	rc = cifs_sign_smb2(iov, n_vec, ses->server, &midQ->sequence_number);
+
+	midQ->midState = MID_REQUEST_SUBMITTED;
+#ifdef CONFIG_CIFS_STATS2
+	atomic_inc(&ses->server->inSend);
+#endif
+	rc = smb_sendv(ses->server, iov, n_vec);
+#ifdef CONFIG_CIFS_STATS2
+	atomic_dec(&ses->server->inSend);
+	midQ->when_sent = jiffies;
+#endif
+
+	mutex_unlock(&ses->server->srv_mutex);
+	cifs_small_buf_release(in_buf);
+
+	dprintk("NOTICE: MIDQ SENT: mid=%d, nr_pages=%d, inFlight=%d\n",
+			midQ->mid, midQ->nr_pages,
+			atomic_read(&ses->server->inFlight));
+
+	return rc;
+}
+
 int
 SendReceive2(const unsigned int xid, struct cifsSesInfo *ses,
 	     struct kvec *iov, int n_vec, int *pRespBufType /* ret */,
diff -Naur linux-2.6.30-ori/fs/proc/Makefile linux-2.6.30-test/fs/proc/Makefile
--- linux-2.6.30-ori/fs/proc/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/proc/Makefile	2009-06-12 18:32:43.000000000 -0400
@@ -18,6 +18,7 @@
 proc-y	+= stat.o
 proc-y	+= uptime.o
 proc-y	+= version.o
+proc-$(CONFIG_TANGO2)	+= em86.o
 proc-$(CONFIG_PROC_SYSCTL)	+= proc_sysctl.o
 proc-$(CONFIG_NET)		+= proc_net.o
 proc-$(CONFIG_PROC_KCORE)	+= kcore.o
diff -Naur linux-2.6.30-ori/fs/proc/em86.c linux-2.6.30-test/fs/proc/em86.c
--- linux-2.6.30-ori/fs/proc/em86.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/proc/em86.c	2009-06-12 18:32:43.000000000 -0400
@@ -0,0 +1,87 @@
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/utsname.h>
+
+extern long long em86_netstats[20];
+
+extern long long em86_stats[20];
+
+extern int tangox_get_hdmioutput();
+
+static int em86dma_proc_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n"
+	                              "%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n", 
+		em86_stats[0],em86_stats[1],em86_stats[2],em86_stats[3],
+		em86_stats[4],em86_stats[5],em86_stats[6],em86_stats[7],
+		em86_stats[8],em86_stats[9],em86_stats[10],em86_stats[11],
+		em86_stats[12],em86_stats[13],em86_stats[14],em86_stats[15],
+		em86_stats[16],em86_stats[17],em86_stats[18],em86_stats[19]);
+	return 0;
+}
+
+static int em86hdmi_proc_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "%d\n",tangox_get_hdmioutput());
+	return 0;
+}
+
+static int em86net_proc_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n"
+	                              "%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n%lld time %lld\n", 
+		em86_netstats[0],em86_netstats[1],em86_netstats[2],em86_netstats[3],
+		em86_netstats[4],em86_netstats[5],em86_netstats[6],em86_netstats[7],
+		em86_netstats[8],em86_netstats[9],em86_netstats[10],em86_netstats[11],
+		em86_netstats[12],em86_netstats[13],em86_netstats[14],em86_netstats[15],
+		em86_netstats[16],em86_netstats[17],em86_netstats[18],em86_netstats[19]);
+	return 0;
+}
+
+static int em86dma_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, em86dma_proc_show, NULL);
+}
+
+static int em86hdmi_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, em86hdmi_proc_show, NULL);
+}
+
+static int em86net_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, em86net_proc_show, NULL);
+}
+
+static const struct file_operations em86dma_proc_fops = {
+	.open		= em86dma_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static const struct file_operations em86hdmi_proc_fops = {
+	.open		= em86hdmi_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static const struct file_operations em86net_proc_fops = {
+	.open		= em86net_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int __init proc_em86_init(void)
+{
+	proc_create("em86dma", 0, NULL, &em86dma_proc_fops);
+	proc_create("em86hdmi", 0, NULL, &em86hdmi_proc_fops);
+	proc_create("em86net", 0, NULL, &em86net_proc_fops);
+	return 0;
+}
+module_init(proc_em86_init);
diff -Naur linux-2.6.30-ori/fs/squashfs/Kconfig linux-2.6.30-test/fs/squashfs/Kconfig
--- linux-2.6.30-ori/fs/squashfs/Kconfig	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/Kconfig	2009-06-15 11:25:12.000000000 -0400
@@ -1,22 +1,20 @@
 config SQUASHFS
-	tristate "SquashFS 4.0 - Squashed file system support"
-	depends on BLOCK
+	tristate "SquashFS 3.3 - Squashed file system support"
 	select ZLIB_INFLATE
 	help
-	  Saying Y here includes support for SquashFS 4.0 (a Compressed
+	  Saying Y here includes support for SquashFS 3.3 (a Compressed
 	  Read-Only File System).  Squashfs is a highly compressed read-only
 	  filesystem for Linux.  It uses zlib compression to compress both
 	  files, inodes and directories.  Inodes in the system are very small
 	  and all blocks are packed to minimise data overhead. Block sizes
 	  greater than 4K are supported up to a maximum of 1 Mbytes (default
-	  block size 128K).  SquashFS 4.0 supports 64 bit filesystems and files
-	  (larger than 4GB), full uid/gid information, hard links and
-	  timestamps.  
+	  block size 128K).  SquashFS 3.3 supports 64 bit filesystems and files
+	  (larger than 4GB), full uid/gid information, hard links and timestamps.  
 
 	  Squashfs is intended for general read-only filesystem use, for
 	  archival use (i.e. in cases where a .tar.gz file may be used), and in
 	  embedded systems where low overhead is needed.  Further information
-	  and tools are available from http://squashfs.sourceforge.net.
+	  and filesystem tools are available from http://squashfs.sourceforge.net.
 
 	  If you want to compile this as a module ( = code which can be
 	  inserted in and removed from the running kernel whenever you want),
@@ -49,3 +47,21 @@
 
 	  Note there must be at least one cached fragment.  Anything
 	  much more than three will probably not make much difference.
+
+config VXFS_FS
+	tristate "FreeVxFS file system support (VERITAS VxFS(TM) compatible)"
+	depends on BLOCK
+	help
+	  FreeVxFS is a file system driver that support the VERITAS VxFS(TM)
+	  file system format.  VERITAS VxFS(TM) is the standard file system
+	  of SCO UnixWare (and possibly others) and optionally available
+	  for Sunsoft Solaris, HP-UX and many other operating systems.
+	  Currently only readonly access is supported.
+
+	  NOTE: the file system type as used by mount(1), mount(2) and
+	  fstab(5) is 'vxfs' as it describes the file system format, not
+	  the actual driver.
+
+	  To compile this as a module, choose M here: the module will be
+	  called freevxfs.  If unsure, say N.
+
diff -Naur linux-2.6.30-ori/fs/squashfs/LzmaDecode.c linux-2.6.30-test/fs/squashfs/LzmaDecode.c
--- linux-2.6.30-ori/fs/squashfs/LzmaDecode.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/LzmaDecode.c	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,584 @@
+/*
+  LzmaDecode.c
+  LZMA Decoder (optimized for Speed version)
+  
+  LZMA SDK 4.40 Copyright (c) 1999-2006 Igor Pavlov (2006-05-01)
+  http://www.7-zip.org/
+
+  LZMA SDK is licensed under two licenses:
+  1) GNU Lesser General Public License (GNU LGPL)
+  2) Common Public License (CPL)
+  It means that you can select one of these two licenses and 
+  follow rules of that license.
+
+  SPECIAL EXCEPTION:
+  Igor Pavlov, as the author of this Code, expressly permits you to 
+  statically or dynamically link your Code (or bind by name) to the 
+  interfaces of this file without subjecting your linked Code to the 
+  terms of the CPL or GNU LGPL. Any modifications or additions 
+  to this file, however, are subject to the LGPL or CPL terms.
+*/
+
+#include "LzmaDecode.h"
+
+#define kNumTopBits 24
+#define kTopValue ((UInt32)1 << kNumTopBits)
+
+#define kNumBitModelTotalBits 11
+#define kBitModelTotal (1 << kNumBitModelTotalBits)
+#define kNumMoveBits 5
+
+#define RC_READ_BYTE (*Buffer++)
+
+#define RC_INIT2 Code = 0; Range = 0xFFFFFFFF; \
+  { int i; for(i = 0; i < 5; i++) { RC_TEST; Code = (Code << 8) | RC_READ_BYTE; }}
+
+#ifdef _LZMA_IN_CB
+
+#define RC_TEST { if (Buffer == BufferLim) \
+  { SizeT size; int result = InCallback->Read(InCallback, &Buffer, &size); if (result != LZMA_RESULT_OK) return result; \
+  BufferLim = Buffer + size; if (size == 0) return LZMA_RESULT_DATA_ERROR; }}
+
+#define RC_INIT Buffer = BufferLim = 0; RC_INIT2
+
+#else
+
+#define RC_TEST { if (Buffer == BufferLim) return LZMA_RESULT_DATA_ERROR; }
+
+#define RC_INIT(buffer, bufferSize) Buffer = buffer; BufferLim = buffer + bufferSize; RC_INIT2
+ 
+#endif
+
+#define RC_NORMALIZE if (Range < kTopValue) { RC_TEST; Range <<= 8; Code = (Code << 8) | RC_READ_BYTE; }
+
+#define IfBit0(p) RC_NORMALIZE; bound = (Range >> kNumBitModelTotalBits) * *(p); if (Code < bound)
+#define UpdateBit0(p) Range = bound; *(p) += (kBitModelTotal - *(p)) >> kNumMoveBits;
+#define UpdateBit1(p) Range -= bound; Code -= bound; *(p) -= (*(p)) >> kNumMoveBits;
+
+#define RC_GET_BIT2(p, mi, A0, A1) IfBit0(p) \
+  { UpdateBit0(p); mi <<= 1; A0; } else \
+  { UpdateBit1(p); mi = (mi + mi) + 1; A1; } 
+  
+#define RC_GET_BIT(p, mi) RC_GET_BIT2(p, mi, ; , ;)               
+
+#define RangeDecoderBitTreeDecode(probs, numLevels, res) \
+  { int i = numLevels; res = 1; \
+  do { CProb *p = probs + res; RC_GET_BIT(p, res) } while(--i != 0); \
+  res -= (1 << numLevels); }
+
+
+#define kNumPosBitsMax 4
+#define kNumPosStatesMax (1 << kNumPosBitsMax)
+
+#define kLenNumLowBits 3
+#define kLenNumLowSymbols (1 << kLenNumLowBits)
+#define kLenNumMidBits 3
+#define kLenNumMidSymbols (1 << kLenNumMidBits)
+#define kLenNumHighBits 8
+#define kLenNumHighSymbols (1 << kLenNumHighBits)
+
+#define LenChoice 0
+#define LenChoice2 (LenChoice + 1)
+#define LenLow (LenChoice2 + 1)
+#define LenMid (LenLow + (kNumPosStatesMax << kLenNumLowBits))
+#define LenHigh (LenMid + (kNumPosStatesMax << kLenNumMidBits))
+#define kNumLenProbs (LenHigh + kLenNumHighSymbols) 
+
+
+#define kNumStates 12
+#define kNumLitStates 7
+
+#define kStartPosModelIndex 4
+#define kEndPosModelIndex 14
+#define kNumFullDistances (1 << (kEndPosModelIndex >> 1))
+
+#define kNumPosSlotBits 6
+#define kNumLenToPosStates 4
+
+#define kNumAlignBits 4
+#define kAlignTableSize (1 << kNumAlignBits)
+
+#define kMatchMinLen 2
+
+#define IsMatch 0
+#define IsRep (IsMatch + (kNumStates << kNumPosBitsMax))
+#define IsRepG0 (IsRep + kNumStates)
+#define IsRepG1 (IsRepG0 + kNumStates)
+#define IsRepG2 (IsRepG1 + kNumStates)
+#define IsRep0Long (IsRepG2 + kNumStates)
+#define PosSlot (IsRep0Long + (kNumStates << kNumPosBitsMax))
+#define SpecPos (PosSlot + (kNumLenToPosStates << kNumPosSlotBits))
+#define Align (SpecPos + kNumFullDistances - kEndPosModelIndex)
+#define LenCoder (Align + kAlignTableSize)
+#define RepLenCoder (LenCoder + kNumLenProbs)
+#define Literal (RepLenCoder + kNumLenProbs)
+
+#if Literal != LZMA_BASE_SIZE
+StopCompilingDueBUG
+#endif
+
+int LzmaDecodeProperties(CLzmaProperties *propsRes, const unsigned char *propsData, int size)
+{
+  unsigned char prop0;
+  if (size < LZMA_PROPERTIES_SIZE)
+    return LZMA_RESULT_DATA_ERROR;
+  prop0 = propsData[0];
+  if (prop0 >= (9 * 5 * 5))
+    return LZMA_RESULT_DATA_ERROR;
+  {
+    for (propsRes->pb = 0; prop0 >= (9 * 5); propsRes->pb++, prop0 -= (9 * 5));
+    for (propsRes->lp = 0; prop0 >= 9; propsRes->lp++, prop0 -= 9);
+    propsRes->lc = prop0;
+    /*
+    unsigned char remainder = (unsigned char)(prop0 / 9);
+    propsRes->lc = prop0 % 9;
+    propsRes->pb = remainder / 5;
+    propsRes->lp = remainder % 5;
+    */
+  }
+
+  #ifdef _LZMA_OUT_READ
+  {
+    int i;
+    propsRes->DictionarySize = 0;
+    for (i = 0; i < 4; i++)
+      propsRes->DictionarySize += (UInt32)(propsData[1 + i]) << (i * 8);
+    if (propsRes->DictionarySize == 0)
+      propsRes->DictionarySize = 1;
+  }
+  #endif
+  return LZMA_RESULT_OK;
+}
+
+#define kLzmaStreamWasFinishedId (-1)
+
+int LzmaDecode(CLzmaDecoderState *vs,
+    #ifdef _LZMA_IN_CB
+    ILzmaInCallback *InCallback,
+    #else
+    const unsigned char *inStream, SizeT inSize, SizeT *inSizeProcessed,
+    #endif
+    unsigned char *outStream, SizeT outSize, SizeT *outSizeProcessed)
+{
+  CProb *p = vs->Probs;
+  SizeT nowPos = 0;
+  Byte previousByte = 0;
+  UInt32 posStateMask = (1 << (vs->Properties.pb)) - 1;
+  UInt32 literalPosMask = (1 << (vs->Properties.lp)) - 1;
+  int lc = vs->Properties.lc;
+
+  #ifdef _LZMA_OUT_READ
+  
+  UInt32 Range = vs->Range;
+  UInt32 Code = vs->Code;
+  #ifdef _LZMA_IN_CB
+  const Byte *Buffer = vs->Buffer;
+  const Byte *BufferLim = vs->BufferLim;
+  #else
+  const Byte *Buffer = inStream;
+  const Byte *BufferLim = inStream + inSize;
+  #endif
+  int state = vs->State;
+  UInt32 rep0 = vs->Reps[0], rep1 = vs->Reps[1], rep2 = vs->Reps[2], rep3 = vs->Reps[3];
+  int len = vs->RemainLen;
+  UInt32 globalPos = vs->GlobalPos;
+  UInt32 distanceLimit = vs->DistanceLimit;
+
+  Byte *dictionary = vs->Dictionary;
+  UInt32 dictionarySize = vs->Properties.DictionarySize;
+  UInt32 dictionaryPos = vs->DictionaryPos;
+
+  Byte tempDictionary[4];
+
+  #ifndef _LZMA_IN_CB
+  *inSizeProcessed = 0;
+  #endif
+  *outSizeProcessed = 0;
+  if (len == kLzmaStreamWasFinishedId)
+    return LZMA_RESULT_OK;
+
+  if (dictionarySize == 0)
+  {
+    dictionary = tempDictionary;
+    dictionarySize = 1;
+    tempDictionary[0] = vs->TempDictionary[0];
+  }
+
+  if (len == kLzmaNeedInitId)
+  {
+    {
+      UInt32 numProbs = Literal + ((UInt32)LZMA_LIT_SIZE << (lc + vs->Properties.lp));
+      UInt32 i;
+      for (i = 0; i < numProbs; i++)
+        p[i] = kBitModelTotal >> 1; 
+      rep0 = rep1 = rep2 = rep3 = 1;
+      state = 0;
+      globalPos = 0;
+      distanceLimit = 0;
+      dictionaryPos = 0;
+      dictionary[dictionarySize - 1] = 0;
+      #ifdef _LZMA_IN_CB
+      RC_INIT;
+      #else
+      RC_INIT(inStream, inSize);
+      #endif
+    }
+    len = 0;
+  }
+  while(len != 0 && nowPos < outSize)
+  {
+    UInt32 pos = dictionaryPos - rep0;
+    if (pos >= dictionarySize)
+      pos += dictionarySize;
+    outStream[nowPos++] = dictionary[dictionaryPos] = dictionary[pos];
+    if (++dictionaryPos == dictionarySize)
+      dictionaryPos = 0;
+    len--;
+  }
+  if (dictionaryPos == 0)
+    previousByte = dictionary[dictionarySize - 1];
+  else
+    previousByte = dictionary[dictionaryPos - 1];
+
+  #else /* if !_LZMA_OUT_READ */
+
+  int state = 0;
+  UInt32 rep0 = 1, rep1 = 1, rep2 = 1, rep3 = 1;
+  int len = 0;
+  const Byte *Buffer;
+  const Byte *BufferLim;
+  UInt32 Range;
+  UInt32 Code;
+
+  #ifndef _LZMA_IN_CB
+  *inSizeProcessed = 0;
+  #endif
+  *outSizeProcessed = 0;
+
+  {
+    UInt32 i;
+    UInt32 numProbs = Literal + ((UInt32)LZMA_LIT_SIZE << (lc + vs->Properties.lp));
+    for (i = 0; i < numProbs; i++)
+      p[i] = kBitModelTotal >> 1;
+  }
+  
+  #ifdef _LZMA_IN_CB
+  RC_INIT;
+  #else
+  RC_INIT(inStream, inSize);
+  #endif
+
+  #endif /* _LZMA_OUT_READ */
+
+  while(nowPos < outSize)
+  {
+    CProb *prob;
+    UInt32 bound;
+    int posState = (int)(
+        (nowPos 
+        #ifdef _LZMA_OUT_READ
+        + globalPos
+        #endif
+        )
+        & posStateMask);
+
+    prob = p + IsMatch + (state << kNumPosBitsMax) + posState;
+    IfBit0(prob)
+    {
+      int symbol = 1;
+      UpdateBit0(prob)
+      prob = p + Literal + (LZMA_LIT_SIZE * 
+        (((
+        (nowPos 
+        #ifdef _LZMA_OUT_READ
+        + globalPos
+        #endif
+        )
+        & literalPosMask) << lc) + (previousByte >> (8 - lc))));
+
+      if (state >= kNumLitStates)
+      {
+        int matchByte;
+        #ifdef _LZMA_OUT_READ
+        UInt32 pos = dictionaryPos - rep0;
+        if (pos >= dictionarySize)
+          pos += dictionarySize;
+        matchByte = dictionary[pos];
+        #else
+        matchByte = outStream[nowPos - rep0];
+        #endif
+        do
+        {
+          int bit;
+          CProb *probLit;
+          matchByte <<= 1;
+          bit = (matchByte & 0x100);
+          probLit = prob + 0x100 + bit + symbol;
+          RC_GET_BIT2(probLit, symbol, if (bit != 0) break, if (bit == 0) break)
+        }
+        while (symbol < 0x100);
+      }
+      while (symbol < 0x100)
+      {
+        CProb *probLit = prob + symbol;
+        RC_GET_BIT(probLit, symbol)
+      }
+      previousByte = (Byte)symbol;
+
+      outStream[nowPos++] = previousByte;
+      #ifdef _LZMA_OUT_READ
+      if (distanceLimit < dictionarySize)
+        distanceLimit++;
+
+      dictionary[dictionaryPos] = previousByte;
+      if (++dictionaryPos == dictionarySize)
+        dictionaryPos = 0;
+      #endif
+      if (state < 4) state = 0;
+      else if (state < 10) state -= 3;
+      else state -= 6;
+    }
+    else             
+    {
+      UpdateBit1(prob);
+      prob = p + IsRep + state;
+      IfBit0(prob)
+      {
+        UpdateBit0(prob);
+        rep3 = rep2;
+        rep2 = rep1;
+        rep1 = rep0;
+        state = state < kNumLitStates ? 0 : 3;
+        prob = p + LenCoder;
+      }
+      else
+      {
+        UpdateBit1(prob);
+        prob = p + IsRepG0 + state;
+        IfBit0(prob)
+        {
+          UpdateBit0(prob);
+          prob = p + IsRep0Long + (state << kNumPosBitsMax) + posState;
+          IfBit0(prob)
+          {
+            #ifdef _LZMA_OUT_READ
+            UInt32 pos;
+            #endif
+            UpdateBit0(prob);
+            
+            #ifdef _LZMA_OUT_READ
+            if (distanceLimit == 0)
+            #else
+            if (nowPos == 0)
+            #endif
+              return LZMA_RESULT_DATA_ERROR;
+            
+            state = state < kNumLitStates ? 9 : 11;
+            #ifdef _LZMA_OUT_READ
+            pos = dictionaryPos - rep0;
+            if (pos >= dictionarySize)
+              pos += dictionarySize;
+            previousByte = dictionary[pos];
+            dictionary[dictionaryPos] = previousByte;
+            if (++dictionaryPos == dictionarySize)
+              dictionaryPos = 0;
+            #else
+            previousByte = outStream[nowPos - rep0];
+            #endif
+            outStream[nowPos++] = previousByte;
+            #ifdef _LZMA_OUT_READ
+            if (distanceLimit < dictionarySize)
+              distanceLimit++;
+            #endif
+
+            continue;
+          }
+          else
+          {
+            UpdateBit1(prob);
+          }
+        }
+        else
+        {
+          UInt32 distance;
+          UpdateBit1(prob);
+          prob = p + IsRepG1 + state;
+          IfBit0(prob)
+          {
+            UpdateBit0(prob);
+            distance = rep1;
+          }
+          else 
+          {
+            UpdateBit1(prob);
+            prob = p + IsRepG2 + state;
+            IfBit0(prob)
+            {
+              UpdateBit0(prob);
+              distance = rep2;
+            }
+            else
+            {
+              UpdateBit1(prob);
+              distance = rep3;
+              rep3 = rep2;
+            }
+            rep2 = rep1;
+          }
+          rep1 = rep0;
+          rep0 = distance;
+        }
+        state = state < kNumLitStates ? 8 : 11;
+        prob = p + RepLenCoder;
+      }
+      {
+        int numBits, offset;
+        CProb *probLen = prob + LenChoice;
+        IfBit0(probLen)
+        {
+          UpdateBit0(probLen);
+          probLen = prob + LenLow + (posState << kLenNumLowBits);
+          offset = 0;
+          numBits = kLenNumLowBits;
+        }
+        else
+        {
+          UpdateBit1(probLen);
+          probLen = prob + LenChoice2;
+          IfBit0(probLen)
+          {
+            UpdateBit0(probLen);
+            probLen = prob + LenMid + (posState << kLenNumMidBits);
+            offset = kLenNumLowSymbols;
+            numBits = kLenNumMidBits;
+          }
+          else
+          {
+            UpdateBit1(probLen);
+            probLen = prob + LenHigh;
+            offset = kLenNumLowSymbols + kLenNumMidSymbols;
+            numBits = kLenNumHighBits;
+          }
+        }
+        RangeDecoderBitTreeDecode(probLen, numBits, len);
+        len += offset;
+      }
+
+      if (state < 4)
+      {
+        int posSlot;
+        state += kNumLitStates;
+        prob = p + PosSlot +
+            ((len < kNumLenToPosStates ? len : kNumLenToPosStates - 1) << 
+            kNumPosSlotBits);
+        RangeDecoderBitTreeDecode(prob, kNumPosSlotBits, posSlot);
+        if (posSlot >= kStartPosModelIndex)
+        {
+          int numDirectBits = ((posSlot >> 1) - 1);
+          rep0 = (2 | ((UInt32)posSlot & 1));
+          if (posSlot < kEndPosModelIndex)
+          {
+            rep0 <<= numDirectBits;
+            prob = p + SpecPos + rep0 - posSlot - 1;
+          }
+          else
+          {
+            numDirectBits -= kNumAlignBits;
+            do
+            {
+              RC_NORMALIZE
+              Range >>= 1;
+              rep0 <<= 1;
+              if (Code >= Range)
+              {
+                Code -= Range;
+                rep0 |= 1;
+              }
+            }
+            while (--numDirectBits != 0);
+            prob = p + Align;
+            rep0 <<= kNumAlignBits;
+            numDirectBits = kNumAlignBits;
+          }
+          {
+            int i = 1;
+            int mi = 1;
+            do
+            {
+              CProb *prob3 = prob + mi;
+              RC_GET_BIT2(prob3, mi, ; , rep0 |= i);
+              i <<= 1;
+            }
+            while(--numDirectBits != 0);
+          }
+        }
+        else
+          rep0 = posSlot;
+        if (++rep0 == (UInt32)(0))
+        {
+          /* it's for stream version */
+          len = kLzmaStreamWasFinishedId;
+          break;
+        }
+      }
+
+      len += kMatchMinLen;
+      #ifdef _LZMA_OUT_READ
+      if (rep0 > distanceLimit) 
+      #else
+      if (rep0 > nowPos)
+      #endif
+        return LZMA_RESULT_DATA_ERROR;
+
+      #ifdef _LZMA_OUT_READ
+      if (dictionarySize - distanceLimit > (UInt32)len)
+        distanceLimit += len;
+      else
+        distanceLimit = dictionarySize;
+      #endif
+
+      do
+      {
+        #ifdef _LZMA_OUT_READ
+        UInt32 pos = dictionaryPos - rep0;
+        if (pos >= dictionarySize)
+          pos += dictionarySize;
+        previousByte = dictionary[pos];
+        dictionary[dictionaryPos] = previousByte;
+        if (++dictionaryPos == dictionarySize)
+          dictionaryPos = 0;
+        #else
+        previousByte = outStream[nowPos - rep0];
+        #endif
+        len--;
+        outStream[nowPos++] = previousByte;
+      }
+      while(len != 0 && nowPos < outSize);
+    }
+  }
+  RC_NORMALIZE;
+
+  #ifdef _LZMA_OUT_READ
+  vs->Range = Range;
+  vs->Code = Code;
+  vs->DictionaryPos = dictionaryPos;
+  vs->GlobalPos = globalPos + (UInt32)nowPos;
+  vs->DistanceLimit = distanceLimit;
+  vs->Reps[0] = rep0;
+  vs->Reps[1] = rep1;
+  vs->Reps[2] = rep2;
+  vs->Reps[3] = rep3;
+  vs->State = state;
+  vs->RemainLen = len;
+  vs->TempDictionary[0] = tempDictionary[0];
+  #endif
+
+  #ifdef _LZMA_IN_CB
+  vs->Buffer = Buffer;
+  vs->BufferLim = BufferLim;
+  #else
+  *inSizeProcessed = (SizeT)(Buffer - inStream);
+  #endif
+  *outSizeProcessed = nowPos;
+  return LZMA_RESULT_OK;
+}
diff -Naur linux-2.6.30-ori/fs/squashfs/LzmaDecode.h linux-2.6.30-test/fs/squashfs/LzmaDecode.h
--- linux-2.6.30-ori/fs/squashfs/LzmaDecode.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/LzmaDecode.h	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,113 @@
+/* 
+  LzmaDecode.h
+  LZMA Decoder interface
+
+  LZMA SDK 4.40 Copyright (c) 1999-2006 Igor Pavlov (2006-05-01)
+  http://www.7-zip.org/
+
+  LZMA SDK is licensed under two licenses:
+  1) GNU Lesser General Public License (GNU LGPL)
+  2) Common Public License (CPL)
+  It means that you can select one of these two licenses and 
+  follow rules of that license.
+
+  SPECIAL EXCEPTION:
+  Igor Pavlov, as the author of this code, expressly permits you to 
+  statically or dynamically link your code (or bind by name) to the 
+  interfaces of this file without subjecting your linked code to the 
+  terms of the CPL or GNU LGPL. Any modifications or additions 
+  to this file, however, are subject to the LGPL or CPL terms.
+*/
+
+#ifndef __LZMADECODE_H
+#define __LZMADECODE_H
+
+#include "LzmaTypes.h"
+
+/* #define _LZMA_IN_CB */
+/* Use callback for input data */
+
+/* #define _LZMA_OUT_READ */
+/* Use read function for output data */
+
+/* #define _LZMA_PROB32 */
+/* It can increase speed on some 32-bit CPUs, 
+   but memory usage will be doubled in that case */
+
+/* #define _LZMA_LOC_OPT */
+/* Enable local speed optimizations inside code */
+
+#ifdef _LZMA_PROB32
+#define CProb UInt32
+#else
+#define CProb UInt16
+#endif
+
+#define LZMA_RESULT_OK 0
+#define LZMA_RESULT_DATA_ERROR 1
+
+#ifdef _LZMA_IN_CB
+typedef struct _ILzmaInCallback
+{
+  int (*Read)(void *object, const unsigned char **buffer, SizeT *bufferSize);
+} ILzmaInCallback;
+#endif
+
+#define LZMA_BASE_SIZE 1846
+#define LZMA_LIT_SIZE 768
+
+#define LZMA_PROPERTIES_SIZE 5
+
+typedef struct _CLzmaProperties
+{
+  int lc;
+  int lp;
+  int pb;
+  #ifdef _LZMA_OUT_READ
+  UInt32 DictionarySize;
+  #endif
+}CLzmaProperties;
+
+int LzmaDecodeProperties(CLzmaProperties *propsRes, const unsigned char *propsData, int size);
+
+#define LzmaGetNumProbs(Properties) (LZMA_BASE_SIZE + (LZMA_LIT_SIZE << ((Properties)->lc + (Properties)->lp)))
+
+#define kLzmaNeedInitId (-2)
+
+typedef struct _CLzmaDecoderState
+{
+  CLzmaProperties Properties;
+  CProb *Probs;
+
+  #ifdef _LZMA_IN_CB
+  const unsigned char *Buffer;
+  const unsigned char *BufferLim;
+  #endif
+
+  #ifdef _LZMA_OUT_READ
+  unsigned char *Dictionary;
+  UInt32 Range;
+  UInt32 Code;
+  UInt32 DictionaryPos;
+  UInt32 GlobalPos;
+  UInt32 DistanceLimit;
+  UInt32 Reps[4];
+  int State;
+  int RemainLen;
+  unsigned char TempDictionary[4];
+  #endif
+} CLzmaDecoderState;
+
+#ifdef _LZMA_OUT_READ
+#define LzmaDecoderInit(vs) { (vs)->RemainLen = kLzmaNeedInitId; }
+#endif
+
+int LzmaDecode(CLzmaDecoderState *vs,
+    #ifdef _LZMA_IN_CB
+    ILzmaInCallback *inCallback,
+    #else
+    const unsigned char *inStream, SizeT inSize, SizeT *inSizeProcessed,
+    #endif
+    unsigned char *outStream, SizeT outSize, SizeT *outSizeProcessed);
+
+#endif
diff -Naur linux-2.6.30-ori/fs/squashfs/LzmaTypes.h linux-2.6.30-test/fs/squashfs/LzmaTypes.h
--- linux-2.6.30-ori/fs/squashfs/LzmaTypes.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/LzmaTypes.h	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,45 @@
+/* 
+LzmaTypes.h 
+
+Types for LZMA Decoder
+
+This file written and distributed to public domain by Igor Pavlov.
+This file is part of LZMA SDK 4.40 (2006-05-01)
+*/
+
+#ifndef __LZMATYPES_H
+#define __LZMATYPES_H
+
+#ifndef _7ZIP_BYTE_DEFINED
+#define _7ZIP_BYTE_DEFINED
+typedef unsigned char Byte;
+#endif 
+
+#ifndef _7ZIP_UINT16_DEFINED
+#define _7ZIP_UINT16_DEFINED
+typedef unsigned short UInt16;
+#endif 
+
+#ifndef _7ZIP_UINT32_DEFINED
+#define _7ZIP_UINT32_DEFINED
+#ifdef _LZMA_UINT32_IS_ULONG
+typedef unsigned long UInt32;
+#else
+typedef unsigned int UInt32;
+#endif
+#endif 
+
+/* #define _LZMA_NO_SYSTEM_SIZE_T */
+/* You can use it, if you don't want <stddef.h> */
+
+#ifndef _7ZIP_SIZET_DEFINED
+#define _7ZIP_SIZET_DEFINED
+#ifdef _LZMA_NO_SYSTEM_SIZE_T
+typedef UInt32 SizeT;
+#else
+#include <stddef.h>
+typedef size_t SizeT;
+#endif
+#endif
+
+#endif
diff -Naur linux-2.6.30-ori/fs/squashfs/Makefile linux-2.6.30-test/fs/squashfs/Makefile
--- linux-2.6.30-ori/fs/squashfs/Makefile	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/Makefile	2009-06-15 11:25:12.000000000 -0400
@@ -2,6 +2,14 @@
 # Makefile for the linux squashfs routines.
 #
 
+# the environment variables are not inherited since 2.6.23
+ifdef SQLZMA_EXTRA_CFLAGS
+EXTRA_CFLAGS += ${SQLZMA_EXTRA_CFLAGS}
+endif
+
 obj-$(CONFIG_SQUASHFS) += squashfs.o
-squashfs-y += block.o cache.o dir.o export.o file.o fragment.o id.o inode.o
-squashfs-y += namei.o super.o symlink.o
+squashfs-y += inode.o
+squashfs-y += squashfs2_0.o
+squashfs-y += module.o
+squashfs-y += uncomp.o
+
diff -Naur linux-2.6.30-ori/fs/squashfs/block.c linux-2.6.30-test/fs/squashfs/block.c
--- linux-2.6.30-ori/fs/squashfs/block.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/block.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,270 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * block.c
- */
-
-/*
- * This file implements the low-level routines to read and decompress
- * datablocks and metadata blocks.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/slab.h>
-#include <linux/mutex.h>
-#include <linux/string.h>
-#include <linux/buffer_head.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Read the metadata block length, this is stored in the first two
- * bytes of the metadata block.
- */
-static struct buffer_head *get_block_length(struct super_block *sb,
-			u64 *cur_index, int *offset, int *length)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	struct buffer_head *bh;
-
-	bh = sb_bread(sb, *cur_index);
-	if (bh == NULL)
-		return NULL;
-
-	if (msblk->devblksize - *offset == 1) {
-		*length = (unsigned char) bh->b_data[*offset];
-		put_bh(bh);
-		bh = sb_bread(sb, ++(*cur_index));
-		if (bh == NULL)
-			return NULL;
-		*length |= (unsigned char) bh->b_data[0] << 8;
-		*offset = 1;
-	} else {
-		*length = (unsigned char) bh->b_data[*offset] |
-			(unsigned char) bh->b_data[*offset + 1] << 8;
-		*offset += 2;
-	}
-
-	return bh;
-}
-
-
-/*
- * Read and decompress a metadata block or datablock.  Length is non-zero
- * if a datablock is being read (the size is stored elsewhere in the
- * filesystem), otherwise the length is obtained from the first two bytes of
- * the metadata block.  A bit in the length field indicates if the block
- * is stored uncompressed in the filesystem (usually because compression
- * generated a larger block - this does occasionally happen with zlib).
- */
-int squashfs_read_data(struct super_block *sb, void **buffer, u64 index,
-			int length, u64 *next_index, int srclength, int pages)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	struct buffer_head **bh;
-	int offset = index & ((1 << msblk->devblksize_log2) - 1);
-	u64 cur_index = index >> msblk->devblksize_log2;
-	int bytes, compressed, b = 0, k = 0, page = 0, avail;
-
-
-	bh = kcalloc((msblk->block_size >> msblk->devblksize_log2) + 1,
-				sizeof(*bh), GFP_KERNEL);
-	if (bh == NULL)
-		return -ENOMEM;
-
-	if (length) {
-		/*
-		 * Datablock.
-		 */
-		bytes = -offset;
-		compressed = SQUASHFS_COMPRESSED_BLOCK(length);
-		length = SQUASHFS_COMPRESSED_SIZE_BLOCK(length);
-		if (next_index)
-			*next_index = index + length;
-
-		TRACE("Block @ 0x%llx, %scompressed size %d, src size %d\n",
-			index, compressed ? "" : "un", length, srclength);
-
-		if (length < 0 || length > srclength ||
-				(index + length) > msblk->bytes_used)
-			goto read_failure;
-
-		for (b = 0; bytes < length; b++, cur_index++) {
-			bh[b] = sb_getblk(sb, cur_index);
-			if (bh[b] == NULL)
-				goto block_release;
-			bytes += msblk->devblksize;
-		}
-		ll_rw_block(READ, b, bh);
-	} else {
-		/*
-		 * Metadata block.
-		 */
-		if ((index + 2) > msblk->bytes_used)
-			goto read_failure;
-
-		bh[0] = get_block_length(sb, &cur_index, &offset, &length);
-		if (bh[0] == NULL)
-			goto read_failure;
-		b = 1;
-
-		bytes = msblk->devblksize - offset;
-		compressed = SQUASHFS_COMPRESSED(length);
-		length = SQUASHFS_COMPRESSED_SIZE(length);
-		if (next_index)
-			*next_index = index + length + 2;
-
-		TRACE("Block @ 0x%llx, %scompressed size %d\n", index,
-				compressed ? "" : "un", length);
-
-		if (length < 0 || length > srclength ||
-					(index + length) > msblk->bytes_used)
-			goto block_release;
-
-		for (; bytes < length; b++) {
-			bh[b] = sb_getblk(sb, ++cur_index);
-			if (bh[b] == NULL)
-				goto block_release;
-			bytes += msblk->devblksize;
-		}
-		ll_rw_block(READ, b - 1, bh + 1);
-	}
-
-	if (compressed) {
-		int zlib_err = 0, zlib_init = 0;
-
-		/*
-		 * Uncompress block.
-		 */
-
-		mutex_lock(&msblk->read_data_mutex);
-
-		msblk->stream.avail_out = 0;
-		msblk->stream.avail_in = 0;
-
-		bytes = length;
-		do {
-			if (msblk->stream.avail_in == 0 && k < b) {
-				avail = min(bytes, msblk->devblksize - offset);
-				bytes -= avail;
-				wait_on_buffer(bh[k]);
-				if (!buffer_uptodate(bh[k]))
-					goto release_mutex;
-
-				if (avail == 0) {
-					offset = 0;
-					put_bh(bh[k++]);
-					continue;
-				}
-
-				msblk->stream.next_in = bh[k]->b_data + offset;
-				msblk->stream.avail_in = avail;
-				offset = 0;
-			}
-
-			if (msblk->stream.avail_out == 0 && page < pages) {
-				msblk->stream.next_out = buffer[page++];
-				msblk->stream.avail_out = PAGE_CACHE_SIZE;
-			}
-
-			if (!zlib_init) {
-				zlib_err = zlib_inflateInit(&msblk->stream);
-				if (zlib_err != Z_OK) {
-					ERROR("zlib_inflateInit returned"
-						" unexpected result 0x%x,"
-						" srclength %d\n", zlib_err,
-						srclength);
-					goto release_mutex;
-				}
-				zlib_init = 1;
-			}
-
-			zlib_err = zlib_inflate(&msblk->stream, Z_SYNC_FLUSH);
-
-			if (msblk->stream.avail_in == 0 && k < b)
-				put_bh(bh[k++]);
-		} while (zlib_err == Z_OK);
-
-		if (zlib_err != Z_STREAM_END) {
-			ERROR("zlib_inflate error, data probably corrupt\n");
-			goto release_mutex;
-		}
-
-		zlib_err = zlib_inflateEnd(&msblk->stream);
-		if (zlib_err != Z_OK) {
-			ERROR("zlib_inflate error, data probably corrupt\n");
-			goto release_mutex;
-		}
-		length = msblk->stream.total_out;
-		mutex_unlock(&msblk->read_data_mutex);
-	} else {
-		/*
-		 * Block is uncompressed.
-		 */
-		int i, in, pg_offset = 0;
-
-		for (i = 0; i < b; i++) {
-			wait_on_buffer(bh[i]);
-			if (!buffer_uptodate(bh[i]))
-				goto block_release;
-		}
-
-		for (bytes = length; k < b; k++) {
-			in = min(bytes, msblk->devblksize - offset);
-			bytes -= in;
-			while (in) {
-				if (pg_offset == PAGE_CACHE_SIZE) {
-					page++;
-					pg_offset = 0;
-				}
-				avail = min_t(int, in, PAGE_CACHE_SIZE -
-						pg_offset);
-				memcpy(buffer[page] + pg_offset,
-						bh[k]->b_data + offset, avail);
-				in -= avail;
-				pg_offset += avail;
-				offset += avail;
-			}
-			offset = 0;
-			put_bh(bh[k]);
-		}
-	}
-
-	kfree(bh);
-	return length;
-
-release_mutex:
-	mutex_unlock(&msblk->read_data_mutex);
-
-block_release:
-	for (; k < b; k++)
-		put_bh(bh[k]);
-
-read_failure:
-	ERROR("squashfs_read_data failed to read block 0x%llx\n",
-					(unsigned long long) index);
-	kfree(bh);
-	return -EIO;
-}
diff -Naur linux-2.6.30-ori/fs/squashfs/dir.c linux-2.6.30-test/fs/squashfs/dir.c
--- linux-2.6.30-ori/fs/squashfs/dir.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/dir.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,235 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * dir.c
- */
-
-/*
- * This file implements code to read directories from disk.
- *
- * See namei.c for a description of directory organisation on disk.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/slab.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-static const unsigned char squashfs_filetype_table[] = {
-	DT_UNKNOWN, DT_DIR, DT_REG, DT_LNK, DT_BLK, DT_CHR, DT_FIFO, DT_SOCK
-};
-
-/*
- * Lookup offset (f_pos) in the directory index, returning the
- * metadata block containing it.
- *
- * If we get an error reading the index then return the part of the index
- * (if any) we have managed to read - the index isn't essential, just
- * quicker.
- */
-static int get_dir_index_using_offset(struct super_block *sb,
-	u64 *next_block, int *next_offset, u64 index_start, int index_offset,
-	int i_count, u64 f_pos)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int err, i, index, length = 0;
-	struct squashfs_dir_index dir_index;
-
-	TRACE("Entered get_dir_index_using_offset, i_count %d, f_pos %lld\n",
-					i_count, f_pos);
-
-	/*
-	 * Translate from external f_pos to the internal f_pos.  This
-	 * is offset by 3 because we invent "." and ".." entries which are
-	 * not actually stored in the directory.
-	 */
-	if (f_pos < 3)
-		return f_pos;
-	f_pos -= 3;
-
-	for (i = 0; i < i_count; i++) {
-		err = squashfs_read_metadata(sb, &dir_index, &index_start,
-				&index_offset, sizeof(dir_index));
-		if (err < 0)
-			break;
-
-		index = le32_to_cpu(dir_index.index);
-		if (index > f_pos)
-			/*
-			 * Found the index we're looking for.
-			 */
-			break;
-
-		err = squashfs_read_metadata(sb, NULL, &index_start,
-				&index_offset, le32_to_cpu(dir_index.size) + 1);
-		if (err < 0)
-			break;
-
-		length = index;
-		*next_block = le32_to_cpu(dir_index.start_block) +
-					msblk->directory_table;
-	}
-
-	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
-
-	/*
-	 * Translate back from internal f_pos to external f_pos.
-	 */
-	return length + 3;
-}
-
-
-static int squashfs_readdir(struct file *file, void *dirent, filldir_t filldir)
-{
-	struct inode *inode = file->f_dentry->d_inode;
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	u64 block = squashfs_i(inode)->start + msblk->directory_table;
-	int offset = squashfs_i(inode)->offset, length = 0, dir_count, size,
-				type, err;
-	unsigned int inode_number;
-	struct squashfs_dir_header dirh;
-	struct squashfs_dir_entry *dire;
-
-	TRACE("Entered squashfs_readdir [%llx:%x]\n", block, offset);
-
-	dire = kmalloc(sizeof(*dire) + SQUASHFS_NAME_LEN + 1, GFP_KERNEL);
-	if (dire == NULL) {
-		ERROR("Failed to allocate squashfs_dir_entry\n");
-		goto finish;
-	}
-
-	/*
-	 * Return "." and  ".." entries as the first two filenames in the
-	 * directory.  To maximise compression these two entries are not
-	 * stored in the directory, and so we invent them here.
-	 *
-	 * It also means that the external f_pos is offset by 3 from the
-	 * on-disk directory f_pos.
-	 */
-	while (file->f_pos < 3) {
-		char *name;
-		int i_ino;
-
-		if (file->f_pos == 0) {
-			name = ".";
-			size = 1;
-			i_ino = inode->i_ino;
-		} else {
-			name = "..";
-			size = 2;
-			i_ino = squashfs_i(inode)->parent;
-		}
-
-		TRACE("Calling filldir(%p, %s, %d, %lld, %d, %d)\n",
-				dirent, name, size, file->f_pos, i_ino,
-				squashfs_filetype_table[1]);
-
-		if (filldir(dirent, name, size, file->f_pos, i_ino,
-				squashfs_filetype_table[1]) < 0) {
-				TRACE("Filldir returned less than 0\n");
-			goto finish;
-		}
-
-		file->f_pos += size;
-	}
-
-	length = get_dir_index_using_offset(inode->i_sb, &block, &offset,
-				squashfs_i(inode)->dir_idx_start,
-				squashfs_i(inode)->dir_idx_offset,
-				squashfs_i(inode)->dir_idx_cnt,
-				file->f_pos);
-
-	while (length < i_size_read(inode)) {
-		/*
-		 * Read directory header
-		 */
-		err = squashfs_read_metadata(inode->i_sb, &dirh, &block,
-					&offset, sizeof(dirh));
-		if (err < 0)
-			goto failed_read;
-
-		length += sizeof(dirh);
-
-		dir_count = le32_to_cpu(dirh.count) + 1;
-		while (dir_count--) {
-			/*
-			 * Read directory entry.
-			 */
-			err = squashfs_read_metadata(inode->i_sb, dire, &block,
-					&offset, sizeof(*dire));
-			if (err < 0)
-				goto failed_read;
-
-			size = le16_to_cpu(dire->size) + 1;
-
-			err = squashfs_read_metadata(inode->i_sb, dire->name,
-					&block, &offset, size);
-			if (err < 0)
-				goto failed_read;
-
-			length += sizeof(*dire) + size;
-
-			if (file->f_pos >= length)
-				continue;
-
-			dire->name[size] = '\0';
-			inode_number = le32_to_cpu(dirh.inode_number) +
-				((short) le16_to_cpu(dire->inode_number));
-			type = le16_to_cpu(dire->type);
-
-			TRACE("Calling filldir(%p, %s, %d, %lld, %x:%x, %d, %d)"
-					"\n", dirent, dire->name, size,
-					file->f_pos,
-					le32_to_cpu(dirh.start_block),
-					le16_to_cpu(dire->offset),
-					inode_number,
-					squashfs_filetype_table[type]);
-
-			if (filldir(dirent, dire->name, size, file->f_pos,
-					inode_number,
-					squashfs_filetype_table[type]) < 0) {
-				TRACE("Filldir returned less than 0\n");
-				goto finish;
-			}
-
-			file->f_pos = length;
-		}
-	}
-
-finish:
-	kfree(dire);
-	return 0;
-
-failed_read:
-	ERROR("Unable to read directory block [%llx:%x]\n", block, offset);
-	kfree(dire);
-	return 0;
-}
-
-
-const struct file_operations squashfs_dir_ops = {
-	.read = generic_read_dir,
-	.readdir = squashfs_readdir
-};
diff -Naur linux-2.6.30-ori/fs/squashfs/export.c linux-2.6.30-test/fs/squashfs/export.c
--- linux-2.6.30-ori/fs/squashfs/export.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/export.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,156 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * export.c
- */
-
-/*
- * This file implements code to make Squashfs filesystems exportable (NFS etc.)
- *
- * The export code uses an inode lookup table to map inode numbers passed in
- * filehandles to an inode location on disk.  This table is stored compressed
- * into metadata blocks.  A second index table is used to locate these.  This
- * second index table for speed of access (and because it is small) is read at
- * mount time and cached in memory.
- *
- * The inode lookup table is used only by the export code, inode disk
- * locations are directly encoded in directories, enabling direct access
- * without an intermediate lookup for all operations except the export ops.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/dcache.h>
-#include <linux/exportfs.h>
-#include <linux/zlib.h>
-#include <linux/slab.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Look-up inode number (ino) in table, returning the inode location.
- */
-static long long squashfs_inode_lookup(struct super_block *sb, int ino_num)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int blk = SQUASHFS_LOOKUP_BLOCK(ino_num - 1);
-	int offset = SQUASHFS_LOOKUP_BLOCK_OFFSET(ino_num - 1);
-	u64 start = le64_to_cpu(msblk->inode_lookup_table[blk]);
-	__le64 ino;
-	int err;
-
-	TRACE("Entered squashfs_inode_lookup, inode_number = %d\n", ino_num);
-
-	err = squashfs_read_metadata(sb, &ino, &start, &offset, sizeof(ino));
-	if (err < 0)
-		return err;
-
-	TRACE("squashfs_inode_lookup, inode = 0x%llx\n",
-		(u64) le64_to_cpu(ino));
-
-	return le64_to_cpu(ino);
-}
-
-
-static struct dentry *squashfs_export_iget(struct super_block *sb,
-	unsigned int ino_num)
-{
-	long long ino;
-	struct dentry *dentry = ERR_PTR(-ENOENT);
-
-	TRACE("Entered squashfs_export_iget\n");
-
-	ino = squashfs_inode_lookup(sb, ino_num);
-	if (ino >= 0)
-		dentry = d_obtain_alias(squashfs_iget(sb, ino, ino_num));
-
-	return dentry;
-}
-
-
-static struct dentry *squashfs_fh_to_dentry(struct super_block *sb,
-		struct fid *fid, int fh_len, int fh_type)
-{
-	if ((fh_type != FILEID_INO32_GEN && fh_type != FILEID_INO32_GEN_PARENT)
-			|| fh_len < 2)
-		return NULL;
-
-	return squashfs_export_iget(sb, fid->i32.ino);
-}
-
-
-static struct dentry *squashfs_fh_to_parent(struct super_block *sb,
-		struct fid *fid, int fh_len, int fh_type)
-{
-	if (fh_type != FILEID_INO32_GEN_PARENT || fh_len < 4)
-		return NULL;
-
-	return squashfs_export_iget(sb, fid->i32.parent_ino);
-}
-
-
-static struct dentry *squashfs_get_parent(struct dentry *child)
-{
-	struct inode *inode = child->d_inode;
-	unsigned int parent_ino = squashfs_i(inode)->parent;
-
-	return squashfs_export_iget(inode->i_sb, parent_ino);
-}
-
-
-/*
- * Read uncompressed inode lookup table indexes off disk into memory
- */
-__le64 *squashfs_read_inode_lookup_table(struct super_block *sb,
-		u64 lookup_table_start, unsigned int inodes)
-{
-	unsigned int length = SQUASHFS_LOOKUP_BLOCK_BYTES(inodes);
-	__le64 *inode_lookup_table;
-	int err;
-
-	TRACE("In read_inode_lookup_table, length %d\n", length);
-
-	/* Allocate inode lookup table indexes */
-	inode_lookup_table = kmalloc(length, GFP_KERNEL);
-	if (inode_lookup_table == NULL) {
-		ERROR("Failed to allocate inode lookup table\n");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	err = squashfs_read_table(sb, inode_lookup_table, lookup_table_start,
-			length);
-	if (err < 0) {
-		ERROR("unable to read inode lookup table\n");
-		kfree(inode_lookup_table);
-		return ERR_PTR(err);
-	}
-
-	return inode_lookup_table;
-}
-
-
-const struct export_operations squashfs_export_ops = {
-	.fh_to_dentry = squashfs_fh_to_dentry,
-	.fh_to_parent = squashfs_fh_to_parent,
-	.get_parent = squashfs_get_parent
-};
diff -Naur linux-2.6.30-ori/fs/squashfs/file.c linux-2.6.30-test/fs/squashfs/file.c
--- linux-2.6.30-ori/fs/squashfs/file.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/file.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,502 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * file.c
- */
-
-/*
- * This file contains code for handling regular files.  A regular file
- * consists of a sequence of contiguous compressed blocks, and/or a
- * compressed fragment block (tail-end packed block).   The compressed size
- * of each datablock is stored in a block list contained within the
- * file inode (itself stored in one or more compressed metadata blocks).
- *
- * To speed up access to datablocks when reading 'large' files (256 Mbytes or
- * larger), the code implements an index cache that caches the mapping from
- * block index to datablock location on disk.
- *
- * The index cache allows Squashfs to handle large files (up to 1.75 TiB) while
- * retaining a simple and space-efficient block list on disk.  The cache
- * is split into slots, caching up to eight 224 GiB files (128 KiB blocks).
- * Larger files use multiple slots, with 1.75 TiB files using all 8 slots.
- * The index cache is designed to be memory efficient, and by default uses
- * 16 KiB.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/kernel.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/pagemap.h>
-#include <linux/mutex.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Locate cache slot in range [offset, index] for specified inode.  If
- * there's more than one return the slot closest to index.
- */
-static struct meta_index *locate_meta_index(struct inode *inode, int offset,
-				int index)
-{
-	struct meta_index *meta = NULL;
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	int i;
-
-	mutex_lock(&msblk->meta_index_mutex);
-
-	TRACE("locate_meta_index: index %d, offset %d\n", index, offset);
-
-	if (msblk->meta_index == NULL)
-		goto not_allocated;
-
-	for (i = 0; i < SQUASHFS_META_SLOTS; i++) {
-		if (msblk->meta_index[i].inode_number == inode->i_ino &&
-				msblk->meta_index[i].offset >= offset &&
-				msblk->meta_index[i].offset <= index &&
-				msblk->meta_index[i].locked == 0) {
-			TRACE("locate_meta_index: entry %d, offset %d\n", i,
-					msblk->meta_index[i].offset);
-			meta = &msblk->meta_index[i];
-			offset = meta->offset;
-		}
-	}
-
-	if (meta)
-		meta->locked = 1;
-
-not_allocated:
-	mutex_unlock(&msblk->meta_index_mutex);
-
-	return meta;
-}
-
-
-/*
- * Find and initialise an empty cache slot for index offset.
- */
-static struct meta_index *empty_meta_index(struct inode *inode, int offset,
-				int skip)
-{
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	struct meta_index *meta = NULL;
-	int i;
-
-	mutex_lock(&msblk->meta_index_mutex);
-
-	TRACE("empty_meta_index: offset %d, skip %d\n", offset, skip);
-
-	if (msblk->meta_index == NULL) {
-		/*
-		 * First time cache index has been used, allocate and
-		 * initialise.  The cache index could be allocated at
-		 * mount time but doing it here means it is allocated only
-		 * if a 'large' file is read.
-		 */
-		msblk->meta_index = kcalloc(SQUASHFS_META_SLOTS,
-			sizeof(*(msblk->meta_index)), GFP_KERNEL);
-		if (msblk->meta_index == NULL) {
-			ERROR("Failed to allocate meta_index\n");
-			goto failed;
-		}
-		for (i = 0; i < SQUASHFS_META_SLOTS; i++) {
-			msblk->meta_index[i].inode_number = 0;
-			msblk->meta_index[i].locked = 0;
-		}
-		msblk->next_meta_index = 0;
-	}
-
-	for (i = SQUASHFS_META_SLOTS; i &&
-			msblk->meta_index[msblk->next_meta_index].locked; i--)
-		msblk->next_meta_index = (msblk->next_meta_index + 1) %
-			SQUASHFS_META_SLOTS;
-
-	if (i == 0) {
-		TRACE("empty_meta_index: failed!\n");
-		goto failed;
-	}
-
-	TRACE("empty_meta_index: returned meta entry %d, %p\n",
-			msblk->next_meta_index,
-			&msblk->meta_index[msblk->next_meta_index]);
-
-	meta = &msblk->meta_index[msblk->next_meta_index];
-	msblk->next_meta_index = (msblk->next_meta_index + 1) %
-			SQUASHFS_META_SLOTS;
-
-	meta->inode_number = inode->i_ino;
-	meta->offset = offset;
-	meta->skip = skip;
-	meta->entries = 0;
-	meta->locked = 1;
-
-failed:
-	mutex_unlock(&msblk->meta_index_mutex);
-	return meta;
-}
-
-
-static void release_meta_index(struct inode *inode, struct meta_index *meta)
-{
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	mutex_lock(&msblk->meta_index_mutex);
-	meta->locked = 0;
-	mutex_unlock(&msblk->meta_index_mutex);
-}
-
-
-/*
- * Read the next n blocks from the block list, starting from
- * metadata block <start_block, offset>.
- */
-static long long read_indexes(struct super_block *sb, int n,
-				u64 *start_block, int *offset)
-{
-	int err, i;
-	long long block = 0;
-	__le32 *blist = kmalloc(PAGE_CACHE_SIZE, GFP_KERNEL);
-
-	if (blist == NULL) {
-		ERROR("read_indexes: Failed to allocate block_list\n");
-		return -ENOMEM;
-	}
-
-	while (n) {
-		int blocks = min_t(int, n, PAGE_CACHE_SIZE >> 2);
-
-		err = squashfs_read_metadata(sb, blist, start_block,
-				offset, blocks << 2);
-		if (err < 0) {
-			ERROR("read_indexes: reading block [%llx:%x]\n",
-				*start_block, *offset);
-			goto failure;
-		}
-
-		for (i = 0; i < blocks; i++) {
-			int size = le32_to_cpu(blist[i]);
-			block += SQUASHFS_COMPRESSED_SIZE_BLOCK(size);
-		}
-		n -= blocks;
-	}
-
-	kfree(blist);
-	return block;
-
-failure:
-	kfree(blist);
-	return err;
-}
-
-
-/*
- * Each cache index slot has SQUASHFS_META_ENTRIES, each of which
- * can cache one index -> datablock/blocklist-block mapping.  We wish
- * to distribute these over the length of the file, entry[0] maps index x,
- * entry[1] maps index x + skip, entry[2] maps index x + 2 * skip, and so on.
- * The larger the file, the greater the skip factor.  The skip factor is
- * limited to the size of the metadata cache (SQUASHFS_CACHED_BLKS) to ensure
- * the number of metadata blocks that need to be read fits into the cache.
- * If the skip factor is limited in this way then the file will use multiple
- * slots.
- */
-static inline int calculate_skip(int blocks)
-{
-	int skip = blocks / ((SQUASHFS_META_ENTRIES + 1)
-		 * SQUASHFS_META_INDEXES);
-	return min(SQUASHFS_CACHED_BLKS - 1, skip + 1);
-}
-
-
-/*
- * Search and grow the index cache for the specified inode, returning the
- * on-disk locations of the datablock and block list metadata block
- * <index_block, index_offset> for index (scaled to nearest cache index).
- */
-static int fill_meta_index(struct inode *inode, int index,
-		u64 *index_block, int *index_offset, u64 *data_block)
-{
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	int skip = calculate_skip(i_size_read(inode) >> msblk->block_log);
-	int offset = 0;
-	struct meta_index *meta;
-	struct meta_entry *meta_entry;
-	u64 cur_index_block = squashfs_i(inode)->block_list_start;
-	int cur_offset = squashfs_i(inode)->offset;
-	u64 cur_data_block = squashfs_i(inode)->start;
-	int err, i;
-
-	/*
-	 * Scale index to cache index (cache slot entry)
-	 */
-	index /= SQUASHFS_META_INDEXES * skip;
-
-	while (offset < index) {
-		meta = locate_meta_index(inode, offset + 1, index);
-
-		if (meta == NULL) {
-			meta = empty_meta_index(inode, offset + 1, skip);
-			if (meta == NULL)
-				goto all_done;
-		} else {
-			offset = index < meta->offset + meta->entries ? index :
-				meta->offset + meta->entries - 1;
-			meta_entry = &meta->meta_entry[offset - meta->offset];
-			cur_index_block = meta_entry->index_block +
-				msblk->inode_table;
-			cur_offset = meta_entry->offset;
-			cur_data_block = meta_entry->data_block;
-			TRACE("get_meta_index: offset %d, meta->offset %d, "
-				"meta->entries %d\n", offset, meta->offset,
-				meta->entries);
-			TRACE("get_meta_index: index_block 0x%llx, offset 0x%x"
-				" data_block 0x%llx\n", cur_index_block,
-				cur_offset, cur_data_block);
-		}
-
-		/*
-		 * If necessary grow cache slot by reading block list.  Cache
-		 * slot is extended up to index or to the end of the slot, in
-		 * which case further slots will be used.
-		 */
-		for (i = meta->offset + meta->entries; i <= index &&
-				i < meta->offset + SQUASHFS_META_ENTRIES; i++) {
-			int blocks = skip * SQUASHFS_META_INDEXES;
-			long long res = read_indexes(inode->i_sb, blocks,
-					&cur_index_block, &cur_offset);
-
-			if (res < 0) {
-				if (meta->entries == 0)
-					/*
-					 * Don't leave an empty slot on read
-					 * error allocated to this inode...
-					 */
-					meta->inode_number = 0;
-				err = res;
-				goto failed;
-			}
-
-			cur_data_block += res;
-			meta_entry = &meta->meta_entry[i - meta->offset];
-			meta_entry->index_block = cur_index_block -
-				msblk->inode_table;
-			meta_entry->offset = cur_offset;
-			meta_entry->data_block = cur_data_block;
-			meta->entries++;
-			offset++;
-		}
-
-		TRACE("get_meta_index: meta->offset %d, meta->entries %d\n",
-				meta->offset, meta->entries);
-
-		release_meta_index(inode, meta);
-	}
-
-all_done:
-	*index_block = cur_index_block;
-	*index_offset = cur_offset;
-	*data_block = cur_data_block;
-
-	/*
-	 * Scale cache index (cache slot entry) to index
-	 */
-	return offset * SQUASHFS_META_INDEXES * skip;
-
-failed:
-	release_meta_index(inode, meta);
-	return err;
-}
-
-
-/*
- * Get the on-disk location and compressed size of the datablock
- * specified by index.  Fill_meta_index() does most of the work.
- */
-static int read_blocklist(struct inode *inode, int index, u64 *block)
-{
-	u64 start;
-	long long blks;
-	int offset;
-	__le32 size;
-	int res = fill_meta_index(inode, index, &start, &offset, block);
-
-	TRACE("read_blocklist: res %d, index %d, start 0x%llx, offset"
-		       " 0x%x, block 0x%llx\n", res, index, start, offset,
-			*block);
-
-	if (res < 0)
-		return res;
-
-	/*
-	 * res contains the index of the mapping returned by fill_meta_index(),
-	 * this will likely be less than the desired index (because the
-	 * meta_index cache works at a higher granularity).  Read any
-	 * extra block indexes needed.
-	 */
-	if (res < index) {
-		blks = read_indexes(inode->i_sb, index - res, &start, &offset);
-		if (blks < 0)
-			return (int) blks;
-		*block += blks;
-	}
-
-	/*
-	 * Read length of block specified by index.
-	 */
-	res = squashfs_read_metadata(inode->i_sb, &size, &start, &offset,
-			sizeof(size));
-	if (res < 0)
-		return res;
-	return le32_to_cpu(size);
-}
-
-
-static int squashfs_readpage(struct file *file, struct page *page)
-{
-	struct inode *inode = page->mapping->host;
-	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
-	int bytes, i, offset = 0, sparse = 0;
-	struct squashfs_cache_entry *buffer = NULL;
-	void *pageaddr;
-
-	int mask = (1 << (msblk->block_log - PAGE_CACHE_SHIFT)) - 1;
-	int index = page->index >> (msblk->block_log - PAGE_CACHE_SHIFT);
-	int start_index = page->index & ~mask;
-	int end_index = start_index | mask;
-	int file_end = i_size_read(inode) >> msblk->block_log;
-
-	TRACE("Entered squashfs_readpage, page index %lx, start block %llx\n",
-				page->index, squashfs_i(inode)->start);
-
-	if (page->index >= ((i_size_read(inode) + PAGE_CACHE_SIZE - 1) >>
-					PAGE_CACHE_SHIFT))
-		goto out;
-
-	if (index < file_end || squashfs_i(inode)->fragment_block ==
-					SQUASHFS_INVALID_BLK) {
-		/*
-		 * Reading a datablock from disk.  Need to read block list
-		 * to get location and block size.
-		 */
-		u64 block = 0;
-		int bsize = read_blocklist(inode, index, &block);
-		if (bsize < 0)
-			goto error_out;
-
-		if (bsize == 0) { /* hole */
-			bytes = index == file_end ?
-				(i_size_read(inode) & (msblk->block_size - 1)) :
-				 msblk->block_size;
-			sparse = 1;
-		} else {
-			/*
-			 * Read and decompress datablock.
-			 */
-			buffer = squashfs_get_datablock(inode->i_sb,
-								block, bsize);
-			if (buffer->error) {
-				ERROR("Unable to read page, block %llx, size %x"
-					"\n", block, bsize);
-				squashfs_cache_put(buffer);
-				goto error_out;
-			}
-			bytes = buffer->length;
-		}
-	} else {
-		/*
-		 * Datablock is stored inside a fragment (tail-end packed
-		 * block).
-		 */
-		buffer = squashfs_get_fragment(inode->i_sb,
-				squashfs_i(inode)->fragment_block,
-				squashfs_i(inode)->fragment_size);
-
-		if (buffer->error) {
-			ERROR("Unable to read page, block %llx, size %x\n",
-				squashfs_i(inode)->fragment_block,
-				squashfs_i(inode)->fragment_size);
-			squashfs_cache_put(buffer);
-			goto error_out;
-		}
-		bytes = i_size_read(inode) & (msblk->block_size - 1);
-		offset = squashfs_i(inode)->fragment_offset;
-	}
-
-	/*
-	 * Loop copying datablock into pages.  As the datablock likely covers
-	 * many PAGE_CACHE_SIZE pages (default block size is 128 KiB) explicitly
-	 * grab the pages from the page cache, except for the page that we've
-	 * been called to fill.
-	 */
-	for (i = start_index; i <= end_index && bytes > 0; i++,
-			bytes -= PAGE_CACHE_SIZE, offset += PAGE_CACHE_SIZE) {
-		struct page *push_page;
-		int avail = sparse ? 0 : min_t(int, bytes, PAGE_CACHE_SIZE);
-
-		TRACE("bytes %d, i %d, available_bytes %d\n", bytes, i, avail);
-
-		push_page = (i == page->index) ? page :
-			grab_cache_page_nowait(page->mapping, i);
-
-		if (!push_page)
-			continue;
-
-		if (PageUptodate(push_page))
-			goto skip_page;
-
-		pageaddr = kmap_atomic(push_page, KM_USER0);
-		squashfs_copy_data(pageaddr, buffer, offset, avail);
-		memset(pageaddr + avail, 0, PAGE_CACHE_SIZE - avail);
-		kunmap_atomic(pageaddr, KM_USER0);
-		flush_dcache_page(push_page);
-		SetPageUptodate(push_page);
-skip_page:
-		unlock_page(push_page);
-		if (i != page->index)
-			page_cache_release(push_page);
-	}
-
-	if (!sparse)
-		squashfs_cache_put(buffer);
-
-	return 0;
-
-error_out:
-	SetPageError(page);
-out:
-	pageaddr = kmap_atomic(page, KM_USER0);
-	memset(pageaddr, 0, PAGE_CACHE_SIZE);
-	kunmap_atomic(pageaddr, KM_USER0);
-	flush_dcache_page(page);
-	if (!PageError(page))
-		SetPageUptodate(page);
-	unlock_page(page);
-
-	return 0;
-}
-
-
-const struct address_space_operations squashfs_aops = {
-	.readpage = squashfs_readpage
-};
diff -Naur linux-2.6.30-ori/fs/squashfs/fragment.c linux-2.6.30-test/fs/squashfs/fragment.c
--- linux-2.6.30-ori/fs/squashfs/fragment.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/fragment.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,98 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * fragment.c
- */
-
-/*
- * This file implements code to handle compressed fragments (tail-end packed
- * datablocks).
- *
- * Regular files contain a fragment index which is mapped to a fragment
- * location on disk and compressed size using a fragment lookup table.
- * Like everything in Squashfs this fragment lookup table is itself stored
- * compressed into metadata blocks.  A second index table is used to locate
- * these.  This second index table for speed of access (and because it
- * is small) is read at mount time and cached in memory.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/slab.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Look-up fragment using the fragment index table.  Return the on disk
- * location of the fragment and its compressed size
- */
-int squashfs_frag_lookup(struct super_block *sb, unsigned int fragment,
-				u64 *fragment_block)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int block = SQUASHFS_FRAGMENT_INDEX(fragment);
-	int offset = SQUASHFS_FRAGMENT_INDEX_OFFSET(fragment);
-	u64 start_block = le64_to_cpu(msblk->fragment_index[block]);
-	struct squashfs_fragment_entry fragment_entry;
-	int size;
-
-	size = squashfs_read_metadata(sb, &fragment_entry, &start_block,
-					&offset, sizeof(fragment_entry));
-	if (size < 0)
-		return size;
-
-	*fragment_block = le64_to_cpu(fragment_entry.start_block);
-	size = le32_to_cpu(fragment_entry.size);
-
-	return size;
-}
-
-
-/*
- * Read the uncompressed fragment lookup table indexes off disk into memory
- */
-__le64 *squashfs_read_fragment_index_table(struct super_block *sb,
-	u64 fragment_table_start, unsigned int fragments)
-{
-	unsigned int length = SQUASHFS_FRAGMENT_INDEX_BYTES(fragments);
-	__le64 *fragment_index;
-	int err;
-
-	/* Allocate fragment lookup table indexes */
-	fragment_index = kmalloc(length, GFP_KERNEL);
-	if (fragment_index == NULL) {
-		ERROR("Failed to allocate fragment index table\n");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	err = squashfs_read_table(sb, fragment_index, fragment_table_start,
-			length);
-	if (err < 0) {
-		ERROR("unable to read fragment index table\n");
-		kfree(fragment_index);
-		return ERR_PTR(err);
-	}
-
-	return fragment_index;
-}
diff -Naur linux-2.6.30-ori/fs/squashfs/id.c linux-2.6.30-test/fs/squashfs/id.c
--- linux-2.6.30-ori/fs/squashfs/id.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/id.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,94 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * id.c
- */
-
-/*
- * This file implements code to handle uids and gids.
- *
- * For space efficiency regular files store uid and gid indexes, which are
- * converted to 32-bit uids/gids using an id look up table.  This table is
- * stored compressed into metadata blocks.  A second index table is used to
- * locate these.  This second index table for speed of access (and because it
- * is small) is read at mount time and cached in memory.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/slab.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Map uid/gid index into real 32-bit uid/gid using the id look up table
- */
-int squashfs_get_id(struct super_block *sb, unsigned int index,
-					unsigned int *id)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int block = SQUASHFS_ID_BLOCK(index);
-	int offset = SQUASHFS_ID_BLOCK_OFFSET(index);
-	u64 start_block = le64_to_cpu(msblk->id_table[block]);
-	__le32 disk_id;
-	int err;
-
-	err = squashfs_read_metadata(sb, &disk_id, &start_block, &offset,
-							sizeof(disk_id));
-	if (err < 0)
-		return err;
-
-	*id = le32_to_cpu(disk_id);
-	return 0;
-}
-
-
-/*
- * Read uncompressed id lookup table indexes from disk into memory
- */
-__le64 *squashfs_read_id_index_table(struct super_block *sb,
-			u64 id_table_start, unsigned short no_ids)
-{
-	unsigned int length = SQUASHFS_ID_BLOCK_BYTES(no_ids);
-	__le64 *id_table;
-	int err;
-
-	TRACE("In read_id_index_table, length %d\n", length);
-
-	/* Allocate id lookup table indexes */
-	id_table = kmalloc(length, GFP_KERNEL);
-	if (id_table == NULL) {
-		ERROR("Failed to allocate id index table\n");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	err = squashfs_read_table(sb, id_table, id_table_start, length);
-	if (err < 0) {
-		ERROR("unable to read id index table\n");
-		kfree(id_table);
-		return ERR_PTR(err);
-	}
-
-	return id_table;
-}
diff -Naur linux-2.6.30-ori/fs/squashfs/inode.c linux-2.6.30-test/fs/squashfs/inode.c
--- linux-2.6.30-ori/fs/squashfs/inode.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/inode.c	2009-06-15 11:25:12.000000000 -0400
@@ -16,333 +16,2308 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * inode.c
  */
 
-/*
- * This file implements code to create and read inodes from disk.
- *
- * Inodes in Squashfs are identified by a 48-bit inode which encodes the
- * location of the compressed metadata block containing the inode, and the byte
- * offset into that block where the inode is placed (<block, offset>).
- *
- * To maximise compression there are different inodes for each file type
- * (regular file, directory, device, etc.), the inode contents and length
- * varying with the type.
- *
- * To further maximise compression, two types of regular file inode and
- * directory inode are defined: inodes optimised for frequently occurring
- * regular files and directories, and extended types where extra
- * information has to be stored.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/zlib.h>
-
 #include "squashfs_fs.h"
+#include <linux/module.h>
+#include <linux/zlib.h>
+#include <linux/fs.h>
 #include "squashfs_fs_sb.h"
 #include "squashfs_fs_i.h"
+#include <linux/buffer_head.h>
+#include <linux/vfs.h>
+#include <linux/vmalloc.h>
+#include <linux/smp_lock.h>
+#include <linux/exportfs.h>
+
 #include "squashfs.h"
+#include "sqlzma.h"
+#include "sqmagic.h"
 
-/*
- * Initialise VFS inode with the base inode information common to all
- * Squashfs inode types.  Sqsh_ino contains the unswapped base inode
- * off disk.
- */
-static int squashfs_new_inode(struct super_block *sb, struct inode *inode,
-				struct squashfs_base_inode *sqsh_ino)
+#undef KeepPreemptive
+#if defined(CONFIG_PREEMPT) && !defined(UnsquashNoPreempt)
+#define KeepPreemptive
+#endif
+
+struct sqlzma {
+#ifdef KeepPreemptive
+	struct mutex mtx;
+#endif
+	unsigned char read_data[SQUASHFS_FILE_MAX_SIZE];
+	struct sqlzma_un un;
+};
+static DEFINE_PER_CPU(struct sqlzma *, sqlzma);
+
+#define dpri(fmt, args...) /* printk("%s:%d: " fmt, __func__, __LINE__, ##args) */
+#define dpri_un(un)	dpri("un{%d, {%d %p}, {%d %p}, {%d %p}}\n", \
+			     (un)->un_lzma, (un)->un_a[0].sz, (un)->un_a[0].buf, \
+			     (un)->un_a[1].sz, (un)->un_a[1].buf, \
+			     (un)->un_a[2].sz, (un)->un_a[2].buf)
+
+static int squashfs_cached_blks;
+
+static struct dentry *squashfs_fh_to_dentry(struct super_block *s,
+		struct fid *fid, int fh_len, int fh_type);
+static struct dentry *squashfs_fh_to_parent(struct super_block *s,
+		struct fid *fid, int fh_len, int fh_type);
+static struct dentry *squashfs_get_parent(struct dentry *child);
+static int squashfs_read_inode(struct inode *i, squashfs_inode_t inode);
+static int squashfs_statfs(struct dentry *, struct kstatfs *);
+static int squashfs_symlink_readpage(struct file *file, struct page *page);
+static long long read_blocklist(struct inode *inode, int index,
+				int readahead_blks, char *block_list,
+				unsigned short **block_p, unsigned int *bsize);
+static int squashfs_readpage(struct file *file, struct page *page);
+static int squashfs_readdir(struct file *, void *, filldir_t);
+static struct dentry *squashfs_lookup(struct inode *, struct dentry *,
+				struct nameidata *);
+static int squashfs_remount(struct super_block *s, int *flags, char *data);
+static void squashfs_put_super(struct super_block *);
+static int squashfs_get_sb(struct file_system_type *,int, const char *, void *,
+				struct vfsmount *);
+static struct inode *squashfs_alloc_inode(struct super_block *sb);
+static void squashfs_destroy_inode(struct inode *inode);
+static int init_inodecache(void);
+static void destroy_inodecache(void);
+
+static struct file_system_type squashfs_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "squashfs",
+	.get_sb = squashfs_get_sb,
+	.kill_sb = kill_block_super,
+	.fs_flags = FS_REQUIRES_DEV
+};
+
+static const unsigned char squashfs_filetype_table[] = {
+	DT_UNKNOWN, DT_DIR, DT_REG, DT_LNK, DT_BLK, DT_CHR, DT_FIFO, DT_SOCK
+};
+
+static struct super_operations squashfs_super_ops = {
+	.alloc_inode = squashfs_alloc_inode,
+	.destroy_inode = squashfs_destroy_inode,
+	.statfs = squashfs_statfs,
+	.put_super = squashfs_put_super,
+	.remount_fs = squashfs_remount
+};
+
+static struct export_operations squashfs_export_ops = {
+	.fh_to_dentry = squashfs_fh_to_dentry,
+	.fh_to_parent = squashfs_fh_to_parent,
+	.get_parent = squashfs_get_parent
+};
+
+SQSH_EXTERN const struct address_space_operations squashfs_symlink_aops = {
+	.readpage = squashfs_symlink_readpage
+};
+
+SQSH_EXTERN const struct address_space_operations squashfs_aops = {
+	.readpage = squashfs_readpage
+};
+
+static const struct file_operations squashfs_dir_ops = {
+	.read = generic_read_dir,
+	.readdir = squashfs_readdir
+};
+
+SQSH_EXTERN struct inode_operations squashfs_dir_inode_ops = {
+	.lookup = squashfs_lookup
+};
+
+
+static struct buffer_head *get_block_length(struct super_block *s,
+				int *cur_index, int *offset, int *c_byte)
 {
-	int err;
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	unsigned short temp;
+	struct buffer_head *bh;
+
+	if (!(bh = sb_bread(s, *cur_index)))
+		goto out;
+
+	if (msblk->devblksize - *offset == 1) {
+		if (msblk->swap)
+			((unsigned char *) &temp)[1] = *((unsigned char *)
+				(bh->b_data + *offset));
+		else
+			((unsigned char *) &temp)[0] = *((unsigned char *)
+				(bh->b_data + *offset));
+		brelse(bh);
+		if (!(bh = sb_bread(s, ++(*cur_index))))
+			goto out;
+		if (msblk->swap)
+			((unsigned char *) &temp)[0] = *((unsigned char *)
+				bh->b_data); 
+		else
+			((unsigned char *) &temp)[1] = *((unsigned char *)
+				bh->b_data); 
+		*c_byte = temp;
+		*offset = 1;
+	} else {
+		if (msblk->swap) {
+			((unsigned char *) &temp)[1] = *((unsigned char *)
+				(bh->b_data + *offset));
+			((unsigned char *) &temp)[0] = *((unsigned char *)
+				(bh->b_data + *offset + 1)); 
+		} else {
+			((unsigned char *) &temp)[0] = *((unsigned char *)
+				(bh->b_data + *offset));
+			((unsigned char *) &temp)[1] = *((unsigned char *)
+				(bh->b_data + *offset + 1)); 
+		}
+		*c_byte = temp;
+		*offset += 2;
+	}
 
-	err = squashfs_get_id(sb, le16_to_cpu(sqsh_ino->uid), &inode->i_uid);
-	if (err)
-		return err;
+	if (SQUASHFS_CHECK_DATA(msblk->sblk.flags)) {
+		if (*offset == msblk->devblksize) {
+			brelse(bh);
+			if (!(bh = sb_bread(s, ++(*cur_index))))
+				goto out;
+			*offset = 0;
+		}
+		if (*((unsigned char *) (bh->b_data + *offset)) !=
+						SQUASHFS_MARKER_BYTE) {
+			ERROR("Metadata block marker corrupt @ %x\n",
+						*cur_index);
+			brelse(bh);
+			goto out;
+		}
+		(*offset)++;
+	}
+	return bh;
 
-	err = squashfs_get_id(sb, le16_to_cpu(sqsh_ino->guid), &inode->i_gid);
-	if (err)
-		return err;
+out:
+	return NULL;
+}
 
-	inode->i_ino = le32_to_cpu(sqsh_ino->inode_number);
-	inode->i_mtime.tv_sec = le32_to_cpu(sqsh_ino->mtime);
-	inode->i_atime.tv_sec = inode->i_mtime.tv_sec;
-	inode->i_ctime.tv_sec = inode->i_mtime.tv_sec;
-	inode->i_mode = le16_to_cpu(sqsh_ino->mode);
-	inode->i_size = 0;
 
-	return err;
+SQSH_EXTERN unsigned int squashfs_read_data(struct super_block *s, char *buffer,
+			long long index, unsigned int length,
+			long long *next_index, int srclength)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	struct buffer_head **bh;
+	unsigned int offset = index & ((1 << msblk->devblksize_log2) - 1);
+	unsigned int cur_index = index >> msblk->devblksize_log2;
+	int bytes, avail_bytes, b = 0, k = 0;
+	unsigned int compressed;
+	unsigned int c_byte = length;
+
+	bh = kmalloc(((sblk->block_size >> msblk->devblksize_log2) + 1) *
+								sizeof(struct buffer_head *), GFP_KERNEL);
+	if (bh == NULL)
+		goto read_failure;
+
+	if (c_byte) {
+		bytes = msblk->devblksize - offset;
+		compressed = SQUASHFS_COMPRESSED_BLOCK(c_byte);
+		c_byte = SQUASHFS_COMPRESSED_SIZE_BLOCK(c_byte);
+
+		TRACE("Block @ 0x%llx, %scompressed size %d, src size %d\n", index,
+					compressed ? "" : "un", (unsigned int) c_byte, srclength);
+
+		if (c_byte > srclength || index < 0 || (index + c_byte) > sblk->bytes_used)
+			goto read_failure;
+
+		bh[0] = sb_getblk(s, cur_index);
+		if (bh[0] == NULL)
+			goto block_release;
+
+		for (b = 1; bytes < c_byte; b++) {
+			bh[b] = sb_getblk(s, ++cur_index);
+			if (bh[b] == NULL)
+				goto block_release;
+			bytes += msblk->devblksize;
+		}
+		ll_rw_block(READ, b, bh);
+	} else {
+		if (index < 0 || (index + 2) > sblk->bytes_used)
+			goto read_failure;
+
+		bh[0] = get_block_length(s, &cur_index, &offset, &c_byte);
+		if (bh[0] == NULL)
+			goto read_failure;
+
+		bytes = msblk->devblksize - offset;
+		compressed = SQUASHFS_COMPRESSED(c_byte);
+		c_byte = SQUASHFS_COMPRESSED_SIZE(c_byte);
+
+		TRACE("Block @ 0x%llx, %scompressed size %d\n", index, compressed
+					? "" : "un", (unsigned int) c_byte);
+
+		if (c_byte > srclength || (index + c_byte) > sblk->bytes_used)
+			goto read_failure;
+
+		for (b = 1; bytes < c_byte; b++) {
+			bh[b] = sb_getblk(s, ++cur_index);
+			if (bh[b] == NULL)
+				goto block_release;
+			bytes += msblk->devblksize;
+		}
+		ll_rw_block(READ, b - 1, bh + 1);
+	}
+
+	if (compressed) {
+		int zlib_err = Z_STREAM_END;
+		int start;
+		enum {Src, Dst};
+		struct sized_buf sbuf[2];
+		struct sqlzma *percpu;
+		unsigned char *p;
+
+		/*
+	 	* uncompress block
+	 	*/
+
+		/* mutex_lock(&msblk->read_data_mutex); */
+
+		start = k;
+		for (; k < b; k++) {
+			wait_on_buffer(bh[k]);
+			if (!buffer_uptodate(bh[k]))
+				goto release_mutex;
+		}
+
+		/* it disables preemption */
+		percpu = get_cpu_var(sqlzma);
+#ifdef KeepPreemptive
+		put_cpu_var(sqlzma);
+		mutex_lock(&percpu->mtx);
+#endif
+		p = percpu->read_data;
+		k = start;
+		for (bytes = 0; k < b; k++) {
+			avail_bytes = min(c_byte - bytes, msblk->devblksize - offset);
+
+			if (k == 0) {
+				/*
+				 * keep this block structture to simplify the
+				 * diff.
+				 */
+				if (avail_bytes == 0) {
+					offset = 0;
+					brelse(bh[k]);
+					continue;
+				}
+			}
+
+			memcpy(p, bh[k]->b_data + offset, avail_bytes);
+			p += avail_bytes;
+#if 0
+			BUG_ON(percpu->read_data + sizeof(percpu->read_data)
+			       < p);
+#endif
+
+			bytes += avail_bytes;
+			offset = 0;
+			brelse(bh[k]);
+		}
+
+		sbuf[Src].buf = percpu->read_data;
+		sbuf[Src].sz = bytes;
+		sbuf[Dst].buf = buffer;
+		sbuf[Dst].sz = srclength;
+		dpri_un(&percpu->un);
+		dpri("src %d %p, dst %d %p\n", sbuf[Src].sz, sbuf[Src].buf,
+		     sbuf[Dst].sz, sbuf[Dst].buf);
+		zlib_err = sqlzma_un(&percpu->un, sbuf + Src, sbuf + Dst);
+		bytes = percpu->un.un_reslen;
+
+#ifdef KeepPreemptive
+		mutex_unlock(&percpu->mtx);
+#else
+		put_cpu_var(sqlzma);
+#endif
+		if (unlikely(zlib_err)) {
+			dpri("zlib_err %d\n", zlib_err);
+			goto release_mutex;
+		}
+		/* mutex_unlock(&msblk->read_data_mutex); */
+	} else {
+		int i;
+
+		for(i = 0; i < b; i++) {
+			wait_on_buffer(bh[i]);
+			if (!buffer_uptodate(bh[i]))
+				goto block_release;
+		}
+
+		for (bytes = 0; k < b; k++) {
+			avail_bytes = min(c_byte - bytes, msblk->devblksize - offset);
+
+			memcpy(buffer + bytes, bh[k]->b_data + offset, avail_bytes);
+			bytes += avail_bytes;
+			offset = 0;
+			brelse(bh[k]);
+		}
+	}
+
+	if (next_index)
+		*next_index = index + c_byte + (length ? 0 :
+				(SQUASHFS_CHECK_DATA(msblk->sblk.flags) ? 3 : 2));
+
+	kfree(bh);
+	return bytes;
+
+release_mutex:
+	/* mutex_unlock(&msblk->read_data_mutex); */
+
+block_release:
+	for (; k < b; k++)
+		brelse(bh[k]);
+
+read_failure:
+	ERROR("sb_bread failed reading block 0x%x\n", cur_index);
+	kfree(bh);
+	return 0;
 }
 
 
-struct inode *squashfs_iget(struct super_block *sb, long long ino,
-				unsigned int ino_number)
+SQSH_EXTERN int squashfs_get_cached_block(struct super_block *s, void *buffer,
+				long long block, unsigned int offset,
+				int length, long long *next_block,
+				unsigned int *next_offset)
 {
-	struct inode *inode = iget_locked(sb, ino_number);
-	int err;
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	int n, i, bytes, return_length = length;
+	long long next_index;
+
+	TRACE("Entered squashfs_get_cached_block [%llx:%x]\n", block, offset);
+
+	while (1) {
+		for (i = 0; i < squashfs_cached_blks; i++) 
+			if (msblk->block_cache[i].block == block)
+				break; 
+		
+		mutex_lock(&msblk->block_cache_mutex);
+
+		if (i == squashfs_cached_blks) {
+			/* read inode header block */
+			if (msblk->unused_cache_blks == 0) {
+				mutex_unlock(&msblk->block_cache_mutex);
+				wait_event(msblk->waitq, msblk->unused_cache_blks);
+				continue;
+			}
 
-	TRACE("Entered squashfs_iget\n");
+			i = msblk->next_cache;
+			for (n = 0; n < squashfs_cached_blks; n++) {
+				if (msblk->block_cache[i].block != SQUASHFS_USED_BLK)
+					break;
+				i = (i + 1) % squashfs_cached_blks;
+			}
+
+			msblk->next_cache = (i + 1) % squashfs_cached_blks;
+
+			if (msblk->block_cache[i].block == SQUASHFS_INVALID_BLK) {
+				msblk->block_cache[i].data = vmalloc(SQUASHFS_METADATA_SIZE);
+				if (msblk->block_cache[i].data == NULL) {
+					ERROR("Failed to allocate cache block\n");
+					mutex_unlock(&msblk->block_cache_mutex);
+					goto out;
+				}
+			}
+	
+			msblk->block_cache[i].block = SQUASHFS_USED_BLK;
+			msblk->unused_cache_blks --;
+			mutex_unlock(&msblk->block_cache_mutex);
+
+			msblk->block_cache[i].length = squashfs_read_data(s,
+				msblk->block_cache[i].data, block, 0, &next_index,
+				SQUASHFS_METADATA_SIZE);
+
+			if (msblk->block_cache[i].length == 0) {
+				ERROR("Unable to read cache block [%llx:%x]\n", block, offset);
+				mutex_lock(&msblk->block_cache_mutex);
+				msblk->block_cache[i].block = SQUASHFS_INVALID_BLK;
+				msblk->unused_cache_blks ++;
+				smp_mb();
+				vfree(msblk->block_cache[i].data);
+				wake_up(&msblk->waitq);
+				mutex_unlock(&msblk->block_cache_mutex);
+				goto out;
+			}
+
+			mutex_lock(&msblk->block_cache_mutex);
+			msblk->block_cache[i].block = block;
+			msblk->block_cache[i].next_index = next_index;
+			msblk->unused_cache_blks ++;
+			smp_mb();
+			wake_up(&msblk->waitq);
+			TRACE("Read cache block [%llx:%x]\n", block, offset);
+		}
+
+		if (msblk->block_cache[i].block != block) {
+			mutex_unlock(&msblk->block_cache_mutex);
+			continue;
+		}
+
+		bytes = msblk->block_cache[i].length - offset;
 
-	if (!inode)
-		return ERR_PTR(-ENOMEM);
-	if (!(inode->i_state & I_NEW))
-		return inode;
-
-	err = squashfs_read_inode(inode, ino);
-	if (err) {
-		iget_failed(inode);
-		return ERR_PTR(err);
+		if (bytes < 1) {
+			mutex_unlock(&msblk->block_cache_mutex);
+			goto out;
+		} else if (bytes >= length) {
+			if (buffer)
+				memcpy(buffer, msblk->block_cache[i].data + offset, length);
+			if (msblk->block_cache[i].length - offset == length) {
+				*next_block = msblk->block_cache[i].next_index;
+				*next_offset = 0;
+			} else {
+				*next_block = block;
+				*next_offset = offset + length;
+			}
+			mutex_unlock(&msblk->block_cache_mutex);
+			goto finish;
+		} else {
+			if (buffer) {
+				memcpy(buffer, msblk->block_cache[i].data + offset, bytes);
+				buffer = (char *) buffer + bytes;
+			}
+			block = msblk->block_cache[i].next_index;
+			mutex_unlock(&msblk->block_cache_mutex);
+			length -= bytes;
+			offset = 0;
+		}
+	}
+
+finish:
+	return return_length;
+out:
+	return 0;
+}
+
+
+static int get_fragment_location(struct super_block *s, unsigned int fragment,
+				long long *fragment_start_block,
+				unsigned int *fragment_size)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	long long start_block =
+		msblk->fragment_index[SQUASHFS_FRAGMENT_INDEX(fragment)];
+	int offset = SQUASHFS_FRAGMENT_INDEX_OFFSET(fragment);
+	struct squashfs_fragment_entry fragment_entry;
+
+	if (msblk->swap) {
+		struct squashfs_fragment_entry sfragment_entry;
+
+		if (!squashfs_get_cached_block(s, &sfragment_entry, start_block, offset,
+					 sizeof(sfragment_entry), &start_block, &offset))
+			goto out;
+		SQUASHFS_SWAP_FRAGMENT_ENTRY(&fragment_entry, &sfragment_entry);
+	} else
+		if (!squashfs_get_cached_block(s, &fragment_entry, start_block, offset,
+					 sizeof(fragment_entry), &start_block, &offset))
+			goto out;
+
+	*fragment_start_block = fragment_entry.start_block;
+	*fragment_size = fragment_entry.size;
+
+	return 1;
+
+out:
+	return 0;
+}
+
+
+SQSH_EXTERN void release_cached_fragment(struct squashfs_sb_info *msblk,
+				struct squashfs_fragment_cache *fragment)
+{
+	mutex_lock(&msblk->fragment_mutex);
+	fragment->locked --;
+	if (fragment->locked == 0) {
+		msblk->unused_frag_blks ++;
+		smp_mb();
+		wake_up(&msblk->fragment_wait_queue);
 	}
+	mutex_unlock(&msblk->fragment_mutex);
+}
+
+
+SQSH_EXTERN
+struct squashfs_fragment_cache *get_cached_fragment(struct super_block *s,
+				long long start_block, int length)
+{
+	int i, n;
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	while (1) {
+		mutex_lock(&msblk->fragment_mutex);
+
+		for (i = 0; i < SQUASHFS_CACHED_FRAGMENTS &&
+				msblk->fragment[i].block != start_block; i++);
+
+		if (i == SQUASHFS_CACHED_FRAGMENTS) {
+			if (msblk->unused_frag_blks == 0) {
+				mutex_unlock(&msblk->fragment_mutex);
+				wait_event(msblk->fragment_wait_queue, msblk->unused_frag_blks);
+				continue;
+			}
+
+			i = msblk->next_fragment;
+			for (n = 0; n < SQUASHFS_CACHED_FRAGMENTS; n++) {
+				if (msblk->fragment[i].locked == 0)
+					break;
+				i = (i + 1) % SQUASHFS_CACHED_FRAGMENTS;
+			}
+
+			msblk->next_fragment = (msblk->next_fragment + 1) %
+				SQUASHFS_CACHED_FRAGMENTS;
+			
+			if (msblk->fragment[i].data == NULL) {
+				msblk->fragment[i].data = vmalloc(sblk->block_size);
+				if (msblk->fragment[i].data == NULL) {
+					ERROR("Failed to allocate fragment cache block\n");
+					mutex_unlock(&msblk->fragment_mutex);
+					goto out;
+				}
+			}
+
+			msblk->unused_frag_blks --;
+			msblk->fragment[i].block = SQUASHFS_INVALID_BLK;
+			msblk->fragment[i].locked = 1;
+			mutex_unlock(&msblk->fragment_mutex);
+
+			msblk->fragment[i].length = squashfs_read_data(s,
+				msblk->fragment[i].data, start_block, length, NULL,
+				sblk->block_size);
+
+			if (msblk->fragment[i].length == 0) {
+				ERROR("Unable to read fragment cache block [%llx]\n", start_block);
+				msblk->fragment[i].locked = 0;
+				msblk->unused_frag_blks ++;
+				smp_mb();
+				wake_up(&msblk->fragment_wait_queue);
+				goto out;
+			}
+
+			mutex_lock(&msblk->fragment_mutex);
+			msblk->fragment[i].block = start_block;
+			TRACE("New fragment %d, start block %lld, locked %d\n",
+				i, msblk->fragment[i].block, msblk->fragment[i].locked);
+			mutex_unlock(&msblk->fragment_mutex);
+			break;
+		}
+
+		if (msblk->fragment[i].locked == 0)
+			msblk->unused_frag_blks --;
+		msblk->fragment[i].locked++;
+		mutex_unlock(&msblk->fragment_mutex);
+		TRACE("Got fragment %d, start block %lld, locked %d\n", i,
+			msblk->fragment[i].block, msblk->fragment[i].locked);
+		break;
+	}
+
+	return &msblk->fragment[i];
+
+out:
+	return NULL;
+}
+
+
+static void squashfs_new_inode(struct squashfs_sb_info *msblk, struct inode *i,
+				struct squashfs_base_inode_header *inodeb)
+{
+	i->i_ino = inodeb->inode_number;
+	i->i_mtime.tv_sec = inodeb->mtime;
+	i->i_atime.tv_sec = inodeb->mtime;
+	i->i_ctime.tv_sec = inodeb->mtime;
+	i->i_uid = msblk->uid[inodeb->uid];
+	i->i_mode = inodeb->mode;
+	i->i_size = 0;
+
+	if (inodeb->guid == SQUASHFS_GUIDS)
+		i->i_gid = i->i_uid;
+	else
+		i->i_gid = msblk->guid[inodeb->guid];
+}
+
+
+static squashfs_inode_t squashfs_inode_lookup(struct super_block *s, int ino)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	long long start = msblk->inode_lookup_table[SQUASHFS_LOOKUP_BLOCK(ino - 1)];
+	int offset = SQUASHFS_LOOKUP_BLOCK_OFFSET(ino - 1);
+	squashfs_inode_t inode;
+
+	TRACE("Entered squashfs_inode_lookup, inode_number = %d\n", ino);
+
+	if (msblk->swap) {
+		squashfs_inode_t sinode;
+
+		if (!squashfs_get_cached_block(s, &sinode, start, offset,
+					sizeof(sinode), &start, &offset))
+			goto out;
+		SQUASHFS_SWAP_INODE_T((&inode), &sinode);
+	} else if (!squashfs_get_cached_block(s, &inode, start, offset,
+					sizeof(inode), &start, &offset))
+			goto out;
+
+	TRACE("squashfs_inode_lookup, inode = 0x%llx\n", inode);
 
-	unlock_new_inode(inode);
 	return inode;
+
+out:
+	return SQUASHFS_INVALID_BLK;
 }
 
 
-/*
- * Initialise VFS inode by reading inode from inode table (compressed
- * metadata).  The format and amount of data read depends on type.
- */
-int squashfs_read_inode(struct inode *inode, long long ino)
+
+static struct dentry *squashfs_export_iget(struct super_block *s,
+	unsigned int inode_number)
 {
-	struct super_block *sb = inode->i_sb;
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	u64 block = SQUASHFS_INODE_BLK(ino) + msblk->inode_table;
-	int err, type, offset = SQUASHFS_INODE_OFFSET(ino);
-	union squashfs_inode squashfs_ino;
-	struct squashfs_base_inode *sqshb_ino = &squashfs_ino.base;
+	squashfs_inode_t inode;
+	struct inode *i;
+	struct dentry *dentry;
+
+	TRACE("Entered squashfs_export_iget\n");
+
+	inode = squashfs_inode_lookup(s, inode_number);
+	if(inode == SQUASHFS_INVALID_BLK) {
+		dentry = ERR_PTR(-ENOENT);
+		goto failure;
+	}
 
-	TRACE("Entered squashfs_read_inode\n");
+	if (inode >= 0)
+		dentry = d_obtain_alias(squashfs_iget(s, inode, inode_number));
+
+failure:
+	return dentry;
+}
 
-	/*
-	 * Read inode base common to all inode types.
-	 */
-	err = squashfs_read_metadata(sb, sqshb_ino, &block,
-				&offset, sizeof(*sqshb_ino));
-	if (err < 0)
-		goto failed_read;
 
-	err = squashfs_new_inode(sb, inode, sqshb_ino);
-	if (err)
-		goto failed_read;
+static struct dentry *squashfs_fh_to_dentry(struct super_block *s,
+		struct fid *fid, int fh_len, int fh_type)
+{
+	if((fh_type != FILEID_INO32_GEN && fh_type != FILEID_INO32_GEN_PARENT) ||
+			fh_len < 2)
+		return NULL;
+
+	return squashfs_export_iget(s, fid->i32.ino);
+}
+
+
+static struct dentry *squashfs_fh_to_parent(struct super_block *s,
+		struct fid *fid, int fh_len, int fh_type)
+{
+	if(fh_type != FILEID_INO32_GEN_PARENT || fh_len < 4)
+		return NULL;
+
+	return squashfs_export_iget(s, fid->i32.parent_ino);
+}
+
+
+static struct dentry *squashfs_get_parent(struct dentry *child)
+{
+	struct inode *i = child->d_inode;
+
+	TRACE("Entered squashfs_get_parent\n");
+
+	return squashfs_export_iget(i->i_sb, SQUASHFS_I(i)->u.s2.parent_inode);
+}
+
+
+SQSH_EXTERN struct inode *squashfs_iget(struct super_block *s,
+				squashfs_inode_t inode, unsigned int inode_number)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct inode *i = iget_locked(s, inode_number);
+
+	TRACE("Entered squashfs_iget\n");
+
+	if(i && (i->i_state & I_NEW)) {
+		(msblk->read_inode)(i, inode);
+		unlock_new_inode(i);
+	}
+
+	return i;
+}
+
 
-	block = SQUASHFS_INODE_BLK(ino) + msblk->inode_table;
-	offset = SQUASHFS_INODE_OFFSET(ino);
+static int squashfs_read_inode(struct inode *i, squashfs_inode_t inode)
+{
+	struct super_block *s = i->i_sb;
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	long long block = SQUASHFS_INODE_BLK(inode) + sblk->inode_table_start;
+	unsigned int offset = SQUASHFS_INODE_OFFSET(inode);
+	long long next_block;
+	unsigned int next_offset;
+	union squashfs_inode_header id, sid;
+	struct squashfs_base_inode_header *inodeb = &id.base, *sinodeb = &sid.base;
+
+	TRACE("Entered squashfs_read_inode\n");
 
-	type = le16_to_cpu(sqshb_ino->inode_type);
-	switch (type) {
-	case SQUASHFS_REG_TYPE: {
-		unsigned int frag_offset, frag;
-		int frag_size;
-		u64 frag_blk;
-		struct squashfs_reg_inode *sqsh_ino = &squashfs_ino.reg;
-
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-							sizeof(*sqsh_ino));
-		if (err < 0)
+	if (msblk->swap) {
+		if (!squashfs_get_cached_block(s, sinodeb, block, offset,
+					sizeof(*sinodeb), &next_block, &next_offset))
+			goto failed_read;
+		SQUASHFS_SWAP_BASE_INODE_HEADER(inodeb, sinodeb, sizeof(*sinodeb));
+	} else
+		if (!squashfs_get_cached_block(s, inodeb, block, offset,
+					sizeof(*inodeb), &next_block, &next_offset))
 			goto failed_read;
 
-		frag = le32_to_cpu(sqsh_ino->fragment);
-		if (frag != SQUASHFS_INVALID_FRAG) {
-			frag_offset = le32_to_cpu(sqsh_ino->offset);
-			frag_size = squashfs_frag_lookup(sb, frag, &frag_blk);
-			if (frag_size < 0) {
-				err = frag_size;
-				goto failed_read;
-			}
-		} else {
+	squashfs_new_inode(msblk, i, inodeb);
+
+	switch(inodeb->inode_type) {
+		case SQUASHFS_FILE_TYPE: {
+			unsigned int frag_size;
+			long long frag_blk;
+			struct squashfs_reg_inode_header *inodep = &id.reg;
+			struct squashfs_reg_inode_header *sinodep = &sid.reg;
+				
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_REG_INODE_HEADER(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
 			frag_blk = SQUASHFS_INVALID_BLK;
-			frag_size = 0;
-			frag_offset = 0;
+
+			if (inodep->fragment != SQUASHFS_INVALID_FRAG)
+					if(!get_fragment_location(s, inodep->fragment, &frag_blk,
+												&frag_size))
+						goto failed_read;
+				
+			i->i_nlink = 1;
+			i->i_size = inodep->file_size;
+			i->i_fop = &generic_ro_fops;
+			i->i_mode |= S_IFREG;
+			i->i_blocks = ((i->i_size - 1) >> 9) + 1;
+			SQUASHFS_I(i)->u.s1.fragment_start_block = frag_blk;
+			SQUASHFS_I(i)->u.s1.fragment_size = frag_size;
+			SQUASHFS_I(i)->u.s1.fragment_offset = inodep->offset;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->u.s1.block_list_start = next_block;
+			SQUASHFS_I(i)->offset = next_offset;
+			i->i_data.a_ops = &squashfs_aops;
+
+			TRACE("File inode %x:%x, start_block %llx, "
+					"block_list_start %llx, offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->start_block, next_block,
+					next_offset);
+			break;
+		}
+		case SQUASHFS_LREG_TYPE: {
+			unsigned int frag_size;
+			long long frag_blk;
+			struct squashfs_lreg_inode_header *inodep = &id.lreg;
+			struct squashfs_lreg_inode_header *sinodep = &sid.lreg;
+				
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_LREG_INODE_HEADER(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			frag_blk = SQUASHFS_INVALID_BLK;
+
+			if (inodep->fragment != SQUASHFS_INVALID_FRAG)
+				if (!get_fragment_location(s, inodep->fragment, &frag_blk,
+												 &frag_size))
+					goto failed_read;
+				
+			i->i_nlink = inodep->nlink;
+			i->i_size = inodep->file_size;
+			i->i_fop = &generic_ro_fops;
+			i->i_mode |= S_IFREG;
+			i->i_blocks = ((i->i_size - 1) >> 9) + 1;
+			SQUASHFS_I(i)->u.s1.fragment_start_block = frag_blk;
+			SQUASHFS_I(i)->u.s1.fragment_size = frag_size;
+			SQUASHFS_I(i)->u.s1.fragment_offset = inodep->offset;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->u.s1.block_list_start = next_block;
+			SQUASHFS_I(i)->offset = next_offset;
+			i->i_data.a_ops = &squashfs_aops;
+
+			TRACE("File inode %x:%x, start_block %llx, "
+					"block_list_start %llx, offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->start_block, next_block,
+					next_offset);
+			break;
+		}
+		case SQUASHFS_DIR_TYPE: {
+			struct squashfs_dir_inode_header *inodep = &id.dir;
+			struct squashfs_dir_inode_header *sinodep = &sid.dir;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_DIR_INODE_HEADER(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			i->i_nlink = inodep->nlink;
+			i->i_size = inodep->file_size;
+			i->i_op = &squashfs_dir_inode_ops;
+			i->i_fop = &squashfs_dir_ops;
+			i->i_mode |= S_IFDIR;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->offset = inodep->offset;
+			SQUASHFS_I(i)->u.s2.directory_index_count = 0;
+			SQUASHFS_I(i)->u.s2.parent_inode = inodep->parent_inode;
+
+			TRACE("Directory inode %x:%x, start_block %x, offset "
+					"%x\n", SQUASHFS_INODE_BLK(inode),
+					offset, inodep->start_block,
+					inodep->offset);
+			break;
+		}
+		case SQUASHFS_LDIR_TYPE: {
+			struct squashfs_ldir_inode_header *inodep = &id.ldir;
+			struct squashfs_ldir_inode_header *sinodep = &sid.ldir;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_LDIR_INODE_HEADER(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			i->i_nlink = inodep->nlink;
+			i->i_size = inodep->file_size;
+			i->i_op = &squashfs_dir_inode_ops;
+			i->i_fop = &squashfs_dir_ops;
+			i->i_mode |= S_IFDIR;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->offset = inodep->offset;
+			SQUASHFS_I(i)->u.s2.directory_index_start = next_block;
+			SQUASHFS_I(i)->u.s2.directory_index_offset = next_offset;
+			SQUASHFS_I(i)->u.s2.directory_index_count = inodep->i_count;
+			SQUASHFS_I(i)->u.s2.parent_inode = inodep->parent_inode;
+
+			TRACE("Long directory inode %x:%x, start_block %x, offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->start_block, inodep->offset);
+			break;
+		}
+		case SQUASHFS_SYMLINK_TYPE: {
+			struct squashfs_symlink_inode_header *inodep = &id.symlink;
+			struct squashfs_symlink_inode_header *sinodep = &sid.symlink;
+	
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_SYMLINK_INODE_HEADER(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			i->i_nlink = inodep->nlink;
+			i->i_size = inodep->symlink_size;
+			i->i_op = &page_symlink_inode_operations;
+			i->i_data.a_ops = &squashfs_symlink_aops;
+			i->i_mode |= S_IFLNK;
+			SQUASHFS_I(i)->start_block = next_block;
+			SQUASHFS_I(i)->offset = next_offset;
+
+			TRACE("Symbolic link inode %x:%x, start_block %llx, offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					next_block, next_offset);
+			break;
+		 }
+		 case SQUASHFS_BLKDEV_TYPE:
+		 case SQUASHFS_CHRDEV_TYPE: {
+			struct squashfs_dev_inode_header *inodep = &id.dev;
+			struct squashfs_dev_inode_header *sinodep = &sid.dev;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_DEV_INODE_HEADER(inodep, sinodep);
+			} else	
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			i->i_nlink = inodep->nlink;
+			i->i_mode |= (inodeb->inode_type == SQUASHFS_CHRDEV_TYPE) ?
+					S_IFCHR : S_IFBLK;
+			init_special_inode(i, i->i_mode, old_decode_dev(inodep->rdev));
+
+			TRACE("Device inode %x:%x, rdev %x\n",
+					SQUASHFS_INODE_BLK(inode), offset, inodep->rdev);
+			break;
+		 }
+		 case SQUASHFS_FIFO_TYPE:
+		 case SQUASHFS_SOCKET_TYPE: {
+			struct squashfs_ipc_inode_header *inodep = &id.ipc;
+			struct squashfs_ipc_inode_header *sinodep = &sid.ipc;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, sinodep, block, offset,
+						sizeof(*sinodep), &next_block, &next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_IPC_INODE_HEADER(inodep, sinodep);
+			} else	
+				if (!squashfs_get_cached_block(s, inodep, block, offset,
+						sizeof(*inodep), &next_block, &next_offset))
+					goto failed_read;
+
+			i->i_nlink = inodep->nlink;
+			i->i_mode |= (inodeb->inode_type == SQUASHFS_FIFO_TYPE)
+							? S_IFIFO : S_IFSOCK;
+			init_special_inode(i, i->i_mode, 0);
+			break;
+		 }
+		 default:
+			ERROR("Unknown inode type %d in squashfs_iget!\n",
+					inodeb->inode_type);
+			goto failed_read1;
+	}
+	
+	return 1;
+
+failed_read:
+	ERROR("Unable to read inode [%llx:%x]\n", block, offset);
+
+failed_read1:
+	make_bad_inode(i);
+	return 0;
+}
+
+
+static int read_inode_lookup_table(struct super_block *s)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	unsigned int length = SQUASHFS_LOOKUP_BLOCK_BYTES(sblk->inodes);
+
+	TRACE("In read_inode_lookup_table, length %d\n", length);
+
+	/* Allocate inode lookup table */
+	msblk->inode_lookup_table = kmalloc(length, GFP_KERNEL);
+	if (msblk->inode_lookup_table == NULL) {
+		ERROR("Failed to allocate inode lookup table\n");
+		return 0;
+	}
+   
+	if (!squashfs_read_data(s, (char *) msblk->inode_lookup_table,
+			sblk->lookup_table_start, length |
+			SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, length)) {
+		ERROR("unable to read inode lookup table\n");
+		return 0;
+	}
+
+	if (msblk->swap) {
+		int i;
+		long long block;
+
+		for (i = 0; i < SQUASHFS_LOOKUP_BLOCKS(sblk->inodes); i++) {
+			/* XXX */
+			SQUASHFS_SWAP_LOOKUP_BLOCKS((&block),
+						&msblk->inode_lookup_table[i], 1);
+			msblk->inode_lookup_table[i] = block;
+		}
+	}
+
+	return 1;
+}
+
+
+static int read_fragment_index_table(struct super_block *s)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	unsigned int length = SQUASHFS_FRAGMENT_INDEX_BYTES(sblk->fragments);
+
+	if(length == 0)
+		return 1;
+
+	/* Allocate fragment index table */
+	msblk->fragment_index = kmalloc(length, GFP_KERNEL);
+	if (msblk->fragment_index == NULL) {
+		ERROR("Failed to allocate fragment index table\n");
+		return 0;
+	}
+   
+	if (!squashfs_read_data(s, (char *) msblk->fragment_index,
+			sblk->fragment_table_start, length |
+			SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, length)) {
+		ERROR("unable to read fragment index table\n");
+		return 0;
+	}
+
+	if (msblk->swap) {
+		int i;
+		long long fragment;
+
+		for (i = 0; i < SQUASHFS_FRAGMENT_INDEXES(sblk->fragments); i++) {
+			/* XXX */
+			SQUASHFS_SWAP_FRAGMENT_INDEXES((&fragment),
+						&msblk->fragment_index[i], 1);
+			msblk->fragment_index[i] = fragment;
+		}
+	}
+
+	return 1;
+}
+
+
+static int readahead_metadata(struct super_block *s)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	int i;
+
+	squashfs_cached_blks = SQUASHFS_CACHED_BLKS;
+
+	/* Init inode_table block pointer array */
+	msblk->block_cache = kmalloc(sizeof(struct squashfs_cache) *
+					squashfs_cached_blks, GFP_KERNEL);
+	if (msblk->block_cache == NULL) {
+		ERROR("Failed to allocate block cache\n");
+		goto failed;
+	}
+
+	for (i = 0; i < squashfs_cached_blks; i++)
+		msblk->block_cache[i].block = SQUASHFS_INVALID_BLK;
+
+	msblk->next_cache = 0;
+	msblk->unused_cache_blks = squashfs_cached_blks;
+
+	return 1;
+
+failed:
+	return 0;
+}
+
+
+static int supported_squashfs_filesystem(struct squashfs_sb_info *msblk, int silent)
+{
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	msblk->read_inode = squashfs_read_inode;
+	msblk->read_blocklist = read_blocklist;
+	msblk->read_fragment_index_table = read_fragment_index_table;
+
+	if (sblk->s_major == 1) {
+		if (!squashfs_1_0_supported(msblk)) {
+			SERROR("Major/Minor mismatch, Squashfs 1.0 filesystems "
+				"are unsupported\n");
+			SERROR("Please recompile with Squashfs 1.0 support enabled\n");
+			return 0;
 		}
+	} else if (sblk->s_major == 2) {
+		if (!squashfs_2_0_supported(msblk)) {
+			SERROR("Major/Minor mismatch, Squashfs 2.0 filesystems "
+				"are unsupported\n");
+			SERROR("Please recompile with Squashfs 2.0 support enabled\n");
+			return 0;
+		}
+	} else if(sblk->s_major != SQUASHFS_MAJOR || sblk->s_minor >
+			SQUASHFS_MINOR) {
+		SERROR("Major/Minor mismatch, trying to mount newer %d.%d "
+				"filesystem\n", sblk->s_major, sblk->s_minor);
+		SERROR("Please update your kernel\n");
+		return 0;
+	}
+
+	return 1;
+}
 
-		inode->i_nlink = 1;
-		inode->i_size = le32_to_cpu(sqsh_ino->file_size);
-		inode->i_fop = &generic_ro_fops;
-		inode->i_mode |= S_IFREG;
-		inode->i_blocks = ((inode->i_size - 1) >> 9) + 1;
-		squashfs_i(inode)->fragment_block = frag_blk;
-		squashfs_i(inode)->fragment_size = frag_size;
-		squashfs_i(inode)->fragment_offset = frag_offset;
-		squashfs_i(inode)->start = le32_to_cpu(sqsh_ino->start_block);
-		squashfs_i(inode)->block_list_start = block;
-		squashfs_i(inode)->offset = offset;
-		inode->i_data.a_ops = &squashfs_aops;
-
-		TRACE("File inode %x:%x, start_block %llx, block_list_start "
-			"%llx, offset %x\n", SQUASHFS_INODE_BLK(ino),
-			offset, squashfs_i(inode)->start, block, offset);
+
+static int squashfs_fill_super(struct super_block *s, void *data, int silent)
+{
+	struct squashfs_sb_info *msblk;
+	struct squashfs_super_block *sblk;
+	int i, err;
+	char b[BDEVNAME_SIZE];
+	struct inode *root;
+
+	TRACE("Entered squashfs_fill_superblock\n");
+
+	err = -ENOMEM;
+	s->s_fs_info = kzalloc(sizeof(struct squashfs_sb_info), GFP_KERNEL);
+	if (s->s_fs_info == NULL) {
+		ERROR("Failed to allocate superblock\n");
+		goto failure;
+	}
+	msblk = s->s_fs_info;
+
+	sblk = &msblk->sblk;
+	
+	msblk->devblksize = sb_min_blocksize(s, BLOCK_SIZE);
+	msblk->devblksize_log2 = ffz(~msblk->devblksize);
+
+	/* mutex_init(&msblk->read_data_mutex); */
+	mutex_init(&msblk->read_page_mutex);
+	mutex_init(&msblk->block_cache_mutex);
+	mutex_init(&msblk->fragment_mutex);
+	mutex_init(&msblk->meta_index_mutex);
+	
+	init_waitqueue_head(&msblk->waitq);
+	init_waitqueue_head(&msblk->fragment_wait_queue);
+
+	/* sblk->bytes_used is checked in squashfs_read_data to ensure reads are not
+ 	 * beyond filesystem end.  As we're using squashfs_read_data to read sblk here,
+ 	 * first set sblk->bytes_used to a useful value */
+	err = -EINVAL;
+	sblk->bytes_used = sizeof(struct squashfs_super_block);
+	if (!squashfs_read_data(s, (char *) sblk, SQUASHFS_START,
+					sizeof(struct squashfs_super_block) |
+					SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, sizeof(struct squashfs_super_block))) {
+		SERROR("unable to read superblock\n");
+		goto failed_mount;
+	}
+
+	/* Check it is a SQUASHFS superblock */
+	s->s_magic = sblk->s_magic;
+	msblk->swap = 0;
+	dpri("magic 0x%x\n", sblk->s_magic);
+	switch (sblk->s_magic) {
+		struct squashfs_super_block ssblk;
+
+	case SQUASHFS_MAGIC_SWAP:
+		/*FALLTHROUGH*/
+	case SQUASHFS_MAGIC_LZMA_SWAP:
+		WARNING("Mounting a different endian SQUASHFS "
+			"filesystem on %s\n", bdevname(s->s_bdev, b));
+
+		SQUASHFS_SWAP_SUPER_BLOCK(&ssblk, sblk);
+		memcpy(sblk, &ssblk, sizeof(struct squashfs_super_block));
+		msblk->swap = 1;
+		/*FALLTHROUGH*/
+	case SQUASHFS_MAGIC:
+	case SQUASHFS_MAGIC_LZMA:
 		break;
+	default:
+		SERROR("Can't find a SQUASHFS superblock on %s\n",
+		       bdevname(s->s_bdev, b));
+		goto failed_mount;
 	}
-	case SQUASHFS_LREG_TYPE: {
-		unsigned int frag_offset, frag;
-		int frag_size;
-		u64 frag_blk;
-		struct squashfs_lreg_inode *sqsh_ino = &squashfs_ino.lreg;
-
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-							sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
 
-		frag = le32_to_cpu(sqsh_ino->fragment);
-		if (frag != SQUASHFS_INVALID_FRAG) {
-			frag_offset = le32_to_cpu(sqsh_ino->offset);
-			frag_size = squashfs_frag_lookup(sb, frag, &frag_blk);
-			if (frag_size < 0) {
-				err = frag_size;
-				goto failed_read;
+	{
+		struct sqlzma *p;
+		dpri("block_size %d, devblksize %d\n",
+		     sblk->block_size, msblk->devblksize);
+		BUG_ON(sblk->block_size > sizeof(p->read_data));
+	}
+
+	/* Check the MAJOR & MINOR versions */
+	if(!supported_squashfs_filesystem(msblk, silent))
+		goto failed_mount;
+
+	/* Check the filesystem does not extend beyond the end of the
+	   block device */
+	if(sblk->bytes_used < 0 || sblk->bytes_used > i_size_read(s->s_bdev->bd_inode))
+		goto failed_mount;
+
+	/* Check the root inode for sanity */
+	if (SQUASHFS_INODE_OFFSET(sblk->root_inode) > SQUASHFS_METADATA_SIZE)
+		goto failed_mount;
+
+	TRACE("Found valid superblock on %s\n", bdevname(s->s_bdev, b));
+	TRACE("Inodes are %scompressed\n", SQUASHFS_UNCOMPRESSED_INODES(sblk->flags)
+					? "un" : "");
+	TRACE("Data is %scompressed\n", SQUASHFS_UNCOMPRESSED_DATA(sblk->flags)
+					? "un" : "");
+	TRACE("Check data is %spresent in the filesystem\n",
+					SQUASHFS_CHECK_DATA(sblk->flags) ?  "" : "not ");
+	TRACE("Filesystem size %lld bytes\n", sblk->bytes_used);
+	TRACE("Block size %d\n", sblk->block_size);
+	TRACE("Number of inodes %d\n", sblk->inodes);
+	if (sblk->s_major > 1)
+		TRACE("Number of fragments %d\n", sblk->fragments);
+	TRACE("Number of uids %d\n", sblk->no_uids);
+	TRACE("Number of gids %d\n", sblk->no_guids);
+	TRACE("sblk->inode_table_start %llx\n", sblk->inode_table_start);
+	TRACE("sblk->directory_table_start %llx\n", sblk->directory_table_start);
+	if (sblk->s_major > 1)
+		TRACE("sblk->fragment_table_start %llx\n", sblk->fragment_table_start);
+	TRACE("sblk->uid_start %llx\n", sblk->uid_start);
+
+	s->s_maxbytes = MAX_LFS_FILESIZE;
+	s->s_flags |= MS_RDONLY;
+	s->s_op = &squashfs_super_ops;
+
+	if (readahead_metadata(s) == 0)
+		goto failed_mount;
+
+	/* Allocate read_page block */
+	err = -ENOMEM;
+	msblk->read_page = vmalloc(sblk->block_size);
+	if (msblk->read_page == NULL) {
+		ERROR("Failed to allocate read_page block\n");
+		goto failed_mount;
+	}
+
+	/* Allocate uid and gid tables */
+	msblk->uid = kmalloc((sblk->no_uids + sblk->no_guids) *
+					sizeof(unsigned int), GFP_KERNEL);
+	if (msblk->uid == NULL) {
+		ERROR("Failed to allocate uid/gid table\n");
+		goto failed_mount;
+	}
+	msblk->guid = msblk->uid + sblk->no_uids;
+   
+	dpri("swap %d\n", msblk->swap);
+	err = -EINVAL;
+	if (msblk->swap) {
+		unsigned int *suid;
+
+		err = -ENOMEM;
+		suid = kmalloc(sizeof(*suid) * (sblk->no_uids + sblk->no_guids),
+			       GFP_KERNEL);
+		if (unlikely(!suid))
+			goto failed_mount;
+
+		err = -EINVAL;
+		if (!squashfs_read_data(s, (char *) &suid, sblk->uid_start,
+					((sblk->no_uids + sblk->no_guids) *
+					 sizeof(unsigned int)) |
+					SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, (sblk->no_uids + sblk->no_guids) * sizeof(unsigned int))) {
+			ERROR("unable to read uid/gid table\n");
+			kfree(suid);
+			goto failed_mount;
+		}
+
+		SQUASHFS_SWAP_DATA(msblk->uid, suid, (sblk->no_uids +
+			sblk->no_guids), (sizeof(unsigned int) * 8));
+		kfree(suid);
+	} else
+		if (!squashfs_read_data(s, (char *) msblk->uid, sblk->uid_start,
+					((sblk->no_uids + sblk->no_guids) *
+					 sizeof(unsigned int)) |
+					SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, (sblk->no_uids + sblk->no_guids) * sizeof(unsigned int))) {
+			ERROR("unable to read uid/gid table\n");
+			goto failed_mount;
+		}
+
+
+	if (sblk->s_major == 1 && squashfs_1_0_supported(msblk))
+		goto allocate_root;
+
+	err = -ENOMEM;
+	msblk->fragment = kzalloc(sizeof(struct squashfs_fragment_cache) *
+				SQUASHFS_CACHED_FRAGMENTS, GFP_KERNEL);
+	if (msblk->fragment == NULL) {
+		ERROR("Failed to allocate fragment block cache\n");
+		goto failed_mount;
+	}
+
+	for (i = 0; i < SQUASHFS_CACHED_FRAGMENTS; i++) {
+		msblk->fragment[i].block = SQUASHFS_INVALID_BLK;
+	}
+
+	msblk->next_fragment = 0;
+	msblk->unused_frag_blks = SQUASHFS_CACHED_FRAGMENTS;
+
+	/* Allocate and read fragment index table */
+	if (msblk->read_fragment_index_table(s) == 0)
+		goto failed_mount;
+
+	if(sblk->s_major < 3 || sblk->lookup_table_start == SQUASHFS_INVALID_BLK)
+		goto allocate_root;
+
+	/* Allocate and read inode lookup table */
+	if (read_inode_lookup_table(s) == 0)
+		goto failed_mount;
+
+	s->s_export_op = &squashfs_export_ops;
+
+allocate_root:
+	dpri("alloate_root\n");
+	root = new_inode(s);
+	if ((msblk->read_inode)(root, sblk->root_inode) == 0) {
+		iput(root);
+		goto failed_mount;
+	}
+	insert_inode_hash(root);
+
+	s->s_root = d_alloc_root(root);
+	if (s->s_root == NULL) {
+		ERROR("Root inode create failed\n");
+		iput(root);
+		goto failed_mount;
+	}
+
+	TRACE("Leaving squashfs_fill_super\n");
+	return 0;
+
+failed_mount:
+	kfree(msblk->inode_lookup_table);
+	kfree(msblk->fragment_index);
+	kfree(msblk->fragment);
+	kfree(msblk->uid);
+	vfree(msblk->read_page);
+	kfree(msblk->block_cache);
+	kfree(msblk->fragment_index_2);
+	kfree(s->s_fs_info);
+	s->s_fs_info = NULL;
+ failure:
+	return err;
+}
+
+
+static int squashfs_statfs(struct dentry *dentry, struct kstatfs *buf)
+{
+	struct squashfs_sb_info *msblk = dentry->d_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	TRACE("Entered squashfs_statfs\n");
+
+	buf->f_type = sblk->s_magic;
+	buf->f_bsize = sblk->block_size;
+	buf->f_blocks = ((sblk->bytes_used - 1) >> sblk->block_log) + 1;
+	buf->f_bfree = buf->f_bavail = 0;
+	buf->f_files = sblk->inodes;
+	buf->f_ffree = 0;
+	buf->f_namelen = SQUASHFS_NAME_LEN;
+
+	return 0;
+}
+
+
+static int squashfs_symlink_readpage(struct file *file, struct page *page)
+{
+	struct inode *inode = page->mapping->host;
+	int index = page->index << PAGE_CACHE_SHIFT, length, bytes, avail_bytes;
+	long long block = SQUASHFS_I(inode)->start_block;
+	int offset = SQUASHFS_I(inode)->offset;
+	void *pageaddr = kmap(page);
+
+	TRACE("Entered squashfs_symlink_readpage, page index %ld, start block "
+				"%llx, offset %x\n", page->index,
+				SQUASHFS_I(inode)->start_block,
+				SQUASHFS_I(inode)->offset);
+
+	for (length = 0; length < index; length += bytes) {
+		bytes = squashfs_get_cached_block(inode->i_sb, NULL, block,
+				offset, PAGE_CACHE_SIZE, &block, &offset);
+		if (bytes == 0) {
+			ERROR("Unable to read symbolic link [%llx:%x]\n", block, offset);
+			goto skip_read;
+		}
+	}
+
+	if (length != index) {
+		ERROR("(squashfs_symlink_readpage) length != index\n");
+		bytes = 0;
+		goto skip_read;
+	}
+
+	avail_bytes = min_t(int, i_size_read(inode) - length, PAGE_CACHE_SIZE);
+
+	bytes = squashfs_get_cached_block(inode->i_sb, pageaddr, block, offset,
+		avail_bytes, &block, &offset);
+	if (bytes == 0)
+		ERROR("Unable to read symbolic link [%llx:%x]\n", block, offset);
+
+skip_read:
+	memset(pageaddr + bytes, 0, PAGE_CACHE_SIZE - bytes);
+	kunmap(page);
+	flush_dcache_page(page);
+	SetPageUptodate(page);
+	unlock_page(page);
+
+	return 0;
+}
+
+
+struct meta_index *locate_meta_index(struct inode *inode, int index, int offset)
+{
+	struct meta_index *meta = NULL;
+	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
+	int i;
+
+	mutex_lock(&msblk->meta_index_mutex);
+
+	TRACE("locate_meta_index: index %d, offset %d\n", index, offset);
+
+	if (msblk->meta_index == NULL)
+		goto not_allocated;
+
+	for (i = 0; i < SQUASHFS_META_NUMBER; i ++) {
+		if (msblk->meta_index[i].inode_number == inode->i_ino &&
+				msblk->meta_index[i].offset >= offset &&
+				msblk->meta_index[i].offset <= index &&
+				msblk->meta_index[i].locked == 0) {
+			TRACE("locate_meta_index: entry %d, offset %d\n", i,
+					msblk->meta_index[i].offset);
+			meta = &msblk->meta_index[i];
+			offset = meta->offset;
+		}
+	}
+
+	if (meta)
+		meta->locked = 1;
+
+not_allocated:
+	mutex_unlock(&msblk->meta_index_mutex);
+
+	return meta;
+}
+
+
+struct meta_index *empty_meta_index(struct inode *inode, int offset, int skip)
+{
+	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
+	struct meta_index *meta = NULL;
+	int i;
+
+	mutex_lock(&msblk->meta_index_mutex);
+
+	TRACE("empty_meta_index: offset %d, skip %d\n", offset, skip);
+
+	if (msblk->meta_index == NULL) {
+		msblk->meta_index = kmalloc(sizeof(struct meta_index) *
+					SQUASHFS_META_NUMBER, GFP_KERNEL);
+		if (msblk->meta_index == NULL) {
+			ERROR("Failed to allocate meta_index\n");
+			goto failed;
+		}
+		for (i = 0; i < SQUASHFS_META_NUMBER; i++) {
+			msblk->meta_index[i].inode_number = 0;
+			msblk->meta_index[i].locked = 0;
+		}
+		msblk->next_meta_index = 0;
+	}
+
+	for (i = SQUASHFS_META_NUMBER; i &&
+			msblk->meta_index[msblk->next_meta_index].locked; i --)
+		msblk->next_meta_index = (msblk->next_meta_index + 1) %
+			SQUASHFS_META_NUMBER;
+
+	if (i == 0) {
+		TRACE("empty_meta_index: failed!\n");
+		goto failed;
+	}
+
+	TRACE("empty_meta_index: returned meta entry %d, %p\n",
+			msblk->next_meta_index,
+			&msblk->meta_index[msblk->next_meta_index]);
+
+	meta = &msblk->meta_index[msblk->next_meta_index];
+	msblk->next_meta_index = (msblk->next_meta_index + 1) %
+			SQUASHFS_META_NUMBER;
+
+	meta->inode_number = inode->i_ino;
+	meta->offset = offset;
+	meta->skip = skip;
+	meta->entries = 0;
+	meta->locked = 1;
+
+failed:
+	mutex_unlock(&msblk->meta_index_mutex);
+	return meta;
+}
+
+
+void release_meta_index(struct inode *inode, struct meta_index *meta)
+{
+	meta->locked = 0;
+	smp_mb();
+}
+
+
+static int read_block_index(struct super_block *s, int blocks, char *block_list,
+				long long *start_block, int *offset)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	unsigned int *block_listp;
+	int block = 0;
+	
+	if (msblk->swap) {
+		char *sblock_list;
+
+		sblock_list = kmalloc(blocks << 2, GFP_KERNEL);
+		if (unlikely(!sblock_list))
+			goto failure;
+
+		if (!squashfs_get_cached_block(s, sblock_list, *start_block,
+				*offset, blocks << 2, start_block, offset)) {
+			ERROR("Fail reading block list [%llx:%x]\n", *start_block, *offset);
+			kfree(sblock_list);
+			goto failure;
+		}
+		SQUASHFS_SWAP_INTS(((unsigned int *)block_list),
+				((unsigned int *)sblock_list), blocks);
+		kfree(sblock_list);
+	} else {
+		if (!squashfs_get_cached_block(s, block_list, *start_block,
+				*offset, blocks << 2, start_block, offset)) {
+			ERROR("Fail reading block list [%llx:%x]\n", *start_block, *offset);
+			goto failure;
+		}
+	}
+
+	for (block_listp = (unsigned int *) block_list; blocks;
+				block_listp++, blocks --)
+		block += SQUASHFS_COMPRESSED_SIZE_BLOCK(*block_listp);
+
+	return block;
+
+failure:
+	return -1;
+}
+
+
+#define SIZE 256
+
+static inline int calculate_skip(int blocks) {
+	int skip = (blocks - 1) / ((SQUASHFS_SLOTS * SQUASHFS_META_ENTRIES + 1) * SQUASHFS_META_INDEXES);
+	return skip >= 7 ? 7 : skip + 1;
+}
+
+
+static int get_meta_index(struct inode *inode, int index,
+		long long *index_block, int *index_offset,
+		long long *data_block, char *block_list)
+{
+	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	int skip = calculate_skip(i_size_read(inode) >> sblk->block_log);
+	int offset = 0;
+	struct meta_index *meta;
+	struct meta_entry *meta_entry;
+	long long cur_index_block = SQUASHFS_I(inode)->u.s1.block_list_start;
+	int cur_offset = SQUASHFS_I(inode)->offset;
+	long long cur_data_block = SQUASHFS_I(inode)->start_block;
+	int i;
+ 
+	index /= SQUASHFS_META_INDEXES * skip;
+
+	while (offset < index) {
+		meta = locate_meta_index(inode, index, offset + 1);
+
+		if (meta == NULL) {
+			meta = empty_meta_index(inode, offset + 1, skip);
+			if (meta == NULL)
+				goto all_done;
+		} else {
+			if(meta->entries == 0)
+				goto failed;
+			/* XXX */
+			offset = index < meta->offset + meta->entries ? index :
+				meta->offset + meta->entries - 1;
+			/* XXX */
+			meta_entry = &meta->meta_entry[offset - meta->offset];
+			cur_index_block = meta_entry->index_block + sblk->inode_table_start;
+			cur_offset = meta_entry->offset;
+			cur_data_block = meta_entry->data_block;
+			TRACE("get_meta_index: offset %d, meta->offset %d, "
+				"meta->entries %d\n", offset, meta->offset, meta->entries);
+			TRACE("get_meta_index: index_block 0x%llx, offset 0x%x"
+				" data_block 0x%llx\n", cur_index_block,
+				cur_offset, cur_data_block);
+		}
+
+		for (i = meta->offset + meta->entries; i <= index &&
+				i < meta->offset + SQUASHFS_META_ENTRIES; i++) {
+			int blocks = skip * SQUASHFS_META_INDEXES;
+
+			while (blocks) {
+				int block = blocks > (SIZE >> 2) ? (SIZE >> 2) : blocks;
+				int res = read_block_index(inode->i_sb, block, block_list,
+					&cur_index_block, &cur_offset);
+
+				if (res == -1)
+					goto failed;
+
+				cur_data_block += res;
+				blocks -= block;
 			}
+
+			meta_entry = &meta->meta_entry[i - meta->offset];
+			meta_entry->index_block = cur_index_block - sblk->inode_table_start;
+			meta_entry->offset = cur_offset;
+			meta_entry->data_block = cur_data_block;
+			meta->entries ++;
+			offset ++;
+		}
+
+		TRACE("get_meta_index: meta->offset %d, meta->entries %d\n",
+				meta->offset, meta->entries);
+
+		release_meta_index(inode, meta);
+	}
+
+all_done:
+	*index_block = cur_index_block;
+	*index_offset = cur_offset;
+	*data_block = cur_data_block;
+
+	return offset * SQUASHFS_META_INDEXES * skip;
+
+failed:
+	release_meta_index(inode, meta);
+	return -1;
+}
+
+
+static long long read_blocklist(struct inode *inode, int index,
+				int readahead_blks, char *block_list,
+				unsigned short **block_p, unsigned int *bsize)
+{
+	long long block_ptr;
+	int offset;
+	long long block;
+	int res = get_meta_index(inode, index, &block_ptr, &offset, &block,
+		block_list);
+
+	TRACE("read_blocklist: res %d, index %d, block_ptr 0x%llx, offset"
+		       " 0x%x, block 0x%llx\n", res, index, block_ptr, offset, block);
+
+	if(res == -1)
+		goto failure;
+
+	index -= res;
+
+	while (index) {
+		int blocks = index > (SIZE >> 2) ? (SIZE >> 2) : index;
+		int res = read_block_index(inode->i_sb, blocks, block_list,
+			&block_ptr, &offset);
+		if (res == -1)
+			goto failure;
+		block += res;
+		index -= blocks;
+	}
+
+	if (read_block_index(inode->i_sb, 1, block_list, &block_ptr, &offset) == -1)
+		goto failure;
+	*bsize = *((unsigned int *) block_list);
+
+	return block;
+
+failure:
+	return 0;
+}
+
+
+static int squashfs_readpage(struct file *file, struct page *page)
+{
+	struct inode *inode = page->mapping->host;
+	struct squashfs_sb_info *msblk = inode->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	unsigned char *block_list = NULL;
+	long long block;
+	unsigned int bsize, i;
+	int bytes;
+	int index = page->index >> (sblk->block_log - PAGE_CACHE_SHIFT);
+ 	void *pageaddr;
+	struct squashfs_fragment_cache *fragment = NULL;
+	char *data_ptr = msblk->read_page;
+	
+	int mask = (1 << (sblk->block_log - PAGE_CACHE_SHIFT)) - 1;
+	int start_index = page->index & ~mask;
+	int end_index = start_index | mask;
+	int file_end = i_size_read(inode) >> sblk->block_log;
+	int sparse = 0;
+
+	TRACE("Entered squashfs_readpage, page index %lx, start block %llx\n",
+					page->index, SQUASHFS_I(inode)->start_block);
+
+	if (page->index >= ((i_size_read(inode) + PAGE_CACHE_SIZE - 1) >>
+					PAGE_CACHE_SHIFT))
+		goto out;
+
+	if (SQUASHFS_I(inode)->u.s1.fragment_start_block == SQUASHFS_INVALID_BLK
+					|| index < file_end) {
+		block_list = kmalloc(SIZE, GFP_KERNEL);
+		if (block_list == NULL) {
+			ERROR("Failed to allocate block_list\n");
+			goto error_out;
+		}
+
+		block = (msblk->read_blocklist)(inode, index, 1, block_list, NULL, &bsize);
+		if (block == 0)
+			goto error_out;
+
+		if (bsize == 0) { /* hole */
+			bytes = index == file_end ?
+				(i_size_read(inode) & (sblk->block_size - 1)) : sblk->block_size;
+			sparse = 1;
 		} else {
-			frag_blk = SQUASHFS_INVALID_BLK;
-			frag_size = 0;
-			frag_offset = 0;
+			mutex_lock(&msblk->read_page_mutex);
+		
+			bytes = squashfs_read_data(inode->i_sb, msblk->read_page, block,
+				bsize, NULL, sblk->block_size);
+
+			if (bytes == 0) {
+				ERROR("Unable to read page, block %llx, size %x\n", block, bsize);
+				mutex_unlock(&msblk->read_page_mutex);
+				goto error_out;
+			}
+		}
+	} else {
+		fragment = get_cached_fragment(inode->i_sb,
+					SQUASHFS_I(inode)-> u.s1.fragment_start_block,
+					SQUASHFS_I(inode)->u.s1.fragment_size);
+
+		if (fragment == NULL) {
+			ERROR("Unable to read page, block %llx, size %x\n",
+					SQUASHFS_I(inode)->u.s1.fragment_start_block,
+					(int) SQUASHFS_I(inode)->u.s1.fragment_size);
+			goto error_out;
 		}
+		bytes = i_size_read(inode) & (sblk->block_size - 1);
+		data_ptr = fragment->data + SQUASHFS_I(inode)->u.s1.fragment_offset;
+	}
 
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		inode->i_size = le64_to_cpu(sqsh_ino->file_size);
-		inode->i_fop = &generic_ro_fops;
-		inode->i_mode |= S_IFREG;
-		inode->i_blocks = ((inode->i_size -
-				le64_to_cpu(sqsh_ino->sparse) - 1) >> 9) + 1;
-
-		squashfs_i(inode)->fragment_block = frag_blk;
-		squashfs_i(inode)->fragment_size = frag_size;
-		squashfs_i(inode)->fragment_offset = frag_offset;
-		squashfs_i(inode)->start = le64_to_cpu(sqsh_ino->start_block);
-		squashfs_i(inode)->block_list_start = block;
-		squashfs_i(inode)->offset = offset;
-		inode->i_data.a_ops = &squashfs_aops;
-
-		TRACE("File inode %x:%x, start_block %llx, block_list_start "
-			"%llx, offset %x\n", SQUASHFS_INODE_BLK(ino),
-			offset, squashfs_i(inode)->start, block, offset);
-		break;
+	for (i = start_index; i <= end_index && bytes > 0; i++,
+						bytes -= PAGE_CACHE_SIZE, data_ptr += PAGE_CACHE_SIZE) {
+		struct page *push_page;
+		int avail = sparse ? 0 : min_t(unsigned int, bytes, PAGE_CACHE_SIZE);
+
+		TRACE("bytes %d, i %d, available_bytes %d\n", bytes, i, avail);
+
+		push_page = (i == page->index) ? page :
+			grab_cache_page_nowait(page->mapping, i);
+
+		if (!push_page)
+			continue;
+
+		if (PageUptodate(push_page))
+			goto skip_page;
+
+ 		pageaddr = kmap_atomic(push_page, KM_USER0);
+		memcpy(pageaddr, data_ptr, avail);
+		memset(pageaddr + avail, 0, PAGE_CACHE_SIZE - avail);
+		kunmap_atomic(pageaddr, KM_USER0);
+		flush_dcache_page(push_page);
+		SetPageUptodate(push_page);
+skip_page:
+		unlock_page(push_page);
+		if(i != page->index)
+			page_cache_release(push_page);
 	}
-	case SQUASHFS_DIR_TYPE: {
-		struct squashfs_dir_inode *sqsh_ino = &squashfs_ino.dir;
 
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-				sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
+	if (SQUASHFS_I(inode)->u.s1.fragment_start_block == SQUASHFS_INVALID_BLK
+					|| index < file_end) {
+		if (!sparse)
+			mutex_unlock(&msblk->read_page_mutex);
+		kfree(block_list);
+	} else
+		release_cached_fragment(msblk, fragment);
 
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		inode->i_size = le16_to_cpu(sqsh_ino->file_size);
-		inode->i_op = &squashfs_dir_inode_ops;
-		inode->i_fop = &squashfs_dir_ops;
-		inode->i_mode |= S_IFDIR;
-		squashfs_i(inode)->start = le32_to_cpu(sqsh_ino->start_block);
-		squashfs_i(inode)->offset = le16_to_cpu(sqsh_ino->offset);
-		squashfs_i(inode)->dir_idx_cnt = 0;
-		squashfs_i(inode)->parent = le32_to_cpu(sqsh_ino->parent_inode);
-
-		TRACE("Directory inode %x:%x, start_block %llx, offset %x\n",
-				SQUASHFS_INODE_BLK(ino), offset,
-				squashfs_i(inode)->start,
-				le16_to_cpu(sqsh_ino->offset));
-		break;
+	return 0;
+
+error_out:
+	SetPageError(page);
+out:
+	pageaddr = kmap_atomic(page, KM_USER0);
+	memset(pageaddr, 0, PAGE_CACHE_SIZE);
+	kunmap_atomic(pageaddr, KM_USER0);
+	flush_dcache_page(page);
+	if (!PageError(page))
+		SetPageUptodate(page);
+	unlock_page(page);
+
+	kfree(block_list);
+	return 0;
+}
+
+
+static int get_dir_index_using_offset(struct super_block *s,
+				long long *next_block, unsigned int *next_offset,
+				long long index_start, unsigned int index_offset, int i_count,
+				long long f_pos)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	int i, length = 0;
+	struct squashfs_dir_index index;
+
+	TRACE("Entered get_dir_index_using_offset, i_count %d, f_pos %d\n",
+					i_count, (unsigned int) f_pos);
+
+	f_pos =- 3;
+	if (f_pos == 0)
+		goto finish;
+
+	for (i = 0; i < i_count; i++) {
+		if (msblk->swap) {
+			struct squashfs_dir_index sindex;
+			squashfs_get_cached_block(s, &sindex, index_start, index_offset,
+					sizeof(sindex), &index_start, &index_offset);
+			SQUASHFS_SWAP_DIR_INDEX(&index, &sindex);
+		} else
+			squashfs_get_cached_block(s, &index, index_start, index_offset,
+					sizeof(index), &index_start, &index_offset);
+
+		if (index.index > f_pos)
+			break;
+
+		squashfs_get_cached_block(s, NULL, index_start, index_offset,
+					index.size + 1, &index_start, &index_offset);
+
+		length = index.index;
+		*next_block = index.start_block + sblk->directory_table_start;
 	}
-	case SQUASHFS_LDIR_TYPE: {
-		struct squashfs_ldir_inode *sqsh_ino = &squashfs_ino.ldir;
 
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-				sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
+	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
 
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		inode->i_size = le32_to_cpu(sqsh_ino->file_size);
-		inode->i_op = &squashfs_dir_inode_ops;
-		inode->i_fop = &squashfs_dir_ops;
-		inode->i_mode |= S_IFDIR;
-		squashfs_i(inode)->start = le32_to_cpu(sqsh_ino->start_block);
-		squashfs_i(inode)->offset = le16_to_cpu(sqsh_ino->offset);
-		squashfs_i(inode)->dir_idx_start = block;
-		squashfs_i(inode)->dir_idx_offset = offset;
-		squashfs_i(inode)->dir_idx_cnt = le16_to_cpu(sqsh_ino->i_count);
-		squashfs_i(inode)->parent = le32_to_cpu(sqsh_ino->parent_inode);
-
-		TRACE("Long directory inode %x:%x, start_block %llx, offset "
-				"%x\n", SQUASHFS_INODE_BLK(ino), offset,
-				squashfs_i(inode)->start,
-				le16_to_cpu(sqsh_ino->offset));
-		break;
+finish:
+	return length + 3;
+}
+
+
+static int get_dir_index_using_name(struct super_block *s,
+				long long *next_block, unsigned int *next_offset,
+				long long index_start, unsigned int index_offset, int i_count,
+				const char *name, int size)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	int i, length = 0;
+	struct squashfs_dir_index *index;
+	char *str;
+
+	TRACE("Entered get_dir_index_using_name, i_count %d\n", i_count);
+
+	str = kmalloc(sizeof(struct squashfs_dir_index) +
+		(SQUASHFS_NAME_LEN + 1) * 2, GFP_KERNEL);
+	if (str == NULL) {
+		ERROR("Failed to allocate squashfs_dir_index\n");
+		goto failure;
 	}
-	case SQUASHFS_SYMLINK_TYPE:
-	case SQUASHFS_LSYMLINK_TYPE: {
-		struct squashfs_symlink_inode *sqsh_ino = &squashfs_ino.symlink;
-
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-				sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
 
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		inode->i_size = le32_to_cpu(sqsh_ino->symlink_size);
-		inode->i_op = &page_symlink_inode_operations;
-		inode->i_data.a_ops = &squashfs_symlink_aops;
-		inode->i_mode |= S_IFLNK;
-		squashfs_i(inode)->start = block;
-		squashfs_i(inode)->offset = offset;
-
-		TRACE("Symbolic link inode %x:%x, start_block %llx, offset "
-				"%x\n", SQUASHFS_INODE_BLK(ino), offset,
-				block, offset);
-		break;
+	index = (struct squashfs_dir_index *) (str + SQUASHFS_NAME_LEN + 1);
+	strncpy(str, name, size);
+	str[size] = '\0';
+
+	for (i = 0; i < i_count; i++) {
+		if (msblk->swap) {
+			struct squashfs_dir_index sindex;
+			squashfs_get_cached_block(s, &sindex, index_start, index_offset,
+				sizeof(sindex), &index_start, &index_offset);
+			SQUASHFS_SWAP_DIR_INDEX(index, &sindex);
+		} else
+			squashfs_get_cached_block(s, index, index_start, index_offset,
+				sizeof(struct squashfs_dir_index), &index_start, &index_offset);
+
+		squashfs_get_cached_block(s, index->name, index_start, index_offset,
+					index->size + 1, &index_start, &index_offset);
+
+		index->name[index->size + 1] = '\0';
+
+		if (strcmp(index->name, str) > 0)
+			break;
+
+		length = index->index;
+		*next_block = index->start_block + sblk->directory_table_start;
 	}
-	case SQUASHFS_BLKDEV_TYPE:
-	case SQUASHFS_CHRDEV_TYPE:
-	case SQUASHFS_LBLKDEV_TYPE:
-	case SQUASHFS_LCHRDEV_TYPE: {
-		struct squashfs_dev_inode *sqsh_ino = &squashfs_ino.dev;
-		unsigned int rdev;
-
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-				sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
 
-		if (type == SQUASHFS_CHRDEV_TYPE)
-			inode->i_mode |= S_IFCHR;
-		else
-			inode->i_mode |= S_IFBLK;
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		rdev = le32_to_cpu(sqsh_ino->rdev);
-		init_special_inode(inode, inode->i_mode, new_decode_dev(rdev));
+	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
+	kfree(str);
 
-		TRACE("Device inode %x:%x, rdev %x\n",
-				SQUASHFS_INODE_BLK(ino), offset, rdev);
-		break;
+failure:
+	return length + 3;
+}
+
+		
+static int squashfs_readdir(struct file *file, void *dirent, filldir_t filldir)
+{
+	struct inode *i = file->f_dentry->d_inode;
+	struct squashfs_sb_info *msblk = i->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	long long next_block = SQUASHFS_I(i)->start_block +
+		sblk->directory_table_start;
+	int next_offset = SQUASHFS_I(i)->offset, length = 0, dir_count;
+	struct squashfs_dir_header dirh;
+	struct squashfs_dir_entry *dire;
+
+	TRACE("Entered squashfs_readdir [%llx:%x]\n", next_block, next_offset);
+
+	dire = kmalloc(sizeof(struct squashfs_dir_entry) +
+		SQUASHFS_NAME_LEN + 1, GFP_KERNEL);
+	if (dire == NULL) {
+		ERROR("Failed to allocate squashfs_dir_entry\n");
+		goto finish;
 	}
-	case SQUASHFS_FIFO_TYPE:
-	case SQUASHFS_SOCKET_TYPE:
-	case SQUASHFS_LFIFO_TYPE:
-	case SQUASHFS_LSOCKET_TYPE: {
-		struct squashfs_ipc_inode *sqsh_ino = &squashfs_ino.ipc;
-
-		err = squashfs_read_metadata(sb, sqsh_ino, &block, &offset,
-				sizeof(*sqsh_ino));
-		if (err < 0)
-			goto failed_read;
 
-		if (type == SQUASHFS_FIFO_TYPE)
-			inode->i_mode |= S_IFIFO;
-		else
-			inode->i_mode |= S_IFSOCK;
-		inode->i_nlink = le32_to_cpu(sqsh_ino->nlink);
-		init_special_inode(inode, inode->i_mode, 0);
-		break;
+	while(file->f_pos < 3) {
+		char *name;
+		int size, i_ino;
+
+		if(file->f_pos == 0) {
+			name = ".";
+			size = 1;
+			i_ino = i->i_ino;
+		} else {
+			name = "..";
+			size = 2;
+			i_ino = SQUASHFS_I(i)->u.s2.parent_inode;
+		}
+		TRACE("Calling filldir(%x, %s, %d, %d, %d, %d)\n",
+				(unsigned int) dirent, name, size, (int)
+				file->f_pos, i_ino, squashfs_filetype_table[1]);
+
+		if (filldir(dirent, name, size, file->f_pos, i_ino,
+				squashfs_filetype_table[1]) < 0) {
+				TRACE("Filldir returned less than 0\n");
+			goto finish;
+		}
+		file->f_pos += size;
 	}
-	default:
-		ERROR("Unknown inode type %d in squashfs_iget!\n", type);
-		return -EINVAL;
+
+	length = get_dir_index_using_offset(i->i_sb, &next_block, &next_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_start,
+				SQUASHFS_I(i)->u.s2.directory_index_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_count, file->f_pos);
+
+	while (length < i_size_read(i)) {
+		/* read directory header */
+		if (msblk->swap) {
+			struct squashfs_dir_header sdirh;
+			
+			if (!squashfs_get_cached_block(i->i_sb, &sdirh, next_block,
+					 next_offset, sizeof(sdirh), &next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(sdirh);
+			SQUASHFS_SWAP_DIR_HEADER(&dirh, &sdirh);
+		} else {
+			if (!squashfs_get_cached_block(i->i_sb, &dirh, next_block,
+					next_offset, sizeof(dirh), &next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(dirh);
+		}
+
+		dir_count = dirh.count + 1;
+		while (dir_count--) {
+			if (msblk->swap) {
+				struct squashfs_dir_entry sdire;
+				if (!squashfs_get_cached_block(i->i_sb, &sdire, next_block,
+						next_offset, sizeof(sdire), &next_block, &next_offset))
+					goto failed_read;
+				
+				length += sizeof(sdire);
+				SQUASHFS_SWAP_DIR_ENTRY(dire, &sdire);
+			} else {
+				if (!squashfs_get_cached_block(i->i_sb, dire, next_block,
+						next_offset, sizeof(*dire), &next_block, &next_offset))
+					goto failed_read;
+
+				length += sizeof(*dire);
+			}
+
+			if (!squashfs_get_cached_block(i->i_sb, dire->name, next_block,
+						next_offset, dire->size + 1, &next_block, &next_offset))
+				goto failed_read;
+
+			length += dire->size + 1;
+
+			if (file->f_pos >= length)
+				continue;
+
+			dire->name[dire->size + 1] = '\0';
+
+			TRACE("Calling filldir(%x, %s, %d, %d, %x:%x, %d, %d)\n",
+					(unsigned int) dirent, dire->name, dire->size + 1,
+					(int) file->f_pos, dirh.start_block, dire->offset,
+					dirh.inode_number + dire->inode_number,
+					squashfs_filetype_table[dire->type]);
+
+			if (filldir(dirent, dire->name, dire->size + 1, file->f_pos,
+					dirh.inode_number + dire->inode_number,
+					squashfs_filetype_table[dire->type]) < 0) {
+				TRACE("Filldir returned less than 0\n");
+				goto finish;
+			}
+			file->f_pos = length;
+		}
 	}
 
+finish:
+	kfree(dire);
 	return 0;
 
 failed_read:
-	ERROR("Unable to read inode 0x%llx\n", ino);
+	ERROR("Unable to read directory block [%llx:%x]\n", next_block,
+		next_offset);
+	kfree(dire);
+	return 0;
+}
+
+
+static struct dentry *squashfs_lookup(struct inode *i, struct dentry *dentry,
+				struct nameidata *nd)
+{
+	const unsigned char *name = dentry->d_name.name;
+	int len = dentry->d_name.len;
+	struct inode *inode = NULL;
+	struct squashfs_sb_info *msblk = i->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	long long next_block = SQUASHFS_I(i)->start_block +
+				sblk->directory_table_start;
+	int next_offset = SQUASHFS_I(i)->offset, length = 0, dir_count;
+	struct squashfs_dir_header dirh;
+	struct squashfs_dir_entry *dire;
+
+	TRACE("Entered squashfs_lookup [%llx:%x]\n", next_block, next_offset);
+
+	dire = kmalloc(sizeof(struct squashfs_dir_entry) +
+		SQUASHFS_NAME_LEN + 1, GFP_KERNEL);
+	if (dire == NULL) {
+		ERROR("Failed to allocate squashfs_dir_entry\n");
+		goto exit_lookup;
+	}
+
+	if (len > SQUASHFS_NAME_LEN)
+		goto exit_lookup;
+
+	length = get_dir_index_using_name(i->i_sb, &next_block, &next_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_start,
+				SQUASHFS_I(i)->u.s2.directory_index_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_count, name, len);
+
+	while (length < i_size_read(i)) {
+		/* read directory header */
+		if (msblk->swap) {
+			struct squashfs_dir_header sdirh;
+			if (!squashfs_get_cached_block(i->i_sb, &sdirh, next_block,
+					 next_offset, sizeof(sdirh), &next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(sdirh);
+			SQUASHFS_SWAP_DIR_HEADER(&dirh, &sdirh);
+		} else {
+			if (!squashfs_get_cached_block(i->i_sb, &dirh, next_block,
+					next_offset, sizeof(dirh), &next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(dirh);
+		}
+
+		dir_count = dirh.count + 1;
+		while (dir_count--) {
+			if (msblk->swap) {
+				struct squashfs_dir_entry sdire;
+				if (!squashfs_get_cached_block(i->i_sb, &sdire, next_block,
+						next_offset, sizeof(sdire), &next_block, &next_offset))
+					goto failed_read;
+				
+				length += sizeof(sdire);
+				SQUASHFS_SWAP_DIR_ENTRY(dire, &sdire);
+			} else {
+				if (!squashfs_get_cached_block(i->i_sb, dire, next_block,
+						next_offset, sizeof(*dire), &next_block, &next_offset))
+					goto failed_read;
+
+				length += sizeof(*dire);
+			}
+
+			if (!squashfs_get_cached_block(i->i_sb, dire->name, next_block,
+					next_offset, dire->size + 1, &next_block, &next_offset))
+				goto failed_read;
+
+			length += dire->size + 1;
+
+			if (name[0] < dire->name[0])
+				goto exit_lookup;
+
+			if ((len == dire->size + 1) && !strncmp(name, dire->name, len)) {
+				squashfs_inode_t ino = SQUASHFS_MKINODE(dirh.start_block,
+								dire->offset);
+
+				TRACE("calling squashfs_iget for directory entry %s, inode"
+					"  %x:%x, %d\n", name, dirh.start_block, dire->offset,
+					dirh.inode_number + dire->inode_number);
+
+				inode = squashfs_iget(i->i_sb, ino, dirh.inode_number + dire->inode_number);
+
+				goto exit_lookup;
+			}
+		}
+	}
+
+exit_lookup:
+	kfree(dire);
+	if (inode)
+		return d_splice_alias(inode, dentry);
+	d_add(dentry, inode);
+	return ERR_PTR(0);
+
+failed_read:
+	ERROR("Unable to read directory block [%llx:%x]\n", next_block,
+		next_offset);
+	goto exit_lookup;
+}
+
+
+static int squashfs_remount(struct super_block *s, int *flags, char *data)
+{
+	*flags |= MS_RDONLY;
+	return 0;
+}
+
+
+static void squashfs_put_super(struct super_block *s)
+{
+	int i;
+
+	if (s->s_fs_info) {
+		struct squashfs_sb_info *sbi = s->s_fs_info;
+		if (sbi->block_cache)
+			for (i = 0; i < squashfs_cached_blks; i++)
+				if (sbi->block_cache[i].block != SQUASHFS_INVALID_BLK)
+					vfree(sbi->block_cache[i].data);
+		if (sbi->fragment)
+			for (i = 0; i < SQUASHFS_CACHED_FRAGMENTS; i++) 
+				vfree(sbi->fragment[i].data);
+		kfree(sbi->fragment);
+		kfree(sbi->block_cache);
+		vfree(sbi->read_page);
+		kfree(sbi->uid);
+		kfree(sbi->fragment_index);
+		kfree(sbi->fragment_index_2);
+		kfree(sbi->meta_index);
+		kfree(s->s_fs_info);
+		s->s_fs_info = NULL;
+	}
+}
+
+
+static int squashfs_get_sb(struct file_system_type *fs_type, int flags,
+				const char *dev_name, void *data, struct vfsmount *mnt)
+{
+	return get_sb_bdev(fs_type, flags, dev_name, data, squashfs_fill_super,
+				mnt);
+}
+
+static void free_sqlzma(void)
+{
+	int cpu;
+	struct sqlzma *p;
+
+	for_each_online_cpu(cpu) {
+		p = per_cpu(sqlzma, cpu);
+		if (p) {
+#ifdef KeepPreemptive
+			mutex_destroy(&p->mtx);
+#endif
+			sqlzma_fin(&p->un);
+			kfree(p);
+		}
+	}
+}
+
+static int __init init_squashfs_fs(void)
+{
+ 	struct sqlzma *p;
+ 	int cpu;
+	int err = init_inodecache();
+	if (err)
+		goto out;
+
+	for_each_online_cpu(cpu) {
+		dpri("%d: %p\n", cpu, per_cpu(sqlzma, cpu));
+		err = -ENOMEM;
+		p = kmalloc(sizeof(struct sqlzma), GFP_KERNEL);
+		if (p) {
+#ifdef KeepPreemptive
+			mutex_init(&p->mtx);
+#endif
+			err = sqlzma_init(&p->un, 1, 0);
+			if (unlikely(err)) {
+				ERROR("Failed to intialize uncompress workspace\n");
+				break;
+			}
+			per_cpu(sqlzma, cpu) = p;
+			err = 0;
+		} else
+			break;
+	}
+	if (unlikely(err)) {
+		free_sqlzma();
+		goto out;
+	}
+ 
+
+	printk(KERN_INFO "squashfs: version 3.3-CVS (2008/04/04) "
+		"Phillip Lougher\n"
+		"squashfs: LZMA suppport for slax.org by jro\n");
+
+	err = register_filesystem(&squashfs_fs_type);
+	if (err)
+ 	if (err) {
+ 		free_sqlzma();
+		destroy_inodecache();
+ 	}
+
+out:
 	return err;
 }
+
+
+static void __exit exit_squashfs_fs(void)
+{
+	unregister_filesystem(&squashfs_fs_type);
+	free_sqlzma();
+	destroy_inodecache();
+}
+
+
+static struct kmem_cache * squashfs_inode_cachep;
+
+
+static struct inode *squashfs_alloc_inode(struct super_block *sb)
+{
+	struct squashfs_inode_info *ei;
+	ei = kmem_cache_alloc(squashfs_inode_cachep, GFP_KERNEL);
+	return ei ? &ei->vfs_inode : NULL;
+}
+
+
+static void squashfs_destroy_inode(struct inode *inode)
+{
+	kmem_cache_free(squashfs_inode_cachep, SQUASHFS_I(inode));
+}
+
+
+static void init_once(void *foo)
+{
+	struct squashfs_inode_info *ei = foo;
+
+	inode_init_once(&ei->vfs_inode);
+}
+ 
+
+static int __init init_inodecache(void)
+{
+	squashfs_inode_cachep = kmem_cache_create("squashfs_inode_cache",
+	    sizeof(struct squashfs_inode_info), 0,
+		SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT, init_once);
+	if (squashfs_inode_cachep == NULL)
+		return -ENOMEM;
+	return 0;
+}
+
+
+static void destroy_inodecache(void)
+{
+	kmem_cache_destroy(squashfs_inode_cachep);
+}
+
+
+module_init(init_squashfs_fs);
+module_exit(exit_squashfs_fs);
+MODULE_DESCRIPTION("squashfs 3.3, a compressed read-only filesystem, and LZMA suppport for slax.org");
+MODULE_AUTHOR("Phillip Lougher <phillip@lougher.demon.co.uk>, and LZMA suppport for slax.org by jro");
+MODULE_LICENSE("GPL");
diff -Naur linux-2.6.30-ori/fs/squashfs/module.c linux-2.6.30-test/fs/squashfs/module.c
--- linux-2.6.30-ori/fs/squashfs/module.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/module.c	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,36 @@
+
+/*
+ * Copyright (C) 2006-2007 Junjiro Okajima
+ * Copyright (C) 2006-2007 Tomas Matejicek, slax.org
+ *
+ * LICENSE follows the described one in lzma.txt.
+ */
+
+/* $Id: module.c,v 1.1 2007-11-05 05:43:36 jro Exp $ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+
+#include "LzmaDecode.c"
+
+EXPORT_SYMBOL(LzmaDecodeProperties);
+EXPORT_SYMBOL(LzmaDecode);
+
+#if 0
+static int __init unlzma_init(void)
+{
+	return 0;
+}
+
+static void __exit unlzma_exit(void)
+{
+}
+
+module_init(unlzma_init);
+module_exit(unlzma_exit);
+#endif
+
+MODULE_LICENSE("GPL");
+MODULE_VERSION("$Id: module.c,v 1.1 2007-11-05 05:43:36 jro Exp $");
+MODULE_DESCRIPTION("LZMA uncompress. "
+		   "A tiny wrapper for LzmaDecode.c in LZMA SDK from www.7-zip.org.");
diff -Naur linux-2.6.30-ori/fs/squashfs/namei.c linux-2.6.30-test/fs/squashfs/namei.c
--- linux-2.6.30-ori/fs/squashfs/namei.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/namei.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,242 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * namei.c
- */
-
-/*
- * This file implements code to do filename lookup in directories.
- *
- * Like inodes, directories are packed into compressed metadata blocks, stored
- * in a directory table.  Directories are accessed using the start address of
- * the metablock containing the directory and the offset into the
- * decompressed block (<block, offset>).
- *
- * Directories are organised in a slightly complex way, and are not simply
- * a list of file names.  The organisation takes advantage of the
- * fact that (in most cases) the inodes of the files will be in the same
- * compressed metadata block, and therefore, can share the start block.
- * Directories are therefore organised in a two level list, a directory
- * header containing the shared start block value, and a sequence of directory
- * entries, each of which share the shared start block.  A new directory header
- * is written once/if the inode start block changes.  The directory
- * header/directory entry list is repeated as many times as necessary.
- *
- * Directories are sorted, and can contain a directory index to speed up
- * file lookup.  Directory indexes store one entry per metablock, each entry
- * storing the index/filename mapping to the first directory header
- * in each metadata block.  Directories are sorted in alphabetical order,
- * and at lookup the index is scanned linearly looking for the first filename
- * alphabetically larger than the filename being looked up.  At this point the
- * location of the metadata block the filename is in has been found.
- * The general idea of the index is ensure only one metadata block needs to be
- * decompressed to do a lookup irrespective of the length of the directory.
- * This scheme has the advantage that it doesn't require extra memory overhead
- * and doesn't require much extra storage on disk.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/dcache.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-/*
- * Lookup name in the directory index, returning the location of the metadata
- * block containing it, and the directory index this represents.
- *
- * If we get an error reading the index then return the part of the index
- * (if any) we have managed to read - the index isn't essential, just
- * quicker.
- */
-static int get_dir_index_using_name(struct super_block *sb,
-			u64 *next_block, int *next_offset, u64 index_start,
-			int index_offset, int i_count, const char *name,
-			int len)
-{
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int i, size, length = 0, err;
-	struct squashfs_dir_index *index;
-	char *str;
-
-	TRACE("Entered get_dir_index_using_name, i_count %d\n", i_count);
-
-	index = kmalloc(sizeof(*index) + SQUASHFS_NAME_LEN * 2 + 2, GFP_KERNEL);
-	if (index == NULL) {
-		ERROR("Failed to allocate squashfs_dir_index\n");
-		goto out;
-	}
-
-	str = &index->name[SQUASHFS_NAME_LEN + 1];
-	strncpy(str, name, len);
-	str[len] = '\0';
-
-	for (i = 0; i < i_count; i++) {
-		err = squashfs_read_metadata(sb, index, &index_start,
-					&index_offset, sizeof(*index));
-		if (err < 0)
-			break;
-
-
-		size = le32_to_cpu(index->size) + 1;
-
-		err = squashfs_read_metadata(sb, index->name, &index_start,
-					&index_offset, size);
-		if (err < 0)
-			break;
-
-		index->name[size] = '\0';
-
-		if (strcmp(index->name, str) > 0)
-			break;
-
-		length = le32_to_cpu(index->index);
-		*next_block = le32_to_cpu(index->start_block) +
-					msblk->directory_table;
-	}
-
-	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
-	kfree(index);
-
-out:
-	/*
-	 * Return index (f_pos) of the looked up metadata block.  Translate
-	 * from internal f_pos to external f_pos which is offset by 3 because
-	 * we invent "." and ".." entries which are not actually stored in the
-	 * directory.
-	 */
-	return length + 3;
-}
-
-
-static struct dentry *squashfs_lookup(struct inode *dir, struct dentry *dentry,
-				 struct nameidata *nd)
-{
-	const unsigned char *name = dentry->d_name.name;
-	int len = dentry->d_name.len;
-	struct inode *inode = NULL;
-	struct squashfs_sb_info *msblk = dir->i_sb->s_fs_info;
-	struct squashfs_dir_header dirh;
-	struct squashfs_dir_entry *dire;
-	u64 block = squashfs_i(dir)->start + msblk->directory_table;
-	int offset = squashfs_i(dir)->offset;
-	int err, length = 0, dir_count, size;
-
-	TRACE("Entered squashfs_lookup [%llx:%x]\n", block, offset);
-
-	dire = kmalloc(sizeof(*dire) + SQUASHFS_NAME_LEN + 1, GFP_KERNEL);
-	if (dire == NULL) {
-		ERROR("Failed to allocate squashfs_dir_entry\n");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	if (len > SQUASHFS_NAME_LEN) {
-		err = -ENAMETOOLONG;
-		goto failed;
-	}
-
-	length = get_dir_index_using_name(dir->i_sb, &block, &offset,
-				squashfs_i(dir)->dir_idx_start,
-				squashfs_i(dir)->dir_idx_offset,
-				squashfs_i(dir)->dir_idx_cnt, name, len);
-
-	while (length < i_size_read(dir)) {
-		/*
-		 * Read directory header.
-		 */
-		err = squashfs_read_metadata(dir->i_sb, &dirh, &block,
-				&offset, sizeof(dirh));
-		if (err < 0)
-			goto read_failure;
-
-		length += sizeof(dirh);
-
-		dir_count = le32_to_cpu(dirh.count) + 1;
-		while (dir_count--) {
-			/*
-			 * Read directory entry.
-			 */
-			err = squashfs_read_metadata(dir->i_sb, dire, &block,
-					&offset, sizeof(*dire));
-			if (err < 0)
-				goto read_failure;
-
-			size = le16_to_cpu(dire->size) + 1;
-
-			err = squashfs_read_metadata(dir->i_sb, dire->name,
-					&block, &offset, size);
-			if (err < 0)
-				goto read_failure;
-
-			length += sizeof(*dire) + size;
-
-			if (name[0] < dire->name[0])
-				goto exit_lookup;
-
-			if (len == size && !strncmp(name, dire->name, len)) {
-				unsigned int blk, off, ino_num;
-				long long ino;
-				blk = le32_to_cpu(dirh.start_block);
-				off = le16_to_cpu(dire->offset);
-				ino_num = le32_to_cpu(dirh.inode_number) +
-					(short) le16_to_cpu(dire->inode_number);
-				ino = SQUASHFS_MKINODE(blk, off);
-
-				TRACE("calling squashfs_iget for directory "
-					"entry %s, inode  %x:%x, %d\n", name,
-					blk, off, ino_num);
-
-				inode = squashfs_iget(dir->i_sb, ino, ino_num);
-				if (IS_ERR(inode)) {
-					err = PTR_ERR(inode);
-					goto failed;
-				}
-
-				goto exit_lookup;
-			}
-		}
-	}
-
-exit_lookup:
-	kfree(dire);
-	if (inode)
-		return d_splice_alias(inode, dentry);
-	d_add(dentry, inode);
-	return ERR_PTR(0);
-
-read_failure:
-	ERROR("Unable to read directory block [%llx:%x]\n",
-		squashfs_i(dir)->start + msblk->directory_table,
-		squashfs_i(dir)->offset);
-failed:
-	kfree(dire);
-	return ERR_PTR(err);
-}
-
-
-const struct inode_operations squashfs_dir_inode_ops = {
-	.lookup = squashfs_lookup
-};
diff -Naur linux-2.6.30-ori/fs/squashfs/sqlzma.h linux-2.6.30-test/fs/squashfs/sqlzma.h
--- linux-2.6.30-ori/fs/squashfs/sqlzma.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/sqlzma.h	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,84 @@
+/*
+ * Copyright (C) 2006-2008 Junjiro Okajima
+ * Copyright (C) 2006-2008 Tomas Matejicek, slax.org
+ *
+ * LICENSE follows the described one in lzma.
+ */
+
+/* $Id: sqlzma.h,v 1.20 2008-03-12 16:58:34 jro Exp $ */
+
+#ifndef __sqlzma_h__
+#define __sqlzma_h__
+
+#ifndef __KERNEL__
+#include <stdlib.h>
+#include <string.h>
+#include <zlib.h>
+#ifdef _REENTRANT
+#include <pthread.h>
+#endif
+#else
+#include <linux/zlib.h>
+#endif
+#define _7ZIP_BYTE_DEFINED
+
+/*
+ * detect the compression method automatically by the first byte of compressed
+ * data.
+ * according to rfc1950, the first byte of zlib compression must be 0x?8.
+ */
+#define is_lzma(c)	(c == 0x5d)
+
+/* ---------------------------------------------------------------------- */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#ifndef __KERNEL__
+/* for mksquashfs only */
+struct sqlzma_opts {
+	unsigned int	try_lzma;
+	unsigned int 	dicsize;
+};
+int sqlzma_cm(struct sqlzma_opts *opts, z_stream *stream, Bytef *next_in,
+	      uInt avail_in, Bytef *next_out, uInt avail_out);
+#endif
+
+/* ---------------------------------------------------------------------- */
+/*
+ * Three patterns for sqlzma uncompression. very dirty code.
+ * - kernel space (squashfs kernel module)
+ * - user space with pthread (mksquashfs)
+ * - user space without pthread (unsquashfs)
+ */
+
+struct sized_buf {
+	unsigned int	sz;
+	unsigned char	*buf;
+};
+
+enum {SQUN_PROB, SQUN_RESULT, SQUN_LAST};
+struct sqlzma_un {
+	int			un_lzma;
+	struct sized_buf	un_a[SQUN_LAST];
+	unsigned char           un_prob[31960]; /* unlzma 64KB - 1MB */
+	z_stream		un_stream;
+#define un_cmbuf	un_stream.next_in
+#define un_cmlen	un_stream.avail_in
+#define un_resbuf	un_stream.next_out
+#define un_resroom	un_stream.avail_out
+#define un_reslen	un_stream.total_out
+};
+
+int sqlzma_init(struct sqlzma_un *un, int do_lzma, unsigned int res_sz);
+int sqlzma_un(struct sqlzma_un *un, struct sized_buf *src,
+	      struct sized_buf *dst);
+void sqlzma_fin(struct sqlzma_un *un);
+
+/* ---------------------------------------------------------------------- */
+
+#ifdef __cplusplus
+};
+#endif
+#endif
diff -Naur linux-2.6.30-ori/fs/squashfs/sqmagic.h linux-2.6.30-test/fs/squashfs/sqmagic.h
--- linux-2.6.30-ori/fs/squashfs/sqmagic.h	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/sqmagic.h	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,17 @@
+/*
+ * Copyright (C) 2006 Junjiro Okajima
+ * Copyright (C) 2006 Tomas Matejicek, slax.org
+ *
+ * LICENSE must follow the one in squashfs.
+ */
+
+/* $Id: sqmagic.h,v 1.2 2006-11-27 03:54:58 jro Exp $ */
+
+#ifndef __sqmagic_h__
+#define __sqmagic_h__
+
+/* see SQUASHFS_MAGIC in squashfs_fs.h */
+#define SQUASHFS_MAGIC_LZMA		0x71736873
+#define SQUASHFS_MAGIC_LZMA_SWAP	0x73687371
+
+#endif
diff -Naur linux-2.6.30-ori/fs/squashfs/squashfs.h linux-2.6.30-test/fs/squashfs/squashfs.h
--- linux-2.6.30-ori/fs/squashfs/squashfs.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/squashfs.h	2009-06-15 11:25:12.000000000 -0400
@@ -1,7 +1,7 @@
 /*
  * Squashfs - a compressed read only filesystem for Linux
  *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
+ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007
  * Phillip Lougher <phillip@lougher.demon.co.uk>
  *
  * This program is free software; you can redistribute it and/or
@@ -16,75 +16,71 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * squashfs.h
  */
 
-#define TRACE(s, args...)	pr_debug("SQUASHFS: "s, ## args)
+#ifdef CONFIG_SQUASHFS_1_0_COMPATIBILITY
+#undef CONFIG_SQUASHFS_1_0_COMPATIBILITY
+#endif
+
+#ifdef SQUASHFS_TRACE
+#define TRACE(s, args...)	printk(KERN_NOTICE "SQUASHFS: "s, ## args)
+#else
+#define TRACE(s, args...)	{}
+#endif
+
+#define ERROR(s, args...)	printk(KERN_ERR "SQUASHFS error: "s, ## args)
+
+#define SERROR(s, args...)	do { \
+				if (!silent) \
+				printk(KERN_ERR "SQUASHFS error: "s, ## args);\
+				} while(0)
 
-#define ERROR(s, args...)	pr_err("SQUASHFS error: "s, ## args)
+#define WARNING(s, args...)	printk(KERN_WARNING "SQUASHFS: "s, ## args)
 
-#define WARNING(s, args...)	pr_warning("SQUASHFS: "s, ## args)
-
-static inline struct squashfs_inode_info *squashfs_i(struct inode *inode)
+static inline struct squashfs_inode_info *SQUASHFS_I(struct inode *inode)
 {
 	return list_entry(inode, struct squashfs_inode_info, vfs_inode);
 }
 
-/* block.c */
-extern int squashfs_read_data(struct super_block *, void **, u64, int, u64 *,
-				int, int);
-
-/* cache.c */
-extern struct squashfs_cache *squashfs_cache_init(char *, int, int);
-extern void squashfs_cache_delete(struct squashfs_cache *);
-extern struct squashfs_cache_entry *squashfs_cache_get(struct super_block *,
-				struct squashfs_cache *, u64, int);
-extern void squashfs_cache_put(struct squashfs_cache_entry *);
-extern int squashfs_copy_data(void *, struct squashfs_cache_entry *, int, int);
-extern int squashfs_read_metadata(struct super_block *, void *, u64 *,
-				int *, int);
-extern struct squashfs_cache_entry *squashfs_get_fragment(struct super_block *,
-				u64, int);
-extern struct squashfs_cache_entry *squashfs_get_datablock(struct super_block *,
-				u64, int);
-extern int squashfs_read_table(struct super_block *, void *, u64, int);
-
-/* export.c */
-extern __le64 *squashfs_read_inode_lookup_table(struct super_block *, u64,
-				unsigned int);
-
-/* fragment.c */
-extern int squashfs_frag_lookup(struct super_block *, unsigned int, u64 *);
-extern __le64 *squashfs_read_fragment_index_table(struct super_block *,
-				u64, unsigned int);
-
-/* id.c */
-extern int squashfs_get_id(struct super_block *, unsigned int, unsigned int *);
-extern __le64 *squashfs_read_id_index_table(struct super_block *, u64,
-				unsigned short);
-
-/* inode.c */
-extern struct inode *squashfs_iget(struct super_block *, long long,
-				unsigned int);
-extern int squashfs_read_inode(struct inode *, long long);
-
-/*
- * Inodes and files operations
- */
-
-/* dir.c */
-extern const struct file_operations squashfs_dir_ops;
-
-/* export.c */
-extern const struct export_operations squashfs_export_ops;
-
-/* file.c */
+#if defined(CONFIG_SQUASHFS_1_0_COMPATIBILITY ) || defined(CONFIG_SQUASHFS_2_0_COMPATIBILITY)
+#define SQSH_EXTERN
+extern unsigned int squashfs_read_data(struct super_block *s, char *buffer,
+				long long index, unsigned int length,
+				long long *next_index, int srclength);
+extern int squashfs_get_cached_block(struct super_block *s, void *buffer,
+				long long block, unsigned int offset,
+				int length, long long *next_block,
+				unsigned int *next_offset);
+extern void release_cached_fragment(struct squashfs_sb_info *msblk, struct
+					squashfs_fragment_cache *fragment);
+extern struct squashfs_fragment_cache *get_cached_fragment(struct super_block
+					*s, long long start_block,
+					int length);
+extern struct inode *squashfs_iget(struct super_block *s, squashfs_inode_t inode, unsigned int inode_number);
+extern const struct address_space_operations squashfs_symlink_aops;
 extern const struct address_space_operations squashfs_aops;
+extern struct inode_operations squashfs_dir_inode_ops;
+#else
+#define SQSH_EXTERN static
+#endif
+
+#ifdef CONFIG_SQUASHFS_1_0_COMPATIBILITY
+extern int squashfs_1_0_supported(struct squashfs_sb_info *msblk);
+#else
+static inline int squashfs_1_0_supported(struct squashfs_sb_info *msblk)
+{
+	return 0;
+}
+#endif
 
-/* namei.c */
-extern const struct inode_operations squashfs_dir_inode_ops;
-
-/* symlink.c */
-extern const struct address_space_operations squashfs_symlink_aops;
+#ifdef CONFIG_SQUASHFS_2_0_COMPATIBILITY
+extern int squashfs_2_0_supported(struct squashfs_sb_info *msblk);
+#else
+static inline int squashfs_2_0_supported(struct squashfs_sb_info *msblk)
+{
+	return 0;
+}
+#endif
diff -Naur linux-2.6.30-ori/fs/squashfs/squashfs2_0.c linux-2.6.30-test/fs/squashfs/squashfs2_0.c
--- linux-2.6.30-ori/fs/squashfs/squashfs2_0.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/squashfs2_0.c	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,740 @@
+/*
+ * Squashfs - a compressed read only filesystem for Linux
+ *
+ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007
+ * Phillip Lougher <phillip@lougher.demon.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2,
+ * or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ *
+ * squashfs2_0.c
+ */
+
+#include "squashfs_fs.h"
+#include <linux/module.h>
+#include <linux/zlib.h>
+#include <linux/fs.h>
+#include "squashfs_fs_sb.h"
+#include "squashfs_fs_i.h"
+
+#include "squashfs.h"
+static int squashfs_readdir_2(struct file *file, void *dirent, filldir_t filldir);
+static struct dentry *squashfs_lookup_2(struct inode *, struct dentry *,
+				struct nameidata *);
+
+static struct file_operations squashfs_dir_ops_2 = {
+	.read = generic_read_dir,
+	.readdir = squashfs_readdir_2
+};
+
+static struct inode_operations squashfs_dir_inode_ops_2 = {
+	.lookup = squashfs_lookup_2
+};
+
+static unsigned char squashfs_filetype_table[] = {
+	DT_UNKNOWN, DT_DIR, DT_REG, DT_LNK, DT_BLK, DT_CHR, DT_FIFO, DT_SOCK
+};
+
+static int read_fragment_index_table_2(struct super_block *s)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	if (!(msblk->fragment_index_2 = kmalloc(SQUASHFS_FRAGMENT_INDEX_BYTES_2
+					(sblk->fragments), GFP_KERNEL))) {
+		ERROR("Failed to allocate uid/gid table\n");
+		return 0;
+	}
+   
+	if (SQUASHFS_FRAGMENT_INDEX_BYTES_2(sblk->fragments) &&
+					!squashfs_read_data(s, (char *)
+					msblk->fragment_index_2,
+					sblk->fragment_table_start,
+					SQUASHFS_FRAGMENT_INDEX_BYTES_2
+					(sblk->fragments) |
+					SQUASHFS_COMPRESSED_BIT_BLOCK, NULL, SQUASHFS_FRAGMENT_INDEX_BYTES_2(sblk->fragments))) {
+		ERROR("unable to read fragment index table\n");
+		return 0;
+	}
+
+	if (msblk->swap) {
+		int i;
+		unsigned int fragment;
+
+		for (i = 0; i < SQUASHFS_FRAGMENT_INDEXES_2(sblk->fragments);
+									i++) {
+			SQUASHFS_SWAP_FRAGMENT_INDEXES_2((&fragment),
+						&msblk->fragment_index_2[i], 1);
+			msblk->fragment_index_2[i] = fragment;
+		}
+	}
+
+	return 1;
+}
+
+
+static int get_fragment_location_2(struct super_block *s, unsigned int fragment,
+				long long *fragment_start_block,
+				unsigned int *fragment_size)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	long long start_block =
+		msblk->fragment_index_2[SQUASHFS_FRAGMENT_INDEX_2(fragment)];
+	int offset = SQUASHFS_FRAGMENT_INDEX_OFFSET_2(fragment);
+	struct squashfs_fragment_entry_2 fragment_entry;
+
+	if (msblk->swap) {
+		struct squashfs_fragment_entry_2 sfragment_entry;
+
+		if (!squashfs_get_cached_block(s, (char *) &sfragment_entry,
+					start_block, offset,
+					sizeof(sfragment_entry), &start_block,
+					&offset))
+			goto out;
+		SQUASHFS_SWAP_FRAGMENT_ENTRY_2(&fragment_entry, &sfragment_entry);
+	} else
+		if (!squashfs_get_cached_block(s, (char *) &fragment_entry,
+					start_block, offset,
+					sizeof(fragment_entry), &start_block,
+					&offset))
+			goto out;
+
+	*fragment_start_block = fragment_entry.start_block;
+	*fragment_size = fragment_entry.size;
+
+	return 1;
+
+out:
+	return 0;
+}
+
+
+static void squashfs_new_inode(struct squashfs_sb_info *msblk, struct inode *i,
+		struct squashfs_base_inode_header_2 *inodeb, unsigned int ino)
+{
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	i->i_ino = ino;
+	i->i_mtime.tv_sec = sblk->mkfs_time;
+	i->i_atime.tv_sec = sblk->mkfs_time;
+	i->i_ctime.tv_sec = sblk->mkfs_time;
+	i->i_uid = msblk->uid[inodeb->uid];
+	i->i_mode = inodeb->mode;
+	i->i_nlink = 1;
+	i->i_size = 0;
+	if (inodeb->guid == SQUASHFS_GUIDS)
+		i->i_gid = i->i_uid;
+	else
+		i->i_gid = msblk->guid[inodeb->guid];
+}
+
+
+static int squashfs_read_inode_2(struct inode *i, squashfs_inode_t inode)
+{
+	struct super_block *s = i->i_sb;
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	unsigned int block = SQUASHFS_INODE_BLK(inode) +
+		sblk->inode_table_start;
+	unsigned int offset = SQUASHFS_INODE_OFFSET(inode);
+	unsigned int ino = SQUASHFS_MK_VFS_INODE(block -
+		sblk->inode_table_start, offset);
+	long long next_block;
+	unsigned int next_offset;
+	union squashfs_inode_header_2 id, sid;
+	struct squashfs_base_inode_header_2 *inodeb = &id.base,
+					  *sinodeb = &sid.base;
+
+	TRACE("Entered squashfs_read_inode_2\n");
+
+	if (msblk->swap) {
+		if (!squashfs_get_cached_block(s, (char *) sinodeb, block,
+					offset, sizeof(*sinodeb), &next_block,
+					&next_offset))
+			goto failed_read;
+		SQUASHFS_SWAP_BASE_INODE_HEADER_2(inodeb, sinodeb,
+					sizeof(*sinodeb));
+	} else
+		if (!squashfs_get_cached_block(s, (char *) inodeb, block,
+					offset, sizeof(*inodeb), &next_block,
+					&next_offset))
+			goto failed_read;
+
+	squashfs_new_inode(msblk, i, inodeb, ino);
+
+	switch(inodeb->inode_type) {
+		case SQUASHFS_FILE_TYPE: {
+			struct squashfs_reg_inode_header_2 *inodep = &id.reg;
+			struct squashfs_reg_inode_header_2 *sinodep = &sid.reg;
+			long long frag_blk;
+			unsigned int frag_size = 0;
+				
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, (char *)
+						sinodep, block, offset,
+						sizeof(*sinodep), &next_block,
+						&next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_REG_INODE_HEADER_2(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, (char *)
+						inodep, block, offset,
+						sizeof(*inodep), &next_block,
+						&next_offset))
+					goto failed_read;
+
+			frag_blk = SQUASHFS_INVALID_BLK;
+			if (inodep->fragment != SQUASHFS_INVALID_FRAG &&
+					!get_fragment_location_2(s,
+					inodep->fragment, &frag_blk, &frag_size))
+				goto failed_read;
+				
+			i->i_size = inodep->file_size;
+			i->i_fop = &generic_ro_fops;
+			i->i_mode |= S_IFREG;
+			i->i_mtime.tv_sec = inodep->mtime;
+			i->i_atime.tv_sec = inodep->mtime;
+			i->i_ctime.tv_sec = inodep->mtime;
+			i->i_blocks = ((i->i_size - 1) >> 9) + 1;
+			SQUASHFS_I(i)->u.s1.fragment_start_block = frag_blk;
+			SQUASHFS_I(i)->u.s1.fragment_size = frag_size;
+			SQUASHFS_I(i)->u.s1.fragment_offset = inodep->offset;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->u.s1.block_list_start = next_block;
+			SQUASHFS_I(i)->offset = next_offset;
+			i->i_data.a_ops = &squashfs_aops;
+
+			TRACE("File inode %x:%x, start_block %x, "
+					"block_list_start %llx, offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->start_block, next_block,
+					next_offset);
+			break;
+		}
+		case SQUASHFS_DIR_TYPE: {
+			struct squashfs_dir_inode_header_2 *inodep = &id.dir;
+			struct squashfs_dir_inode_header_2 *sinodep = &sid.dir;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, (char *)
+						sinodep, block, offset,
+						sizeof(*sinodep), &next_block,
+						&next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_DIR_INODE_HEADER_2(inodep, sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, (char *)
+						inodep, block, offset,
+						sizeof(*inodep), &next_block,
+						&next_offset))
+					goto failed_read;
+
+			i->i_size = inodep->file_size;
+			i->i_op = &squashfs_dir_inode_ops_2;
+			i->i_fop = &squashfs_dir_ops_2;
+			i->i_mode |= S_IFDIR;
+			i->i_mtime.tv_sec = inodep->mtime;
+			i->i_atime.tv_sec = inodep->mtime;
+			i->i_ctime.tv_sec = inodep->mtime;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->offset = inodep->offset;
+			SQUASHFS_I(i)->u.s2.directory_index_count = 0;
+			SQUASHFS_I(i)->u.s2.parent_inode = 0;
+
+			TRACE("Directory inode %x:%x, start_block %x, offset "
+					"%x\n", SQUASHFS_INODE_BLK(inode),
+					offset, inodep->start_block,
+					inodep->offset);
+			break;
+		}
+		case SQUASHFS_LDIR_TYPE: {
+			struct squashfs_ldir_inode_header_2 *inodep = &id.ldir;
+			struct squashfs_ldir_inode_header_2 *sinodep = &sid.ldir;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, (char *)
+						sinodep, block, offset,
+						sizeof(*sinodep), &next_block,
+						&next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_LDIR_INODE_HEADER_2(inodep,
+						sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, (char *)
+						inodep, block, offset,
+						sizeof(*inodep), &next_block,
+						&next_offset))
+					goto failed_read;
+
+			i->i_size = inodep->file_size;
+			i->i_op = &squashfs_dir_inode_ops_2;
+			i->i_fop = &squashfs_dir_ops_2;
+			i->i_mode |= S_IFDIR;
+			i->i_mtime.tv_sec = inodep->mtime;
+			i->i_atime.tv_sec = inodep->mtime;
+			i->i_ctime.tv_sec = inodep->mtime;
+			SQUASHFS_I(i)->start_block = inodep->start_block;
+			SQUASHFS_I(i)->offset = inodep->offset;
+			SQUASHFS_I(i)->u.s2.directory_index_start = next_block;
+			SQUASHFS_I(i)->u.s2.directory_index_offset =
+								next_offset;
+			SQUASHFS_I(i)->u.s2.directory_index_count =
+								inodep->i_count;
+			SQUASHFS_I(i)->u.s2.parent_inode = 0;
+
+			TRACE("Long directory inode %x:%x, start_block %x, "
+					"offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->start_block, inodep->offset);
+			break;
+		}
+		case SQUASHFS_SYMLINK_TYPE: {
+			struct squashfs_symlink_inode_header_2 *inodep =
+								&id.symlink;
+			struct squashfs_symlink_inode_header_2 *sinodep =
+								&sid.symlink;
+	
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, (char *)
+						sinodep, block, offset,
+						sizeof(*sinodep), &next_block,
+						&next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_SYMLINK_INODE_HEADER_2(inodep,
+								sinodep);
+			} else
+				if (!squashfs_get_cached_block(s, (char *)
+						inodep, block, offset,
+						sizeof(*inodep), &next_block,
+						&next_offset))
+					goto failed_read;
+
+			i->i_size = inodep->symlink_size;
+			i->i_op = &page_symlink_inode_operations;
+			i->i_data.a_ops = &squashfs_symlink_aops;
+			i->i_mode |= S_IFLNK;
+			SQUASHFS_I(i)->start_block = next_block;
+			SQUASHFS_I(i)->offset = next_offset;
+
+			TRACE("Symbolic link inode %x:%x, start_block %llx, "
+					"offset %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					next_block, next_offset);
+			break;
+		 }
+		 case SQUASHFS_BLKDEV_TYPE:
+		 case SQUASHFS_CHRDEV_TYPE: {
+			struct squashfs_dev_inode_header_2 *inodep = &id.dev;
+			struct squashfs_dev_inode_header_2 *sinodep = &sid.dev;
+
+			if (msblk->swap) {
+				if (!squashfs_get_cached_block(s, (char *)
+						sinodep, block, offset,
+						sizeof(*sinodep), &next_block,
+						&next_offset))
+					goto failed_read;
+				SQUASHFS_SWAP_DEV_INODE_HEADER_2(inodep, sinodep);
+			} else	
+				if (!squashfs_get_cached_block(s, (char *)
+						inodep, block, offset,
+						sizeof(*inodep), &next_block,
+						&next_offset))
+					goto failed_read;
+
+			i->i_mode |= (inodeb->inode_type ==
+					SQUASHFS_CHRDEV_TYPE) ?  S_IFCHR :
+					S_IFBLK;
+			init_special_inode(i, i->i_mode,
+					old_decode_dev(inodep->rdev));
+
+			TRACE("Device inode %x:%x, rdev %x\n",
+					SQUASHFS_INODE_BLK(inode), offset,
+					inodep->rdev);
+			break;
+		 }
+		 case SQUASHFS_FIFO_TYPE:
+		 case SQUASHFS_SOCKET_TYPE: {
+
+			i->i_mode |= (inodeb->inode_type == SQUASHFS_FIFO_TYPE)
+							? S_IFIFO : S_IFSOCK;
+			init_special_inode(i, i->i_mode, 0);
+			break;
+		 }
+		 default:
+			ERROR("Unknown inode type %d in squashfs_iget!\n",
+					inodeb->inode_type);
+			goto failed_read1;
+	}
+	
+	return 1;
+
+failed_read:
+	ERROR("Unable to read inode [%x:%x]\n", block, offset);
+
+failed_read1:
+	return 0;
+}
+
+
+static int get_dir_index_using_offset(struct super_block *s, long long 
+				*next_block, unsigned int *next_offset,
+				long long index_start,
+				unsigned int index_offset, int i_count,
+				long long f_pos)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	int i, length = 0;
+	struct squashfs_dir_index_2 index;
+
+	TRACE("Entered get_dir_index_using_offset, i_count %d, f_pos %d\n",
+					i_count, (unsigned int) f_pos);
+
+	if (f_pos == 0)
+		goto finish;
+
+	for (i = 0; i < i_count; i++) {
+		if (msblk->swap) {
+			struct squashfs_dir_index_2 sindex;
+			squashfs_get_cached_block(s, (char *) &sindex,
+					index_start, index_offset,
+					sizeof(sindex), &index_start,
+					&index_offset);
+			SQUASHFS_SWAP_DIR_INDEX_2(&index, &sindex);
+		} else
+			squashfs_get_cached_block(s, (char *) &index,
+					index_start, index_offset,
+					sizeof(index), &index_start,
+					&index_offset);
+
+		if (index.index > f_pos)
+			break;
+
+		squashfs_get_cached_block(s, NULL, index_start, index_offset,
+					index.size + 1, &index_start,
+					&index_offset);
+
+		length = index.index;
+		*next_block = index.start_block + sblk->directory_table_start;
+	}
+
+	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
+
+finish:
+	return length;
+}
+
+
+static int get_dir_index_using_name(struct super_block *s, long long
+				*next_block, unsigned int *next_offset,
+				long long index_start,
+				unsigned int index_offset, int i_count,
+				const char *name, int size)
+{
+	struct squashfs_sb_info *msblk = s->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	int i, length = 0;
+	struct squashfs_dir_index_2 *index;
+	char *str;
+
+	TRACE("Entered get_dir_index_using_name, i_count %d\n", i_count);
+
+	if (!(str = kmalloc(sizeof(struct squashfs_dir_index) +
+		(SQUASHFS_NAME_LEN + 1) * 2, GFP_KERNEL))) {
+		ERROR("Failed to allocate squashfs_dir_index\n");
+		goto failure;
+	}
+
+	index = (struct squashfs_dir_index_2 *) (str + SQUASHFS_NAME_LEN + 1);
+	strncpy(str, name, size);
+	str[size] = '\0';
+
+	for (i = 0; i < i_count; i++) {
+		if (msblk->swap) {
+			struct squashfs_dir_index_2 sindex;
+			squashfs_get_cached_block(s, (char *) &sindex,
+					index_start, index_offset,
+					sizeof(sindex), &index_start,
+					&index_offset);
+			SQUASHFS_SWAP_DIR_INDEX_2(index, &sindex);
+		} else
+			squashfs_get_cached_block(s, (char *) index,
+					index_start, index_offset,
+					sizeof(struct squashfs_dir_index_2),
+					&index_start, &index_offset);
+
+		squashfs_get_cached_block(s, index->name, index_start,
+					index_offset, index->size + 1,
+					&index_start, &index_offset);
+
+		index->name[index->size + 1] = '\0';
+
+		if (strcmp(index->name, str) > 0)
+			break;
+
+		length = index->index;
+		*next_block = index->start_block + sblk->directory_table_start;
+	}
+
+	*next_offset = (length + *next_offset) % SQUASHFS_METADATA_SIZE;
+	kfree(str);
+failure:
+	return length;
+}
+
+		
+static int squashfs_readdir_2(struct file *file, void *dirent, filldir_t filldir)
+{
+	struct inode *i = file->f_dentry->d_inode;
+	struct squashfs_sb_info *msblk = i->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	long long next_block = SQUASHFS_I(i)->start_block +
+		sblk->directory_table_start;
+	int next_offset = SQUASHFS_I(i)->offset, length = 0,
+		dir_count;
+	struct squashfs_dir_header_2 dirh;
+	struct squashfs_dir_entry_2 *dire;
+
+	TRACE("Entered squashfs_readdir_2 [%llx:%x]\n", next_block, next_offset);
+
+	if (!(dire = kmalloc(sizeof(struct squashfs_dir_entry) +
+		SQUASHFS_NAME_LEN + 1, GFP_KERNEL))) {
+		ERROR("Failed to allocate squashfs_dir_entry\n");
+		goto finish;
+	}
+
+	length = get_dir_index_using_offset(i->i_sb, &next_block, &next_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_start,
+				SQUASHFS_I(i)->u.s2.directory_index_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_count,
+				file->f_pos);
+
+	while (length < i_size_read(i)) {
+		/* read directory header */
+		if (msblk->swap) {
+			struct squashfs_dir_header_2 sdirh;
+			
+			if (!squashfs_get_cached_block(i->i_sb, (char *) &sdirh,
+					next_block, next_offset, sizeof(sdirh),
+					&next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(sdirh);
+			SQUASHFS_SWAP_DIR_HEADER_2(&dirh, &sdirh);
+		} else {
+			if (!squashfs_get_cached_block(i->i_sb, (char *) &dirh,
+					next_block, next_offset, sizeof(dirh),
+					&next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(dirh);
+		}
+
+		dir_count = dirh.count + 1;
+		while (dir_count--) {
+			if (msblk->swap) {
+				struct squashfs_dir_entry_2 sdire;
+				if (!squashfs_get_cached_block(i->i_sb, (char *)
+						&sdire, next_block, next_offset,
+						sizeof(sdire), &next_block,
+						&next_offset))
+					goto failed_read;
+				
+				length += sizeof(sdire);
+				SQUASHFS_SWAP_DIR_ENTRY_2(dire, &sdire);
+			} else {
+				if (!squashfs_get_cached_block(i->i_sb, (char *)
+						dire, next_block, next_offset,
+						sizeof(*dire), &next_block,
+						&next_offset))
+					goto failed_read;
+
+				length += sizeof(*dire);
+			}
+
+			if (!squashfs_get_cached_block(i->i_sb, dire->name,
+						next_block, next_offset,
+						dire->size + 1, &next_block,
+						&next_offset))
+				goto failed_read;
+
+			length += dire->size + 1;
+
+			if (file->f_pos >= length)
+				continue;
+
+			dire->name[dire->size + 1] = '\0';
+
+			TRACE("Calling filldir(%x, %s, %d, %d, %x:%x, %d)\n",
+					(unsigned int) dirent, dire->name,
+					dire->size + 1, (int) file->f_pos,
+					dirh.start_block, dire->offset,
+					squashfs_filetype_table[dire->type]);
+
+			if (filldir(dirent, dire->name, dire->size + 1,
+					file->f_pos, SQUASHFS_MK_VFS_INODE(
+					dirh.start_block, dire->offset),
+					squashfs_filetype_table[dire->type])
+					< 0) {
+				TRACE("Filldir returned less than 0\n");
+				goto finish;
+			}
+			file->f_pos = length;
+		}
+	}
+
+finish:
+	kfree(dire);
+	return 0;
+
+failed_read:
+	ERROR("Unable to read directory block [%llx:%x]\n", next_block,
+		next_offset);
+	kfree(dire);
+	return 0;
+}
+
+
+static struct dentry *squashfs_lookup_2(struct inode *i, struct dentry *dentry,
+				struct nameidata *nd)
+{
+	const unsigned char *name = dentry->d_name.name;
+	int len = dentry->d_name.len;
+	struct inode *inode = NULL;
+	struct squashfs_sb_info *msblk = i->i_sb->s_fs_info;
+	struct squashfs_super_block *sblk = &msblk->sblk;
+	long long next_block = SQUASHFS_I(i)->start_block +
+				sblk->directory_table_start;
+	int next_offset = SQUASHFS_I(i)->offset, length = 0,
+				dir_count;
+	struct squashfs_dir_header_2 dirh;
+	struct squashfs_dir_entry_2 *dire;
+	int sorted = sblk->s_major == 2 && sblk->s_minor >= 1;
+
+	TRACE("Entered squashfs_lookup_2 [%llx:%x]\n", next_block, next_offset);
+
+	if (!(dire = kmalloc(sizeof(struct squashfs_dir_entry) +
+		SQUASHFS_NAME_LEN + 1, GFP_KERNEL))) {
+		ERROR("Failed to allocate squashfs_dir_entry\n");
+		goto exit_loop;
+	}
+
+	if (len > SQUASHFS_NAME_LEN)
+		goto exit_loop;
+
+	length = get_dir_index_using_name(i->i_sb, &next_block, &next_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_start,
+				SQUASHFS_I(i)->u.s2.directory_index_offset,
+				SQUASHFS_I(i)->u.s2.directory_index_count, name,
+				len);
+
+	while (length < i_size_read(i)) {
+		/* read directory header */
+		if (msblk->swap) {
+			struct squashfs_dir_header_2 sdirh;
+			if (!squashfs_get_cached_block(i->i_sb, (char *) &sdirh,
+					next_block, next_offset, sizeof(sdirh),
+					&next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(sdirh);
+			SQUASHFS_SWAP_DIR_HEADER_2(&dirh, &sdirh);
+		} else {
+			if (!squashfs_get_cached_block(i->i_sb, (char *) &dirh,
+					next_block, next_offset, sizeof(dirh),
+					&next_block, &next_offset))
+				goto failed_read;
+
+			length += sizeof(dirh);
+		}
+
+		dir_count = dirh.count + 1;
+		while (dir_count--) {
+			if (msblk->swap) {
+				struct squashfs_dir_entry_2 sdire;
+				if (!squashfs_get_cached_block(i->i_sb, (char *)
+						&sdire, next_block,next_offset,
+						sizeof(sdire), &next_block,
+						&next_offset))
+					goto failed_read;
+				
+				length += sizeof(sdire);
+				SQUASHFS_SWAP_DIR_ENTRY_2(dire, &sdire);
+			} else {
+				if (!squashfs_get_cached_block(i->i_sb, (char *)
+						dire, next_block,next_offset,
+						sizeof(*dire), &next_block,
+						&next_offset))
+					goto failed_read;
+
+				length += sizeof(*dire);
+			}
+
+			if (!squashfs_get_cached_block(i->i_sb, dire->name,
+					next_block, next_offset, dire->size + 1,
+					&next_block, &next_offset))
+				goto failed_read;
+
+			length += dire->size + 1;
+
+			if (sorted && name[0] < dire->name[0])
+				goto exit_loop;
+
+			if ((len == dire->size + 1) && !strncmp(name,
+						dire->name, len)) {
+				squashfs_inode_t ino =
+					SQUASHFS_MKINODE(dirh.start_block,
+					dire->offset);
+				unsigned int inode_number = SQUASHFS_MK_VFS_INODE(dirh.start_block,
+					dire->offset);
+
+				TRACE("calling squashfs_iget for directory "
+					"entry %s, inode %x:%x, %lld\n", name,
+					dirh.start_block, dire->offset, ino);
+
+				inode = squashfs_iget(i->i_sb, ino, inode_number);
+
+				goto exit_loop;
+			}
+		}
+	}
+
+exit_loop:
+	kfree(dire);
+	d_add(dentry, inode);
+	return ERR_PTR(0);
+
+failed_read:
+	ERROR("Unable to read directory block [%llx:%x]\n", next_block,
+		next_offset);
+	goto exit_loop;
+}
+
+
+int squashfs_2_0_supported(struct squashfs_sb_info *msblk)
+{
+	struct squashfs_super_block *sblk = &msblk->sblk;
+
+	msblk->read_inode = squashfs_read_inode_2;
+	msblk->read_fragment_index_table = read_fragment_index_table_2;
+
+	sblk->bytes_used = sblk->bytes_used_2;
+	sblk->uid_start = sblk->uid_start_2;
+	sblk->guid_start = sblk->guid_start_2;
+	sblk->inode_table_start = sblk->inode_table_start_2;
+	sblk->directory_table_start = sblk->directory_table_start_2;
+	sblk->fragment_table_start = sblk->fragment_table_start_2;
+
+	return 1;
+}
diff -Naur linux-2.6.30-ori/fs/squashfs/squashfs_fs.h linux-2.6.30-test/fs/squashfs/squashfs_fs.h
--- linux-2.6.30-ori/fs/squashfs/squashfs_fs.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/squashfs_fs.h	2009-06-15 11:25:12.000000000 -0400
@@ -1,9 +1,10 @@
 #ifndef SQUASHFS_FS
 #define SQUASHFS_FS
+
 /*
  * Squashfs
  *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
+ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007
  * Phillip Lougher <phillip@lougher.demon.co.uk>
  *
  * This program is free software; you can redistribute it and/or
@@ -18,14 +19,20 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * squashfs_fs.h
  */
 
-#define SQUASHFS_CACHED_FRAGMENTS	CONFIG_SQUASHFS_FRAGMENT_CACHE_SIZE
-#define SQUASHFS_MAJOR			4
-#define SQUASHFS_MINOR			0
+#ifndef CONFIG_SQUASHFS_2_0_COMPATIBILITY
+#define CONFIG_SQUASHFS_2_0_COMPATIBILITY
+#endif
+
+#define SQUASHFS_CACHED_FRAGMENTS	CONFIG_SQUASHFS_FRAGMENT_CACHE_SIZE	
+#define SQUASHFS_MAJOR			3
+#define SQUASHFS_MINOR			1
+#define SQUASHFS_MAGIC			0x73717368
+#define SQUASHFS_MAGIC_SWAP		0x68737173
 #define SQUASHFS_START			0
 
 /* size of metadata (inode and directory) blocks */
@@ -37,20 +44,23 @@
 #define SQUASHFS_FILE_LOG		17
 
 #define SQUASHFS_FILE_MAX_SIZE		1048576
-#define SQUASHFS_FILE_MAX_LOG		20
 
 /* Max number of uids and gids */
-#define SQUASHFS_IDS			65536
+#define SQUASHFS_UIDS			256
+#define SQUASHFS_GUIDS			255
 
 /* Max length of filename (not 255) */
 #define SQUASHFS_NAME_LEN		256
 
-#define SQUASHFS_INVALID_FRAG		(0xffffffffU)
-#define SQUASHFS_INVALID_BLK		(-1LL)
+#define SQUASHFS_INVALID		((long long) 0xffffffffffff)
+#define SQUASHFS_INVALID_FRAG		((unsigned int) 0xffffffff)
+#define SQUASHFS_INVALID_BLK		((long long) -1)
+#define SQUASHFS_USED_BLK		((long long) -2)
 
 /* Filesystem flags */
 #define SQUASHFS_NOI			0
 #define SQUASHFS_NOD			1
+#define SQUASHFS_CHECK			2
 #define SQUASHFS_NOF			3
 #define SQUASHFS_NO_FRAG		4
 #define SQUASHFS_ALWAYS_FRAG		5
@@ -80,9 +90,17 @@
 #define SQUASHFS_EXPORTABLE(flags)		SQUASHFS_BIT(flags, \
 						SQUASHFS_EXPORT)
 
+#define SQUASHFS_CHECK_DATA(flags)		SQUASHFS_BIT(flags, \
+						SQUASHFS_CHECK)
+
+#define SQUASHFS_MKFLAGS(noi, nod, check_data, nof, no_frag, always_frag, \
+		duplicate_checking, exortable)	(noi | (nod << 1) | (check_data << 2) \
+		| (nof << 3) | (no_frag << 4) | (always_frag << 5) | \
+		(duplicate_checking << 6) | (exportable << 7))
+
 /* Max number of types and file types */
 #define SQUASHFS_DIR_TYPE		1
-#define SQUASHFS_REG_TYPE		2
+#define SQUASHFS_FILE_TYPE		2
 #define SQUASHFS_SYMLINK_TYPE		3
 #define SQUASHFS_BLKDEV_TYPE		4
 #define SQUASHFS_CHRDEV_TYPE		5
@@ -90,11 +108,10 @@
 #define SQUASHFS_SOCKET_TYPE		7
 #define SQUASHFS_LDIR_TYPE		8
 #define SQUASHFS_LREG_TYPE		9
-#define SQUASHFS_LSYMLINK_TYPE		10
-#define SQUASHFS_LBLKDEV_TYPE		11
-#define SQUASHFS_LCHRDEV_TYPE		12
-#define SQUASHFS_LFIFO_TYPE		13
-#define SQUASHFS_LSOCKET_TYPE		14
+
+/* 1.0 filesystem type definitions */
+#define SQUASHFS_TYPES			5
+#define SQUASHFS_IPC_TYPE		0
 
 /* Flag whether block is compressed or uncompressed, bit is set if block is
  * uncompressed */
@@ -105,30 +122,34 @@
 
 #define SQUASHFS_COMPRESSED(B)		(!((B) & SQUASHFS_COMPRESSED_BIT))
 
-#define SQUASHFS_COMPRESSED_BIT_BLOCK	(1 << 24)
+#define SQUASHFS_COMPRESSED_BIT_BLOCK		(1 << 24)
 
 #define SQUASHFS_COMPRESSED_SIZE_BLOCK(B)	((B) & \
-						~SQUASHFS_COMPRESSED_BIT_BLOCK)
+	~SQUASHFS_COMPRESSED_BIT_BLOCK)
 
 #define SQUASHFS_COMPRESSED_BLOCK(B)	(!((B) & SQUASHFS_COMPRESSED_BIT_BLOCK))
 
 /*
  * Inode number ops.  Inodes consist of a compressed block number, and an
- * uncompressed offset within that block
+ * uncompressed  offset within that block
  */
-#define SQUASHFS_INODE_BLK(A)		((unsigned int) ((A) >> 16))
+#define SQUASHFS_INODE_BLK(a)		((unsigned int) ((a) >> 16))
 
-#define SQUASHFS_INODE_OFFSET(A)	((unsigned int) ((A) & 0xffff))
+#define SQUASHFS_INODE_OFFSET(a)	((unsigned int) ((a) & 0xffff))
 
-#define SQUASHFS_MKINODE(A, B)		((long long)(((long long) (A)\
+#define SQUASHFS_MKINODE(A, B)		((squashfs_inode_t)(((squashfs_inode_t) (A)\
 					<< 16) + (B)))
 
+/* Compute 32 bit VFS inode number from squashfs inode number */
+#define SQUASHFS_MK_VFS_INODE(a, b)	((unsigned int) (((a) << 8) + \
+					((b) >> 2) + 1))
+/* XXX */
+
 /* Translate between VFS mode and squashfs mode */
-#define SQUASHFS_MODE(A)		((A) & 0xfff)
+#define SQUASHFS_MODE(a)		((a) & 0xfff)
 
 /* fragment and fragment table defines */
-#define SQUASHFS_FRAGMENT_BYTES(A)	\
-				((A) * sizeof(struct squashfs_fragment_entry))
+#define SQUASHFS_FRAGMENT_BYTES(A)	((A) * sizeof(struct squashfs_fragment_entry))
 
 #define SQUASHFS_FRAGMENT_INDEX(A)	(SQUASHFS_FRAGMENT_BYTES(A) / \
 					SQUASHFS_METADATA_SIZE)
@@ -141,57 +162,42 @@
 					SQUASHFS_METADATA_SIZE)
 
 #define SQUASHFS_FRAGMENT_INDEX_BYTES(A)	(SQUASHFS_FRAGMENT_INDEXES(A) *\
-						sizeof(u64))
+						sizeof(long long))
 
 /* inode lookup table defines */
-#define SQUASHFS_LOOKUP_BYTES(A)	((A) * sizeof(u64))
+#define SQUASHFS_LOOKUP_BYTES(A)	((A) * sizeof(squashfs_inode_t))
 
-#define SQUASHFS_LOOKUP_BLOCK(A)	(SQUASHFS_LOOKUP_BYTES(A) / \
-					SQUASHFS_METADATA_SIZE)
+#define SQUASHFS_LOOKUP_BLOCK(A)		(SQUASHFS_LOOKUP_BYTES(A) / \
+						SQUASHFS_METADATA_SIZE)
 
-#define SQUASHFS_LOOKUP_BLOCK_OFFSET(A)	(SQUASHFS_LOOKUP_BYTES(A) % \
-					SQUASHFS_METADATA_SIZE)
+#define SQUASHFS_LOOKUP_BLOCK_OFFSET(A)		(SQUASHFS_LOOKUP_BYTES(A) % \
+						SQUASHFS_METADATA_SIZE)
 
 #define SQUASHFS_LOOKUP_BLOCKS(A)	((SQUASHFS_LOOKUP_BYTES(A) + \
 					SQUASHFS_METADATA_SIZE - 1) / \
 					SQUASHFS_METADATA_SIZE)
 
 #define SQUASHFS_LOOKUP_BLOCK_BYTES(A)	(SQUASHFS_LOOKUP_BLOCKS(A) *\
-					sizeof(u64))
-
-/* uid/gid lookup table defines */
-#define SQUASHFS_ID_BYTES(A)		((A) * sizeof(unsigned int))
-
-#define SQUASHFS_ID_BLOCK(A)		(SQUASHFS_ID_BYTES(A) / \
-					SQUASHFS_METADATA_SIZE)
-
-#define SQUASHFS_ID_BLOCK_OFFSET(A)	(SQUASHFS_ID_BYTES(A) % \
-					SQUASHFS_METADATA_SIZE)
-
-#define SQUASHFS_ID_BLOCKS(A)		((SQUASHFS_ID_BYTES(A) + \
-					SQUASHFS_METADATA_SIZE - 1) / \
-					SQUASHFS_METADATA_SIZE)
-
-#define SQUASHFS_ID_BLOCK_BYTES(A)	(SQUASHFS_ID_BLOCKS(A) *\
-					sizeof(u64))
+					sizeof(long long))
 
 /* cached data constants for filesystem */
 #define SQUASHFS_CACHED_BLKS		8
 
 #define SQUASHFS_MAX_FILE_SIZE_LOG	64
 
-#define SQUASHFS_MAX_FILE_SIZE		(1LL << \
+#define SQUASHFS_MAX_FILE_SIZE		((long long) 1 << \
 					(SQUASHFS_MAX_FILE_SIZE_LOG - 2))
 
 #define SQUASHFS_MARKER_BYTE		0xff
 
 /* meta index cache */
 #define SQUASHFS_META_INDEXES	(SQUASHFS_METADATA_SIZE / sizeof(unsigned int))
-#define SQUASHFS_META_ENTRIES	127
-#define SQUASHFS_META_SLOTS	8
+#define SQUASHFS_META_ENTRIES	31
+#define SQUASHFS_META_NUMBER	8
+#define SQUASHFS_SLOTS		4
 
 struct meta_entry {
-	u64			data_block;
+	long long		data_block;
 	unsigned int		index_block;
 	unsigned short		offset;
 	unsigned short		pad;
@@ -211,170 +217,719 @@
 /*
  * definitions for structures on disk
  */
-#define ZLIB_COMPRESSION	 1
+
+typedef long long		squashfs_block_t;
+typedef long long		squashfs_inode_t;
 
 struct squashfs_super_block {
-	__le32			s_magic;
-	__le32			inodes;
-	__le32			mkfs_time;
-	__le32			block_size;
-	__le32			fragments;
-	__le16			compression;
-	__le16			block_log;
-	__le16			flags;
-	__le16			no_ids;
-	__le16			s_major;
-	__le16			s_minor;
-	__le64			root_inode;
-	__le64			bytes_used;
-	__le64			id_table_start;
-	__le64			xattr_table_start;
-	__le64			inode_table_start;
-	__le64			directory_table_start;
-	__le64			fragment_table_start;
-	__le64			lookup_table_start;
-};
+	unsigned int		s_magic;
+	unsigned int		inodes;
+	unsigned int		bytes_used_2;
+	unsigned int		uid_start_2;
+	unsigned int		guid_start_2;
+	unsigned int		inode_table_start_2;
+	unsigned int		directory_table_start_2;
+	unsigned int		s_major:16;
+	unsigned int		s_minor:16;
+	unsigned int		block_size_1:16;
+	unsigned int		block_log:16;
+	unsigned int		flags:8;
+	unsigned int		no_uids:8;
+	unsigned int		no_guids:8;
+	unsigned int		mkfs_time /* time of filesystem creation */;
+	squashfs_inode_t	root_inode;
+	unsigned int		block_size;
+	unsigned int		fragments;
+	unsigned int		fragment_table_start_2;
+	long long		bytes_used;
+	long long		uid_start;
+	long long		guid_start;
+	long long		inode_table_start;
+	long long		directory_table_start;
+	long long		fragment_table_start;
+	long long		lookup_table_start;
+} __attribute__ ((packed));
 
 struct squashfs_dir_index {
-	__le32			index;
-	__le32			start_block;
-	__le32			size;
+	unsigned int		index;
+	unsigned int		start_block;
+	unsigned char		size;
 	unsigned char		name[0];
-};
+} __attribute__ ((packed));
 
-struct squashfs_base_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-};
+#define SQUASHFS_BASE_INODE_HEADER		\
+	unsigned int		inode_type:4;	\
+	unsigned int		mode:12;	\
+	unsigned int		uid:8;		\
+	unsigned int		guid:8;		\
+	unsigned int		mtime;		\
+	unsigned int 		inode_number;
+
+struct squashfs_base_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+} __attribute__ ((packed));
+
+struct squashfs_ipc_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+} __attribute__ ((packed));
+
+struct squashfs_dev_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+	unsigned short		rdev;
+} __attribute__ ((packed));
+	
+struct squashfs_symlink_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+	unsigned short		symlink_size;
+	char			symlink[0];
+} __attribute__ ((packed));
 
-struct squashfs_ipc_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			nlink;
-};
+struct squashfs_reg_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	squashfs_block_t	start_block;
+	unsigned int		fragment;
+	unsigned int		offset;
+	unsigned int		file_size;
+	unsigned short		block_list[0];
+} __attribute__ ((packed));
+
+struct squashfs_lreg_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+	squashfs_block_t	start_block;
+	unsigned int		fragment;
+	unsigned int		offset;
+	long long		file_size;
+	unsigned short		block_list[0];
+} __attribute__ ((packed));
+
+struct squashfs_dir_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+	unsigned int		file_size:19;
+	unsigned int		offset:13;
+	unsigned int		start_block;
+	unsigned int		parent_inode;
+} __attribute__  ((packed));
+
+struct squashfs_ldir_inode_header {
+	SQUASHFS_BASE_INODE_HEADER;
+	unsigned int		nlink;
+	unsigned int		file_size:27;
+	unsigned int		offset:13;
+	unsigned int		start_block;
+	unsigned int		i_count:16;
+	unsigned int		parent_inode;
+	struct squashfs_dir_index	index[0];
+} __attribute__  ((packed));
 
-struct squashfs_dev_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			nlink;
-	__le32			rdev;
+union squashfs_inode_header {
+	struct squashfs_base_inode_header	base;
+	struct squashfs_dev_inode_header	dev;
+	struct squashfs_symlink_inode_header	symlink;
+	struct squashfs_reg_inode_header	reg;
+	struct squashfs_lreg_inode_header	lreg;
+	struct squashfs_dir_inode_header	dir;
+	struct squashfs_ldir_inode_header	ldir;
+	struct squashfs_ipc_inode_header	ipc;
 };
+	
+struct squashfs_dir_entry {
+	unsigned int		offset:13;
+	unsigned int		type:3;
+	unsigned int		size:8;
+	signed int		inode_number:16; /* very important signedness */
+	char			name[0];
+} __attribute__ ((packed));
+
+struct squashfs_dir_header {
+	unsigned int		count:8;
+	unsigned int		start_block;
+	unsigned int		inode_number;
+} __attribute__ ((packed));
+
+struct squashfs_fragment_entry {
+	long long		start_block;
+	unsigned int		size;
+	unsigned int		pending;
+} __attribute__ ((packed));
+
+extern int squashfs_uncompress_block(void *d, int dstlen, void *s, int srclen);
+extern int squashfs_uncompress_init(void);
+extern int squashfs_uncompress_exit(void);
+
+/*
+ * macros to convert each packed bitfield structure from little endian to big
+ * endian and vice versa.  These are needed when creating or using a filesystem
+ * on a machine with different byte ordering to the target architecture.
+ *
+ */
 
-struct squashfs_symlink_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			nlink;
-	__le32			symlink_size;
+#define SQUASHFS_SWAP_START \
+	int bits;\
+	int b_pos;\
+	unsigned long long val;\
+	unsigned char *s;\
+	unsigned char *d;
+
+#define SQUASHFS_SWAP_SUPER_BLOCK(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_super_block));\
+	SQUASHFS_SWAP((s)->s_magic, d, 0, 32);\
+	SQUASHFS_SWAP((s)->inodes, d, 32, 32);\
+	SQUASHFS_SWAP((s)->bytes_used_2, d, 64, 32);\
+	SQUASHFS_SWAP((s)->uid_start_2, d, 96, 32);\
+	SQUASHFS_SWAP((s)->guid_start_2, d, 128, 32);\
+	SQUASHFS_SWAP((s)->inode_table_start_2, d, 160, 32);\
+	SQUASHFS_SWAP((s)->directory_table_start_2, d, 192, 32);\
+	SQUASHFS_SWAP((s)->s_major, d, 224, 16);\
+	SQUASHFS_SWAP((s)->s_minor, d, 240, 16);\
+	SQUASHFS_SWAP((s)->block_size_1, d, 256, 16);\
+	SQUASHFS_SWAP((s)->block_log, d, 272, 16);\
+	SQUASHFS_SWAP((s)->flags, d, 288, 8);\
+	SQUASHFS_SWAP((s)->no_uids, d, 296, 8);\
+	SQUASHFS_SWAP((s)->no_guids, d, 304, 8);\
+	SQUASHFS_SWAP((s)->mkfs_time, d, 312, 32);\
+	SQUASHFS_SWAP((s)->root_inode, d, 344, 64);\
+	SQUASHFS_SWAP((s)->block_size, d, 408, 32);\
+	SQUASHFS_SWAP((s)->fragments, d, 440, 32);\
+	SQUASHFS_SWAP((s)->fragment_table_start_2, d, 472, 32);\
+	SQUASHFS_SWAP((s)->bytes_used, d, 504, 64);\
+	SQUASHFS_SWAP((s)->uid_start, d, 568, 64);\
+	SQUASHFS_SWAP((s)->guid_start, d, 632, 64);\
+	SQUASHFS_SWAP((s)->inode_table_start, d, 696, 64);\
+	SQUASHFS_SWAP((s)->directory_table_start, d, 760, 64);\
+	SQUASHFS_SWAP((s)->fragment_table_start, d, 824, 64);\
+	SQUASHFS_SWAP((s)->lookup_table_start, d, 888, 64);\
+}
+
+#define SQUASHFS_SWAP_BASE_INODE_CORE(s, d, n)\
+	SQUASHFS_MEMSET(s, d, n);\
+	SQUASHFS_SWAP((s)->inode_type, d, 0, 4);\
+	SQUASHFS_SWAP((s)->mode, d, 4, 12);\
+	SQUASHFS_SWAP((s)->uid, d, 16, 8);\
+	SQUASHFS_SWAP((s)->guid, d, 24, 8);\
+	SQUASHFS_SWAP((s)->mtime, d, 32, 32);\
+	SQUASHFS_SWAP((s)->inode_number, d, 64, 32);
+
+#define SQUASHFS_SWAP_BASE_INODE_HEADER(s, d, n) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, n)\
+}
+
+#define SQUASHFS_SWAP_IPC_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_ipc_inode_header))\
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+}
+
+#define SQUASHFS_SWAP_DEV_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_dev_inode_header)); \
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+	SQUASHFS_SWAP((s)->rdev, d, 128, 16);\
+}
+
+#define SQUASHFS_SWAP_SYMLINK_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_symlink_inode_header));\
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+	SQUASHFS_SWAP((s)->symlink_size, d, 128, 16);\
+}
+
+#define SQUASHFS_SWAP_REG_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_reg_inode_header));\
+	SQUASHFS_SWAP((s)->start_block, d, 96, 64);\
+	SQUASHFS_SWAP((s)->fragment, d, 160, 32);\
+	SQUASHFS_SWAP((s)->offset, d, 192, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 224, 32);\
+}
+
+#define SQUASHFS_SWAP_LREG_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_lreg_inode_header));\
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 128, 64);\
+	SQUASHFS_SWAP((s)->fragment, d, 192, 32);\
+	SQUASHFS_SWAP((s)->offset, d, 224, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 256, 64);\
+}
+
+#define SQUASHFS_SWAP_DIR_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_dir_inode_header));\
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 128, 19);\
+	SQUASHFS_SWAP((s)->offset, d, 147, 13);\
+	SQUASHFS_SWAP((s)->start_block, d, 160, 32);\
+	SQUASHFS_SWAP((s)->parent_inode, d, 192, 32);\
+}
+
+#define SQUASHFS_SWAP_LDIR_INODE_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE(s, d, \
+			sizeof(struct squashfs_ldir_inode_header));\
+	SQUASHFS_SWAP((s)->nlink, d, 96, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 128, 27);\
+	SQUASHFS_SWAP((s)->offset, d, 155, 13);\
+	SQUASHFS_SWAP((s)->start_block, d, 168, 32);\
+	SQUASHFS_SWAP((s)->i_count, d, 200, 16);\
+	SQUASHFS_SWAP((s)->parent_inode, d, 216, 32);\
+}
+
+#define SQUASHFS_SWAP_DIR_INDEX(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_index));\
+	SQUASHFS_SWAP((s)->index, d, 0, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 32, 32);\
+	SQUASHFS_SWAP((s)->size, d, 64, 8);\
+}
+
+#define SQUASHFS_SWAP_DIR_HEADER(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_header));\
+	SQUASHFS_SWAP((s)->count, d, 0, 8);\
+	SQUASHFS_SWAP((s)->start_block, d, 8, 32);\
+	SQUASHFS_SWAP((s)->inode_number, d, 40, 32);\
+}
+
+#define SQUASHFS_SWAP_DIR_ENTRY(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_entry));\
+	SQUASHFS_SWAP((s)->offset, d, 0, 13);\
+	SQUASHFS_SWAP((s)->type, d, 13, 3);\
+	SQUASHFS_SWAP((s)->size, d, 16, 8);\
+	SQUASHFS_SWAP((s)->inode_number, d, 24, 16);\
+}
+
+#define SQUASHFS_SWAP_FRAGMENT_ENTRY(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_fragment_entry));\
+	SQUASHFS_SWAP((s)->start_block, d, 0, 64);\
+	SQUASHFS_SWAP((s)->size, d, 64, 32);\
+}
+
+#define SQUASHFS_SWAP_INODE_T(s, d) SQUASHFS_SWAP_LONG_LONGS(s, d, 1)
+
+#define SQUASHFS_SWAP_SHORTS(s, d, n) {\
+	int entry;\
+	int bit_position;\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, n * 2);\
+	for(entry = 0, bit_position = 0; entry < n; entry++, bit_position += \
+			16)\
+		SQUASHFS_SWAP(s[entry], d, bit_position, 16);\
+}
+
+#define SQUASHFS_SWAP_INTS(s, d, n) {\
+	int entry;\
+	int bit_position;\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, n * 4);\
+	for(entry = 0, bit_position = 0; entry < n; entry++, bit_position += \
+			32)\
+		SQUASHFS_SWAP(s[entry], d, bit_position, 32);\
+}
+
+#define SQUASHFS_SWAP_LONG_LONGS(s, d, n) {\
+	int entry;\
+	int bit_position;\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, n * 8);\
+	for(entry = 0, bit_position = 0; entry < n; entry++, bit_position += \
+			64)\
+		SQUASHFS_SWAP(s[entry], d, bit_position, 64);\
+}
+
+#define SQUASHFS_SWAP_DATA(s, d, n, bits) {\
+	int entry;\
+	int bit_position;\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, n * bits / 8);\
+	for(entry = 0, bit_position = 0; entry < n; entry++, bit_position += \
+			bits)\
+		SQUASHFS_SWAP(s[entry], d, bit_position, bits);\
+}
+
+#define SQUASHFS_SWAP_FRAGMENT_INDEXES(s, d, n) SQUASHFS_SWAP_LONG_LONGS(s, d, n)
+#define SQUASHFS_SWAP_LOOKUP_BLOCKS(s, d, n) SQUASHFS_SWAP_LONG_LONGS(s, d, n)
+
+#ifdef CONFIG_SQUASHFS_1_0_COMPATIBILITY
+
+struct squashfs_base_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+} __attribute__ ((packed));
+
+struct squashfs_ipc_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+	unsigned int		type:4;
+	unsigned int		offset:4;
+} __attribute__ ((packed));
+
+struct squashfs_dev_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+	unsigned short		rdev;
+} __attribute__ ((packed));
+	
+struct squashfs_symlink_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+	unsigned short		symlink_size;
 	char			symlink[0];
-};
+} __attribute__ ((packed));
 
-struct squashfs_reg_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			start_block;
-	__le32			fragment;
-	__le32			offset;
-	__le32			file_size;
-	__le16			block_list[0];
-};
+struct squashfs_reg_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+	unsigned int		mtime;
+	unsigned int		start_block;
+	unsigned int		file_size:32;
+	unsigned short		block_list[0];
+} __attribute__ ((packed));
+
+struct squashfs_dir_inode_header_1 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:4; /* index into uid table */
+	unsigned int		guid:4; /* index into guid table */
+	unsigned int		file_size:19;
+	unsigned int		offset:13;
+	unsigned int		mtime;
+	unsigned int		start_block:24;
+} __attribute__  ((packed));
+
+union squashfs_inode_header_1 {
+	struct squashfs_base_inode_header_1	base;
+	struct squashfs_dev_inode_header_1	dev;
+	struct squashfs_symlink_inode_header_1	symlink;
+	struct squashfs_reg_inode_header_1	reg;
+	struct squashfs_dir_inode_header_1	dir;
+	struct squashfs_ipc_inode_header_1	ipc;
+};
+
+#define SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, n) \
+	SQUASHFS_MEMSET(s, d, n);\
+	SQUASHFS_SWAP((s)->inode_type, d, 0, 4);\
+	SQUASHFS_SWAP((s)->mode, d, 4, 12);\
+	SQUASHFS_SWAP((s)->uid, d, 16, 4);\
+	SQUASHFS_SWAP((s)->guid, d, 20, 4);
+
+#define SQUASHFS_SWAP_BASE_INODE_HEADER_1(s, d, n) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, n)\
+}
+
+#define SQUASHFS_SWAP_IPC_INODE_HEADER_1(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, \
+			sizeof(struct squashfs_ipc_inode_header_1));\
+	SQUASHFS_SWAP((s)->type, d, 24, 4);\
+	SQUASHFS_SWAP((s)->offset, d, 28, 4);\
+}
+
+#define SQUASHFS_SWAP_DEV_INODE_HEADER_1(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, \
+			sizeof(struct squashfs_dev_inode_header_1));\
+	SQUASHFS_SWAP((s)->rdev, d, 24, 16);\
+}
+
+#define SQUASHFS_SWAP_SYMLINK_INODE_HEADER_1(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, \
+			sizeof(struct squashfs_symlink_inode_header_1));\
+	SQUASHFS_SWAP((s)->symlink_size, d, 24, 16);\
+}
+
+#define SQUASHFS_SWAP_REG_INODE_HEADER_1(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, \
+			sizeof(struct squashfs_reg_inode_header_1));\
+	SQUASHFS_SWAP((s)->mtime, d, 24, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 56, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 88, 32);\
+}
+
+#define SQUASHFS_SWAP_DIR_INODE_HEADER_1(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_1(s, d, \
+			sizeof(struct squashfs_dir_inode_header_1));\
+	SQUASHFS_SWAP((s)->file_size, d, 24, 19);\
+	SQUASHFS_SWAP((s)->offset, d, 43, 13);\
+	SQUASHFS_SWAP((s)->mtime, d, 56, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 88, 24);\
+}
 
-struct squashfs_lreg_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le64			start_block;
-	__le64			file_size;
-	__le64			sparse;
-	__le32			nlink;
-	__le32			fragment;
-	__le32			offset;
-	__le32			xattr;
-	__le16			block_list[0];
-};
+#endif
 
-struct squashfs_dir_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			start_block;
-	__le32			nlink;
-	__le16			file_size;
-	__le16			offset;
-	__le32			parent_inode;
-};
+#ifdef CONFIG_SQUASHFS_2_0_COMPATIBILITY
 
-struct squashfs_ldir_inode {
-	__le16			inode_type;
-	__le16			mode;
-	__le16			uid;
-	__le16			guid;
-	__le32			mtime;
-	__le32	 		inode_number;
-	__le32			nlink;
-	__le32			file_size;
-	__le32			start_block;
-	__le32			parent_inode;
-	__le16			i_count;
-	__le16			offset;
-	__le32			xattr;
-	struct squashfs_dir_index	index[0];
-};
+struct squashfs_dir_index_2 {
+	unsigned int		index:27;
+	unsigned int		start_block:29;
+	unsigned char		size;
+	unsigned char		name[0];
+} __attribute__ ((packed));
 
-union squashfs_inode {
-	struct squashfs_base_inode		base;
-	struct squashfs_dev_inode		dev;
-	struct squashfs_symlink_inode		symlink;
-	struct squashfs_reg_inode		reg;
-	struct squashfs_lreg_inode		lreg;
-	struct squashfs_dir_inode		dir;
-	struct squashfs_ldir_inode		ldir;
-	struct squashfs_ipc_inode		ipc;
-};
+struct squashfs_base_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+} __attribute__ ((packed));
+
+struct squashfs_ipc_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+} __attribute__ ((packed));
+
+struct squashfs_dev_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+	unsigned short		rdev;
+} __attribute__ ((packed));
+	
+struct squashfs_symlink_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+	unsigned short		symlink_size;
+	char			symlink[0];
+} __attribute__ ((packed));
 
-struct squashfs_dir_entry {
-	__le16			offset;
-	__le16			inode_number;
-	__le16			type;
-	__le16			size;
+struct squashfs_reg_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+	unsigned int		mtime;
+	unsigned int		start_block;
+	unsigned int		fragment;
+	unsigned int		offset;
+	unsigned int		file_size:32;
+	unsigned short		block_list[0];
+} __attribute__ ((packed));
+
+struct squashfs_dir_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+	unsigned int		file_size:19;
+	unsigned int		offset:13;
+	unsigned int		mtime;
+	unsigned int		start_block:24;
+} __attribute__  ((packed));
+
+struct squashfs_ldir_inode_header_2 {
+	unsigned int		inode_type:4;
+	unsigned int		mode:12; /* protection */
+	unsigned int		uid:8; /* index into uid table */
+	unsigned int		guid:8; /* index into guid table */
+	unsigned int		file_size:27;
+	unsigned int		offset:13;
+	unsigned int		mtime;
+	unsigned int		start_block:24;
+	unsigned int		i_count:16;
+	struct squashfs_dir_index_2	index[0];
+} __attribute__  ((packed));
+
+union squashfs_inode_header_2 {
+	struct squashfs_base_inode_header_2	base;
+	struct squashfs_dev_inode_header_2	dev;
+	struct squashfs_symlink_inode_header_2	symlink;
+	struct squashfs_reg_inode_header_2	reg;
+	struct squashfs_dir_inode_header_2	dir;
+	struct squashfs_ldir_inode_header_2	ldir;
+	struct squashfs_ipc_inode_header_2	ipc;
+};
+	
+struct squashfs_dir_header_2 {
+	unsigned int		count:8;
+	unsigned int		start_block:24;
+} __attribute__ ((packed));
+
+struct squashfs_dir_entry_2 {
+	unsigned int		offset:13;
+	unsigned int		type:3;
+	unsigned int		size:8;
 	char			name[0];
-};
+} __attribute__ ((packed));
 
-struct squashfs_dir_header {
-	__le32			count;
-	__le32			start_block;
-	__le32			inode_number;
-};
+struct squashfs_fragment_entry_2 {
+	unsigned int		start_block;
+	unsigned int		size;
+} __attribute__ ((packed));
+
+#define SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, n)\
+	SQUASHFS_MEMSET(s, d, n);\
+	SQUASHFS_SWAP((s)->inode_type, d, 0, 4);\
+	SQUASHFS_SWAP((s)->mode, d, 4, 12);\
+	SQUASHFS_SWAP((s)->uid, d, 16, 8);\
+	SQUASHFS_SWAP((s)->guid, d, 24, 8);\
+
+#define SQUASHFS_SWAP_BASE_INODE_HEADER_2(s, d, n) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, n)\
+}
+
+#define SQUASHFS_SWAP_IPC_INODE_HEADER_2(s, d) \
+	SQUASHFS_SWAP_BASE_INODE_HEADER_2(s, d, sizeof(struct squashfs_ipc_inode_header_2))
+
+#define SQUASHFS_SWAP_DEV_INODE_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, \
+			sizeof(struct squashfs_dev_inode_header_2)); \
+	SQUASHFS_SWAP((s)->rdev, d, 32, 16);\
+}
+
+#define SQUASHFS_SWAP_SYMLINK_INODE_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, \
+			sizeof(struct squashfs_symlink_inode_header_2));\
+	SQUASHFS_SWAP((s)->symlink_size, d, 32, 16);\
+}
+
+#define SQUASHFS_SWAP_REG_INODE_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, \
+			sizeof(struct squashfs_reg_inode_header_2));\
+	SQUASHFS_SWAP((s)->mtime, d, 32, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 64, 32);\
+	SQUASHFS_SWAP((s)->fragment, d, 96, 32);\
+	SQUASHFS_SWAP((s)->offset, d, 128, 32);\
+	SQUASHFS_SWAP((s)->file_size, d, 160, 32);\
+}
+
+#define SQUASHFS_SWAP_DIR_INODE_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, \
+			sizeof(struct squashfs_dir_inode_header_2));\
+	SQUASHFS_SWAP((s)->file_size, d, 32, 19);\
+	SQUASHFS_SWAP((s)->offset, d, 51, 13);\
+	SQUASHFS_SWAP((s)->mtime, d, 64, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 96, 24);\
+}
+
+#define SQUASHFS_SWAP_LDIR_INODE_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_SWAP_BASE_INODE_CORE_2(s, d, \
+			sizeof(struct squashfs_ldir_inode_header_2));\
+	SQUASHFS_SWAP((s)->file_size, d, 32, 27);\
+	SQUASHFS_SWAP((s)->offset, d, 59, 13);\
+	SQUASHFS_SWAP((s)->mtime, d, 72, 32);\
+	SQUASHFS_SWAP((s)->start_block, d, 104, 24);\
+	SQUASHFS_SWAP((s)->i_count, d, 128, 16);\
+}
+
+#define SQUASHFS_SWAP_DIR_INDEX_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_index_2));\
+	SQUASHFS_SWAP((s)->index, d, 0, 27);\
+	SQUASHFS_SWAP((s)->start_block, d, 27, 29);\
+	SQUASHFS_SWAP((s)->size, d, 56, 8);\
+}
+#define SQUASHFS_SWAP_DIR_HEADER_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_header_2));\
+	SQUASHFS_SWAP((s)->count, d, 0, 8);\
+	SQUASHFS_SWAP((s)->start_block, d, 8, 24);\
+}
+
+#define SQUASHFS_SWAP_DIR_ENTRY_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_dir_entry_2));\
+	SQUASHFS_SWAP((s)->offset, d, 0, 13);\
+	SQUASHFS_SWAP((s)->type, d, 13, 3);\
+	SQUASHFS_SWAP((s)->size, d, 16, 8);\
+}
+
+#define SQUASHFS_SWAP_FRAGMENT_ENTRY_2(s, d) {\
+	SQUASHFS_SWAP_START\
+	SQUASHFS_MEMSET(s, d, sizeof(struct squashfs_fragment_entry_2));\
+	SQUASHFS_SWAP((s)->start_block, d, 0, 32);\
+	SQUASHFS_SWAP((s)->size, d, 32, 32);\
+}
 
-struct squashfs_fragment_entry {
-	__le64			start_block;
-	__le32			size;
-	unsigned int		unused;
-};
+#define SQUASHFS_SWAP_FRAGMENT_INDEXES_2(s, d, n) SQUASHFS_SWAP_INTS(s, d, n)
 
+/* fragment and fragment table defines */
+#define SQUASHFS_FRAGMENT_BYTES_2(A)	(A * sizeof(struct squashfs_fragment_entry_2))
+
+#define SQUASHFS_FRAGMENT_INDEX_2(A)	(SQUASHFS_FRAGMENT_BYTES_2(A) / \
+					SQUASHFS_METADATA_SIZE)
+
+#define SQUASHFS_FRAGMENT_INDEX_OFFSET_2(A)	(SQUASHFS_FRAGMENT_BYTES_2(A) % \
+						SQUASHFS_METADATA_SIZE)
+
+#define SQUASHFS_FRAGMENT_INDEXES_2(A)	((SQUASHFS_FRAGMENT_BYTES_2(A) + \
+					SQUASHFS_METADATA_SIZE - 1) / \
+					SQUASHFS_METADATA_SIZE)
+
+#define SQUASHFS_FRAGMENT_INDEX_BYTES_2(A)	(SQUASHFS_FRAGMENT_INDEXES_2(A) *\
+						sizeof(int))
+
+#endif
+
+#ifdef __KERNEL__
+
+/*
+ * macros used to swap each structure entry, taking into account
+ * bitfields and different bitfield placing conventions on differing
+ * architectures
+ */
+
+#include <asm/byteorder.h>
+
+#ifdef __BIG_ENDIAN
+	/* convert from little endian to big endian */
+#define SQUASHFS_SWAP(value, p, pos, tbits) _SQUASHFS_SWAP(value, p, pos, \
+		tbits, b_pos)
+#else
+	/* convert from big endian to little endian */ 
+#define SQUASHFS_SWAP(value, p, pos, tbits) _SQUASHFS_SWAP(value, p, pos, \
+		tbits, 64 - tbits - b_pos)
+#endif
+
+#define _SQUASHFS_SWAP(value, p, pos, tbits, SHIFT) {\
+	b_pos = pos % 8;\
+	val = 0;\
+	s = (unsigned char *)p + (pos / 8);\
+	d = ((unsigned char *) &val) + 7;\
+	for(bits = 0; bits < (tbits + b_pos); bits += 8) \
+		*d-- = *s++;\
+	value = (val >> (SHIFT))/* & ((1 << tbits) - 1)*/;\
+}
+
+#define SQUASHFS_MEMSET(s, d, n)	memset(s, 0, n);
+
+#endif
 #endif
diff -Naur linux-2.6.30-ori/fs/squashfs/squashfs_fs_i.h linux-2.6.30-test/fs/squashfs/squashfs_fs_i.h
--- linux-2.6.30-ori/fs/squashfs/squashfs_fs_i.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/squashfs_fs_i.h	2009-06-15 11:25:12.000000000 -0400
@@ -3,7 +3,7 @@
 /*
  * Squashfs
  *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
+ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007
  * Phillip Lougher <phillip@lougher.demon.co.uk>
  *
  * This program is free software; you can redistribute it and/or
@@ -18,28 +18,28 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * squashfs_fs_i.h
  */
 
 struct squashfs_inode_info {
-	u64		start;
-	int		offset;
+	long long	start_block;
+	unsigned int	offset;
 	union {
 		struct {
-			u64		fragment_block;
-			int		fragment_size;
-			int		fragment_offset;
-			u64		block_list_start;
-		};
+			long long	fragment_start_block;
+			unsigned int	fragment_size;
+			unsigned int	fragment_offset;
+			long long	block_list_start;
+		} s1;
 		struct {
-			u64		dir_idx_start;
-			int		dir_idx_offset;
-			int		dir_idx_cnt;
-			int		parent;
-		};
-	};
+			long long	directory_index_start;
+			unsigned int	directory_index_offset;
+			unsigned int	directory_index_count;
+			unsigned int	parent_inode;
+		} s2;
+	} u;
 	struct inode	vfs_inode;
 };
 #endif
diff -Naur linux-2.6.30-ori/fs/squashfs/squashfs_fs_sb.h linux-2.6.30-test/fs/squashfs/squashfs_fs_sb.h
--- linux-2.6.30-ori/fs/squashfs/squashfs_fs_sb.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/squashfs_fs_sb.h	2009-06-15 11:25:12.000000000 -0400
@@ -3,7 +3,7 @@
 /*
  * Squashfs
  *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
+ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007
  * Phillip Lougher <phillip@lougher.demon.co.uk>
  *
  * This program is free software; you can redistribute it and/or
@@ -18,7 +18,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
+ * Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
  *
  * squashfs_fs_sb.h
  */
@@ -26,51 +26,51 @@
 #include "squashfs_fs.h"
 
 struct squashfs_cache {
-	char			*name;
-	int			entries;
-	int			next_blk;
-	int			num_waiters;
-	int			unused;
-	int			block_size;
-	int			pages;
-	spinlock_t		lock;
-	wait_queue_head_t	wait_queue;
-	struct squashfs_cache_entry *entry;
+	long long	block;
+	int		length;
+	long long	next_index;
+	char		*data;
 };
 
-struct squashfs_cache_entry {
-	u64			block;
-	int			length;
-	int			refcount;
-	u64			next_index;
-	int			pending;
-	int			error;
-	int			num_waiters;
-	wait_queue_head_t	wait_queue;
-	struct squashfs_cache	*cache;
-	void			**data;
+struct squashfs_fragment_cache {
+	long long	block;
+	int		length;
+	unsigned int	locked;
+	char		*data;
 };
 
 struct squashfs_sb_info {
+	struct squashfs_super_block	sblk;
 	int			devblksize;
 	int			devblksize_log2;
+	int			swap;
 	struct squashfs_cache	*block_cache;
-	struct squashfs_cache	*fragment_cache;
-	struct squashfs_cache	*read_page;
+	struct squashfs_fragment_cache	*fragment;
+	int			next_cache;
+	int			next_fragment;
 	int			next_meta_index;
-	__le64			*id_table;
-	__le64			*fragment_index;
+	unsigned int		*uid;
+	unsigned int		*guid;
+	long long		*fragment_index;
 	unsigned int		*fragment_index_2;
-	struct mutex		read_data_mutex;
+	char			*read_page;
+	/* struct mutex		read_data_mutex; */
+	struct mutex		read_page_mutex;
+	struct mutex		block_cache_mutex;
+	struct mutex		fragment_mutex;
 	struct mutex		meta_index_mutex;
+	wait_queue_head_t	waitq;
+	wait_queue_head_t	fragment_wait_queue;
 	struct meta_index	*meta_index;
-	z_stream		stream;
-	__le64			*inode_lookup_table;
-	u64			inode_table;
-	u64			directory_table;
-	unsigned int		block_size;
-	unsigned short		block_log;
-	long long		bytes_used;
-	unsigned int		inodes;
+	/* z_stream		stream; */
+	long long		*inode_lookup_table;
+	int			unused_cache_blks;
+	int			unused_frag_blks;
+	int			(*read_inode)(struct inode *i,  squashfs_inode_t \
+				inode);
+	long long		(*read_blocklist)(struct inode *inode, int \
+				index, int readahead_blks, char *block_list, \
+				unsigned short **block_p, unsigned int *bsize);
+	int			(*read_fragment_index_table)(struct super_block *s);
 };
 #endif
diff -Naur linux-2.6.30-ori/fs/squashfs/symlink.c linux-2.6.30-test/fs/squashfs/symlink.c
--- linux-2.6.30-ori/fs/squashfs/symlink.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/fs/squashfs/symlink.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,118 +0,0 @@
-/*
- * Squashfs - a compressed read only filesystem for Linux
- *
- * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008
- * Phillip Lougher <phillip@lougher.demon.co.uk>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version 2,
- * or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- *
- * symlink.c
- */
-
-/*
- * This file implements code to handle symbolic links.
- *
- * The data contents of symbolic links are stored inside the symbolic
- * link inode within the inode table.  This allows the normally small symbolic
- * link to be compressed as part of the inode table, achieving much greater
- * compression than if the symbolic link was compressed individually.
- */
-
-#include <linux/fs.h>
-#include <linux/vfs.h>
-#include <linux/kernel.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/pagemap.h>
-#include <linux/zlib.h>
-
-#include "squashfs_fs.h"
-#include "squashfs_fs_sb.h"
-#include "squashfs_fs_i.h"
-#include "squashfs.h"
-
-static int squashfs_symlink_readpage(struct file *file, struct page *page)
-{
-	struct inode *inode = page->mapping->host;
-	struct super_block *sb = inode->i_sb;
-	struct squashfs_sb_info *msblk = sb->s_fs_info;
-	int index = page->index << PAGE_CACHE_SHIFT;
-	u64 block = squashfs_i(inode)->start;
-	int offset = squashfs_i(inode)->offset;
-	int length = min_t(int, i_size_read(inode) - index, PAGE_CACHE_SIZE);
-	int bytes, copied;
-	void *pageaddr;
-	struct squashfs_cache_entry *entry;
-
-	TRACE("Entered squashfs_symlink_readpage, page index %ld, start block "
-			"%llx, offset %x\n", page->index, block, offset);
-
-	/*
-	 * Skip index bytes into symlink metadata.
-	 */
-	if (index) {
-		bytes = squashfs_read_metadata(sb, NULL, &block, &offset,
-								index);
-		if (bytes < 0) {
-			ERROR("Unable to read symlink [%llx:%x]\n",
-				squashfs_i(inode)->start,
-				squashfs_i(inode)->offset);
-			goto error_out;
-		}
-	}
-
-	/*
-	 * Read length bytes from symlink metadata.  Squashfs_read_metadata
-	 * is not used here because it can sleep and we want to use
-	 * kmap_atomic to map the page.  Instead call the underlying
-	 * squashfs_cache_get routine.  As length bytes may overlap metadata
-	 * blocks, we may need to call squashfs_cache_get multiple times.
-	 */
-	for (bytes = 0; bytes < length; offset = 0, bytes += copied) {
-		entry = squashfs_cache_get(sb, msblk->block_cache, block, 0);
-		if (entry->error) {
-			ERROR("Unable to read symlink [%llx:%x]\n",
-				squashfs_i(inode)->start,
-				squashfs_i(inode)->offset);
-			squashfs_cache_put(entry);
-			goto error_out;
-		}
-
-		pageaddr = kmap_atomic(page, KM_USER0);
-		copied = squashfs_copy_data(pageaddr + bytes, entry, offset,
-								length - bytes);
-		if (copied == length - bytes)
-			memset(pageaddr + length, 0, PAGE_CACHE_SIZE - length);
-		else
-			block = entry->next_index;
-		kunmap_atomic(pageaddr, KM_USER0);
-		squashfs_cache_put(entry);
-	}
-
-	flush_dcache_page(page);
-	SetPageUptodate(page);
-	unlock_page(page);
-	return 0;
-
-error_out:
-	SetPageError(page);
-	unlock_page(page);
-	return 0;
-}
-
-
-const struct address_space_operations squashfs_symlink_aops = {
-	.readpage = squashfs_symlink_readpage
-};
diff -Naur linux-2.6.30-ori/fs/squashfs/uncomp.c linux-2.6.30-test/fs/squashfs/uncomp.c
--- linux-2.6.30-ori/fs/squashfs/uncomp.c	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/fs/squashfs/uncomp.c	2009-06-15 11:25:12.000000000 -0400
@@ -0,0 +1,223 @@
+/*
+ * Copyright (C) 2006-2008 Junjiro Okajima
+ * Copyright (C) 2006-2008 Tomas Matejicek, slax.org
+ *
+ * LICENSE follows the described one in lzma.txt.
+ */
+
+/* $Id: uncomp.c,v 1.7 2008-03-12 16:58:34 jro Exp $ */
+
+/* extract some parts from lzma443/C/7zip/Compress/LZMA_C/LzmaTest.c */
+
+#ifndef __KERNEL__
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <errno.h>
+#include <assert.h>
+#include <pthread.h>
+#define unlikely(x)		__builtin_expect(!!(x), 0)
+#define BUG_ON(x)		assert(!(x))
+/* sqlzma buffers are always larger than a page. true? */
+#define kmalloc(sz,gfp)		malloc(sz)
+#define kfree(p)		free(p)
+#define zlib_inflate(s, f)	inflate(s, f)
+#define zlib_inflateInit(s)	inflateInit(s)
+#define zlib_inflateReset(s)	inflateReset(s)
+#define zlib_inflateEnd(s)	inflateEnd(s)
+#else
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/vmalloc.h>
+#ifndef WARN_ON_ONCE
+#define WARN_ON_ONCE(b)	WARN_ON(b)
+#endif
+#endif /* __KERNEL__ */
+
+#include "sqlzma.h"
+#include "LzmaDecode.h"
+
+static int LzmaUncompress(struct sqlzma_un *un)
+{
+	int err, i, ret;
+	SizeT outSize, inProcessed, outProcessed, srclen;
+	/* it's about 24-80 bytes structure, if int is 32-bit */
+	CLzmaDecoderState state;
+	unsigned char *dst, *src, a[8];
+	struct sized_buf *sbuf;
+
+	/* Decode LZMA properties and allocate memory */
+	err = -EINVAL;
+	src = (void *)un->un_cmbuf;
+	ret = LzmaDecodeProperties(&state.Properties, src,
+				   LZMA_PROPERTIES_SIZE);
+	src += LZMA_PROPERTIES_SIZE;
+	if (unlikely(ret != LZMA_RESULT_OK))
+		goto out;
+	i = LzmaGetNumProbs(&state.Properties);
+	if (unlikely(i <= 0))
+		i = 1;
+	i *= sizeof(CProb);
+	sbuf = un->un_a + SQUN_PROB;
+	if (unlikely(sbuf->sz < i)) {
+		if (sbuf->buf && sbuf->buf != un->un_prob)
+			kfree(sbuf->buf);
+#ifdef __KERNEL__
+		printk("%s:%d: %d --> %d\n", __func__, __LINE__, sbuf->sz, i);
+#else
+		printf("%d --> %d\n", sbuf->sz, i);
+#endif
+		err = -ENOMEM;
+		sbuf->sz = 0;
+		sbuf->buf = kmalloc(i, GFP_ATOMIC);
+		if (unlikely(!sbuf->buf))
+			goto out;
+		sbuf->sz = i;
+	}
+	state.Probs = (void *)sbuf->buf;
+
+	/* Read uncompressed size */
+	memcpy(a, src, sizeof(a));
+	src += sizeof(a);
+	outSize = a[0] | (a[1] << 8) | (a[2] << 16) | (a[3] << 24);
+
+	err = -EINVAL;
+	dst = un->un_resbuf;
+	if (unlikely(!dst || outSize > un->un_reslen))
+		goto out;
+	un->un_reslen = outSize;
+	srclen = un->un_cmlen - (src - un->un_cmbuf);
+
+	/* Decompress */
+	err = LzmaDecode(&state, src, srclen, &inProcessed, dst, outSize,
+			 &outProcessed);
+	if (unlikely(err))
+		err = -EINVAL;
+
+ out:
+#ifndef __KERNEL__
+	if (err)
+		fprintf(stderr, "err %d\n", err);
+#endif
+	return err;
+}
+
+int sqlzma_un(struct sqlzma_un *un, struct sized_buf *src,
+	      struct sized_buf *dst)
+{
+	int err, by_lzma = 1;
+	if (un->un_lzma && is_lzma(*src->buf)) {
+		un->un_cmbuf = src->buf;
+		un->un_cmlen = src->sz;
+		un->un_resbuf = dst->buf;
+		un->un_reslen = dst->sz;
+
+		/* this library is thread-safe */
+		err = LzmaUncompress(un);
+		goto out;
+	}
+
+	by_lzma = 0;
+	err = zlib_inflateReset(&un->un_stream);
+	if (unlikely(err != Z_OK))
+		goto out;
+	un->un_stream.next_in = src->buf;
+	un->un_stream.avail_in = src->sz;
+	un->un_stream.next_out = dst->buf;
+	un->un_stream.avail_out = dst->sz;
+	err = zlib_inflate(&un->un_stream, Z_FINISH);
+	if (err == Z_STREAM_END)
+		err = 0;
+
+ out:
+	if (unlikely(err)) {
+#ifdef __KERNEL__
+		WARN_ON_ONCE(1);
+#else
+		char a[64] = "ZLIB ";
+		if (by_lzma) {
+			strcpy(a, "LZMA ");
+#ifdef _REENTRANT
+			strerror_r(err, a + 5, sizeof(a) - 5);
+#else
+			strncat(a, strerror(err), sizeof(a) - 5);
+#endif
+		} else
+			strncat(a, zError(err), sizeof(a) - 5);
+		fprintf(stderr, "%s: %.*s\n", __func__, sizeof(a), a);
+#endif
+	}
+	return err;
+}
+
+int sqlzma_init(struct sqlzma_un *un, int do_lzma, unsigned int res_sz)
+{
+	int err;
+
+	err = -ENOMEM;
+	un->un_lzma = do_lzma;
+	memset(un->un_a, 0, sizeof(un->un_a));
+	un->un_a[SQUN_PROB].buf = un->un_prob;
+	un->un_a[SQUN_PROB].sz = sizeof(un->un_prob);
+	if (res_sz) {
+		un->un_a[SQUN_RESULT].buf = kmalloc(res_sz, GFP_KERNEL);
+		if (unlikely(!un->un_a[SQUN_RESULT].buf))
+			return err;
+		un->un_a[SQUN_RESULT].sz = res_sz;
+	}
+
+	un->un_stream.next_in = NULL;
+	un->un_stream.avail_in = 0;
+#ifdef __KERNEL__
+	un->un_stream.workspace = kmalloc(zlib_inflate_workspacesize(),
+					  GFP_KERNEL);
+	if (unlikely(!un->un_stream.workspace))
+		return err;
+#else
+	un->un_stream.opaque = NULL;
+	un->un_stream.zalloc = Z_NULL;
+	un->un_stream.zfree = Z_NULL;
+#endif
+	err = zlib_inflateInit(&un->un_stream);
+	if (unlikely(err == Z_MEM_ERROR))
+		return -ENOMEM;
+	BUG_ON(err);
+	return err;
+}
+
+void sqlzma_fin(struct sqlzma_un *un)
+{
+	int i;
+	for (i = 0; i < SQUN_LAST; i++)
+		if (un->un_a[i].buf && un->un_a[i].buf != un->un_prob)
+			kfree(un->un_a[i].buf);
+	BUG_ON(zlib_inflateEnd(&un->un_stream) != Z_OK);
+}
+
+#ifdef __KERNEL__
+EXPORT_SYMBOL(sqlzma_un);
+EXPORT_SYMBOL(sqlzma_init);
+EXPORT_SYMBOL(sqlzma_fin);
+
+#if 0
+static int __init sqlzma_init(void)
+{
+	return 0;
+}
+
+static void __exit sqlzma_exit(void)
+{
+}
+
+module_init(sqlzma_init);
+module_exit(sqlzma_exit);
+#endif
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Junjiro Okajima <sfjro at users dot sf dot net>");
+MODULE_VERSION("$Id: uncomp.c,v 1.7 2008-03-12 16:58:34 jro Exp $");
+MODULE_DESCRIPTION("LZMA uncompress for squashfs. "
+		   "Some functions for squashfs to support LZMA and "
+		   "a tiny wrapper for LzmaDecode.c in LZMA SDK from www.7-zip.org.");
+#endif
diff -Naur linux-2.6.30-ori/include/linux/serial_reg.h linux-2.6.30-test/include/linux/serial_reg.h
--- linux-2.6.30-ori/include/linux/serial_reg.h	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/include/linux/serial_reg.h	2009-06-12 18:32:56.000000000 -0400
@@ -15,12 +15,44 @@
 #define _LINUX_SERIAL_REG_H
 
 /*
- * DLAB=0
+ * smp863x has an 16550 uart, but registers have been messed up...
  */
+#ifdef CONFIG_TANGOX
+
 #define UART_RX		0	/* In:  Receive buffer */
-#define UART_TX		0	/* Out: Transmit buffer */
+#define UART_TX		1	/* Out: Transmit buffer */
+#define UART_IER	2	/* Out: Interrupt Enable Register */
+#define UART_IIR	3	/* In:  Interrupt ID Register */
+#define UART_FCR	4	/* Out: FIFO Control Register */
+#define UART_LCR	5	/* Out: Line Control Register */
+#define UART_MCR	6	/* Out: Modem Control Register */
+#define UART_LSR	7	/* In:  Line Status Register */
+#define UART_MSR	8	/* In:  Modem Status Register */
+#define UART_SCR	9	/* I/O: Scratch Register */
+
+/* EFR does not exist on TANGOX,  we use a magic to catch accesses and
+ * make them nop */
+#define UART_EFR	42
+
+#else
 
+#define UART_RX		0	/* In:  Receive buffer */
+#define UART_TX		0	/* Out: Transmit buffer */
 #define UART_IER	1	/* Out: Interrupt Enable Register */
+#define UART_IIR	2	/* In:  Interrupt ID Register */
+#define UART_EFR	2	/* I/O: Extended Features Register */
+#define UART_FCR	2	/* Out: FIFO Control Register */
+#define UART_LCR	3	/* Out: Line Control Register */
+#define UART_MCR	4	/* Out: Modem Control Register */
+#define UART_LSR	5	/* In:  Line Status Register */
+#define UART_MSR	6	/* In:  Modem Status Register */
+#define UART_SCR	7	/* I/O: Scratch Register */
+
+#endif
+
+/*
+ * DLAB=0
+ */
 #define UART_IER_MSI		0x08 /* Enable Modem status interrupt */
 #define UART_IER_RLSI		0x04 /* Enable receiver line status interrupt */
 #define UART_IER_THRI		0x02 /* Enable Transmitter holding register int. */
@@ -30,7 +62,6 @@
  */
 #define UART_IERX_SLEEP		0x10 /* Enable sleep mode */
 
-#define UART_IIR	2	/* In:  Interrupt ID Register */
 #define UART_IIR_NO_INT		0x01 /* No interrupts pending */
 #define UART_IIR_ID		0x06 /* Mask for the interrupt ID */
 #define UART_IIR_MSI		0x00 /* Modem status interrupt */
@@ -40,7 +71,6 @@
 
 #define UART_IIR_BUSY		0x07 /* DesignWare APB Busy Detect */
 
-#define UART_FCR	2	/* Out: FIFO Control Register */
 #define UART_FCR_ENABLE_FIFO	0x01 /* Enable the FIFO */
 #define UART_FCR_CLEAR_RCVR	0x02 /* Clear the RCVR FIFO */
 #define UART_FCR_CLEAR_XMIT	0x04 /* Clear the XMIT FIFO */
@@ -83,7 +113,6 @@
 #define UART_FCR6_T_TRIGGER_30	0x30 /* Mask for transmit trigger set at 30 */
 #define UART_FCR7_64BYTE	0x20 /* Go into 64 byte mode (TI16C750) */
 
-#define UART_LCR	3	/* Out: Line Control Register */
 /*
  * Note: if the word length is 5 bits (UART_LCR_WLEN5), then setting 
  * UART_LCR_STOP will select 1.5 stop bits, not 2 stop bits.
@@ -99,7 +128,6 @@
 #define UART_LCR_WLEN7		0x02 /* Wordlength: 7 bits */
 #define UART_LCR_WLEN8		0x03 /* Wordlength: 8 bits */
 
-#define UART_MCR	4	/* Out: Modem Control Register */
 #define UART_MCR_CLKSEL		0x80 /* Divide clock by 4 (TI16C752, EFR[4]=1) */
 #define UART_MCR_TCRTLR		0x40 /* Access TCR/TLR (TI16C752, EFR[4]=1) */
 #define UART_MCR_XONANY		0x20 /* Enable Xon Any (TI16C752, EFR[4]=1) */
@@ -110,7 +138,6 @@
 #define UART_MCR_RTS		0x02 /* RTS complement */
 #define UART_MCR_DTR		0x01 /* DTR complement */
 
-#define UART_LSR	5	/* In:  Line Status Register */
 #define UART_LSR_TEMT		0x40 /* Transmitter empty */
 #define UART_LSR_THRE		0x20 /* Transmit-hold-register empty */
 #define UART_LSR_BI		0x10 /* Break interrupt indicator */
@@ -120,7 +147,6 @@
 #define UART_LSR_DR		0x01 /* Receiver data ready */
 #define UART_LSR_BRK_ERROR_BITS	0x1E /* BI, FE, PE, OE bits */
 
-#define UART_MSR	6	/* In:  Modem Status Register */
 #define UART_MSR_DCD		0x80 /* Data Carrier Detect */
 #define UART_MSR_RI		0x40 /* Ring Indicator */
 #define UART_MSR_DSR		0x20 /* Data Set Ready */
@@ -131,18 +157,25 @@
 #define UART_MSR_DCTS		0x01 /* Delta CTS */
 #define UART_MSR_ANY_DELTA	0x0F /* Any of the delta bits! */
 
-#define UART_SCR	7	/* I/O: Scratch Register */
 
 /*
  * DLAB=1
  */
+
+/*
+ * smp863x has DLM and DLM in one register
+ */
+#ifdef CONFIG_TANGOX
+#define UART_DL		10
+#define UART_CLKSEL	11	/* Clock selection */
+#else
 #define UART_DLL	0	/* Out: Divisor Latch Low */
 #define UART_DLM	1	/* Out: Divisor Latch High */
+#endif
 
 /*
  * LCR=0xBF (or DLAB=1 for 16C660)
  */
-#define UART_EFR	2	/* I/O: Extended Features Register */
 #define UART_EFR_CTS		0x80 /* CTS flow control */
 #define UART_EFR_RTS		0x40 /* RTS flow control */
 #define UART_EFR_SCD		0x20 /* Special character detect */
diff -Naur linux-2.6.30-ori/mm/memory.c linux-2.6.30-test/mm/memory.c
--- linux-2.6.30-ori/mm/memory.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/mm/memory.c	2009-06-12 18:32:56.000000000 -0400
@@ -1347,8 +1347,10 @@
 			if (pages) {
 				pages[i] = page;
 
-				flush_anon_page(vma, page, start);
-				flush_dcache_page(page);
+				if (!test_thread_flag(TIF_DMA)) {
+					flush_anon_page(vma, page, start);
+					flush_dcache_page(page);
+				}
 			}
 			if (vmas)
 				vmas[i] = vma;
diff -Naur linux-2.6.30-ori/mm/page_alloc.c linux-2.6.30-test/mm/page_alloc.c
--- linux-2.6.30-ori/mm/page_alloc.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/mm/page_alloc.c	2009-06-12 18:32:56.000000000 -0400
@@ -1475,6 +1475,7 @@
 	int alloc_flags;
 	unsigned long did_some_progress;
 	unsigned long pages_reclaimed = 0;
+	int num_retries = 0;
 
 	lockdep_trace_alloc(gfp_mask);
 
@@ -1664,6 +1665,12 @@
 
 nopage:
 	if (!(gfp_mask & __GFP_NOWARN) && printk_ratelimit()) {
+		if (++num_retries < 16) {
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule_timeout(HZ);
+			goto rebalance;
+		}
+
 		printk(KERN_WARNING "%s: page allocation failure."
 			" order:%d, mode:0x%x\n",
 			p->comm, order, gfp_mask);
diff -Naur linux-2.6.30-ori/net/core/dev.c linux-2.6.30-test/net/core/dev.c
--- linux-2.6.30-ori/net/core/dev.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/net/core/dev.c	2009-06-12 18:32:56.000000000 -0400
@@ -1586,8 +1586,10 @@
 
 /* Take action when hardware reception checksum errors are detected. */
 #ifdef CONFIG_BUG
+extern long long em86_netstats[20];
 void netdev_rx_csum_fault(struct net_device *dev)
 {
+	em86_netstats[14]+=1;
 	if (net_ratelimit()) {
 		printk(KERN_ERR "%s: hw csum failure.\n",
 			dev ? dev->name : "<unknown>");
diff -Naur linux-2.6.30-ori/net/ipv4/tcp_input.c linux-2.6.30-test/net/ipv4/tcp_input.c
--- linux-2.6.30-ori/net/ipv4/tcp_input.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/net/ipv4/tcp_input.c	2009-06-12 18:32:56.000000000 -0400
@@ -72,6 +72,37 @@
 #include <asm/unaligned.h>
 #include <net/netdma.h>
 
+// JFT Tests
+#ifdef CONFIG_TANGO2
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO2
+#include <linux/interrupt.h>
+#include <asm/tango2/rmem86xxid.h>
+#include <asm/tango2/rmdefs.h>
+#include <asm/tango2/emhwlib_dram.h>
+#include <asm/tango2/tango2_gbus.h>
+#include <asm/tango2/tango2.h>
+#include <asm/tango2/tango2api.h>
+#include <asm/tango2/memcfg.h>
+#elif defined(CONFIG_TANGO3)
+#define EM86XX_CHIP EM86XX_CHIPID_TANGO3
+#include <linux/interrupt.h>
+#include <asm/tango3/rmem86xxid.h>
+#include <asm/tango3/rmdefs.h>
+#include <asm/tango3/emhwlib_dram.h>
+#include <asm/tango3/tango3_gbus.h>
+#include <asm/tango3/tango3.h>
+#include <asm/tango3/tango3api.h>
+#include <asm/tango3/hardware.h>
+#else
+#error "Unknown architecture"
+#endif
+
+long long em86_netstats[20] = {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0};
+static inline unsigned long tangox_getxtal(void)
+{
+	return(gbus_readl(REG_BASE_system_block + SYS_xtal_in_cnt));
+}
+
 int sysctl_tcp_timestamps __read_mostly = 1;
 int sysctl_tcp_window_scaling __read_mostly = 1;
 int sysctl_tcp_sack __read_mostly = 1;
@@ -4941,8 +4972,16 @@
 	if (skb_csum_unnecessary(skb))
 		err = skb_copy_datagram_iovec(skb, hlen, tp->ucopy.iov, chunk);
 	else
+	{ // JFT Test
+		unsigned long t1,t2;
+		em86_netstats[0] +=1;
+		t1=tangox_getxtal();
+		//err = skb_copy_datagram_iovec(skb, hlen, tp->ucopy.iov, chunk);
 		err = skb_copy_and_csum_datagram_iovec(skb, hlen,
 						       tp->ucopy.iov);
+		t2=tangox_getxtal();
+		em86_netstats[1]+=(t2-t1);
+	}
 
 	if (!err) {
 		tp->ucopy.len -= chunk;
@@ -4972,8 +5011,16 @@
 static inline int tcp_checksum_complete_user(struct sock *sk,
 					     struct sk_buff *skb)
 {
-	return !skb_csum_unnecessary(skb) &&
+	// JFT Test
+	unsigned long t1,t2;
+	int tmp;
+	em86_netstats[2] +=1;
+	t1=tangox_getxtal();
+	tmp = !skb_csum_unnecessary(skb) &&
 	       __tcp_checksum_complete_user(sk, skb);
+	t2=tangox_getxtal();
+	em86_netstats[3]+=(t2-t1);
+	return tmp;
 }
 
 #ifdef CONFIG_NET_DMA
@@ -5229,6 +5276,7 @@
 					tcp_cleanup_rbuf(sk, skb->len);
 			}
 			if (!eaten) {
+				// Test JFT don't run checksum...
 				if (tcp_checksum_complete_user(sk, skb))
 					goto csum_error;
 
@@ -5801,3 +5849,4 @@
 EXPORT_SYMBOL(tcp_rcv_established);
 EXPORT_SYMBOL(tcp_rcv_state_process);
 EXPORT_SYMBOL(tcp_initialize_rcv_mss);
+EXPORT_SYMBOL(em86_netstats);
diff -Naur linux-2.6.30-ori/net/ipv4/tcp_input.c.orig linux-2.6.30-test/net/ipv4/tcp_input.c.orig
--- linux-2.6.30-ori/net/ipv4/tcp_input.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ linux-2.6.30-test/net/ipv4/tcp_input.c.orig	2009-06-09 23:05:27.000000000 -0400
@@ -0,0 +1,5803 @@
+/*
+ * INET		An implementation of the TCP/IP protocol suite for the LINUX
+ *		operating system.  INET is implemented using the  BSD Socket
+ *		interface as the means of communication with the user level.
+ *
+ *		Implementation of the Transmission Control Protocol(TCP).
+ *
+ * Authors:	Ross Biro
+ *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
+ *		Mark Evans, <evansmp@uhura.aston.ac.uk>
+ *		Corey Minyard <wf-rch!minyard@relay.EU.net>
+ *		Florian La Roche, <flla@stud.uni-sb.de>
+ *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>
+ *		Linus Torvalds, <torvalds@cs.helsinki.fi>
+ *		Alan Cox, <gw4pts@gw4pts.ampr.org>
+ *		Matthew Dillon, <dillon@apollo.west.oic.com>
+ *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>
+ *		Jorge Cwik, <jorge@laser.satlink.net>
+ */
+
+/*
+ * Changes:
+ *		Pedro Roque	:	Fast Retransmit/Recovery.
+ *					Two receive queues.
+ *					Retransmit queue handled by TCP.
+ *					Better retransmit timer handling.
+ *					New congestion avoidance.
+ *					Header prediction.
+ *					Variable renaming.
+ *
+ *		Eric		:	Fast Retransmit.
+ *		Randy Scott	:	MSS option defines.
+ *		Eric Schenk	:	Fixes to slow start algorithm.
+ *		Eric Schenk	:	Yet another double ACK bug.
+ *		Eric Schenk	:	Delayed ACK bug fixes.
+ *		Eric Schenk	:	Floyd style fast retrans war avoidance.
+ *		David S. Miller	:	Don't allow zero congestion window.
+ *		Eric Schenk	:	Fix retransmitter so that it sends
+ *					next packet on ack of previous packet.
+ *		Andi Kleen	:	Moved open_request checking here
+ *					and process RSTs for open_requests.
+ *		Andi Kleen	:	Better prune_queue, and other fixes.
+ *		Andrey Savochkin:	Fix RTT measurements in the presence of
+ *					timestamps.
+ *		Andrey Savochkin:	Check sequence numbers correctly when
+ *					removing SACKs due to in sequence incoming
+ *					data segments.
+ *		Andi Kleen:		Make sure we never ack data there is not
+ *					enough room for. Also make this condition
+ *					a fatal error if it might still happen.
+ *		Andi Kleen:		Add tcp_measure_rcv_mss to make
+ *					connections with MSS<min(MTU,ann. MSS)
+ *					work without delayed acks.
+ *		Andi Kleen:		Process packets with PSH set in the
+ *					fast path.
+ *		J Hadi Salim:		ECN support
+ *	 	Andrei Gurtov,
+ *		Pasi Sarolahti,
+ *		Panu Kuhlberg:		Experimental audit of TCP (re)transmission
+ *					engine. Lots of bugs are found.
+ *		Pasi Sarolahti:		F-RTO for dealing with spurious RTOs
+ */
+
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/sysctl.h>
+#include <linux/kernel.h>
+#include <net/dst.h>
+#include <net/tcp.h>
+#include <net/inet_common.h>
+#include <linux/ipsec.h>
+#include <asm/unaligned.h>
+#include <net/netdma.h>
+
+int sysctl_tcp_timestamps __read_mostly = 1;
+int sysctl_tcp_window_scaling __read_mostly = 1;
+int sysctl_tcp_sack __read_mostly = 1;
+int sysctl_tcp_fack __read_mostly = 1;
+int sysctl_tcp_reordering __read_mostly = TCP_FASTRETRANS_THRESH;
+int sysctl_tcp_ecn __read_mostly;
+int sysctl_tcp_dsack __read_mostly = 1;
+int sysctl_tcp_app_win __read_mostly = 31;
+int sysctl_tcp_adv_win_scale __read_mostly = 2;
+
+int sysctl_tcp_stdurg __read_mostly;
+int sysctl_tcp_rfc1337 __read_mostly;
+int sysctl_tcp_max_orphans __read_mostly = NR_FILE;
+int sysctl_tcp_frto __read_mostly = 2;
+int sysctl_tcp_frto_response __read_mostly;
+int sysctl_tcp_nometrics_save __read_mostly;
+
+int sysctl_tcp_moderate_rcvbuf __read_mostly = 1;
+int sysctl_tcp_abc __read_mostly;
+
+#define FLAG_DATA		0x01 /* Incoming frame contained data.		*/
+#define FLAG_WIN_UPDATE		0x02 /* Incoming ACK was a window update.	*/
+#define FLAG_DATA_ACKED		0x04 /* This ACK acknowledged new data.		*/
+#define FLAG_RETRANS_DATA_ACKED	0x08 /* "" "" some of which was retransmitted.	*/
+#define FLAG_SYN_ACKED		0x10 /* This ACK acknowledged SYN.		*/
+#define FLAG_DATA_SACKED	0x20 /* New SACK.				*/
+#define FLAG_ECE		0x40 /* ECE in this ACK				*/
+#define FLAG_DATA_LOST		0x80 /* SACK detected data lossage.		*/
+#define FLAG_SLOWPATH		0x100 /* Do not skip RFC checks for window update.*/
+#define FLAG_ONLY_ORIG_SACKED	0x200 /* SACKs only non-rexmit sent before RTO */
+#define FLAG_SND_UNA_ADVANCED	0x400 /* Snd_una was changed (!= FLAG_DATA_ACKED) */
+#define FLAG_DSACKING_ACK	0x800 /* SACK blocks contained D-SACK info */
+#define FLAG_NONHEAD_RETRANS_ACKED	0x1000 /* Non-head rexmitted data was ACKed */
+#define FLAG_SACK_RENEGING	0x2000 /* snd_una advanced to a sacked seq */
+
+#define FLAG_ACKED		(FLAG_DATA_ACKED|FLAG_SYN_ACKED)
+#define FLAG_NOT_DUP		(FLAG_DATA|FLAG_WIN_UPDATE|FLAG_ACKED)
+#define FLAG_CA_ALERT		(FLAG_DATA_SACKED|FLAG_ECE)
+#define FLAG_FORWARD_PROGRESS	(FLAG_ACKED|FLAG_DATA_SACKED)
+#define FLAG_ANY_PROGRESS	(FLAG_FORWARD_PROGRESS|FLAG_SND_UNA_ADVANCED)
+
+#define TCP_REMNANT (TCP_FLAG_FIN|TCP_FLAG_URG|TCP_FLAG_SYN|TCP_FLAG_PSH)
+#define TCP_HP_BITS (~(TCP_RESERVED_BITS|TCP_FLAG_PSH))
+
+/* Adapt the MSS value used to make delayed ack decision to the
+ * real world.
+ */
+static void tcp_measure_rcv_mss(struct sock *sk, const struct sk_buff *skb)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	const unsigned int lss = icsk->icsk_ack.last_seg_size;
+	unsigned int len;
+
+	icsk->icsk_ack.last_seg_size = 0;
+
+	/* skb->len may jitter because of SACKs, even if peer
+	 * sends good full-sized frames.
+	 */
+	len = skb_shinfo(skb)->gso_size ? : skb->len;
+	if (len >= icsk->icsk_ack.rcv_mss) {
+		icsk->icsk_ack.rcv_mss = len;
+	} else {
+		/* Otherwise, we make more careful check taking into account,
+		 * that SACKs block is variable.
+		 *
+		 * "len" is invariant segment length, including TCP header.
+		 */
+		len += skb->data - skb_transport_header(skb);
+		if (len >= TCP_MIN_RCVMSS + sizeof(struct tcphdr) ||
+		    /* If PSH is not set, packet should be
+		     * full sized, provided peer TCP is not badly broken.
+		     * This observation (if it is correct 8)) allows
+		     * to handle super-low mtu links fairly.
+		     */
+		    (len >= TCP_MIN_MSS + sizeof(struct tcphdr) &&
+		     !(tcp_flag_word(tcp_hdr(skb)) & TCP_REMNANT))) {
+			/* Subtract also invariant (if peer is RFC compliant),
+			 * tcp header plus fixed timestamp option length.
+			 * Resulting "len" is MSS free of SACK jitter.
+			 */
+			len -= tcp_sk(sk)->tcp_header_len;
+			icsk->icsk_ack.last_seg_size = len;
+			if (len == lss) {
+				icsk->icsk_ack.rcv_mss = len;
+				return;
+			}
+		}
+		if (icsk->icsk_ack.pending & ICSK_ACK_PUSHED)
+			icsk->icsk_ack.pending |= ICSK_ACK_PUSHED2;
+		icsk->icsk_ack.pending |= ICSK_ACK_PUSHED;
+	}
+}
+
+static void tcp_incr_quickack(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	unsigned quickacks = tcp_sk(sk)->rcv_wnd / (2 * icsk->icsk_ack.rcv_mss);
+
+	if (quickacks == 0)
+		quickacks = 2;
+	if (quickacks > icsk->icsk_ack.quick)
+		icsk->icsk_ack.quick = min(quickacks, TCP_MAX_QUICKACKS);
+}
+
+void tcp_enter_quickack_mode(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	tcp_incr_quickack(sk);
+	icsk->icsk_ack.pingpong = 0;
+	icsk->icsk_ack.ato = TCP_ATO_MIN;
+}
+
+/* Send ACKs quickly, if "quick" count is not exhausted
+ * and the session is not interactive.
+ */
+
+static inline int tcp_in_quickack_mode(const struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	return icsk->icsk_ack.quick && !icsk->icsk_ack.pingpong;
+}
+
+static inline void TCP_ECN_queue_cwr(struct tcp_sock *tp)
+{
+	if (tp->ecn_flags & TCP_ECN_OK)
+		tp->ecn_flags |= TCP_ECN_QUEUE_CWR;
+}
+
+static inline void TCP_ECN_accept_cwr(struct tcp_sock *tp, struct sk_buff *skb)
+{
+	if (tcp_hdr(skb)->cwr)
+		tp->ecn_flags &= ~TCP_ECN_DEMAND_CWR;
+}
+
+static inline void TCP_ECN_withdraw_cwr(struct tcp_sock *tp)
+{
+	tp->ecn_flags &= ~TCP_ECN_DEMAND_CWR;
+}
+
+static inline void TCP_ECN_check_ce(struct tcp_sock *tp, struct sk_buff *skb)
+{
+	if (tp->ecn_flags & TCP_ECN_OK) {
+		if (INET_ECN_is_ce(TCP_SKB_CB(skb)->flags))
+			tp->ecn_flags |= TCP_ECN_DEMAND_CWR;
+		/* Funny extension: if ECT is not set on a segment,
+		 * it is surely retransmit. It is not in ECN RFC,
+		 * but Linux follows this rule. */
+		else if (INET_ECN_is_not_ect((TCP_SKB_CB(skb)->flags)))
+			tcp_enter_quickack_mode((struct sock *)tp);
+	}
+}
+
+static inline void TCP_ECN_rcv_synack(struct tcp_sock *tp, struct tcphdr *th)
+{
+	if ((tp->ecn_flags & TCP_ECN_OK) && (!th->ece || th->cwr))
+		tp->ecn_flags &= ~TCP_ECN_OK;
+}
+
+static inline void TCP_ECN_rcv_syn(struct tcp_sock *tp, struct tcphdr *th)
+{
+	if ((tp->ecn_flags & TCP_ECN_OK) && (!th->ece || !th->cwr))
+		tp->ecn_flags &= ~TCP_ECN_OK;
+}
+
+static inline int TCP_ECN_rcv_ecn_echo(struct tcp_sock *tp, struct tcphdr *th)
+{
+	if (th->ece && !th->syn && (tp->ecn_flags & TCP_ECN_OK))
+		return 1;
+	return 0;
+}
+
+/* Buffer size and advertised window tuning.
+ *
+ * 1. Tuning sk->sk_sndbuf, when connection enters established state.
+ */
+
+static void tcp_fixup_sndbuf(struct sock *sk)
+{
+	int sndmem = tcp_sk(sk)->rx_opt.mss_clamp + MAX_TCP_HEADER + 16 +
+		     sizeof(struct sk_buff);
+
+	if (sk->sk_sndbuf < 3 * sndmem)
+		sk->sk_sndbuf = min(3 * sndmem, sysctl_tcp_wmem[2]);
+}
+
+/* 2. Tuning advertised window (window_clamp, rcv_ssthresh)
+ *
+ * All tcp_full_space() is split to two parts: "network" buffer, allocated
+ * forward and advertised in receiver window (tp->rcv_wnd) and
+ * "application buffer", required to isolate scheduling/application
+ * latencies from network.
+ * window_clamp is maximal advertised window. It can be less than
+ * tcp_full_space(), in this case tcp_full_space() - window_clamp
+ * is reserved for "application" buffer. The less window_clamp is
+ * the smoother our behaviour from viewpoint of network, but the lower
+ * throughput and the higher sensitivity of the connection to losses. 8)
+ *
+ * rcv_ssthresh is more strict window_clamp used at "slow start"
+ * phase to predict further behaviour of this connection.
+ * It is used for two goals:
+ * - to enforce header prediction at sender, even when application
+ *   requires some significant "application buffer". It is check #1.
+ * - to prevent pruning of receive queue because of misprediction
+ *   of receiver window. Check #2.
+ *
+ * The scheme does not work when sender sends good segments opening
+ * window and then starts to feed us spaghetti. But it should work
+ * in common situations. Otherwise, we have to rely on queue collapsing.
+ */
+
+/* Slow part of check#2. */
+static int __tcp_grow_window(const struct sock *sk, const struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	/* Optimize this! */
+	int truesize = tcp_win_from_space(skb->truesize) >> 1;
+	int window = tcp_win_from_space(sysctl_tcp_rmem[2]) >> 1;
+
+	while (tp->rcv_ssthresh <= window) {
+		if (truesize <= skb->len)
+			return 2 * inet_csk(sk)->icsk_ack.rcv_mss;
+
+		truesize >>= 1;
+		window >>= 1;
+	}
+	return 0;
+}
+
+static void tcp_grow_window(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	/* Check #1 */
+	if (tp->rcv_ssthresh < tp->window_clamp &&
+	    (int)tp->rcv_ssthresh < tcp_space(sk) &&
+	    !tcp_memory_pressure) {
+		int incr;
+
+		/* Check #2. Increase window, if skb with such overhead
+		 * will fit to rcvbuf in future.
+		 */
+		if (tcp_win_from_space(skb->truesize) <= skb->len)
+			incr = 2 * tp->advmss;
+		else
+			incr = __tcp_grow_window(sk, skb);
+
+		if (incr) {
+			tp->rcv_ssthresh = min(tp->rcv_ssthresh + incr,
+					       tp->window_clamp);
+			inet_csk(sk)->icsk_ack.quick |= 1;
+		}
+	}
+}
+
+/* 3. Tuning rcvbuf, when connection enters established state. */
+
+static void tcp_fixup_rcvbuf(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int rcvmem = tp->advmss + MAX_TCP_HEADER + 16 + sizeof(struct sk_buff);
+
+	/* Try to select rcvbuf so that 4 mss-sized segments
+	 * will fit to window and corresponding skbs will fit to our rcvbuf.
+	 * (was 3; 4 is minimum to allow fast retransmit to work.)
+	 */
+	while (tcp_win_from_space(rcvmem) < tp->advmss)
+		rcvmem += 128;
+	if (sk->sk_rcvbuf < 4 * rcvmem)
+		sk->sk_rcvbuf = min(4 * rcvmem, sysctl_tcp_rmem[2]);
+}
+
+/* 4. Try to fixup all. It is made immediately after connection enters
+ *    established state.
+ */
+static void tcp_init_buffer_space(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int maxwin;
+
+	if (!(sk->sk_userlocks & SOCK_RCVBUF_LOCK))
+		tcp_fixup_rcvbuf(sk);
+	if (!(sk->sk_userlocks & SOCK_SNDBUF_LOCK))
+		tcp_fixup_sndbuf(sk);
+
+	tp->rcvq_space.space = tp->rcv_wnd;
+
+	maxwin = tcp_full_space(sk);
+
+	if (tp->window_clamp >= maxwin) {
+		tp->window_clamp = maxwin;
+
+		if (sysctl_tcp_app_win && maxwin > 4 * tp->advmss)
+			tp->window_clamp = max(maxwin -
+					       (maxwin >> sysctl_tcp_app_win),
+					       4 * tp->advmss);
+	}
+
+	/* Force reservation of one segment. */
+	if (sysctl_tcp_app_win &&
+	    tp->window_clamp > 2 * tp->advmss &&
+	    tp->window_clamp + tp->advmss > maxwin)
+		tp->window_clamp = max(2 * tp->advmss, maxwin - tp->advmss);
+
+	tp->rcv_ssthresh = min(tp->rcv_ssthresh, tp->window_clamp);
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+}
+
+/* 5. Recalculate window clamp after socket hit its memory bounds. */
+static void tcp_clamp_window(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	icsk->icsk_ack.quick = 0;
+
+	if (sk->sk_rcvbuf < sysctl_tcp_rmem[2] &&
+	    !(sk->sk_userlocks & SOCK_RCVBUF_LOCK) &&
+	    !tcp_memory_pressure &&
+	    atomic_read(&tcp_memory_allocated) < sysctl_tcp_mem[0]) {
+		sk->sk_rcvbuf = min(atomic_read(&sk->sk_rmem_alloc),
+				    sysctl_tcp_rmem[2]);
+	}
+	if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf)
+		tp->rcv_ssthresh = min(tp->window_clamp, 2U * tp->advmss);
+}
+
+/* Initialize RCV_MSS value.
+ * RCV_MSS is an our guess about MSS used by the peer.
+ * We haven't any direct information about the MSS.
+ * It's better to underestimate the RCV_MSS rather than overestimate.
+ * Overestimations make us ACKing less frequently than needed.
+ * Underestimations are more easy to detect and fix by tcp_measure_rcv_mss().
+ */
+void tcp_initialize_rcv_mss(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	unsigned int hint = min_t(unsigned int, tp->advmss, tp->mss_cache);
+
+	hint = min(hint, tp->rcv_wnd / 2);
+	hint = min(hint, TCP_MIN_RCVMSS);
+	hint = max(hint, TCP_MIN_MSS);
+
+	inet_csk(sk)->icsk_ack.rcv_mss = hint;
+}
+
+/* Receiver "autotuning" code.
+ *
+ * The algorithm for RTT estimation w/o timestamps is based on
+ * Dynamic Right-Sizing (DRS) by Wu Feng and Mike Fisk of LANL.
+ * <http://www.lanl.gov/radiant/website/pubs/drs/lacsi2001.ps>
+ *
+ * More detail on this code can be found at
+ * <http://www.psc.edu/~jheffner/senior_thesis.ps>,
+ * though this reference is out of date.  A new paper
+ * is pending.
+ */
+static void tcp_rcv_rtt_update(struct tcp_sock *tp, u32 sample, int win_dep)
+{
+	u32 new_sample = tp->rcv_rtt_est.rtt;
+	long m = sample;
+
+	if (m == 0)
+		m = 1;
+
+	if (new_sample != 0) {
+		/* If we sample in larger samples in the non-timestamp
+		 * case, we could grossly overestimate the RTT especially
+		 * with chatty applications or bulk transfer apps which
+		 * are stalled on filesystem I/O.
+		 *
+		 * Also, since we are only going for a minimum in the
+		 * non-timestamp case, we do not smooth things out
+		 * else with timestamps disabled convergence takes too
+		 * long.
+		 */
+		if (!win_dep) {
+			m -= (new_sample >> 3);
+			new_sample += m;
+		} else if (m < new_sample)
+			new_sample = m << 3;
+	} else {
+		/* No previous measure. */
+		new_sample = m << 3;
+	}
+
+	if (tp->rcv_rtt_est.rtt != new_sample)
+		tp->rcv_rtt_est.rtt = new_sample;
+}
+
+static inline void tcp_rcv_rtt_measure(struct tcp_sock *tp)
+{
+	if (tp->rcv_rtt_est.time == 0)
+		goto new_measure;
+	if (before(tp->rcv_nxt, tp->rcv_rtt_est.seq))
+		return;
+	tcp_rcv_rtt_update(tp, jiffies - tp->rcv_rtt_est.time, 1);
+
+new_measure:
+	tp->rcv_rtt_est.seq = tp->rcv_nxt + tp->rcv_wnd;
+	tp->rcv_rtt_est.time = tcp_time_stamp;
+}
+
+static inline void tcp_rcv_rtt_measure_ts(struct sock *sk,
+					  const struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (tp->rx_opt.rcv_tsecr &&
+	    (TCP_SKB_CB(skb)->end_seq -
+	     TCP_SKB_CB(skb)->seq >= inet_csk(sk)->icsk_ack.rcv_mss))
+		tcp_rcv_rtt_update(tp, tcp_time_stamp - tp->rx_opt.rcv_tsecr, 0);
+}
+
+/*
+ * This function should be called every time data is copied to user space.
+ * It calculates the appropriate TCP receive buffer space.
+ */
+void tcp_rcv_space_adjust(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int time;
+	int space;
+
+	if (tp->rcvq_space.time == 0)
+		goto new_measure;
+
+	time = tcp_time_stamp - tp->rcvq_space.time;
+	if (time < (tp->rcv_rtt_est.rtt >> 3) || tp->rcv_rtt_est.rtt == 0)
+		return;
+
+	space = 2 * (tp->copied_seq - tp->rcvq_space.seq);
+
+	space = max(tp->rcvq_space.space, space);
+
+	if (tp->rcvq_space.space != space) {
+		int rcvmem;
+
+		tp->rcvq_space.space = space;
+
+		if (sysctl_tcp_moderate_rcvbuf &&
+		    !(sk->sk_userlocks & SOCK_RCVBUF_LOCK)) {
+			int new_clamp = space;
+
+			/* Receive space grows, normalize in order to
+			 * take into account packet headers and sk_buff
+			 * structure overhead.
+			 */
+			space /= tp->advmss;
+			if (!space)
+				space = 1;
+			rcvmem = (tp->advmss + MAX_TCP_HEADER +
+				  16 + sizeof(struct sk_buff));
+			while (tcp_win_from_space(rcvmem) < tp->advmss)
+				rcvmem += 128;
+			space *= rcvmem;
+			space = min(space, sysctl_tcp_rmem[2]);
+			if (space > sk->sk_rcvbuf) {
+				sk->sk_rcvbuf = space;
+
+				/* Make the window clamp follow along.  */
+				tp->window_clamp = new_clamp;
+			}
+		}
+	}
+
+new_measure:
+	tp->rcvq_space.seq = tp->copied_seq;
+	tp->rcvq_space.time = tcp_time_stamp;
+}
+
+/* There is something which you must keep in mind when you analyze the
+ * behavior of the tp->ato delayed ack timeout interval.  When a
+ * connection starts up, we want to ack as quickly as possible.  The
+ * problem is that "good" TCP's do slow start at the beginning of data
+ * transmission.  The means that until we send the first few ACK's the
+ * sender will sit on his end and only queue most of his data, because
+ * he can only send snd_cwnd unacked packets at any given time.  For
+ * each ACK we send, he increments snd_cwnd and transmits more of his
+ * queue.  -DaveM
+ */
+static void tcp_event_data_recv(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	u32 now;
+
+	inet_csk_schedule_ack(sk);
+
+	tcp_measure_rcv_mss(sk, skb);
+
+	tcp_rcv_rtt_measure(tp);
+
+	now = tcp_time_stamp;
+
+	if (!icsk->icsk_ack.ato) {
+		/* The _first_ data packet received, initialize
+		 * delayed ACK engine.
+		 */
+		tcp_incr_quickack(sk);
+		icsk->icsk_ack.ato = TCP_ATO_MIN;
+	} else {
+		int m = now - icsk->icsk_ack.lrcvtime;
+
+		if (m <= TCP_ATO_MIN / 2) {
+			/* The fastest case is the first. */
+			icsk->icsk_ack.ato = (icsk->icsk_ack.ato >> 1) + TCP_ATO_MIN / 2;
+		} else if (m < icsk->icsk_ack.ato) {
+			icsk->icsk_ack.ato = (icsk->icsk_ack.ato >> 1) + m;
+			if (icsk->icsk_ack.ato > icsk->icsk_rto)
+				icsk->icsk_ack.ato = icsk->icsk_rto;
+		} else if (m > icsk->icsk_rto) {
+			/* Too long gap. Apparently sender failed to
+			 * restart window, so that we send ACKs quickly.
+			 */
+			tcp_incr_quickack(sk);
+			sk_mem_reclaim(sk);
+		}
+	}
+	icsk->icsk_ack.lrcvtime = now;
+
+	TCP_ECN_check_ce(tp, skb);
+
+	if (skb->len >= 128)
+		tcp_grow_window(sk, skb);
+}
+
+/* Called to compute a smoothed rtt estimate. The data fed to this
+ * routine either comes from timestamps, or from segments that were
+ * known _not_ to have been retransmitted [see Karn/Partridge
+ * Proceedings SIGCOMM 87]. The algorithm is from the SIGCOMM 88
+ * piece by Van Jacobson.
+ * NOTE: the next three routines used to be one big routine.
+ * To save cycles in the RFC 1323 implementation it was better to break
+ * it up into three procedures. -- erics
+ */
+static void tcp_rtt_estimator(struct sock *sk, const __u32 mrtt)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	long m = mrtt; /* RTT */
+
+	/*	The following amusing code comes from Jacobson's
+	 *	article in SIGCOMM '88.  Note that rtt and mdev
+	 *	are scaled versions of rtt and mean deviation.
+	 *	This is designed to be as fast as possible
+	 *	m stands for "measurement".
+	 *
+	 *	On a 1990 paper the rto value is changed to:
+	 *	RTO = rtt + 4 * mdev
+	 *
+	 * Funny. This algorithm seems to be very broken.
+	 * These formulae increase RTO, when it should be decreased, increase
+	 * too slowly, when it should be increased quickly, decrease too quickly
+	 * etc. I guess in BSD RTO takes ONE value, so that it is absolutely
+	 * does not matter how to _calculate_ it. Seems, it was trap
+	 * that VJ failed to avoid. 8)
+	 */
+	if (m == 0)
+		m = 1;
+	if (tp->srtt != 0) {
+		m -= (tp->srtt >> 3);	/* m is now error in rtt est */
+		tp->srtt += m;		/* rtt = 7/8 rtt + 1/8 new */
+		if (m < 0) {
+			m = -m;		/* m is now abs(error) */
+			m -= (tp->mdev >> 2);   /* similar update on mdev */
+			/* This is similar to one of Eifel findings.
+			 * Eifel blocks mdev updates when rtt decreases.
+			 * This solution is a bit different: we use finer gain
+			 * for mdev in this case (alpha*beta).
+			 * Like Eifel it also prevents growth of rto,
+			 * but also it limits too fast rto decreases,
+			 * happening in pure Eifel.
+			 */
+			if (m > 0)
+				m >>= 3;
+		} else {
+			m -= (tp->mdev >> 2);   /* similar update on mdev */
+		}
+		tp->mdev += m;	    	/* mdev = 3/4 mdev + 1/4 new */
+		if (tp->mdev > tp->mdev_max) {
+			tp->mdev_max = tp->mdev;
+			if (tp->mdev_max > tp->rttvar)
+				tp->rttvar = tp->mdev_max;
+		}
+		if (after(tp->snd_una, tp->rtt_seq)) {
+			if (tp->mdev_max < tp->rttvar)
+				tp->rttvar -= (tp->rttvar - tp->mdev_max) >> 2;
+			tp->rtt_seq = tp->snd_nxt;
+			tp->mdev_max = tcp_rto_min(sk);
+		}
+	} else {
+		/* no previous measure. */
+		tp->srtt = m << 3;	/* take the measured time to be rtt */
+		tp->mdev = m << 1;	/* make sure rto = 3*rtt */
+		tp->mdev_max = tp->rttvar = max(tp->mdev, tcp_rto_min(sk));
+		tp->rtt_seq = tp->snd_nxt;
+	}
+}
+
+/* Calculate rto without backoff.  This is the second half of Van Jacobson's
+ * routine referred to above.
+ */
+static inline void tcp_set_rto(struct sock *sk)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	/* Old crap is replaced with new one. 8)
+	 *
+	 * More seriously:
+	 * 1. If rtt variance happened to be less 50msec, it is hallucination.
+	 *    It cannot be less due to utterly erratic ACK generation made
+	 *    at least by solaris and freebsd. "Erratic ACKs" has _nothing_
+	 *    to do with delayed acks, because at cwnd>2 true delack timeout
+	 *    is invisible. Actually, Linux-2.4 also generates erratic
+	 *    ACKs in some circumstances.
+	 */
+	inet_csk(sk)->icsk_rto = (tp->srtt >> 3) + tp->rttvar;
+
+	/* 2. Fixups made earlier cannot be right.
+	 *    If we do not estimate RTO correctly without them,
+	 *    all the algo is pure shit and should be replaced
+	 *    with correct one. It is exactly, which we pretend to do.
+	 */
+
+	/* NOTE: clamping at TCP_RTO_MIN is not required, current algo
+	 * guarantees that rto is higher.
+	 */
+	if (inet_csk(sk)->icsk_rto > TCP_RTO_MAX)
+		inet_csk(sk)->icsk_rto = TCP_RTO_MAX;
+}
+
+/* Save metrics learned by this TCP session.
+   This function is called only, when TCP finishes successfully
+   i.e. when it enters TIME-WAIT or goes from LAST-ACK to CLOSE.
+ */
+void tcp_update_metrics(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct dst_entry *dst = __sk_dst_get(sk);
+
+	if (sysctl_tcp_nometrics_save)
+		return;
+
+	dst_confirm(dst);
+
+	if (dst && (dst->flags & DST_HOST)) {
+		const struct inet_connection_sock *icsk = inet_csk(sk);
+		int m;
+		unsigned long rtt;
+
+		if (icsk->icsk_backoff || !tp->srtt) {
+			/* This session failed to estimate rtt. Why?
+			 * Probably, no packets returned in time.
+			 * Reset our results.
+			 */
+			if (!(dst_metric_locked(dst, RTAX_RTT)))
+				dst->metrics[RTAX_RTT - 1] = 0;
+			return;
+		}
+
+		rtt = dst_metric_rtt(dst, RTAX_RTT);
+		m = rtt - tp->srtt;
+
+		/* If newly calculated rtt larger than stored one,
+		 * store new one. Otherwise, use EWMA. Remember,
+		 * rtt overestimation is always better than underestimation.
+		 */
+		if (!(dst_metric_locked(dst, RTAX_RTT))) {
+			if (m <= 0)
+				set_dst_metric_rtt(dst, RTAX_RTT, tp->srtt);
+			else
+				set_dst_metric_rtt(dst, RTAX_RTT, rtt - (m >> 3));
+		}
+
+		if (!(dst_metric_locked(dst, RTAX_RTTVAR))) {
+			unsigned long var;
+			if (m < 0)
+				m = -m;
+
+			/* Scale deviation to rttvar fixed point */
+			m >>= 1;
+			if (m < tp->mdev)
+				m = tp->mdev;
+
+			var = dst_metric_rtt(dst, RTAX_RTTVAR);
+			if (m >= var)
+				var = m;
+			else
+				var -= (var - m) >> 2;
+
+			set_dst_metric_rtt(dst, RTAX_RTTVAR, var);
+		}
+
+		if (tp->snd_ssthresh >= 0xFFFF) {
+			/* Slow start still did not finish. */
+			if (dst_metric(dst, RTAX_SSTHRESH) &&
+			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&
+			    (tp->snd_cwnd >> 1) > dst_metric(dst, RTAX_SSTHRESH))
+				dst->metrics[RTAX_SSTHRESH-1] = tp->snd_cwnd >> 1;
+			if (!dst_metric_locked(dst, RTAX_CWND) &&
+			    tp->snd_cwnd > dst_metric(dst, RTAX_CWND))
+				dst->metrics[RTAX_CWND - 1] = tp->snd_cwnd;
+		} else if (tp->snd_cwnd > tp->snd_ssthresh &&
+			   icsk->icsk_ca_state == TCP_CA_Open) {
+			/* Cong. avoidance phase, cwnd is reliable. */
+			if (!dst_metric_locked(dst, RTAX_SSTHRESH))
+				dst->metrics[RTAX_SSTHRESH-1] =
+					max(tp->snd_cwnd >> 1, tp->snd_ssthresh);
+			if (!dst_metric_locked(dst, RTAX_CWND))
+				dst->metrics[RTAX_CWND-1] = (dst_metric(dst, RTAX_CWND) + tp->snd_cwnd) >> 1;
+		} else {
+			/* Else slow start did not finish, cwnd is non-sense,
+			   ssthresh may be also invalid.
+			 */
+			if (!dst_metric_locked(dst, RTAX_CWND))
+				dst->metrics[RTAX_CWND-1] = (dst_metric(dst, RTAX_CWND) + tp->snd_ssthresh) >> 1;
+			if (dst_metric(dst, RTAX_SSTHRESH) &&
+			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&
+			    tp->snd_ssthresh > dst_metric(dst, RTAX_SSTHRESH))
+				dst->metrics[RTAX_SSTHRESH-1] = tp->snd_ssthresh;
+		}
+
+		if (!dst_metric_locked(dst, RTAX_REORDERING)) {
+			if (dst_metric(dst, RTAX_REORDERING) < tp->reordering &&
+			    tp->reordering != sysctl_tcp_reordering)
+				dst->metrics[RTAX_REORDERING-1] = tp->reordering;
+		}
+	}
+}
+
+/* Numbers are taken from RFC3390.
+ *
+ * John Heffner states:
+ *
+ *	The RFC specifies a window of no more than 4380 bytes
+ *	unless 2*MSS > 4380.  Reading the pseudocode in the RFC
+ *	is a bit misleading because they use a clamp at 4380 bytes
+ *	rather than use a multiplier in the relevant range.
+ */
+__u32 tcp_init_cwnd(struct tcp_sock *tp, struct dst_entry *dst)
+{
+	__u32 cwnd = (dst ? dst_metric(dst, RTAX_INITCWND) : 0);
+
+	if (!cwnd) {
+		if (tp->mss_cache > 1460)
+			cwnd = 2;
+		else
+			cwnd = (tp->mss_cache > 1095) ? 3 : 4;
+	}
+	return min_t(__u32, cwnd, tp->snd_cwnd_clamp);
+}
+
+/* Set slow start threshold and cwnd not falling to slow start */
+void tcp_enter_cwr(struct sock *sk, const int set_ssthresh)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+
+	tp->prior_ssthresh = 0;
+	tp->bytes_acked = 0;
+	if (icsk->icsk_ca_state < TCP_CA_CWR) {
+		tp->undo_marker = 0;
+		if (set_ssthresh)
+			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+		tp->snd_cwnd = min(tp->snd_cwnd,
+				   tcp_packets_in_flight(tp) + 1U);
+		tp->snd_cwnd_cnt = 0;
+		tp->high_seq = tp->snd_nxt;
+		tp->snd_cwnd_stamp = tcp_time_stamp;
+		TCP_ECN_queue_cwr(tp);
+
+		tcp_set_ca_state(sk, TCP_CA_CWR);
+	}
+}
+
+/*
+ * Packet counting of FACK is based on in-order assumptions, therefore TCP
+ * disables it when reordering is detected
+ */
+static void tcp_disable_fack(struct tcp_sock *tp)
+{
+	/* RFC3517 uses different metric in lost marker => reset on change */
+	if (tcp_is_fack(tp))
+		tp->lost_skb_hint = NULL;
+	tp->rx_opt.sack_ok &= ~2;
+}
+
+/* Take a notice that peer is sending D-SACKs */
+static void tcp_dsack_seen(struct tcp_sock *tp)
+{
+	tp->rx_opt.sack_ok |= 4;
+}
+
+/* Initialize metrics on socket. */
+
+static void tcp_init_metrics(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct dst_entry *dst = __sk_dst_get(sk);
+
+	if (dst == NULL)
+		goto reset;
+
+	dst_confirm(dst);
+
+	if (dst_metric_locked(dst, RTAX_CWND))
+		tp->snd_cwnd_clamp = dst_metric(dst, RTAX_CWND);
+	if (dst_metric(dst, RTAX_SSTHRESH)) {
+		tp->snd_ssthresh = dst_metric(dst, RTAX_SSTHRESH);
+		if (tp->snd_ssthresh > tp->snd_cwnd_clamp)
+			tp->snd_ssthresh = tp->snd_cwnd_clamp;
+	}
+	if (dst_metric(dst, RTAX_REORDERING) &&
+	    tp->reordering != dst_metric(dst, RTAX_REORDERING)) {
+		tcp_disable_fack(tp);
+		tp->reordering = dst_metric(dst, RTAX_REORDERING);
+	}
+
+	if (dst_metric(dst, RTAX_RTT) == 0)
+		goto reset;
+
+	if (!tp->srtt && dst_metric_rtt(dst, RTAX_RTT) < (TCP_TIMEOUT_INIT << 3))
+		goto reset;
+
+	/* Initial rtt is determined from SYN,SYN-ACK.
+	 * The segment is small and rtt may appear much
+	 * less than real one. Use per-dst memory
+	 * to make it more realistic.
+	 *
+	 * A bit of theory. RTT is time passed after "normal" sized packet
+	 * is sent until it is ACKed. In normal circumstances sending small
+	 * packets force peer to delay ACKs and calculation is correct too.
+	 * The algorithm is adaptive and, provided we follow specs, it
+	 * NEVER underestimate RTT. BUT! If peer tries to make some clever
+	 * tricks sort of "quick acks" for time long enough to decrease RTT
+	 * to low value, and then abruptly stops to do it and starts to delay
+	 * ACKs, wait for troubles.
+	 */
+	if (dst_metric_rtt(dst, RTAX_RTT) > tp->srtt) {
+		tp->srtt = dst_metric_rtt(dst, RTAX_RTT);
+		tp->rtt_seq = tp->snd_nxt;
+	}
+	if (dst_metric_rtt(dst, RTAX_RTTVAR) > tp->mdev) {
+		tp->mdev = dst_metric_rtt(dst, RTAX_RTTVAR);
+		tp->mdev_max = tp->rttvar = max(tp->mdev, tcp_rto_min(sk));
+	}
+	tcp_set_rto(sk);
+	if (inet_csk(sk)->icsk_rto < TCP_TIMEOUT_INIT && !tp->rx_opt.saw_tstamp)
+		goto reset;
+
+cwnd:
+	tp->snd_cwnd = tcp_init_cwnd(tp, dst);
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+	return;
+
+reset:
+	/* Play conservative. If timestamps are not
+	 * supported, TCP will fail to recalculate correct
+	 * rtt, if initial rto is too small. FORGET ALL AND RESET!
+	 */
+	if (!tp->rx_opt.saw_tstamp && tp->srtt) {
+		tp->srtt = 0;
+		tp->mdev = tp->mdev_max = tp->rttvar = TCP_TIMEOUT_INIT;
+		inet_csk(sk)->icsk_rto = TCP_TIMEOUT_INIT;
+	}
+	goto cwnd;
+}
+
+static void tcp_update_reordering(struct sock *sk, const int metric,
+				  const int ts)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (metric > tp->reordering) {
+		int mib_idx;
+
+		tp->reordering = min(TCP_MAX_REORDERING, metric);
+
+		/* This exciting event is worth to be remembered. 8) */
+		if (ts)
+			mib_idx = LINUX_MIB_TCPTSREORDER;
+		else if (tcp_is_reno(tp))
+			mib_idx = LINUX_MIB_TCPRENOREORDER;
+		else if (tcp_is_fack(tp))
+			mib_idx = LINUX_MIB_TCPFACKREORDER;
+		else
+			mib_idx = LINUX_MIB_TCPSACKREORDER;
+
+		NET_INC_STATS_BH(sock_net(sk), mib_idx);
+#if FASTRETRANS_DEBUG > 1
+		printk(KERN_DEBUG "Disorder%d %d %u f%u s%u rr%d\n",
+		       tp->rx_opt.sack_ok, inet_csk(sk)->icsk_ca_state,
+		       tp->reordering,
+		       tp->fackets_out,
+		       tp->sacked_out,
+		       tp->undo_marker ? tp->undo_retrans : 0);
+#endif
+		tcp_disable_fack(tp);
+	}
+}
+
+/* This must be called before lost_out is incremented */
+static void tcp_verify_retransmit_hint(struct tcp_sock *tp, struct sk_buff *skb)
+{
+	if ((tp->retransmit_skb_hint == NULL) ||
+	    before(TCP_SKB_CB(skb)->seq,
+		   TCP_SKB_CB(tp->retransmit_skb_hint)->seq))
+		tp->retransmit_skb_hint = skb;
+
+	if (!tp->lost_out ||
+	    after(TCP_SKB_CB(skb)->end_seq, tp->retransmit_high))
+		tp->retransmit_high = TCP_SKB_CB(skb)->end_seq;
+}
+
+static void tcp_skb_mark_lost(struct tcp_sock *tp, struct sk_buff *skb)
+{
+	if (!(TCP_SKB_CB(skb)->sacked & (TCPCB_LOST|TCPCB_SACKED_ACKED))) {
+		tcp_verify_retransmit_hint(tp, skb);
+
+		tp->lost_out += tcp_skb_pcount(skb);
+		TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;
+	}
+}
+
+static void tcp_skb_mark_lost_uncond_verify(struct tcp_sock *tp,
+					    struct sk_buff *skb)
+{
+	tcp_verify_retransmit_hint(tp, skb);
+
+	if (!(TCP_SKB_CB(skb)->sacked & (TCPCB_LOST|TCPCB_SACKED_ACKED))) {
+		tp->lost_out += tcp_skb_pcount(skb);
+		TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;
+	}
+}
+
+/* This procedure tags the retransmission queue when SACKs arrive.
+ *
+ * We have three tag bits: SACKED(S), RETRANS(R) and LOST(L).
+ * Packets in queue with these bits set are counted in variables
+ * sacked_out, retrans_out and lost_out, correspondingly.
+ *
+ * Valid combinations are:
+ * Tag  InFlight	Description
+ * 0	1		- orig segment is in flight.
+ * S	0		- nothing flies, orig reached receiver.
+ * L	0		- nothing flies, orig lost by net.
+ * R	2		- both orig and retransmit are in flight.
+ * L|R	1		- orig is lost, retransmit is in flight.
+ * S|R  1		- orig reached receiver, retrans is still in flight.
+ * (L|S|R is logically valid, it could occur when L|R is sacked,
+ *  but it is equivalent to plain S and code short-curcuits it to S.
+ *  L|S is logically invalid, it would mean -1 packet in flight 8))
+ *
+ * These 6 states form finite state machine, controlled by the following events:
+ * 1. New ACK (+SACK) arrives. (tcp_sacktag_write_queue())
+ * 2. Retransmission. (tcp_retransmit_skb(), tcp_xmit_retransmit_queue())
+ * 3. Loss detection event of one of three flavors:
+ *	A. Scoreboard estimator decided the packet is lost.
+ *	   A'. Reno "three dupacks" marks head of queue lost.
+ *	   A''. Its FACK modfication, head until snd.fack is lost.
+ *	B. SACK arrives sacking data transmitted after never retransmitted
+ *	   hole was sent out.
+ *	C. SACK arrives sacking SND.NXT at the moment, when the
+ *	   segment was retransmitted.
+ * 4. D-SACK added new rule: D-SACK changes any tag to S.
+ *
+ * It is pleasant to note, that state diagram turns out to be commutative,
+ * so that we are allowed not to be bothered by order of our actions,
+ * when multiple events arrive simultaneously. (see the function below).
+ *
+ * Reordering detection.
+ * --------------------
+ * Reordering metric is maximal distance, which a packet can be displaced
+ * in packet stream. With SACKs we can estimate it:
+ *
+ * 1. SACK fills old hole and the corresponding segment was not
+ *    ever retransmitted -> reordering. Alas, we cannot use it
+ *    when segment was retransmitted.
+ * 2. The last flaw is solved with D-SACK. D-SACK arrives
+ *    for retransmitted and already SACKed segment -> reordering..
+ * Both of these heuristics are not used in Loss state, when we cannot
+ * account for retransmits accurately.
+ *
+ * SACK block validation.
+ * ----------------------
+ *
+ * SACK block range validation checks that the received SACK block fits to
+ * the expected sequence limits, i.e., it is between SND.UNA and SND.NXT.
+ * Note that SND.UNA is not included to the range though being valid because
+ * it means that the receiver is rather inconsistent with itself reporting
+ * SACK reneging when it should advance SND.UNA. Such SACK block this is
+ * perfectly valid, however, in light of RFC2018 which explicitly states
+ * that "SACK block MUST reflect the newest segment.  Even if the newest
+ * segment is going to be discarded ...", not that it looks very clever
+ * in case of head skb. Due to potentional receiver driven attacks, we
+ * choose to avoid immediate execution of a walk in write queue due to
+ * reneging and defer head skb's loss recovery to standard loss recovery
+ * procedure that will eventually trigger (nothing forbids us doing this).
+ *
+ * Implements also blockage to start_seq wrap-around. Problem lies in the
+ * fact that though start_seq (s) is before end_seq (i.e., not reversed),
+ * there's no guarantee that it will be before snd_nxt (n). The problem
+ * happens when start_seq resides between end_seq wrap (e_w) and snd_nxt
+ * wrap (s_w):
+ *
+ *         <- outs wnd ->                          <- wrapzone ->
+ *         u     e      n                         u_w   e_w  s n_w
+ *         |     |      |                          |     |   |  |
+ * |<------------+------+----- TCP seqno space --------------+---------->|
+ * ...-- <2^31 ->|                                           |<--------...
+ * ...---- >2^31 ------>|                                    |<--------...
+ *
+ * Current code wouldn't be vulnerable but it's better still to discard such
+ * crazy SACK blocks. Doing this check for start_seq alone closes somewhat
+ * similar case (end_seq after snd_nxt wrap) as earlier reversed check in
+ * snd_nxt wrap -> snd_una region will then become "well defined", i.e.,
+ * equal to the ideal case (infinite seqno space without wrap caused issues).
+ *
+ * With D-SACK the lower bound is extended to cover sequence space below
+ * SND.UNA down to undo_marker, which is the last point of interest. Yet
+ * again, D-SACK block must not to go across snd_una (for the same reason as
+ * for the normal SACK blocks, explained above). But there all simplicity
+ * ends, TCP might receive valid D-SACKs below that. As long as they reside
+ * fully below undo_marker they do not affect behavior in anyway and can
+ * therefore be safely ignored. In rare cases (which are more or less
+ * theoretical ones), the D-SACK will nicely cross that boundary due to skb
+ * fragmentation and packet reordering past skb's retransmission. To consider
+ * them correctly, the acceptable range must be extended even more though
+ * the exact amount is rather hard to quantify. However, tp->max_window can
+ * be used as an exaggerated estimate.
+ */
+static int tcp_is_sackblock_valid(struct tcp_sock *tp, int is_dsack,
+				  u32 start_seq, u32 end_seq)
+{
+	/* Too far in future, or reversed (interpretation is ambiguous) */
+	if (after(end_seq, tp->snd_nxt) || !before(start_seq, end_seq))
+		return 0;
+
+	/* Nasty start_seq wrap-around check (see comments above) */
+	if (!before(start_seq, tp->snd_nxt))
+		return 0;
+
+	/* In outstanding window? ...This is valid exit for D-SACKs too.
+	 * start_seq == snd_una is non-sensical (see comments above)
+	 */
+	if (after(start_seq, tp->snd_una))
+		return 1;
+
+	if (!is_dsack || !tp->undo_marker)
+		return 0;
+
+	/* ...Then it's D-SACK, and must reside below snd_una completely */
+	if (!after(end_seq, tp->snd_una))
+		return 0;
+
+	if (!before(start_seq, tp->undo_marker))
+		return 1;
+
+	/* Too old */
+	if (!after(end_seq, tp->undo_marker))
+		return 0;
+
+	/* Undo_marker boundary crossing (overestimates a lot). Known already:
+	 *   start_seq < undo_marker and end_seq >= undo_marker.
+	 */
+	return !before(start_seq, end_seq - tp->max_window);
+}
+
+/* Check for lost retransmit. This superb idea is borrowed from "ratehalving".
+ * Event "C". Later note: FACK people cheated me again 8), we have to account
+ * for reordering! Ugly, but should help.
+ *
+ * Search retransmitted skbs from write_queue that were sent when snd_nxt was
+ * less than what is now known to be received by the other end (derived from
+ * highest SACK block). Also calculate the lowest snd_nxt among the remaining
+ * retransmitted skbs to avoid some costly processing per ACKs.
+ */
+static void tcp_mark_lost_retrans(struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+	int cnt = 0;
+	u32 new_low_seq = tp->snd_nxt;
+	u32 received_upto = tcp_highest_sack_seq(tp);
+
+	if (!tcp_is_fack(tp) || !tp->retrans_out ||
+	    !after(received_upto, tp->lost_retrans_low) ||
+	    icsk->icsk_ca_state != TCP_CA_Recovery)
+		return;
+
+	tcp_for_write_queue(skb, sk) {
+		u32 ack_seq = TCP_SKB_CB(skb)->ack_seq;
+
+		if (skb == tcp_send_head(sk))
+			break;
+		if (cnt == tp->retrans_out)
+			break;
+		if (!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una))
+			continue;
+
+		if (!(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_RETRANS))
+			continue;
+
+		/* TODO: We would like to get rid of tcp_is_fack(tp) only
+		 * constraint here (see above) but figuring out that at
+		 * least tp->reordering SACK blocks reside between ack_seq
+		 * and received_upto is not easy task to do cheaply with
+		 * the available datastructures.
+		 *
+		 * Whether FACK should check here for tp->reordering segs
+		 * in-between one could argue for either way (it would be
+		 * rather simple to implement as we could count fack_count
+		 * during the walk and do tp->fackets_out - fack_count).
+		 */
+		if (after(received_upto, ack_seq)) {
+			TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;
+			tp->retrans_out -= tcp_skb_pcount(skb);
+
+			tcp_skb_mark_lost_uncond_verify(tp, skb);
+			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSTRETRANSMIT);
+		} else {
+			if (before(ack_seq, new_low_seq))
+				new_low_seq = ack_seq;
+			cnt += tcp_skb_pcount(skb);
+		}
+	}
+
+	if (tp->retrans_out)
+		tp->lost_retrans_low = new_low_seq;
+}
+
+static int tcp_check_dsack(struct sock *sk, struct sk_buff *ack_skb,
+			   struct tcp_sack_block_wire *sp, int num_sacks,
+			   u32 prior_snd_una)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 start_seq_0 = get_unaligned_be32(&sp[0].start_seq);
+	u32 end_seq_0 = get_unaligned_be32(&sp[0].end_seq);
+	int dup_sack = 0;
+
+	if (before(start_seq_0, TCP_SKB_CB(ack_skb)->ack_seq)) {
+		dup_sack = 1;
+		tcp_dsack_seen(tp);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPDSACKRECV);
+	} else if (num_sacks > 1) {
+		u32 end_seq_1 = get_unaligned_be32(&sp[1].end_seq);
+		u32 start_seq_1 = get_unaligned_be32(&sp[1].start_seq);
+
+		if (!after(end_seq_0, end_seq_1) &&
+		    !before(start_seq_0, start_seq_1)) {
+			dup_sack = 1;
+			tcp_dsack_seen(tp);
+			NET_INC_STATS_BH(sock_net(sk),
+					LINUX_MIB_TCPDSACKOFORECV);
+		}
+	}
+
+	/* D-SACK for already forgotten data... Do dumb counting. */
+	if (dup_sack &&
+	    !after(end_seq_0, prior_snd_una) &&
+	    after(end_seq_0, tp->undo_marker))
+		tp->undo_retrans--;
+
+	return dup_sack;
+}
+
+struct tcp_sacktag_state {
+	int reord;
+	int fack_count;
+	int flag;
+};
+
+/* Check if skb is fully within the SACK block. In presence of GSO skbs,
+ * the incoming SACK may not exactly match but we can find smaller MSS
+ * aligned portion of it that matches. Therefore we might need to fragment
+ * which may fail and creates some hassle (caller must handle error case
+ * returns).
+ *
+ * FIXME: this could be merged to shift decision code
+ */
+static int tcp_match_skb_to_sack(struct sock *sk, struct sk_buff *skb,
+				 u32 start_seq, u32 end_seq)
+{
+	int in_sack, err;
+	unsigned int pkt_len;
+	unsigned int mss;
+
+	in_sack = !after(start_seq, TCP_SKB_CB(skb)->seq) &&
+		  !before(end_seq, TCP_SKB_CB(skb)->end_seq);
+
+	if (tcp_skb_pcount(skb) > 1 && !in_sack &&
+	    after(TCP_SKB_CB(skb)->end_seq, start_seq)) {
+		mss = tcp_skb_mss(skb);
+		in_sack = !after(start_seq, TCP_SKB_CB(skb)->seq);
+
+		if (!in_sack) {
+			pkt_len = start_seq - TCP_SKB_CB(skb)->seq;
+			if (pkt_len < mss)
+				pkt_len = mss;
+		} else {
+			pkt_len = end_seq - TCP_SKB_CB(skb)->seq;
+			if (pkt_len < mss)
+				return -EINVAL;
+		}
+
+		/* Round if necessary so that SACKs cover only full MSSes
+		 * and/or the remaining small portion (if present)
+		 */
+		if (pkt_len > mss) {
+			unsigned int new_len = (pkt_len / mss) * mss;
+			if (!in_sack && new_len < pkt_len) {
+				new_len += mss;
+				if (new_len > skb->len)
+					return 0;
+			}
+			pkt_len = new_len;
+		}
+		err = tcp_fragment(sk, skb, pkt_len, mss);
+		if (err < 0)
+			return err;
+	}
+
+	return in_sack;
+}
+
+static u8 tcp_sacktag_one(struct sk_buff *skb, struct sock *sk,
+			  struct tcp_sacktag_state *state,
+			  int dup_sack, int pcount)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u8 sacked = TCP_SKB_CB(skb)->sacked;
+	int fack_count = state->fack_count;
+
+	/* Account D-SACK for retransmitted packet. */
+	if (dup_sack && (sacked & TCPCB_RETRANS)) {
+		if (after(TCP_SKB_CB(skb)->end_seq, tp->undo_marker))
+			tp->undo_retrans--;
+		if (sacked & TCPCB_SACKED_ACKED)
+			state->reord = min(fack_count, state->reord);
+	}
+
+	/* Nothing to do; acked frame is about to be dropped (was ACKed). */
+	if (!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una))
+		return sacked;
+
+	if (!(sacked & TCPCB_SACKED_ACKED)) {
+		if (sacked & TCPCB_SACKED_RETRANS) {
+			/* If the segment is not tagged as lost,
+			 * we do not clear RETRANS, believing
+			 * that retransmission is still in flight.
+			 */
+			if (sacked & TCPCB_LOST) {
+				sacked &= ~(TCPCB_LOST|TCPCB_SACKED_RETRANS);
+				tp->lost_out -= pcount;
+				tp->retrans_out -= pcount;
+			}
+		} else {
+			if (!(sacked & TCPCB_RETRANS)) {
+				/* New sack for not retransmitted frame,
+				 * which was in hole. It is reordering.
+				 */
+				if (before(TCP_SKB_CB(skb)->seq,
+					   tcp_highest_sack_seq(tp)))
+					state->reord = min(fack_count,
+							   state->reord);
+
+				/* SACK enhanced F-RTO (RFC4138; Appendix B) */
+				if (!after(TCP_SKB_CB(skb)->end_seq, tp->frto_highmark))
+					state->flag |= FLAG_ONLY_ORIG_SACKED;
+			}
+
+			if (sacked & TCPCB_LOST) {
+				sacked &= ~TCPCB_LOST;
+				tp->lost_out -= pcount;
+			}
+		}
+
+		sacked |= TCPCB_SACKED_ACKED;
+		state->flag |= FLAG_DATA_SACKED;
+		tp->sacked_out += pcount;
+
+		fack_count += pcount;
+
+		/* Lost marker hint past SACKed? Tweak RFC3517 cnt */
+		if (!tcp_is_fack(tp) && (tp->lost_skb_hint != NULL) &&
+		    before(TCP_SKB_CB(skb)->seq,
+			   TCP_SKB_CB(tp->lost_skb_hint)->seq))
+			tp->lost_cnt_hint += pcount;
+
+		if (fack_count > tp->fackets_out)
+			tp->fackets_out = fack_count;
+	}
+
+	/* D-SACK. We can detect redundant retransmission in S|R and plain R
+	 * frames and clear it. undo_retrans is decreased above, L|R frames
+	 * are accounted above as well.
+	 */
+	if (dup_sack && (sacked & TCPCB_SACKED_RETRANS)) {
+		sacked &= ~TCPCB_SACKED_RETRANS;
+		tp->retrans_out -= pcount;
+	}
+
+	return sacked;
+}
+
+static int tcp_shifted_skb(struct sock *sk, struct sk_buff *skb,
+			   struct tcp_sacktag_state *state,
+			   unsigned int pcount, int shifted, int mss,
+			   int dup_sack)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *prev = tcp_write_queue_prev(sk, skb);
+
+	BUG_ON(!pcount);
+
+	/* Tweak before seqno plays */
+	if (!tcp_is_fack(tp) && tcp_is_sack(tp) && tp->lost_skb_hint &&
+	    !before(TCP_SKB_CB(tp->lost_skb_hint)->seq, TCP_SKB_CB(skb)->seq))
+		tp->lost_cnt_hint += pcount;
+
+	TCP_SKB_CB(prev)->end_seq += shifted;
+	TCP_SKB_CB(skb)->seq += shifted;
+
+	skb_shinfo(prev)->gso_segs += pcount;
+	BUG_ON(skb_shinfo(skb)->gso_segs < pcount);
+	skb_shinfo(skb)->gso_segs -= pcount;
+
+	/* When we're adding to gso_segs == 1, gso_size will be zero,
+	 * in theory this shouldn't be necessary but as long as DSACK
+	 * code can come after this skb later on it's better to keep
+	 * setting gso_size to something.
+	 */
+	if (!skb_shinfo(prev)->gso_size) {
+		skb_shinfo(prev)->gso_size = mss;
+		skb_shinfo(prev)->gso_type = sk->sk_gso_type;
+	}
+
+	/* CHECKME: To clear or not to clear? Mimics normal skb currently */
+	if (skb_shinfo(skb)->gso_segs <= 1) {
+		skb_shinfo(skb)->gso_size = 0;
+		skb_shinfo(skb)->gso_type = 0;
+	}
+
+	/* We discard results */
+	tcp_sacktag_one(skb, sk, state, dup_sack, pcount);
+
+	/* Difference in this won't matter, both ACKed by the same cumul. ACK */
+	TCP_SKB_CB(prev)->sacked |= (TCP_SKB_CB(skb)->sacked & TCPCB_EVER_RETRANS);
+
+	if (skb->len > 0) {
+		BUG_ON(!tcp_skb_pcount(skb));
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SACKSHIFTED);
+		return 0;
+	}
+
+	/* Whole SKB was eaten :-) */
+
+	if (skb == tp->retransmit_skb_hint)
+		tp->retransmit_skb_hint = prev;
+	if (skb == tp->scoreboard_skb_hint)
+		tp->scoreboard_skb_hint = prev;
+	if (skb == tp->lost_skb_hint) {
+		tp->lost_skb_hint = prev;
+		tp->lost_cnt_hint -= tcp_skb_pcount(prev);
+	}
+
+	TCP_SKB_CB(skb)->flags |= TCP_SKB_CB(prev)->flags;
+	if (skb == tcp_highest_sack(sk))
+		tcp_advance_highest_sack(sk, skb);
+
+	tcp_unlink_write_queue(skb, sk);
+	sk_wmem_free_skb(sk, skb);
+
+	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SACKMERGED);
+
+	return 1;
+}
+
+/* I wish gso_size would have a bit more sane initialization than
+ * something-or-zero which complicates things
+ */
+static int tcp_skb_seglen(struct sk_buff *skb)
+{
+	return tcp_skb_pcount(skb) == 1 ? skb->len : tcp_skb_mss(skb);
+}
+
+/* Shifting pages past head area doesn't work */
+static int skb_can_shift(struct sk_buff *skb)
+{
+	return !skb_headlen(skb) && skb_is_nonlinear(skb);
+}
+
+/* Try collapsing SACK blocks spanning across multiple skbs to a single
+ * skb.
+ */
+static struct sk_buff *tcp_shift_skb_data(struct sock *sk, struct sk_buff *skb,
+					  struct tcp_sacktag_state *state,
+					  u32 start_seq, u32 end_seq,
+					  int dup_sack)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *prev;
+	int mss;
+	int pcount = 0;
+	int len;
+	int in_sack;
+
+	if (!sk_can_gso(sk))
+		goto fallback;
+
+	/* Normally R but no L won't result in plain S */
+	if (!dup_sack &&
+	    (TCP_SKB_CB(skb)->sacked & (TCPCB_LOST|TCPCB_SACKED_RETRANS)) == TCPCB_SACKED_RETRANS)
+		goto fallback;
+	if (!skb_can_shift(skb))
+		goto fallback;
+	/* This frame is about to be dropped (was ACKed). */
+	if (!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una))
+		goto fallback;
+
+	/* Can only happen with delayed DSACK + discard craziness */
+	if (unlikely(skb == tcp_write_queue_head(sk)))
+		goto fallback;
+	prev = tcp_write_queue_prev(sk, skb);
+
+	if ((TCP_SKB_CB(prev)->sacked & TCPCB_TAGBITS) != TCPCB_SACKED_ACKED)
+		goto fallback;
+
+	in_sack = !after(start_seq, TCP_SKB_CB(skb)->seq) &&
+		  !before(end_seq, TCP_SKB_CB(skb)->end_seq);
+
+	if (in_sack) {
+		len = skb->len;
+		pcount = tcp_skb_pcount(skb);
+		mss = tcp_skb_seglen(skb);
+
+		/* TODO: Fix DSACKs to not fragment already SACKed and we can
+		 * drop this restriction as unnecessary
+		 */
+		if (mss != tcp_skb_seglen(prev))
+			goto fallback;
+	} else {
+		if (!after(TCP_SKB_CB(skb)->end_seq, start_seq))
+			goto noop;
+		/* CHECKME: This is non-MSS split case only?, this will
+		 * cause skipped skbs due to advancing loop btw, original
+		 * has that feature too
+		 */
+		if (tcp_skb_pcount(skb) <= 1)
+			goto noop;
+
+		in_sack = !after(start_seq, TCP_SKB_CB(skb)->seq);
+		if (!in_sack) {
+			/* TODO: head merge to next could be attempted here
+			 * if (!after(TCP_SKB_CB(skb)->end_seq, end_seq)),
+			 * though it might not be worth of the additional hassle
+			 *
+			 * ...we can probably just fallback to what was done
+			 * previously. We could try merging non-SACKed ones
+			 * as well but it probably isn't going to buy off
+			 * because later SACKs might again split them, and
+			 * it would make skb timestamp tracking considerably
+			 * harder problem.
+			 */
+			goto fallback;
+		}
+
+		len = end_seq - TCP_SKB_CB(skb)->seq;
+		BUG_ON(len < 0);
+		BUG_ON(len > skb->len);
+
+		/* MSS boundaries should be honoured or else pcount will
+		 * severely break even though it makes things bit trickier.
+		 * Optimize common case to avoid most of the divides
+		 */
+		mss = tcp_skb_mss(skb);
+
+		/* TODO: Fix DSACKs to not fragment already SACKed and we can
+		 * drop this restriction as unnecessary
+		 */
+		if (mss != tcp_skb_seglen(prev))
+			goto fallback;
+
+		if (len == mss) {
+			pcount = 1;
+		} else if (len < mss) {
+			goto noop;
+		} else {
+			pcount = len / mss;
+			len = pcount * mss;
+		}
+	}
+
+	if (!skb_shift(prev, skb, len))
+		goto fallback;
+	if (!tcp_shifted_skb(sk, skb, state, pcount, len, mss, dup_sack))
+		goto out;
+
+	/* Hole filled allows collapsing with the next as well, this is very
+	 * useful when hole on every nth skb pattern happens
+	 */
+	if (prev == tcp_write_queue_tail(sk))
+		goto out;
+	skb = tcp_write_queue_next(sk, prev);
+
+	if (!skb_can_shift(skb) ||
+	    (skb == tcp_send_head(sk)) ||
+	    ((TCP_SKB_CB(skb)->sacked & TCPCB_TAGBITS) != TCPCB_SACKED_ACKED) ||
+	    (mss != tcp_skb_seglen(skb)))
+		goto out;
+
+	len = skb->len;
+	if (skb_shift(prev, skb, len)) {
+		pcount += tcp_skb_pcount(skb);
+		tcp_shifted_skb(sk, skb, state, tcp_skb_pcount(skb), len, mss, 0);
+	}
+
+out:
+	state->fack_count += pcount;
+	return prev;
+
+noop:
+	return skb;
+
+fallback:
+	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SACKSHIFTFALLBACK);
+	return NULL;
+}
+
+static struct sk_buff *tcp_sacktag_walk(struct sk_buff *skb, struct sock *sk,
+					struct tcp_sack_block *next_dup,
+					struct tcp_sacktag_state *state,
+					u32 start_seq, u32 end_seq,
+					int dup_sack_in)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *tmp;
+
+	tcp_for_write_queue_from(skb, sk) {
+		int in_sack = 0;
+		int dup_sack = dup_sack_in;
+
+		if (skb == tcp_send_head(sk))
+			break;
+
+		/* queue is in-order => we can short-circuit the walk early */
+		if (!before(TCP_SKB_CB(skb)->seq, end_seq))
+			break;
+
+		if ((next_dup != NULL) &&
+		    before(TCP_SKB_CB(skb)->seq, next_dup->end_seq)) {
+			in_sack = tcp_match_skb_to_sack(sk, skb,
+							next_dup->start_seq,
+							next_dup->end_seq);
+			if (in_sack > 0)
+				dup_sack = 1;
+		}
+
+		/* skb reference here is a bit tricky to get right, since
+		 * shifting can eat and free both this skb and the next,
+		 * so not even _safe variant of the loop is enough.
+		 */
+		if (in_sack <= 0) {
+			tmp = tcp_shift_skb_data(sk, skb, state,
+						 start_seq, end_seq, dup_sack);
+			if (tmp != NULL) {
+				if (tmp != skb) {
+					skb = tmp;
+					continue;
+				}
+
+				in_sack = 0;
+			} else {
+				in_sack = tcp_match_skb_to_sack(sk, skb,
+								start_seq,
+								end_seq);
+			}
+		}
+
+		if (unlikely(in_sack < 0))
+			break;
+
+		if (in_sack) {
+			TCP_SKB_CB(skb)->sacked = tcp_sacktag_one(skb, sk,
+								  state,
+								  dup_sack,
+								  tcp_skb_pcount(skb));
+
+			if (!before(TCP_SKB_CB(skb)->seq,
+				    tcp_highest_sack_seq(tp)))
+				tcp_advance_highest_sack(sk, skb);
+		}
+
+		state->fack_count += tcp_skb_pcount(skb);
+	}
+	return skb;
+}
+
+/* Avoid all extra work that is being done by sacktag while walking in
+ * a normal way
+ */
+static struct sk_buff *tcp_sacktag_skip(struct sk_buff *skb, struct sock *sk,
+					struct tcp_sacktag_state *state,
+					u32 skip_to_seq)
+{
+	tcp_for_write_queue_from(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+
+		if (after(TCP_SKB_CB(skb)->end_seq, skip_to_seq))
+			break;
+
+		state->fack_count += tcp_skb_pcount(skb);
+	}
+	return skb;
+}
+
+static struct sk_buff *tcp_maybe_skipping_dsack(struct sk_buff *skb,
+						struct sock *sk,
+						struct tcp_sack_block *next_dup,
+						struct tcp_sacktag_state *state,
+						u32 skip_to_seq)
+{
+	if (next_dup == NULL)
+		return skb;
+
+	if (before(next_dup->start_seq, skip_to_seq)) {
+		skb = tcp_sacktag_skip(skb, sk, state, next_dup->start_seq);
+		skb = tcp_sacktag_walk(skb, sk, NULL, state,
+				       next_dup->start_seq, next_dup->end_seq,
+				       1);
+	}
+
+	return skb;
+}
+
+static int tcp_sack_cache_ok(struct tcp_sock *tp, struct tcp_sack_block *cache)
+{
+	return cache < tp->recv_sack_cache + ARRAY_SIZE(tp->recv_sack_cache);
+}
+
+static int
+tcp_sacktag_write_queue(struct sock *sk, struct sk_buff *ack_skb,
+			u32 prior_snd_una)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	unsigned char *ptr = (skb_transport_header(ack_skb) +
+			      TCP_SKB_CB(ack_skb)->sacked);
+	struct tcp_sack_block_wire *sp_wire = (struct tcp_sack_block_wire *)(ptr+2);
+	struct tcp_sack_block sp[TCP_NUM_SACKS];
+	struct tcp_sack_block *cache;
+	struct tcp_sacktag_state state;
+	struct sk_buff *skb;
+	int num_sacks = min(TCP_NUM_SACKS, (ptr[1] - TCPOLEN_SACK_BASE) >> 3);
+	int used_sacks;
+	int found_dup_sack = 0;
+	int i, j;
+	int first_sack_index;
+
+	state.flag = 0;
+	state.reord = tp->packets_out;
+
+	if (!tp->sacked_out) {
+		if (WARN_ON(tp->fackets_out))
+			tp->fackets_out = 0;
+		tcp_highest_sack_reset(sk);
+	}
+
+	found_dup_sack = tcp_check_dsack(sk, ack_skb, sp_wire,
+					 num_sacks, prior_snd_una);
+	if (found_dup_sack)
+		state.flag |= FLAG_DSACKING_ACK;
+
+	/* Eliminate too old ACKs, but take into
+	 * account more or less fresh ones, they can
+	 * contain valid SACK info.
+	 */
+	if (before(TCP_SKB_CB(ack_skb)->ack_seq, prior_snd_una - tp->max_window))
+		return 0;
+
+	if (!tp->packets_out)
+		goto out;
+
+	used_sacks = 0;
+	first_sack_index = 0;
+	for (i = 0; i < num_sacks; i++) {
+		int dup_sack = !i && found_dup_sack;
+
+		sp[used_sacks].start_seq = get_unaligned_be32(&sp_wire[i].start_seq);
+		sp[used_sacks].end_seq = get_unaligned_be32(&sp_wire[i].end_seq);
+
+		if (!tcp_is_sackblock_valid(tp, dup_sack,
+					    sp[used_sacks].start_seq,
+					    sp[used_sacks].end_seq)) {
+			int mib_idx;
+
+			if (dup_sack) {
+				if (!tp->undo_marker)
+					mib_idx = LINUX_MIB_TCPDSACKIGNOREDNOUNDO;
+				else
+					mib_idx = LINUX_MIB_TCPDSACKIGNOREDOLD;
+			} else {
+				/* Don't count olds caused by ACK reordering */
+				if ((TCP_SKB_CB(ack_skb)->ack_seq != tp->snd_una) &&
+				    !after(sp[used_sacks].end_seq, tp->snd_una))
+					continue;
+				mib_idx = LINUX_MIB_TCPSACKDISCARD;
+			}
+
+			NET_INC_STATS_BH(sock_net(sk), mib_idx);
+			if (i == 0)
+				first_sack_index = -1;
+			continue;
+		}
+
+		/* Ignore very old stuff early */
+		if (!after(sp[used_sacks].end_seq, prior_snd_una))
+			continue;
+
+		used_sacks++;
+	}
+
+	/* order SACK blocks to allow in order walk of the retrans queue */
+	for (i = used_sacks - 1; i > 0; i--) {
+		for (j = 0; j < i; j++) {
+			if (after(sp[j].start_seq, sp[j + 1].start_seq)) {
+				swap(sp[j], sp[j + 1]);
+
+				/* Track where the first SACK block goes to */
+				if (j == first_sack_index)
+					first_sack_index = j + 1;
+			}
+		}
+	}
+
+	skb = tcp_write_queue_head(sk);
+	state.fack_count = 0;
+	i = 0;
+
+	if (!tp->sacked_out) {
+		/* It's already past, so skip checking against it */
+		cache = tp->recv_sack_cache + ARRAY_SIZE(tp->recv_sack_cache);
+	} else {
+		cache = tp->recv_sack_cache;
+		/* Skip empty blocks in at head of the cache */
+		while (tcp_sack_cache_ok(tp, cache) && !cache->start_seq &&
+		       !cache->end_seq)
+			cache++;
+	}
+
+	while (i < used_sacks) {
+		u32 start_seq = sp[i].start_seq;
+		u32 end_seq = sp[i].end_seq;
+		int dup_sack = (found_dup_sack && (i == first_sack_index));
+		struct tcp_sack_block *next_dup = NULL;
+
+		if (found_dup_sack && ((i + 1) == first_sack_index))
+			next_dup = &sp[i + 1];
+
+		/* Event "B" in the comment above. */
+		if (after(end_seq, tp->high_seq))
+			state.flag |= FLAG_DATA_LOST;
+
+		/* Skip too early cached blocks */
+		while (tcp_sack_cache_ok(tp, cache) &&
+		       !before(start_seq, cache->end_seq))
+			cache++;
+
+		/* Can skip some work by looking recv_sack_cache? */
+		if (tcp_sack_cache_ok(tp, cache) && !dup_sack &&
+		    after(end_seq, cache->start_seq)) {
+
+			/* Head todo? */
+			if (before(start_seq, cache->start_seq)) {
+				skb = tcp_sacktag_skip(skb, sk, &state,
+						       start_seq);
+				skb = tcp_sacktag_walk(skb, sk, next_dup,
+						       &state,
+						       start_seq,
+						       cache->start_seq,
+						       dup_sack);
+			}
+
+			/* Rest of the block already fully processed? */
+			if (!after(end_seq, cache->end_seq))
+				goto advance_sp;
+
+			skb = tcp_maybe_skipping_dsack(skb, sk, next_dup,
+						       &state,
+						       cache->end_seq);
+
+			/* ...tail remains todo... */
+			if (tcp_highest_sack_seq(tp) == cache->end_seq) {
+				/* ...but better entrypoint exists! */
+				skb = tcp_highest_sack(sk);
+				if (skb == NULL)
+					break;
+				state.fack_count = tp->fackets_out;
+				cache++;
+				goto walk;
+			}
+
+			skb = tcp_sacktag_skip(skb, sk, &state, cache->end_seq);
+			/* Check overlap against next cached too (past this one already) */
+			cache++;
+			continue;
+		}
+
+		if (!before(start_seq, tcp_highest_sack_seq(tp))) {
+			skb = tcp_highest_sack(sk);
+			if (skb == NULL)
+				break;
+			state.fack_count = tp->fackets_out;
+		}
+		skb = tcp_sacktag_skip(skb, sk, &state, start_seq);
+
+walk:
+		skb = tcp_sacktag_walk(skb, sk, next_dup, &state,
+				       start_seq, end_seq, dup_sack);
+
+advance_sp:
+		/* SACK enhanced FRTO (RFC4138, Appendix B): Clearing correct
+		 * due to in-order walk
+		 */
+		if (after(end_seq, tp->frto_highmark))
+			state.flag &= ~FLAG_ONLY_ORIG_SACKED;
+
+		i++;
+	}
+
+	/* Clear the head of the cache sack blocks so we can skip it next time */
+	for (i = 0; i < ARRAY_SIZE(tp->recv_sack_cache) - used_sacks; i++) {
+		tp->recv_sack_cache[i].start_seq = 0;
+		tp->recv_sack_cache[i].end_seq = 0;
+	}
+	for (j = 0; j < used_sacks; j++)
+		tp->recv_sack_cache[i++] = sp[j];
+
+	tcp_mark_lost_retrans(sk);
+
+	tcp_verify_left_out(tp);
+
+	if ((state.reord < tp->fackets_out) &&
+	    ((icsk->icsk_ca_state != TCP_CA_Loss) || tp->undo_marker) &&
+	    (!tp->frto_highmark || after(tp->snd_una, tp->frto_highmark)))
+		tcp_update_reordering(sk, tp->fackets_out - state.reord, 0);
+
+out:
+
+#if FASTRETRANS_DEBUG > 0
+	WARN_ON((int)tp->sacked_out < 0);
+	WARN_ON((int)tp->lost_out < 0);
+	WARN_ON((int)tp->retrans_out < 0);
+	WARN_ON((int)tcp_packets_in_flight(tp) < 0);
+#endif
+	return state.flag;
+}
+
+/* Limits sacked_out so that sum with lost_out isn't ever larger than
+ * packets_out. Returns zero if sacked_out adjustement wasn't necessary.
+ */
+static int tcp_limit_reno_sacked(struct tcp_sock *tp)
+{
+	u32 holes;
+
+	holes = max(tp->lost_out, 1U);
+	holes = min(holes, tp->packets_out);
+
+	if ((tp->sacked_out + holes) > tp->packets_out) {
+		tp->sacked_out = tp->packets_out - holes;
+		return 1;
+	}
+	return 0;
+}
+
+/* If we receive more dupacks than we expected counting segments
+ * in assumption of absent reordering, interpret this as reordering.
+ * The only another reason could be bug in receiver TCP.
+ */
+static void tcp_check_reno_reordering(struct sock *sk, const int addend)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (tcp_limit_reno_sacked(tp))
+		tcp_update_reordering(sk, tp->packets_out + addend, 0);
+}
+
+/* Emulate SACKs for SACKless connection: account for a new dupack. */
+
+static void tcp_add_reno_sack(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->sacked_out++;
+	tcp_check_reno_reordering(sk, 0);
+	tcp_verify_left_out(tp);
+}
+
+/* Account for ACK, ACKing some data in Reno Recovery phase. */
+
+static void tcp_remove_reno_sacks(struct sock *sk, int acked)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (acked > 0) {
+		/* One ACK acked hole. The rest eat duplicate ACKs. */
+		if (acked - 1 >= tp->sacked_out)
+			tp->sacked_out = 0;
+		else
+			tp->sacked_out -= acked - 1;
+	}
+	tcp_check_reno_reordering(sk, acked);
+	tcp_verify_left_out(tp);
+}
+
+static inline void tcp_reset_reno_sack(struct tcp_sock *tp)
+{
+	tp->sacked_out = 0;
+}
+
+static int tcp_is_sackfrto(const struct tcp_sock *tp)
+{
+	return (sysctl_tcp_frto == 0x2) && !tcp_is_reno(tp);
+}
+
+/* F-RTO can only be used if TCP has never retransmitted anything other than
+ * head (SACK enhanced variant from Appendix B of RFC4138 is more robust here)
+ */
+int tcp_use_frto(struct sock *sk)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct sk_buff *skb;
+
+	if (!sysctl_tcp_frto)
+		return 0;
+
+	/* MTU probe and F-RTO won't really play nicely along currently */
+	if (icsk->icsk_mtup.probe_size)
+		return 0;
+
+	if (tcp_is_sackfrto(tp))
+		return 1;
+
+	/* Avoid expensive walking of rexmit queue if possible */
+	if (tp->retrans_out > 1)
+		return 0;
+
+	skb = tcp_write_queue_head(sk);
+	if (tcp_skb_is_last(sk, skb))
+		return 1;
+	skb = tcp_write_queue_next(sk, skb);	/* Skips head */
+	tcp_for_write_queue_from(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+		if (TCP_SKB_CB(skb)->sacked & TCPCB_RETRANS)
+			return 0;
+		/* Short-circuit when first non-SACKed skb has been checked */
+		if (!(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED))
+			break;
+	}
+	return 1;
+}
+
+/* RTO occurred, but do not yet enter Loss state. Instead, defer RTO
+ * recovery a bit and use heuristics in tcp_process_frto() to detect if
+ * the RTO was spurious. Only clear SACKED_RETRANS of the head here to
+ * keep retrans_out counting accurate (with SACK F-RTO, other than head
+ * may still have that bit set); TCPCB_LOST and remaining SACKED_RETRANS
+ * bits are handled if the Loss state is really to be entered (in
+ * tcp_enter_frto_loss).
+ *
+ * Do like tcp_enter_loss() would; when RTO expires the second time it
+ * does:
+ *  "Reduce ssthresh if it has not yet been made inside this window."
+ */
+void tcp_enter_frto(struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+
+	if ((!tp->frto_counter && icsk->icsk_ca_state <= TCP_CA_Disorder) ||
+	    tp->snd_una == tp->high_seq ||
+	    ((icsk->icsk_ca_state == TCP_CA_Loss || tp->frto_counter) &&
+	     !icsk->icsk_retransmits)) {
+		tp->prior_ssthresh = tcp_current_ssthresh(sk);
+		/* Our state is too optimistic in ssthresh() call because cwnd
+		 * is not reduced until tcp_enter_frto_loss() when previous F-RTO
+		 * recovery has not yet completed. Pattern would be this: RTO,
+		 * Cumulative ACK, RTO (2xRTO for the same segment does not end
+		 * up here twice).
+		 * RFC4138 should be more specific on what to do, even though
+		 * RTO is quite unlikely to occur after the first Cumulative ACK
+		 * due to back-off and complexity of triggering events ...
+		 */
+		if (tp->frto_counter) {
+			u32 stored_cwnd;
+			stored_cwnd = tp->snd_cwnd;
+			tp->snd_cwnd = 2;
+			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+			tp->snd_cwnd = stored_cwnd;
+		} else {
+			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+		}
+		/* ... in theory, cong.control module could do "any tricks" in
+		 * ssthresh(), which means that ca_state, lost bits and lost_out
+		 * counter would have to be faked before the call occurs. We
+		 * consider that too expensive, unlikely and hacky, so modules
+		 * using these in ssthresh() must deal these incompatibility
+		 * issues if they receives CA_EVENT_FRTO and frto_counter != 0
+		 */
+		tcp_ca_event(sk, CA_EVENT_FRTO);
+	}
+
+	tp->undo_marker = tp->snd_una;
+	tp->undo_retrans = 0;
+
+	skb = tcp_write_queue_head(sk);
+	if (TCP_SKB_CB(skb)->sacked & TCPCB_RETRANS)
+		tp->undo_marker = 0;
+	if (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_RETRANS) {
+		TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;
+		tp->retrans_out -= tcp_skb_pcount(skb);
+	}
+	tcp_verify_left_out(tp);
+
+	/* Too bad if TCP was application limited */
+	tp->snd_cwnd = min(tp->snd_cwnd, tcp_packets_in_flight(tp) + 1);
+
+	/* Earlier loss recovery underway (see RFC4138; Appendix B).
+	 * The last condition is necessary at least in tp->frto_counter case.
+	 */
+	if (tcp_is_sackfrto(tp) && (tp->frto_counter ||
+	    ((1 << icsk->icsk_ca_state) & (TCPF_CA_Recovery|TCPF_CA_Loss))) &&
+	    after(tp->high_seq, tp->snd_una)) {
+		tp->frto_highmark = tp->high_seq;
+	} else {
+		tp->frto_highmark = tp->snd_nxt;
+	}
+	tcp_set_ca_state(sk, TCP_CA_Disorder);
+	tp->high_seq = tp->snd_nxt;
+	tp->frto_counter = 1;
+}
+
+/* Enter Loss state after F-RTO was applied. Dupack arrived after RTO,
+ * which indicates that we should follow the traditional RTO recovery,
+ * i.e. mark everything lost and do go-back-N retransmission.
+ */
+static void tcp_enter_frto_loss(struct sock *sk, int allowed_segments, int flag)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+
+	tp->lost_out = 0;
+	tp->retrans_out = 0;
+	if (tcp_is_reno(tp))
+		tcp_reset_reno_sack(tp);
+
+	tcp_for_write_queue(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+
+		TCP_SKB_CB(skb)->sacked &= ~TCPCB_LOST;
+		/*
+		 * Count the retransmission made on RTO correctly (only when
+		 * waiting for the first ACK and did not get it)...
+		 */
+		if ((tp->frto_counter == 1) && !(flag & FLAG_DATA_ACKED)) {
+			/* For some reason this R-bit might get cleared? */
+			if (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_RETRANS)
+				tp->retrans_out += tcp_skb_pcount(skb);
+			/* ...enter this if branch just for the first segment */
+			flag |= FLAG_DATA_ACKED;
+		} else {
+			if (TCP_SKB_CB(skb)->sacked & TCPCB_RETRANS)
+				tp->undo_marker = 0;
+			TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;
+		}
+
+		/* Marking forward transmissions that were made after RTO lost
+		 * can cause unnecessary retransmissions in some scenarios,
+		 * SACK blocks will mitigate that in some but not in all cases.
+		 * We used to not mark them but it was causing break-ups with
+		 * receivers that do only in-order receival.
+		 *
+		 * TODO: we could detect presence of such receiver and select
+		 * different behavior per flow.
+		 */
+		if (!(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED)) {
+			TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;
+			tp->lost_out += tcp_skb_pcount(skb);
+			tp->retransmit_high = TCP_SKB_CB(skb)->end_seq;
+		}
+	}
+	tcp_verify_left_out(tp);
+
+	tp->snd_cwnd = tcp_packets_in_flight(tp) + allowed_segments;
+	tp->snd_cwnd_cnt = 0;
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+	tp->frto_counter = 0;
+	tp->bytes_acked = 0;
+
+	tp->reordering = min_t(unsigned int, tp->reordering,
+			       sysctl_tcp_reordering);
+	tcp_set_ca_state(sk, TCP_CA_Loss);
+	tp->high_seq = tp->snd_nxt;
+	TCP_ECN_queue_cwr(tp);
+
+	tcp_clear_all_retrans_hints(tp);
+}
+
+static void tcp_clear_retrans_partial(struct tcp_sock *tp)
+{
+	tp->retrans_out = 0;
+	tp->lost_out = 0;
+
+	tp->undo_marker = 0;
+	tp->undo_retrans = 0;
+}
+
+void tcp_clear_retrans(struct tcp_sock *tp)
+{
+	tcp_clear_retrans_partial(tp);
+
+	tp->fackets_out = 0;
+	tp->sacked_out = 0;
+}
+
+/* Enter Loss state. If "how" is not zero, forget all SACK information
+ * and reset tags completely, otherwise preserve SACKs. If receiver
+ * dropped its ofo queue, we will know this due to reneging detection.
+ */
+void tcp_enter_loss(struct sock *sk, int how)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+
+	/* Reduce ssthresh if it has not yet been made inside this window. */
+	if (icsk->icsk_ca_state <= TCP_CA_Disorder || tp->snd_una == tp->high_seq ||
+	    (icsk->icsk_ca_state == TCP_CA_Loss && !icsk->icsk_retransmits)) {
+		tp->prior_ssthresh = tcp_current_ssthresh(sk);
+		tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+		tcp_ca_event(sk, CA_EVENT_LOSS);
+	}
+	tp->snd_cwnd	   = 1;
+	tp->snd_cwnd_cnt   = 0;
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+
+	tp->bytes_acked = 0;
+	tcp_clear_retrans_partial(tp);
+
+	if (tcp_is_reno(tp))
+		tcp_reset_reno_sack(tp);
+
+	if (!how) {
+		/* Push undo marker, if it was plain RTO and nothing
+		 * was retransmitted. */
+		tp->undo_marker = tp->snd_una;
+	} else {
+		tp->sacked_out = 0;
+		tp->fackets_out = 0;
+	}
+	tcp_clear_all_retrans_hints(tp);
+
+	tcp_for_write_queue(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+
+		if (TCP_SKB_CB(skb)->sacked & TCPCB_RETRANS)
+			tp->undo_marker = 0;
+		TCP_SKB_CB(skb)->sacked &= (~TCPCB_TAGBITS)|TCPCB_SACKED_ACKED;
+		if (!(TCP_SKB_CB(skb)->sacked&TCPCB_SACKED_ACKED) || how) {
+			TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_ACKED;
+			TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;
+			tp->lost_out += tcp_skb_pcount(skb);
+			tp->retransmit_high = TCP_SKB_CB(skb)->end_seq;
+		}
+	}
+	tcp_verify_left_out(tp);
+
+	tp->reordering = min_t(unsigned int, tp->reordering,
+			       sysctl_tcp_reordering);
+	tcp_set_ca_state(sk, TCP_CA_Loss);
+	tp->high_seq = tp->snd_nxt;
+	TCP_ECN_queue_cwr(tp);
+	/* Abort F-RTO algorithm if one is in progress */
+	tp->frto_counter = 0;
+}
+
+/* If ACK arrived pointing to a remembered SACK, it means that our
+ * remembered SACKs do not reflect real state of receiver i.e.
+ * receiver _host_ is heavily congested (or buggy).
+ *
+ * Do processing similar to RTO timeout.
+ */
+static int tcp_check_sack_reneging(struct sock *sk, int flag)
+{
+	if (flag & FLAG_SACK_RENEGING) {
+		struct inet_connection_sock *icsk = inet_csk(sk);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPSACKRENEGING);
+
+		tcp_enter_loss(sk, 1);
+		icsk->icsk_retransmits++;
+		tcp_retransmit_skb(sk, tcp_write_queue_head(sk));
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+					  icsk->icsk_rto, TCP_RTO_MAX);
+		return 1;
+	}
+	return 0;
+}
+
+static inline int tcp_fackets_out(struct tcp_sock *tp)
+{
+	return tcp_is_reno(tp) ? tp->sacked_out + 1 : tp->fackets_out;
+}
+
+/* Heurestics to calculate number of duplicate ACKs. There's no dupACKs
+ * counter when SACK is enabled (without SACK, sacked_out is used for
+ * that purpose).
+ *
+ * Instead, with FACK TCP uses fackets_out that includes both SACKed
+ * segments up to the highest received SACK block so far and holes in
+ * between them.
+ *
+ * With reordering, holes may still be in flight, so RFC3517 recovery
+ * uses pure sacked_out (total number of SACKed segments) even though
+ * it violates the RFC that uses duplicate ACKs, often these are equal
+ * but when e.g. out-of-window ACKs or packet duplication occurs,
+ * they differ. Since neither occurs due to loss, TCP should really
+ * ignore them.
+ */
+static inline int tcp_dupack_heurestics(struct tcp_sock *tp)
+{
+	return tcp_is_fack(tp) ? tp->fackets_out : tp->sacked_out + 1;
+}
+
+static inline int tcp_skb_timedout(struct sock *sk, struct sk_buff *skb)
+{
+	return (tcp_time_stamp - TCP_SKB_CB(skb)->when > inet_csk(sk)->icsk_rto);
+}
+
+static inline int tcp_head_timedout(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	return tp->packets_out &&
+	       tcp_skb_timedout(sk, tcp_write_queue_head(sk));
+}
+
+/* Linux NewReno/SACK/FACK/ECN state machine.
+ * --------------------------------------
+ *
+ * "Open"	Normal state, no dubious events, fast path.
+ * "Disorder"   In all the respects it is "Open",
+ *		but requires a bit more attention. It is entered when
+ *		we see some SACKs or dupacks. It is split of "Open"
+ *		mainly to move some processing from fast path to slow one.
+ * "CWR"	CWND was reduced due to some Congestion Notification event.
+ *		It can be ECN, ICMP source quench, local device congestion.
+ * "Recovery"	CWND was reduced, we are fast-retransmitting.
+ * "Loss"	CWND was reduced due to RTO timeout or SACK reneging.
+ *
+ * tcp_fastretrans_alert() is entered:
+ * - each incoming ACK, if state is not "Open"
+ * - when arrived ACK is unusual, namely:
+ *	* SACK
+ *	* Duplicate ACK.
+ *	* ECN ECE.
+ *
+ * Counting packets in flight is pretty simple.
+ *
+ *	in_flight = packets_out - left_out + retrans_out
+ *
+ *	packets_out is SND.NXT-SND.UNA counted in packets.
+ *
+ *	retrans_out is number of retransmitted segments.
+ *
+ *	left_out is number of segments left network, but not ACKed yet.
+ *
+ *		left_out = sacked_out + lost_out
+ *
+ *     sacked_out: Packets, which arrived to receiver out of order
+ *		   and hence not ACKed. With SACKs this number is simply
+ *		   amount of SACKed data. Even without SACKs
+ *		   it is easy to give pretty reliable estimate of this number,
+ *		   counting duplicate ACKs.
+ *
+ *       lost_out: Packets lost by network. TCP has no explicit
+ *		   "loss notification" feedback from network (for now).
+ *		   It means that this number can be only _guessed_.
+ *		   Actually, it is the heuristics to predict lossage that
+ *		   distinguishes different algorithms.
+ *
+ *	F.e. after RTO, when all the queue is considered as lost,
+ *	lost_out = packets_out and in_flight = retrans_out.
+ *
+ *		Essentially, we have now two algorithms counting
+ *		lost packets.
+ *
+ *		FACK: It is the simplest heuristics. As soon as we decided
+ *		that something is lost, we decide that _all_ not SACKed
+ *		packets until the most forward SACK are lost. I.e.
+ *		lost_out = fackets_out - sacked_out and left_out = fackets_out.
+ *		It is absolutely correct estimate, if network does not reorder
+ *		packets. And it loses any connection to reality when reordering
+ *		takes place. We use FACK by default until reordering
+ *		is suspected on the path to this destination.
+ *
+ *		NewReno: when Recovery is entered, we assume that one segment
+ *		is lost (classic Reno). While we are in Recovery and
+ *		a partial ACK arrives, we assume that one more packet
+ *		is lost (NewReno). This heuristics are the same in NewReno
+ *		and SACK.
+ *
+ *  Imagine, that's all! Forget about all this shamanism about CWND inflation
+ *  deflation etc. CWND is real congestion window, never inflated, changes
+ *  only according to classic VJ rules.
+ *
+ * Really tricky (and requiring careful tuning) part of algorithm
+ * is hidden in functions tcp_time_to_recover() and tcp_xmit_retransmit_queue().
+ * The first determines the moment _when_ we should reduce CWND and,
+ * hence, slow down forward transmission. In fact, it determines the moment
+ * when we decide that hole is caused by loss, rather than by a reorder.
+ *
+ * tcp_xmit_retransmit_queue() decides, _what_ we should retransmit to fill
+ * holes, caused by lost packets.
+ *
+ * And the most logically complicated part of algorithm is undo
+ * heuristics. We detect false retransmits due to both too early
+ * fast retransmit (reordering) and underestimated RTO, analyzing
+ * timestamps and D-SACKs. When we detect that some segments were
+ * retransmitted by mistake and CWND reduction was wrong, we undo
+ * window reduction and abort recovery phase. This logic is hidden
+ * inside several functions named tcp_try_undo_<something>.
+ */
+
+/* This function decides, when we should leave Disordered state
+ * and enter Recovery phase, reducing congestion window.
+ *
+ * Main question: may we further continue forward transmission
+ * with the same cwnd?
+ */
+static int tcp_time_to_recover(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	__u32 packets_out;
+
+	/* Do not perform any recovery during F-RTO algorithm */
+	if (tp->frto_counter)
+		return 0;
+
+	/* Trick#1: The loss is proven. */
+	if (tp->lost_out)
+		return 1;
+
+	/* Not-A-Trick#2 : Classic rule... */
+	if (tcp_dupack_heurestics(tp) > tp->reordering)
+		return 1;
+
+	/* Trick#3 : when we use RFC2988 timer restart, fast
+	 * retransmit can be triggered by timeout of queue head.
+	 */
+	if (tcp_is_fack(tp) && tcp_head_timedout(sk))
+		return 1;
+
+	/* Trick#4: It is still not OK... But will it be useful to delay
+	 * recovery more?
+	 */
+	packets_out = tp->packets_out;
+	if (packets_out <= tp->reordering &&
+	    tp->sacked_out >= max_t(__u32, packets_out/2, sysctl_tcp_reordering) &&
+	    !tcp_may_send_now(sk)) {
+		/* We have nothing to send. This connection is limited
+		 * either by receiver window or by application.
+		 */
+		return 1;
+	}
+
+	return 0;
+}
+
+/* New heuristics: it is possible only after we switched to restart timer
+ * each time when something is ACKed. Hence, we can detect timed out packets
+ * during fast retransmit without falling to slow start.
+ *
+ * Usefulness of this as is very questionable, since we should know which of
+ * the segments is the next to timeout which is relatively expensive to find
+ * in general case unless we add some data structure just for that. The
+ * current approach certainly won't find the right one too often and when it
+ * finally does find _something_ it usually marks large part of the window
+ * right away (because a retransmission with a larger timestamp blocks the
+ * loop from advancing). -ij
+ */
+static void tcp_timeout_skbs(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+
+	if (!tcp_is_fack(tp) || !tcp_head_timedout(sk))
+		return;
+
+	skb = tp->scoreboard_skb_hint;
+	if (tp->scoreboard_skb_hint == NULL)
+		skb = tcp_write_queue_head(sk);
+
+	tcp_for_write_queue_from(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+		if (!tcp_skb_timedout(sk, skb))
+			break;
+
+		tcp_skb_mark_lost(tp, skb);
+	}
+
+	tp->scoreboard_skb_hint = skb;
+
+	tcp_verify_left_out(tp);
+}
+
+/* Mark head of queue up as lost. With RFC3517 SACK, the packets is
+ * is against sacked "cnt", otherwise it's against facked "cnt"
+ */
+static void tcp_mark_head_lost(struct sock *sk, int packets)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+	int cnt, oldcnt;
+	int err;
+	unsigned int mss;
+
+	WARN_ON(packets > tp->packets_out);
+	if (tp->lost_skb_hint) {
+		skb = tp->lost_skb_hint;
+		cnt = tp->lost_cnt_hint;
+	} else {
+		skb = tcp_write_queue_head(sk);
+		cnt = 0;
+	}
+
+	tcp_for_write_queue_from(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+		/* TODO: do this better */
+		/* this is not the most efficient way to do this... */
+		tp->lost_skb_hint = skb;
+		tp->lost_cnt_hint = cnt;
+
+		if (after(TCP_SKB_CB(skb)->end_seq, tp->high_seq))
+			break;
+
+		oldcnt = cnt;
+		if (tcp_is_fack(tp) || tcp_is_reno(tp) ||
+		    (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED))
+			cnt += tcp_skb_pcount(skb);
+
+		if (cnt > packets) {
+			if (tcp_is_sack(tp) || (oldcnt >= packets))
+				break;
+
+			mss = skb_shinfo(skb)->gso_size;
+			err = tcp_fragment(sk, skb, (packets - oldcnt) * mss, mss);
+			if (err < 0)
+				break;
+			cnt = packets;
+		}
+
+		tcp_skb_mark_lost(tp, skb);
+	}
+	tcp_verify_left_out(tp);
+}
+
+/* Account newly detected lost packet(s) */
+
+static void tcp_update_scoreboard(struct sock *sk, int fast_rexmit)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tcp_is_reno(tp)) {
+		tcp_mark_head_lost(sk, 1);
+	} else if (tcp_is_fack(tp)) {
+		int lost = tp->fackets_out - tp->reordering;
+		if (lost <= 0)
+			lost = 1;
+		tcp_mark_head_lost(sk, lost);
+	} else {
+		int sacked_upto = tp->sacked_out - tp->reordering;
+		if (sacked_upto < fast_rexmit)
+			sacked_upto = fast_rexmit;
+		tcp_mark_head_lost(sk, sacked_upto);
+	}
+
+	tcp_timeout_skbs(sk);
+}
+
+/* CWND moderation, preventing bursts due to too big ACKs
+ * in dubious situations.
+ */
+static inline void tcp_moderate_cwnd(struct tcp_sock *tp)
+{
+	tp->snd_cwnd = min(tp->snd_cwnd,
+			   tcp_packets_in_flight(tp) + tcp_max_burst(tp));
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+}
+
+/* Lower bound on congestion window is slow start threshold
+ * unless congestion avoidance choice decides to overide it.
+ */
+static inline u32 tcp_cwnd_min(const struct sock *sk)
+{
+	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)->icsk_ca_ops;
+
+	return ca_ops->min_cwnd ? ca_ops->min_cwnd(sk) : tcp_sk(sk)->snd_ssthresh;
+}
+
+/* Decrease cwnd each second ack. */
+static void tcp_cwnd_down(struct sock *sk, int flag)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int decr = tp->snd_cwnd_cnt + 1;
+
+	if ((flag & (FLAG_ANY_PROGRESS | FLAG_DSACKING_ACK)) ||
+	    (tcp_is_reno(tp) && !(flag & FLAG_NOT_DUP))) {
+		tp->snd_cwnd_cnt = decr & 1;
+		decr >>= 1;
+
+		if (decr && tp->snd_cwnd > tcp_cwnd_min(sk))
+			tp->snd_cwnd -= decr;
+
+		tp->snd_cwnd = min(tp->snd_cwnd, tcp_packets_in_flight(tp) + 1);
+		tp->snd_cwnd_stamp = tcp_time_stamp;
+	}
+}
+
+/* Nothing was retransmitted or returned timestamp is less
+ * than timestamp of the first retransmission.
+ */
+static inline int tcp_packet_delayed(struct tcp_sock *tp)
+{
+	return !tp->retrans_stamp ||
+		(tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&
+		 before(tp->rx_opt.rcv_tsecr, tp->retrans_stamp));
+}
+
+/* Undo procedures. */
+
+#if FASTRETRANS_DEBUG > 1
+static void DBGUNDO(struct sock *sk, const char *msg)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_sock *inet = inet_sk(sk);
+
+	if (sk->sk_family == AF_INET) {
+		printk(KERN_DEBUG "Undo %s %pI4/%u c%u l%u ss%u/%u p%u\n",
+		       msg,
+		       &inet->daddr, ntohs(inet->dport),
+		       tp->snd_cwnd, tcp_left_out(tp),
+		       tp->snd_ssthresh, tp->prior_ssthresh,
+		       tp->packets_out);
+	}
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	else if (sk->sk_family == AF_INET6) {
+		struct ipv6_pinfo *np = inet6_sk(sk);
+		printk(KERN_DEBUG "Undo %s %pI6/%u c%u l%u ss%u/%u p%u\n",
+		       msg,
+		       &np->daddr, ntohs(inet->dport),
+		       tp->snd_cwnd, tcp_left_out(tp),
+		       tp->snd_ssthresh, tp->prior_ssthresh,
+		       tp->packets_out);
+	}
+#endif
+}
+#else
+#define DBGUNDO(x...) do { } while (0)
+#endif
+
+static void tcp_undo_cwr(struct sock *sk, const int undo)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tp->prior_ssthresh) {
+		const struct inet_connection_sock *icsk = inet_csk(sk);
+
+		if (icsk->icsk_ca_ops->undo_cwnd)
+			tp->snd_cwnd = icsk->icsk_ca_ops->undo_cwnd(sk);
+		else
+			tp->snd_cwnd = max(tp->snd_cwnd, tp->snd_ssthresh << 1);
+
+		if (undo && tp->prior_ssthresh > tp->snd_ssthresh) {
+			tp->snd_ssthresh = tp->prior_ssthresh;
+			TCP_ECN_withdraw_cwr(tp);
+		}
+	} else {
+		tp->snd_cwnd = max(tp->snd_cwnd, tp->snd_ssthresh);
+	}
+	tcp_moderate_cwnd(tp);
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+}
+
+static inline int tcp_may_undo(struct tcp_sock *tp)
+{
+	return tp->undo_marker && (!tp->undo_retrans || tcp_packet_delayed(tp));
+}
+
+/* People celebrate: "We love our President!" */
+static int tcp_try_undo_recovery(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tcp_may_undo(tp)) {
+		int mib_idx;
+
+		/* Happy end! We did not retransmit anything
+		 * or our original transmission succeeded.
+		 */
+		DBGUNDO(sk, inet_csk(sk)->icsk_ca_state == TCP_CA_Loss ? "loss" : "retrans");
+		tcp_undo_cwr(sk, 1);
+		if (inet_csk(sk)->icsk_ca_state == TCP_CA_Loss)
+			mib_idx = LINUX_MIB_TCPLOSSUNDO;
+		else
+			mib_idx = LINUX_MIB_TCPFULLUNDO;
+
+		NET_INC_STATS_BH(sock_net(sk), mib_idx);
+		tp->undo_marker = 0;
+	}
+	if (tp->snd_una == tp->high_seq && tcp_is_reno(tp)) {
+		/* Hold old state until something *above* high_seq
+		 * is ACKed. For Reno it is MUST to prevent false
+		 * fast retransmits (RFC2582). SACK TCP is safe. */
+		tcp_moderate_cwnd(tp);
+		return 1;
+	}
+	tcp_set_ca_state(sk, TCP_CA_Open);
+	return 0;
+}
+
+/* Try to undo cwnd reduction, because D-SACKs acked all retransmitted data */
+static void tcp_try_undo_dsack(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tp->undo_marker && !tp->undo_retrans) {
+		DBGUNDO(sk, "D-SACK");
+		tcp_undo_cwr(sk, 1);
+		tp->undo_marker = 0;
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPDSACKUNDO);
+	}
+}
+
+/* Undo during fast recovery after partial ACK. */
+
+static int tcp_try_undo_partial(struct sock *sk, int acked)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	/* Partial ACK arrived. Force Hoe's retransmit. */
+	int failed = tcp_is_reno(tp) || (tcp_fackets_out(tp) > tp->reordering);
+
+	if (tcp_may_undo(tp)) {
+		/* Plain luck! Hole if filled with delayed
+		 * packet, rather than with a retransmit.
+		 */
+		if (tp->retrans_out == 0)
+			tp->retrans_stamp = 0;
+
+		tcp_update_reordering(sk, tcp_fackets_out(tp) + acked, 1);
+
+		DBGUNDO(sk, "Hoe");
+		tcp_undo_cwr(sk, 0);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPARTIALUNDO);
+
+		/* So... Do not make Hoe's retransmit yet.
+		 * If the first packet was delayed, the rest
+		 * ones are most probably delayed as well.
+		 */
+		failed = 0;
+	}
+	return failed;
+}
+
+/* Undo during loss recovery after partial ACK. */
+static int tcp_try_undo_loss(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tcp_may_undo(tp)) {
+		struct sk_buff *skb;
+		tcp_for_write_queue(skb, sk) {
+			if (skb == tcp_send_head(sk))
+				break;
+			TCP_SKB_CB(skb)->sacked &= ~TCPCB_LOST;
+		}
+
+		tcp_clear_all_retrans_hints(tp);
+
+		DBGUNDO(sk, "partial loss");
+		tp->lost_out = 0;
+		tcp_undo_cwr(sk, 1);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSSUNDO);
+		inet_csk(sk)->icsk_retransmits = 0;
+		tp->undo_marker = 0;
+		if (tcp_is_sack(tp))
+			tcp_set_ca_state(sk, TCP_CA_Open);
+		return 1;
+	}
+	return 0;
+}
+
+static inline void tcp_complete_cwr(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_ssthresh);
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+	tcp_ca_event(sk, CA_EVENT_COMPLETE_CWR);
+}
+
+static void tcp_try_keep_open(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int state = TCP_CA_Open;
+
+	if (tcp_left_out(tp) || tp->retrans_out || tp->undo_marker)
+		state = TCP_CA_Disorder;
+
+	if (inet_csk(sk)->icsk_ca_state != state) {
+		tcp_set_ca_state(sk, state);
+		tp->high_seq = tp->snd_nxt;
+	}
+}
+
+static void tcp_try_to_open(struct sock *sk, int flag)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	tcp_verify_left_out(tp);
+
+	if (!tp->frto_counter && tp->retrans_out == 0)
+		tp->retrans_stamp = 0;
+
+	if (flag & FLAG_ECE)
+		tcp_enter_cwr(sk, 1);
+
+	if (inet_csk(sk)->icsk_ca_state != TCP_CA_CWR) {
+		tcp_try_keep_open(sk);
+		tcp_moderate_cwnd(tp);
+	} else {
+		tcp_cwnd_down(sk, flag);
+	}
+}
+
+static void tcp_mtup_probe_failed(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	icsk->icsk_mtup.search_high = icsk->icsk_mtup.probe_size - 1;
+	icsk->icsk_mtup.probe_size = 0;
+}
+
+static void tcp_mtup_probe_success(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	/* FIXME: breaks with very large cwnd */
+	tp->prior_ssthresh = tcp_current_ssthresh(sk);
+	tp->snd_cwnd = tp->snd_cwnd *
+		       tcp_mss_to_mtu(sk, tp->mss_cache) /
+		       icsk->icsk_mtup.probe_size;
+	tp->snd_cwnd_cnt = 0;
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+	tp->rcv_ssthresh = tcp_current_ssthresh(sk);
+
+	icsk->icsk_mtup.search_low = icsk->icsk_mtup.probe_size;
+	icsk->icsk_mtup.probe_size = 0;
+	tcp_sync_mss(sk, icsk->icsk_pmtu_cookie);
+}
+
+/* Do a simple retransmit without using the backoff mechanisms in
+ * tcp_timer. This is used for path mtu discovery.
+ * The socket is already locked here.
+ */
+void tcp_simple_retransmit(struct sock *sk)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb;
+	unsigned int mss = tcp_current_mss(sk);
+	u32 prior_lost = tp->lost_out;
+
+	tcp_for_write_queue(skb, sk) {
+		if (skb == tcp_send_head(sk))
+			break;
+		if (tcp_skb_seglen(skb) > mss &&
+		    !(TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED)) {
+			if (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_RETRANS) {
+				TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;
+				tp->retrans_out -= tcp_skb_pcount(skb);
+			}
+			tcp_skb_mark_lost_uncond_verify(tp, skb);
+		}
+	}
+
+	tcp_clear_retrans_hints_partial(tp);
+
+	if (prior_lost == tp->lost_out)
+		return;
+
+	if (tcp_is_reno(tp))
+		tcp_limit_reno_sacked(tp);
+
+	tcp_verify_left_out(tp);
+
+	/* Don't muck with the congestion window here.
+	 * Reason is that we do not increase amount of _data_
+	 * in network, but units changed and effective
+	 * cwnd/ssthresh really reduced now.
+	 */
+	if (icsk->icsk_ca_state != TCP_CA_Loss) {
+		tp->high_seq = tp->snd_nxt;
+		tp->snd_ssthresh = tcp_current_ssthresh(sk);
+		tp->prior_ssthresh = 0;
+		tp->undo_marker = 0;
+		tcp_set_ca_state(sk, TCP_CA_Loss);
+	}
+	tcp_xmit_retransmit_queue(sk);
+}
+
+/* Process an event, which can update packets-in-flight not trivially.
+ * Main goal of this function is to calculate new estimate for left_out,
+ * taking into account both packets sitting in receiver's buffer and
+ * packets lost by network.
+ *
+ * Besides that it does CWND reduction, when packet loss is detected
+ * and changes state of machine.
+ *
+ * It does _not_ decide what to send, it is made in function
+ * tcp_xmit_retransmit_queue().
+ */
+static void tcp_fastretrans_alert(struct sock *sk, int pkts_acked, int flag)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	int is_dupack = !(flag & (FLAG_SND_UNA_ADVANCED | FLAG_NOT_DUP));
+	int do_lost = is_dupack || ((flag & FLAG_DATA_SACKED) &&
+				    (tcp_fackets_out(tp) > tp->reordering));
+	int fast_rexmit = 0, mib_idx;
+
+	if (WARN_ON(!tp->packets_out && tp->sacked_out))
+		tp->sacked_out = 0;
+	if (WARN_ON(!tp->sacked_out && tp->fackets_out))
+		tp->fackets_out = 0;
+
+	/* Now state machine starts.
+	 * A. ECE, hence prohibit cwnd undoing, the reduction is required. */
+	if (flag & FLAG_ECE)
+		tp->prior_ssthresh = 0;
+
+	/* B. In all the states check for reneging SACKs. */
+	if (tcp_check_sack_reneging(sk, flag))
+		return;
+
+	/* C. Process data loss notification, provided it is valid. */
+	if (tcp_is_fack(tp) && (flag & FLAG_DATA_LOST) &&
+	    before(tp->snd_una, tp->high_seq) &&
+	    icsk->icsk_ca_state != TCP_CA_Open &&
+	    tp->fackets_out > tp->reordering) {
+		tcp_mark_head_lost(sk, tp->fackets_out - tp->reordering);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSS);
+	}
+
+	/* D. Check consistency of the current state. */
+	tcp_verify_left_out(tp);
+
+	/* E. Check state exit conditions. State can be terminated
+	 *    when high_seq is ACKed. */
+	if (icsk->icsk_ca_state == TCP_CA_Open) {
+		WARN_ON(tp->retrans_out != 0);
+		tp->retrans_stamp = 0;
+	} else if (!before(tp->snd_una, tp->high_seq)) {
+		switch (icsk->icsk_ca_state) {
+		case TCP_CA_Loss:
+			icsk->icsk_retransmits = 0;
+			if (tcp_try_undo_recovery(sk))
+				return;
+			break;
+
+		case TCP_CA_CWR:
+			/* CWR is to be held something *above* high_seq
+			 * is ACKed for CWR bit to reach receiver. */
+			if (tp->snd_una != tp->high_seq) {
+				tcp_complete_cwr(sk);
+				tcp_set_ca_state(sk, TCP_CA_Open);
+			}
+			break;
+
+		case TCP_CA_Disorder:
+			tcp_try_undo_dsack(sk);
+			if (!tp->undo_marker ||
+			    /* For SACK case do not Open to allow to undo
+			     * catching for all duplicate ACKs. */
+			    tcp_is_reno(tp) || tp->snd_una != tp->high_seq) {
+				tp->undo_marker = 0;
+				tcp_set_ca_state(sk, TCP_CA_Open);
+			}
+			break;
+
+		case TCP_CA_Recovery:
+			if (tcp_is_reno(tp))
+				tcp_reset_reno_sack(tp);
+			if (tcp_try_undo_recovery(sk))
+				return;
+			tcp_complete_cwr(sk);
+			break;
+		}
+	}
+
+	/* F. Process state. */
+	switch (icsk->icsk_ca_state) {
+	case TCP_CA_Recovery:
+		if (!(flag & FLAG_SND_UNA_ADVANCED)) {
+			if (tcp_is_reno(tp) && is_dupack)
+				tcp_add_reno_sack(sk);
+		} else
+			do_lost = tcp_try_undo_partial(sk, pkts_acked);
+		break;
+	case TCP_CA_Loss:
+		if (flag & FLAG_DATA_ACKED)
+			icsk->icsk_retransmits = 0;
+		if (tcp_is_reno(tp) && flag & FLAG_SND_UNA_ADVANCED)
+			tcp_reset_reno_sack(tp);
+		if (!tcp_try_undo_loss(sk)) {
+			tcp_moderate_cwnd(tp);
+			tcp_xmit_retransmit_queue(sk);
+			return;
+		}
+		if (icsk->icsk_ca_state != TCP_CA_Open)
+			return;
+		/* Loss is undone; fall through to processing in Open state. */
+	default:
+		if (tcp_is_reno(tp)) {
+			if (flag & FLAG_SND_UNA_ADVANCED)
+				tcp_reset_reno_sack(tp);
+			if (is_dupack)
+				tcp_add_reno_sack(sk);
+		}
+
+		if (icsk->icsk_ca_state == TCP_CA_Disorder)
+			tcp_try_undo_dsack(sk);
+
+		if (!tcp_time_to_recover(sk)) {
+			tcp_try_to_open(sk, flag);
+			return;
+		}
+
+		/* MTU probe failure: don't reduce cwnd */
+		if (icsk->icsk_ca_state < TCP_CA_CWR &&
+		    icsk->icsk_mtup.probe_size &&
+		    tp->snd_una == tp->mtu_probe.probe_seq_start) {
+			tcp_mtup_probe_failed(sk);
+			/* Restores the reduction we did in tcp_mtup_probe() */
+			tp->snd_cwnd++;
+			tcp_simple_retransmit(sk);
+			return;
+		}
+
+		/* Otherwise enter Recovery state */
+
+		if (tcp_is_reno(tp))
+			mib_idx = LINUX_MIB_TCPRENORECOVERY;
+		else
+			mib_idx = LINUX_MIB_TCPSACKRECOVERY;
+
+		NET_INC_STATS_BH(sock_net(sk), mib_idx);
+
+		tp->high_seq = tp->snd_nxt;
+		tp->prior_ssthresh = 0;
+		tp->undo_marker = tp->snd_una;
+		tp->undo_retrans = tp->retrans_out;
+
+		if (icsk->icsk_ca_state < TCP_CA_CWR) {
+			if (!(flag & FLAG_ECE))
+				tp->prior_ssthresh = tcp_current_ssthresh(sk);
+			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
+			TCP_ECN_queue_cwr(tp);
+		}
+
+		tp->bytes_acked = 0;
+		tp->snd_cwnd_cnt = 0;
+		tcp_set_ca_state(sk, TCP_CA_Recovery);
+		fast_rexmit = 1;
+	}
+
+	if (do_lost || (tcp_is_fack(tp) && tcp_head_timedout(sk)))
+		tcp_update_scoreboard(sk, fast_rexmit);
+	tcp_cwnd_down(sk, flag);
+	tcp_xmit_retransmit_queue(sk);
+}
+
+static void tcp_valid_rtt_meas(struct sock *sk, u32 seq_rtt)
+{
+	tcp_rtt_estimator(sk, seq_rtt);
+	tcp_set_rto(sk);
+	inet_csk(sk)->icsk_backoff = 0;
+}
+
+/* Read draft-ietf-tcplw-high-performance before mucking
+ * with this code. (Supersedes RFC1323)
+ */
+static void tcp_ack_saw_tstamp(struct sock *sk, int flag)
+{
+	/* RTTM Rule: A TSecr value received in a segment is used to
+	 * update the averaged RTT measurement only if the segment
+	 * acknowledges some new data, i.e., only if it advances the
+	 * left edge of the send window.
+	 *
+	 * See draft-ietf-tcplw-high-performance-00, section 3.3.
+	 * 1998/04/10 Andrey V. Savochkin <saw@msu.ru>
+	 *
+	 * Changed: reset backoff as soon as we see the first valid sample.
+	 * If we do not, we get strongly overestimated rto. With timestamps
+	 * samples are accepted even from very old segments: f.e., when rtt=1
+	 * increases to 8, we retransmit 5 times and after 8 seconds delayed
+	 * answer arrives rto becomes 120 seconds! If at least one of segments
+	 * in window is lost... Voila.	 			--ANK (010210)
+	 */
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	tcp_valid_rtt_meas(sk, tcp_time_stamp - tp->rx_opt.rcv_tsecr);
+}
+
+static void tcp_ack_no_tstamp(struct sock *sk, u32 seq_rtt, int flag)
+{
+	/* We don't have a timestamp. Can only use
+	 * packets that are not retransmitted to determine
+	 * rtt estimates. Also, we must not reset the
+	 * backoff for rto until we get a non-retransmitted
+	 * packet. This allows us to deal with a situation
+	 * where the network delay has increased suddenly.
+	 * I.e. Karn's algorithm. (SIGCOMM '87, p5.)
+	 */
+
+	if (flag & FLAG_RETRANS_DATA_ACKED)
+		return;
+
+	tcp_valid_rtt_meas(sk, seq_rtt);
+}
+
+static inline void tcp_ack_update_rtt(struct sock *sk, const int flag,
+				      const s32 seq_rtt)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	/* Note that peer MAY send zero echo. In this case it is ignored. (rfc1323) */
+	if (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr)
+		tcp_ack_saw_tstamp(sk, flag);
+	else if (seq_rtt >= 0)
+		tcp_ack_no_tstamp(sk, seq_rtt, flag);
+}
+
+static void tcp_cong_avoid(struct sock *sk, u32 ack, u32 in_flight)
+{
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	icsk->icsk_ca_ops->cong_avoid(sk, ack, in_flight);
+	tcp_sk(sk)->snd_cwnd_stamp = tcp_time_stamp;
+}
+
+/* Restart timer after forward progress on connection.
+ * RFC2988 recommends to restart timer to now+rto.
+ */
+static void tcp_rearm_rto(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (!tp->packets_out) {
+		inet_csk_clear_xmit_timer(sk, ICSK_TIME_RETRANS);
+	} else {
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+					  inet_csk(sk)->icsk_rto, TCP_RTO_MAX);
+	}
+}
+
+/* If we get here, the whole TSO packet has not been acked. */
+static u32 tcp_tso_acked(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 packets_acked;
+
+	BUG_ON(!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una));
+
+	packets_acked = tcp_skb_pcount(skb);
+	if (tcp_trim_head(sk, skb, tp->snd_una - TCP_SKB_CB(skb)->seq))
+		return 0;
+	packets_acked -= tcp_skb_pcount(skb);
+
+	if (packets_acked) {
+		BUG_ON(tcp_skb_pcount(skb) == 0);
+		BUG_ON(!before(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq));
+	}
+
+	return packets_acked;
+}
+
+/* Remove acknowledged frames from the retransmission queue. If our packet
+ * is before the ack sequence we can discard it as it's confirmed to have
+ * arrived at the other end.
+ */
+static int tcp_clean_rtx_queue(struct sock *sk, int prior_fackets,
+			       u32 prior_snd_una)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	const struct inet_connection_sock *icsk = inet_csk(sk);
+	struct sk_buff *skb;
+	u32 now = tcp_time_stamp;
+	int fully_acked = 1;
+	int flag = 0;
+	u32 pkts_acked = 0;
+	u32 reord = tp->packets_out;
+	u32 prior_sacked = tp->sacked_out;
+	s32 seq_rtt = -1;
+	s32 ca_seq_rtt = -1;
+	ktime_t last_ackt = net_invalid_timestamp();
+
+	while ((skb = tcp_write_queue_head(sk)) && skb != tcp_send_head(sk)) {
+		struct tcp_skb_cb *scb = TCP_SKB_CB(skb);
+		u32 acked_pcount;
+		u8 sacked = scb->sacked;
+
+		/* Determine how many packets and what bytes were acked, tso and else */
+		if (after(scb->end_seq, tp->snd_una)) {
+			if (tcp_skb_pcount(skb) == 1 ||
+			    !after(tp->snd_una, scb->seq))
+				break;
+
+			acked_pcount = tcp_tso_acked(sk, skb);
+			if (!acked_pcount)
+				break;
+
+			fully_acked = 0;
+		} else {
+			acked_pcount = tcp_skb_pcount(skb);
+		}
+
+		if (sacked & TCPCB_RETRANS) {
+			if (sacked & TCPCB_SACKED_RETRANS)
+				tp->retrans_out -= acked_pcount;
+			flag |= FLAG_RETRANS_DATA_ACKED;
+			ca_seq_rtt = -1;
+			seq_rtt = -1;
+			if ((flag & FLAG_DATA_ACKED) || (acked_pcount > 1))
+				flag |= FLAG_NONHEAD_RETRANS_ACKED;
+		} else {
+			ca_seq_rtt = now - scb->when;
+			last_ackt = skb->tstamp;
+			if (seq_rtt < 0) {
+				seq_rtt = ca_seq_rtt;
+			}
+			if (!(sacked & TCPCB_SACKED_ACKED))
+				reord = min(pkts_acked, reord);
+		}
+
+		if (sacked & TCPCB_SACKED_ACKED)
+			tp->sacked_out -= acked_pcount;
+		if (sacked & TCPCB_LOST)
+			tp->lost_out -= acked_pcount;
+
+		tp->packets_out -= acked_pcount;
+		pkts_acked += acked_pcount;
+
+		/* Initial outgoing SYN's get put onto the write_queue
+		 * just like anything else we transmit.  It is not
+		 * true data, and if we misinform our callers that
+		 * this ACK acks real data, we will erroneously exit
+		 * connection startup slow start one packet too
+		 * quickly.  This is severely frowned upon behavior.
+		 */
+		if (!(scb->flags & TCPCB_FLAG_SYN)) {
+			flag |= FLAG_DATA_ACKED;
+		} else {
+			flag |= FLAG_SYN_ACKED;
+			tp->retrans_stamp = 0;
+		}
+
+		if (!fully_acked)
+			break;
+
+		tcp_unlink_write_queue(skb, sk);
+		sk_wmem_free_skb(sk, skb);
+		tp->scoreboard_skb_hint = NULL;
+		if (skb == tp->retransmit_skb_hint)
+			tp->retransmit_skb_hint = NULL;
+		if (skb == tp->lost_skb_hint)
+			tp->lost_skb_hint = NULL;
+	}
+
+	if (likely(between(tp->snd_up, prior_snd_una, tp->snd_una)))
+		tp->snd_up = tp->snd_una;
+
+	if (skb && (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED))
+		flag |= FLAG_SACK_RENEGING;
+
+	if (flag & FLAG_ACKED) {
+		const struct tcp_congestion_ops *ca_ops
+			= inet_csk(sk)->icsk_ca_ops;
+
+		if (unlikely(icsk->icsk_mtup.probe_size &&
+			     !after(tp->mtu_probe.probe_seq_end, tp->snd_una))) {
+			tcp_mtup_probe_success(sk);
+		}
+
+		tcp_ack_update_rtt(sk, flag, seq_rtt);
+		tcp_rearm_rto(sk);
+
+		if (tcp_is_reno(tp)) {
+			tcp_remove_reno_sacks(sk, pkts_acked);
+		} else {
+			int delta;
+
+			/* Non-retransmitted hole got filled? That's reordering */
+			if (reord < prior_fackets)
+				tcp_update_reordering(sk, tp->fackets_out - reord, 0);
+
+			delta = tcp_is_fack(tp) ? pkts_acked :
+						  prior_sacked - tp->sacked_out;
+			tp->lost_cnt_hint -= min(tp->lost_cnt_hint, delta);
+		}
+
+		tp->fackets_out -= min(pkts_acked, tp->fackets_out);
+
+		if (ca_ops->pkts_acked) {
+			s32 rtt_us = -1;
+
+			/* Is the ACK triggering packet unambiguous? */
+			if (!(flag & FLAG_RETRANS_DATA_ACKED)) {
+				/* High resolution needed and available? */
+				if (ca_ops->flags & TCP_CONG_RTT_STAMP &&
+				    !ktime_equal(last_ackt,
+						 net_invalid_timestamp()))
+					rtt_us = ktime_us_delta(ktime_get_real(),
+								last_ackt);
+				else if (ca_seq_rtt > 0)
+					rtt_us = jiffies_to_usecs(ca_seq_rtt);
+			}
+
+			ca_ops->pkts_acked(sk, pkts_acked, rtt_us);
+		}
+	}
+
+#if FASTRETRANS_DEBUG > 0
+	WARN_ON((int)tp->sacked_out < 0);
+	WARN_ON((int)tp->lost_out < 0);
+	WARN_ON((int)tp->retrans_out < 0);
+	if (!tp->packets_out && tcp_is_sack(tp)) {
+		icsk = inet_csk(sk);
+		if (tp->lost_out) {
+			printk(KERN_DEBUG "Leak l=%u %d\n",
+			       tp->lost_out, icsk->icsk_ca_state);
+			tp->lost_out = 0;
+		}
+		if (tp->sacked_out) {
+			printk(KERN_DEBUG "Leak s=%u %d\n",
+			       tp->sacked_out, icsk->icsk_ca_state);
+			tp->sacked_out = 0;
+		}
+		if (tp->retrans_out) {
+			printk(KERN_DEBUG "Leak r=%u %d\n",
+			       tp->retrans_out, icsk->icsk_ca_state);
+			tp->retrans_out = 0;
+		}
+	}
+#endif
+	return flag;
+}
+
+static void tcp_ack_probe(struct sock *sk)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	/* Was it a usable window open? */
+
+	if (!after(TCP_SKB_CB(tcp_send_head(sk))->end_seq, tcp_wnd_end(tp))) {
+		icsk->icsk_backoff = 0;
+		inet_csk_clear_xmit_timer(sk, ICSK_TIME_PROBE0);
+		/* Socket must be waked up by subsequent tcp_data_snd_check().
+		 * This function is not for random using!
+		 */
+	} else {
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_PROBE0,
+					  min(icsk->icsk_rto << icsk->icsk_backoff, TCP_RTO_MAX),
+					  TCP_RTO_MAX);
+	}
+}
+
+static inline int tcp_ack_is_dubious(const struct sock *sk, const int flag)
+{
+	return (!(flag & FLAG_NOT_DUP) || (flag & FLAG_CA_ALERT) ||
+		inet_csk(sk)->icsk_ca_state != TCP_CA_Open);
+}
+
+static inline int tcp_may_raise_cwnd(const struct sock *sk, const int flag)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	return (!(flag & FLAG_ECE) || tp->snd_cwnd < tp->snd_ssthresh) &&
+		!((1 << inet_csk(sk)->icsk_ca_state) & (TCPF_CA_Recovery | TCPF_CA_CWR));
+}
+
+/* Check that window update is acceptable.
+ * The function assumes that snd_una<=ack<=snd_next.
+ */
+static inline int tcp_may_update_window(const struct tcp_sock *tp,
+					const u32 ack, const u32 ack_seq,
+					const u32 nwin)
+{
+	return (after(ack, tp->snd_una) ||
+		after(ack_seq, tp->snd_wl1) ||
+		(ack_seq == tp->snd_wl1 && nwin > tp->snd_wnd));
+}
+
+/* Update our send window.
+ *
+ * Window update algorithm, described in RFC793/RFC1122 (used in linux-2.2
+ * and in FreeBSD. NetBSD's one is even worse.) is wrong.
+ */
+static int tcp_ack_update_window(struct sock *sk, struct sk_buff *skb, u32 ack,
+				 u32 ack_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int flag = 0;
+	u32 nwin = ntohs(tcp_hdr(skb)->window);
+
+	if (likely(!tcp_hdr(skb)->syn))
+		nwin <<= tp->rx_opt.snd_wscale;
+
+	if (tcp_may_update_window(tp, ack, ack_seq, nwin)) {
+		flag |= FLAG_WIN_UPDATE;
+		tcp_update_wl(tp, ack_seq);
+
+		if (tp->snd_wnd != nwin) {
+			tp->snd_wnd = nwin;
+
+			/* Note, it is the only place, where
+			 * fast path is recovered for sending TCP.
+			 */
+			tp->pred_flags = 0;
+			tcp_fast_path_check(sk);
+
+			if (nwin > tp->max_window) {
+				tp->max_window = nwin;
+				tcp_sync_mss(sk, inet_csk(sk)->icsk_pmtu_cookie);
+			}
+		}
+	}
+
+	tp->snd_una = ack;
+
+	return flag;
+}
+
+/* A very conservative spurious RTO response algorithm: reduce cwnd and
+ * continue in congestion avoidance.
+ */
+static void tcp_conservative_spur_to_response(struct tcp_sock *tp)
+{
+	tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_ssthresh);
+	tp->snd_cwnd_cnt = 0;
+	tp->bytes_acked = 0;
+	TCP_ECN_queue_cwr(tp);
+	tcp_moderate_cwnd(tp);
+}
+
+/* A conservative spurious RTO response algorithm: reduce cwnd using
+ * rate halving and continue in congestion avoidance.
+ */
+static void tcp_ratehalving_spur_to_response(struct sock *sk)
+{
+	tcp_enter_cwr(sk, 0);
+}
+
+static void tcp_undo_spur_to_response(struct sock *sk, int flag)
+{
+	if (flag & FLAG_ECE)
+		tcp_ratehalving_spur_to_response(sk);
+	else
+		tcp_undo_cwr(sk, 1);
+}
+
+/* F-RTO spurious RTO detection algorithm (RFC4138)
+ *
+ * F-RTO affects during two new ACKs following RTO (well, almost, see inline
+ * comments). State (ACK number) is kept in frto_counter. When ACK advances
+ * window (but not to or beyond highest sequence sent before RTO):
+ *   On First ACK,  send two new segments out.
+ *   On Second ACK, RTO was likely spurious. Do spurious response (response
+ *                  algorithm is not part of the F-RTO detection algorithm
+ *                  given in RFC4138 but can be selected separately).
+ * Otherwise (basically on duplicate ACK), RTO was (likely) caused by a loss
+ * and TCP falls back to conventional RTO recovery. F-RTO allows overriding
+ * of Nagle, this is done using frto_counter states 2 and 3, when a new data
+ * segment of any size sent during F-RTO, state 2 is upgraded to 3.
+ *
+ * Rationale: if the RTO was spurious, new ACKs should arrive from the
+ * original window even after we transmit two new data segments.
+ *
+ * SACK version:
+ *   on first step, wait until first cumulative ACK arrives, then move to
+ *   the second step. In second step, the next ACK decides.
+ *
+ * F-RTO is implemented (mainly) in four functions:
+ *   - tcp_use_frto() is used to determine if TCP is can use F-RTO
+ *   - tcp_enter_frto() prepares TCP state on RTO if F-RTO is used, it is
+ *     called when tcp_use_frto() showed green light
+ *   - tcp_process_frto() handles incoming ACKs during F-RTO algorithm
+ *   - tcp_enter_frto_loss() is called if there is not enough evidence
+ *     to prove that the RTO is indeed spurious. It transfers the control
+ *     from F-RTO to the conventional RTO recovery
+ */
+static int tcp_process_frto(struct sock *sk, int flag)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	tcp_verify_left_out(tp);
+
+	/* Duplicate the behavior from Loss state (fastretrans_alert) */
+	if (flag & FLAG_DATA_ACKED)
+		inet_csk(sk)->icsk_retransmits = 0;
+
+	if ((flag & FLAG_NONHEAD_RETRANS_ACKED) ||
+	    ((tp->frto_counter >= 2) && (flag & FLAG_RETRANS_DATA_ACKED)))
+		tp->undo_marker = 0;
+
+	if (!before(tp->snd_una, tp->frto_highmark)) {
+		tcp_enter_frto_loss(sk, (tp->frto_counter == 1 ? 2 : 3), flag);
+		return 1;
+	}
+
+	if (!tcp_is_sackfrto(tp)) {
+		/* RFC4138 shortcoming in step 2; should also have case c):
+		 * ACK isn't duplicate nor advances window, e.g., opposite dir
+		 * data, winupdate
+		 */
+		if (!(flag & FLAG_ANY_PROGRESS) && (flag & FLAG_NOT_DUP))
+			return 1;
+
+		if (!(flag & FLAG_DATA_ACKED)) {
+			tcp_enter_frto_loss(sk, (tp->frto_counter == 1 ? 0 : 3),
+					    flag);
+			return 1;
+		}
+	} else {
+		if (!(flag & FLAG_DATA_ACKED) && (tp->frto_counter == 1)) {
+			/* Prevent sending of new data. */
+			tp->snd_cwnd = min(tp->snd_cwnd,
+					   tcp_packets_in_flight(tp));
+			return 1;
+		}
+
+		if ((tp->frto_counter >= 2) &&
+		    (!(flag & FLAG_FORWARD_PROGRESS) ||
+		     ((flag & FLAG_DATA_SACKED) &&
+		      !(flag & FLAG_ONLY_ORIG_SACKED)))) {
+			/* RFC4138 shortcoming (see comment above) */
+			if (!(flag & FLAG_FORWARD_PROGRESS) &&
+			    (flag & FLAG_NOT_DUP))
+				return 1;
+
+			tcp_enter_frto_loss(sk, 3, flag);
+			return 1;
+		}
+	}
+
+	if (tp->frto_counter == 1) {
+		/* tcp_may_send_now needs to see updated state */
+		tp->snd_cwnd = tcp_packets_in_flight(tp) + 2;
+		tp->frto_counter = 2;
+
+		if (!tcp_may_send_now(sk))
+			tcp_enter_frto_loss(sk, 2, flag);
+
+		return 1;
+	} else {
+		switch (sysctl_tcp_frto_response) {
+		case 2:
+			tcp_undo_spur_to_response(sk, flag);
+			break;
+		case 1:
+			tcp_conservative_spur_to_response(tp);
+			break;
+		default:
+			tcp_ratehalving_spur_to_response(sk);
+			break;
+		}
+		tp->frto_counter = 0;
+		tp->undo_marker = 0;
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPSPURIOUSRTOS);
+	}
+	return 0;
+}
+
+/* This routine deals with incoming acks, but not outgoing ones. */
+static int tcp_ack(struct sock *sk, struct sk_buff *skb, int flag)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 prior_snd_una = tp->snd_una;
+	u32 ack_seq = TCP_SKB_CB(skb)->seq;
+	u32 ack = TCP_SKB_CB(skb)->ack_seq;
+	u32 prior_in_flight;
+	u32 prior_fackets;
+	int prior_packets;
+	int frto_cwnd = 0;
+
+	/* If the ack is older than previous acks
+	 * then we can probably ignore it.
+	 */
+	if (before(ack, prior_snd_una))
+		goto old_ack;
+
+	/* If the ack includes data we haven't sent yet, discard
+	 * this segment (RFC793 Section 3.9).
+	 */
+	if (after(ack, tp->snd_nxt))
+		goto invalid_ack;
+
+	if (after(ack, prior_snd_una))
+		flag |= FLAG_SND_UNA_ADVANCED;
+
+	if (sysctl_tcp_abc) {
+		if (icsk->icsk_ca_state < TCP_CA_CWR)
+			tp->bytes_acked += ack - prior_snd_una;
+		else if (icsk->icsk_ca_state == TCP_CA_Loss)
+			/* we assume just one segment left network */
+			tp->bytes_acked += min(ack - prior_snd_una,
+					       tp->mss_cache);
+	}
+
+	prior_fackets = tp->fackets_out;
+	prior_in_flight = tcp_packets_in_flight(tp);
+
+	if (!(flag & FLAG_SLOWPATH) && after(ack, prior_snd_una)) {
+		/* Window is constant, pure forward advance.
+		 * No more checks are required.
+		 * Note, we use the fact that SND.UNA>=SND.WL2.
+		 */
+		tcp_update_wl(tp, ack_seq);
+		tp->snd_una = ack;
+		flag |= FLAG_WIN_UPDATE;
+
+		tcp_ca_event(sk, CA_EVENT_FAST_ACK);
+
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPACKS);
+	} else {
+		if (ack_seq != TCP_SKB_CB(skb)->end_seq)
+			flag |= FLAG_DATA;
+		else
+			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPUREACKS);
+
+		flag |= tcp_ack_update_window(sk, skb, ack, ack_seq);
+
+		if (TCP_SKB_CB(skb)->sacked)
+			flag |= tcp_sacktag_write_queue(sk, skb, prior_snd_una);
+
+		if (TCP_ECN_rcv_ecn_echo(tp, tcp_hdr(skb)))
+			flag |= FLAG_ECE;
+
+		tcp_ca_event(sk, CA_EVENT_SLOW_ACK);
+	}
+
+	/* We passed data and got it acked, remove any soft error
+	 * log. Something worked...
+	 */
+	sk->sk_err_soft = 0;
+	icsk->icsk_probes_out = 0;
+	tp->rcv_tstamp = tcp_time_stamp;
+	prior_packets = tp->packets_out;
+	if (!prior_packets)
+		goto no_queue;
+
+	/* See if we can take anything off of the retransmit queue. */
+	flag |= tcp_clean_rtx_queue(sk, prior_fackets, prior_snd_una);
+
+	if (tp->frto_counter)
+		frto_cwnd = tcp_process_frto(sk, flag);
+	/* Guarantee sacktag reordering detection against wrap-arounds */
+	if (before(tp->frto_highmark, tp->snd_una))
+		tp->frto_highmark = 0;
+
+	if (tcp_ack_is_dubious(sk, flag)) {
+		/* Advance CWND, if state allows this. */
+		if ((flag & FLAG_DATA_ACKED) && !frto_cwnd &&
+		    tcp_may_raise_cwnd(sk, flag))
+			tcp_cong_avoid(sk, ack, prior_in_flight);
+		tcp_fastretrans_alert(sk, prior_packets - tp->packets_out,
+				      flag);
+	} else {
+		if ((flag & FLAG_DATA_ACKED) && !frto_cwnd)
+			tcp_cong_avoid(sk, ack, prior_in_flight);
+	}
+
+	if ((flag & FLAG_FORWARD_PROGRESS) || !(flag & FLAG_NOT_DUP))
+		dst_confirm(sk->sk_dst_cache);
+
+	return 1;
+
+no_queue:
+	/* If this ack opens up a zero window, clear backoff.  It was
+	 * being used to time the probes, and is probably far higher than
+	 * it needs to be for normal retransmission.
+	 */
+	if (tcp_send_head(sk))
+		tcp_ack_probe(sk);
+	return 1;
+
+invalid_ack:
+	SOCK_DEBUG(sk, "Ack %u after %u:%u\n", ack, tp->snd_una, tp->snd_nxt);
+	return -1;
+
+old_ack:
+	if (TCP_SKB_CB(skb)->sacked) {
+		tcp_sacktag_write_queue(sk, skb, prior_snd_una);
+		if (icsk->icsk_ca_state == TCP_CA_Open)
+			tcp_try_keep_open(sk);
+	}
+
+	SOCK_DEBUG(sk, "Ack %u before %u:%u\n", ack, tp->snd_una, tp->snd_nxt);
+	return 0;
+}
+
+/* Look for tcp options. Normally only called on SYN and SYNACK packets.
+ * But, this can also be called on packets in the established flow when
+ * the fast version below fails.
+ */
+void tcp_parse_options(struct sk_buff *skb, struct tcp_options_received *opt_rx,
+		       int estab)
+{
+	unsigned char *ptr;
+	struct tcphdr *th = tcp_hdr(skb);
+	int length = (th->doff * 4) - sizeof(struct tcphdr);
+
+	ptr = (unsigned char *)(th + 1);
+	opt_rx->saw_tstamp = 0;
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return;
+		case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2) /* "silly options" */
+				return;
+			if (opsize > length)
+				return;	/* don't parse partial options */
+			switch (opcode) {
+			case TCPOPT_MSS:
+				if (opsize == TCPOLEN_MSS && th->syn && !estab) {
+					u16 in_mss = get_unaligned_be16(ptr);
+					if (in_mss) {
+						if (opt_rx->user_mss &&
+						    opt_rx->user_mss < in_mss)
+							in_mss = opt_rx->user_mss;
+						opt_rx->mss_clamp = in_mss;
+					}
+				}
+				break;
+			case TCPOPT_WINDOW:
+				if (opsize == TCPOLEN_WINDOW && th->syn &&
+				    !estab && sysctl_tcp_window_scaling) {
+					__u8 snd_wscale = *(__u8 *)ptr;
+					opt_rx->wscale_ok = 1;
+					if (snd_wscale > 14) {
+						if (net_ratelimit())
+							printk(KERN_INFO "tcp_parse_options: Illegal window "
+							       "scaling value %d >14 received.\n",
+							       snd_wscale);
+						snd_wscale = 14;
+					}
+					opt_rx->snd_wscale = snd_wscale;
+				}
+				break;
+			case TCPOPT_TIMESTAMP:
+				if ((opsize == TCPOLEN_TIMESTAMP) &&
+				    ((estab && opt_rx->tstamp_ok) ||
+				     (!estab && sysctl_tcp_timestamps))) {
+					opt_rx->saw_tstamp = 1;
+					opt_rx->rcv_tsval = get_unaligned_be32(ptr);
+					opt_rx->rcv_tsecr = get_unaligned_be32(ptr + 4);
+				}
+				break;
+			case TCPOPT_SACK_PERM:
+				if (opsize == TCPOLEN_SACK_PERM && th->syn &&
+				    !estab && sysctl_tcp_sack) {
+					opt_rx->sack_ok = 1;
+					tcp_sack_reset(opt_rx);
+				}
+				break;
+
+			case TCPOPT_SACK:
+				if ((opsize >= (TCPOLEN_SACK_BASE + TCPOLEN_SACK_PERBLOCK)) &&
+				   !((opsize - TCPOLEN_SACK_BASE) % TCPOLEN_SACK_PERBLOCK) &&
+				   opt_rx->sack_ok) {
+					TCP_SKB_CB(skb)->sacked = (ptr - 2) - (unsigned char *)th;
+				}
+				break;
+#ifdef CONFIG_TCP_MD5SIG
+			case TCPOPT_MD5SIG:
+				/*
+				 * The MD5 Hash has already been
+				 * checked (see tcp_v{4,6}_do_rcv()).
+				 */
+				break;
+#endif
+			}
+
+			ptr += opsize-2;
+			length -= opsize;
+		}
+	}
+}
+
+static int tcp_parse_aligned_timestamp(struct tcp_sock *tp, struct tcphdr *th)
+{
+	__be32 *ptr = (__be32 *)(th + 1);
+
+	if (*ptr == htonl((TCPOPT_NOP << 24) | (TCPOPT_NOP << 16)
+			  | (TCPOPT_TIMESTAMP << 8) | TCPOLEN_TIMESTAMP)) {
+		tp->rx_opt.saw_tstamp = 1;
+		++ptr;
+		tp->rx_opt.rcv_tsval = ntohl(*ptr);
+		++ptr;
+		tp->rx_opt.rcv_tsecr = ntohl(*ptr);
+		return 1;
+	}
+	return 0;
+}
+
+/* Fast parse options. This hopes to only see timestamps.
+ * If it is wrong it falls back on tcp_parse_options().
+ */
+static int tcp_fast_parse_options(struct sk_buff *skb, struct tcphdr *th,
+				  struct tcp_sock *tp)
+{
+	if (th->doff == sizeof(struct tcphdr) >> 2) {
+		tp->rx_opt.saw_tstamp = 0;
+		return 0;
+	} else if (tp->rx_opt.tstamp_ok &&
+		   th->doff == (sizeof(struct tcphdr)>>2)+(TCPOLEN_TSTAMP_ALIGNED>>2)) {
+		if (tcp_parse_aligned_timestamp(tp, th))
+			return 1;
+	}
+	tcp_parse_options(skb, &tp->rx_opt, 1);
+	return 1;
+}
+
+#ifdef CONFIG_TCP_MD5SIG
+/*
+ * Parse MD5 Signature option
+ */
+u8 *tcp_parse_md5sig_option(struct tcphdr *th)
+{
+	int length = (th->doff << 2) - sizeof (*th);
+	u8 *ptr = (u8*)(th + 1);
+
+	/* If the TCP option is too short, we can short cut */
+	if (length < TCPOLEN_MD5SIG)
+		return NULL;
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize;
+
+		switch(opcode) {
+		case TCPOPT_EOL:
+			return NULL;
+		case TCPOPT_NOP:
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2 || opsize > length)
+				return NULL;
+			if (opcode == TCPOPT_MD5SIG)
+				return ptr;
+		}
+		ptr += opsize - 2;
+		length -= opsize;
+	}
+	return NULL;
+}
+#endif
+
+static inline void tcp_store_ts_recent(struct tcp_sock *tp)
+{
+	tp->rx_opt.ts_recent = tp->rx_opt.rcv_tsval;
+	tp->rx_opt.ts_recent_stamp = get_seconds();
+}
+
+static inline void tcp_replace_ts_recent(struct tcp_sock *tp, u32 seq)
+{
+	if (tp->rx_opt.saw_tstamp && !after(seq, tp->rcv_wup)) {
+		/* PAWS bug workaround wrt. ACK frames, the PAWS discard
+		 * extra check below makes sure this can only happen
+		 * for pure ACK frames.  -DaveM
+		 *
+		 * Not only, also it occurs for expired timestamps.
+		 */
+
+		if (tcp_paws_check(&tp->rx_opt, 0))
+			tcp_store_ts_recent(tp);
+	}
+}
+
+/* Sorry, PAWS as specified is broken wrt. pure-ACKs -DaveM
+ *
+ * It is not fatal. If this ACK does _not_ change critical state (seqs, window)
+ * it can pass through stack. So, the following predicate verifies that
+ * this segment is not used for anything but congestion avoidance or
+ * fast retransmit. Moreover, we even are able to eliminate most of such
+ * second order effects, if we apply some small "replay" window (~RTO)
+ * to timestamp space.
+ *
+ * All these measures still do not guarantee that we reject wrapped ACKs
+ * on networks with high bandwidth, when sequence space is recycled fastly,
+ * but it guarantees that such events will be very rare and do not affect
+ * connection seriously. This doesn't look nice, but alas, PAWS is really
+ * buggy extension.
+ *
+ * [ Later note. Even worse! It is buggy for segments _with_ data. RFC
+ * states that events when retransmit arrives after original data are rare.
+ * It is a blatant lie. VJ forgot about fast retransmit! 8)8) It is
+ * the biggest problem on large power networks even with minor reordering.
+ * OK, let's give it small replay window. If peer clock is even 1hz, it is safe
+ * up to bandwidth of 18Gigabit/sec. 8) ]
+ */
+
+static int tcp_disordered_ack(const struct sock *sk, const struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct tcphdr *th = tcp_hdr(skb);
+	u32 seq = TCP_SKB_CB(skb)->seq;
+	u32 ack = TCP_SKB_CB(skb)->ack_seq;
+
+	return (/* 1. Pure ACK with correct sequence number. */
+		(th->ack && seq == TCP_SKB_CB(skb)->end_seq && seq == tp->rcv_nxt) &&
+
+		/* 2. ... and duplicate ACK. */
+		ack == tp->snd_una &&
+
+		/* 3. ... and does not update window. */
+		!tcp_may_update_window(tp, ack, seq, ntohs(th->window) << tp->rx_opt.snd_wscale) &&
+
+		/* 4. ... and sits in replay window. */
+		(s32)(tp->rx_opt.ts_recent - tp->rx_opt.rcv_tsval) <= (inet_csk(sk)->icsk_rto * 1024) / HZ);
+}
+
+static inline int tcp_paws_discard(const struct sock *sk,
+				   const struct sk_buff *skb)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+
+	return !tcp_paws_check(&tp->rx_opt, TCP_PAWS_WINDOW) &&
+	       !tcp_disordered_ack(sk, skb);
+}
+
+/* Check segment sequence number for validity.
+ *
+ * Segment controls are considered valid, if the segment
+ * fits to the window after truncation to the window. Acceptability
+ * of data (and SYN, FIN, of course) is checked separately.
+ * See tcp_data_queue(), for example.
+ *
+ * Also, controls (RST is main one) are accepted using RCV.WUP instead
+ * of RCV.NXT. Peer still did not advance his SND.UNA when we
+ * delayed ACK, so that hisSND.UNA<=ourRCV.WUP.
+ * (borrowed from freebsd)
+ */
+
+static inline int tcp_sequence(struct tcp_sock *tp, u32 seq, u32 end_seq)
+{
+	return	!before(end_seq, tp->rcv_wup) &&
+		!after(seq, tp->rcv_nxt + tcp_receive_window(tp));
+}
+
+/* When we get a reset we do this. */
+static void tcp_reset(struct sock *sk)
+{
+	/* We want the right error as BSD sees it (and indeed as we do). */
+	switch (sk->sk_state) {
+	case TCP_SYN_SENT:
+		sk->sk_err = ECONNREFUSED;
+		break;
+	case TCP_CLOSE_WAIT:
+		sk->sk_err = EPIPE;
+		break;
+	case TCP_CLOSE:
+		return;
+	default:
+		sk->sk_err = ECONNRESET;
+	}
+
+	if (!sock_flag(sk, SOCK_DEAD))
+		sk->sk_error_report(sk);
+
+	tcp_done(sk);
+}
+
+/*
+ * 	Process the FIN bit. This now behaves as it is supposed to work
+ *	and the FIN takes effect when it is validly part of sequence
+ *	space. Not before when we get holes.
+ *
+ *	If we are ESTABLISHED, a received fin moves us to CLOSE-WAIT
+ *	(and thence onto LAST-ACK and finally, CLOSE, we never enter
+ *	TIME-WAIT)
+ *
+ *	If we are in FINWAIT-1, a received FIN indicates simultaneous
+ *	close and we go into CLOSING (and later onto TIME-WAIT)
+ *
+ *	If we are in FINWAIT-2, a received FIN moves us to TIME-WAIT.
+ */
+static void tcp_fin(struct sk_buff *skb, struct sock *sk, struct tcphdr *th)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	inet_csk_schedule_ack(sk);
+
+	sk->sk_shutdown |= RCV_SHUTDOWN;
+	sock_set_flag(sk, SOCK_DONE);
+
+	switch (sk->sk_state) {
+	case TCP_SYN_RECV:
+	case TCP_ESTABLISHED:
+		/* Move to CLOSE_WAIT */
+		tcp_set_state(sk, TCP_CLOSE_WAIT);
+		inet_csk(sk)->icsk_ack.pingpong = 1;
+		break;
+
+	case TCP_CLOSE_WAIT:
+	case TCP_CLOSING:
+		/* Received a retransmission of the FIN, do
+		 * nothing.
+		 */
+		break;
+	case TCP_LAST_ACK:
+		/* RFC793: Remain in the LAST-ACK state. */
+		break;
+
+	case TCP_FIN_WAIT1:
+		/* This case occurs when a simultaneous close
+		 * happens, we must ack the received FIN and
+		 * enter the CLOSING state.
+		 */
+		tcp_send_ack(sk);
+		tcp_set_state(sk, TCP_CLOSING);
+		break;
+	case TCP_FIN_WAIT2:
+		/* Received a FIN -- send ACK and enter TIME_WAIT. */
+		tcp_send_ack(sk);
+		tcp_time_wait(sk, TCP_TIME_WAIT, 0);
+		break;
+	default:
+		/* Only TCP_LISTEN and TCP_CLOSE are left, in these
+		 * cases we should never reach this piece of code.
+		 */
+		printk(KERN_ERR "%s: Impossible, sk->sk_state=%d\n",
+		       __func__, sk->sk_state);
+		break;
+	}
+
+	/* It _is_ possible, that we have something out-of-order _after_ FIN.
+	 * Probably, we should reset in this case. For now drop them.
+	 */
+	__skb_queue_purge(&tp->out_of_order_queue);
+	if (tcp_is_sack(tp))
+		tcp_sack_reset(&tp->rx_opt);
+	sk_mem_reclaim(sk);
+
+	if (!sock_flag(sk, SOCK_DEAD)) {
+		sk->sk_state_change(sk);
+
+		/* Do not send POLL_HUP for half duplex close. */
+		if (sk->sk_shutdown == SHUTDOWN_MASK ||
+		    sk->sk_state == TCP_CLOSE)
+			sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_HUP);
+		else
+			sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_IN);
+	}
+}
+
+static inline int tcp_sack_extend(struct tcp_sack_block *sp, u32 seq,
+				  u32 end_seq)
+{
+	if (!after(seq, sp->end_seq) && !after(sp->start_seq, end_seq)) {
+		if (before(seq, sp->start_seq))
+			sp->start_seq = seq;
+		if (after(end_seq, sp->end_seq))
+			sp->end_seq = end_seq;
+		return 1;
+	}
+	return 0;
+}
+
+static void tcp_dsack_set(struct sock *sk, u32 seq, u32 end_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tcp_is_sack(tp) && sysctl_tcp_dsack) {
+		int mib_idx;
+
+		if (before(seq, tp->rcv_nxt))
+			mib_idx = LINUX_MIB_TCPDSACKOLDSENT;
+		else
+			mib_idx = LINUX_MIB_TCPDSACKOFOSENT;
+
+		NET_INC_STATS_BH(sock_net(sk), mib_idx);
+
+		tp->rx_opt.dsack = 1;
+		tp->duplicate_sack[0].start_seq = seq;
+		tp->duplicate_sack[0].end_seq = end_seq;
+	}
+}
+
+static void tcp_dsack_extend(struct sock *sk, u32 seq, u32 end_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (!tp->rx_opt.dsack)
+		tcp_dsack_set(sk, seq, end_seq);
+	else
+		tcp_sack_extend(tp->duplicate_sack, seq, end_seq);
+}
+
+static void tcp_send_dupack(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
+	    before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_DELAYEDACKLOST);
+		tcp_enter_quickack_mode(sk);
+
+		if (tcp_is_sack(tp) && sysctl_tcp_dsack) {
+			u32 end_seq = TCP_SKB_CB(skb)->end_seq;
+
+			if (after(TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt))
+				end_seq = tp->rcv_nxt;
+			tcp_dsack_set(sk, TCP_SKB_CB(skb)->seq, end_seq);
+		}
+	}
+
+	tcp_send_ack(sk);
+}
+
+/* These routines update the SACK block as out-of-order packets arrive or
+ * in-order packets close up the sequence space.
+ */
+static void tcp_sack_maybe_coalesce(struct tcp_sock *tp)
+{
+	int this_sack;
+	struct tcp_sack_block *sp = &tp->selective_acks[0];
+	struct tcp_sack_block *swalk = sp + 1;
+
+	/* See if the recent change to the first SACK eats into
+	 * or hits the sequence space of other SACK blocks, if so coalesce.
+	 */
+	for (this_sack = 1; this_sack < tp->rx_opt.num_sacks;) {
+		if (tcp_sack_extend(sp, swalk->start_seq, swalk->end_seq)) {
+			int i;
+
+			/* Zap SWALK, by moving every further SACK up by one slot.
+			 * Decrease num_sacks.
+			 */
+			tp->rx_opt.num_sacks--;
+			for (i = this_sack; i < tp->rx_opt.num_sacks; i++)
+				sp[i] = sp[i + 1];
+			continue;
+		}
+		this_sack++, swalk++;
+	}
+}
+
+static void tcp_sack_new_ofo_skb(struct sock *sk, u32 seq, u32 end_seq)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct tcp_sack_block *sp = &tp->selective_acks[0];
+	int cur_sacks = tp->rx_opt.num_sacks;
+	int this_sack;
+
+	if (!cur_sacks)
+		goto new_sack;
+
+	for (this_sack = 0; this_sack < cur_sacks; this_sack++, sp++) {
+		if (tcp_sack_extend(sp, seq, end_seq)) {
+			/* Rotate this_sack to the first one. */
+			for (; this_sack > 0; this_sack--, sp--)
+				swap(*sp, *(sp - 1));
+			if (cur_sacks > 1)
+				tcp_sack_maybe_coalesce(tp);
+			return;
+		}
+	}
+
+	/* Could not find an adjacent existing SACK, build a new one,
+	 * put it at the front, and shift everyone else down.  We
+	 * always know there is at least one SACK present already here.
+	 *
+	 * If the sack array is full, forget about the last one.
+	 */
+	if (this_sack >= TCP_NUM_SACKS) {
+		this_sack--;
+		tp->rx_opt.num_sacks--;
+		sp--;
+	}
+	for (; this_sack > 0; this_sack--, sp--)
+		*sp = *(sp - 1);
+
+new_sack:
+	/* Build the new head SACK, and we're done. */
+	sp->start_seq = seq;
+	sp->end_seq = end_seq;
+	tp->rx_opt.num_sacks++;
+}
+
+/* RCV.NXT advances, some SACKs should be eaten. */
+
+static void tcp_sack_remove(struct tcp_sock *tp)
+{
+	struct tcp_sack_block *sp = &tp->selective_acks[0];
+	int num_sacks = tp->rx_opt.num_sacks;
+	int this_sack;
+
+	/* Empty ofo queue, hence, all the SACKs are eaten. Clear. */
+	if (skb_queue_empty(&tp->out_of_order_queue)) {
+		tp->rx_opt.num_sacks = 0;
+		return;
+	}
+
+	for (this_sack = 0; this_sack < num_sacks;) {
+		/* Check if the start of the sack is covered by RCV.NXT. */
+		if (!before(tp->rcv_nxt, sp->start_seq)) {
+			int i;
+
+			/* RCV.NXT must cover all the block! */
+			WARN_ON(before(tp->rcv_nxt, sp->end_seq));
+
+			/* Zap this SACK, by moving forward any other SACKS. */
+			for (i=this_sack+1; i < num_sacks; i++)
+				tp->selective_acks[i-1] = tp->selective_acks[i];
+			num_sacks--;
+			continue;
+		}
+		this_sack++;
+		sp++;
+	}
+	tp->rx_opt.num_sacks = num_sacks;
+}
+
+/* This one checks to see if we can put data from the
+ * out_of_order queue into the receive_queue.
+ */
+static void tcp_ofo_queue(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	__u32 dsack_high = tp->rcv_nxt;
+	struct sk_buff *skb;
+
+	while ((skb = skb_peek(&tp->out_of_order_queue)) != NULL) {
+		if (after(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))
+			break;
+
+		if (before(TCP_SKB_CB(skb)->seq, dsack_high)) {
+			__u32 dsack = dsack_high;
+			if (before(TCP_SKB_CB(skb)->end_seq, dsack_high))
+				dsack_high = TCP_SKB_CB(skb)->end_seq;
+			tcp_dsack_extend(sk, TCP_SKB_CB(skb)->seq, dsack);
+		}
+
+		if (!after(TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt)) {
+			SOCK_DEBUG(sk, "ofo packet was already received \n");
+			__skb_unlink(skb, &tp->out_of_order_queue);
+			__kfree_skb(skb);
+			continue;
+		}
+		SOCK_DEBUG(sk, "ofo requeuing : rcv_next %X seq %X - %X\n",
+			   tp->rcv_nxt, TCP_SKB_CB(skb)->seq,
+			   TCP_SKB_CB(skb)->end_seq);
+
+		__skb_unlink(skb, &tp->out_of_order_queue);
+		__skb_queue_tail(&sk->sk_receive_queue, skb);
+		tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;
+		if (tcp_hdr(skb)->fin)
+			tcp_fin(skb, sk, tcp_hdr(skb));
+	}
+}
+
+static int tcp_prune_ofo_queue(struct sock *sk);
+static int tcp_prune_queue(struct sock *sk);
+
+static inline int tcp_try_rmem_schedule(struct sock *sk, unsigned int size)
+{
+	if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf ||
+	    !sk_rmem_schedule(sk, size)) {
+
+		if (tcp_prune_queue(sk) < 0)
+			return -1;
+
+		if (!sk_rmem_schedule(sk, size)) {
+			if (!tcp_prune_ofo_queue(sk))
+				return -1;
+
+			if (!sk_rmem_schedule(sk, size))
+				return -1;
+		}
+	}
+	return 0;
+}
+
+static void tcp_data_queue(struct sock *sk, struct sk_buff *skb)
+{
+	struct tcphdr *th = tcp_hdr(skb);
+	struct tcp_sock *tp = tcp_sk(sk);
+	int eaten = -1;
+
+	if (TCP_SKB_CB(skb)->seq == TCP_SKB_CB(skb)->end_seq)
+		goto drop;
+
+	__skb_pull(skb, th->doff * 4);
+
+	TCP_ECN_accept_cwr(tp, skb);
+
+	tp->rx_opt.dsack = 0;
+
+	/*  Queue data for delivery to the user.
+	 *  Packets in sequence go to the receive queue.
+	 *  Out of sequence packets to the out_of_order_queue.
+	 */
+	if (TCP_SKB_CB(skb)->seq == tp->rcv_nxt) {
+		if (tcp_receive_window(tp) == 0)
+			goto out_of_window;
+
+		/* Ok. In sequence. In window. */
+		if (tp->ucopy.task == current &&
+		    tp->copied_seq == tp->rcv_nxt && tp->ucopy.len &&
+		    sock_owned_by_user(sk) && !tp->urg_data) {
+			int chunk = min_t(unsigned int, skb->len,
+					  tp->ucopy.len);
+
+			__set_current_state(TASK_RUNNING);
+
+			local_bh_enable();
+			if (!skb_copy_datagram_iovec(skb, 0, tp->ucopy.iov, chunk)) {
+				tp->ucopy.len -= chunk;
+				tp->copied_seq += chunk;
+				eaten = (chunk == skb->len && !th->fin);
+				tcp_rcv_space_adjust(sk);
+			}
+			local_bh_disable();
+		}
+
+		if (eaten <= 0) {
+queue_and_out:
+			if (eaten < 0 &&
+			    tcp_try_rmem_schedule(sk, skb->truesize))
+				goto drop;
+
+			skb_set_owner_r(skb, sk);
+			__skb_queue_tail(&sk->sk_receive_queue, skb);
+		}
+		tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;
+		if (skb->len)
+			tcp_event_data_recv(sk, skb);
+		if (th->fin)
+			tcp_fin(skb, sk, th);
+
+		if (!skb_queue_empty(&tp->out_of_order_queue)) {
+			tcp_ofo_queue(sk);
+
+			/* RFC2581. 4.2. SHOULD send immediate ACK, when
+			 * gap in queue is filled.
+			 */
+			if (skb_queue_empty(&tp->out_of_order_queue))
+				inet_csk(sk)->icsk_ack.pingpong = 0;
+		}
+
+		if (tp->rx_opt.num_sacks)
+			tcp_sack_remove(tp);
+
+		tcp_fast_path_check(sk);
+
+		if (eaten > 0)
+			__kfree_skb(skb);
+		else if (!sock_flag(sk, SOCK_DEAD))
+			sk->sk_data_ready(sk, 0);
+		return;
+	}
+
+	if (!after(TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt)) {
+		/* A retransmit, 2nd most common case.  Force an immediate ack. */
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_DELAYEDACKLOST);
+		tcp_dsack_set(sk, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq);
+
+out_of_window:
+		tcp_enter_quickack_mode(sk);
+		inet_csk_schedule_ack(sk);
+drop:
+		__kfree_skb(skb);
+		return;
+	}
+
+	/* Out of window. F.e. zero window probe. */
+	if (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt + tcp_receive_window(tp)))
+		goto out_of_window;
+
+	tcp_enter_quickack_mode(sk);
+
+	if (before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {
+		/* Partial packet, seq < rcv_next < end_seq */
+		SOCK_DEBUG(sk, "partial packet: rcv_next %X seq %X - %X\n",
+			   tp->rcv_nxt, TCP_SKB_CB(skb)->seq,
+			   TCP_SKB_CB(skb)->end_seq);
+
+		tcp_dsack_set(sk, TCP_SKB_CB(skb)->seq, tp->rcv_nxt);
+
+		/* If window is closed, drop tail of packet. But after
+		 * remembering D-SACK for its head made in previous line.
+		 */
+		if (!tcp_receive_window(tp))
+			goto out_of_window;
+		goto queue_and_out;
+	}
+
+	TCP_ECN_check_ce(tp, skb);
+
+	if (tcp_try_rmem_schedule(sk, skb->truesize))
+		goto drop;
+
+	/* Disable header prediction. */
+	tp->pred_flags = 0;
+	inet_csk_schedule_ack(sk);
+
+	SOCK_DEBUG(sk, "out of order segment: rcv_next %X seq %X - %X\n",
+		   tp->rcv_nxt, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq);
+
+	skb_set_owner_r(skb, sk);
+
+	if (!skb_peek(&tp->out_of_order_queue)) {
+		/* Initial out of order segment, build 1 SACK. */
+		if (tcp_is_sack(tp)) {
+			tp->rx_opt.num_sacks = 1;
+			tp->selective_acks[0].start_seq = TCP_SKB_CB(skb)->seq;
+			tp->selective_acks[0].end_seq =
+						TCP_SKB_CB(skb)->end_seq;
+		}
+		__skb_queue_head(&tp->out_of_order_queue, skb);
+	} else {
+		struct sk_buff *skb1 = tp->out_of_order_queue.prev;
+		u32 seq = TCP_SKB_CB(skb)->seq;
+		u32 end_seq = TCP_SKB_CB(skb)->end_seq;
+
+		if (seq == TCP_SKB_CB(skb1)->end_seq) {
+			__skb_queue_after(&tp->out_of_order_queue, skb1, skb);
+
+			if (!tp->rx_opt.num_sacks ||
+			    tp->selective_acks[0].end_seq != seq)
+				goto add_sack;
+
+			/* Common case: data arrive in order after hole. */
+			tp->selective_acks[0].end_seq = end_seq;
+			return;
+		}
+
+		/* Find place to insert this segment. */
+		do {
+			if (!after(TCP_SKB_CB(skb1)->seq, seq))
+				break;
+		} while ((skb1 = skb1->prev) !=
+			 (struct sk_buff *)&tp->out_of_order_queue);
+
+		/* Do skb overlap to previous one? */
+		if (skb1 != (struct sk_buff *)&tp->out_of_order_queue &&
+		    before(seq, TCP_SKB_CB(skb1)->end_seq)) {
+			if (!after(end_seq, TCP_SKB_CB(skb1)->end_seq)) {
+				/* All the bits are present. Drop. */
+				__kfree_skb(skb);
+				tcp_dsack_set(sk, seq, end_seq);
+				goto add_sack;
+			}
+			if (after(seq, TCP_SKB_CB(skb1)->seq)) {
+				/* Partial overlap. */
+				tcp_dsack_set(sk, seq,
+					      TCP_SKB_CB(skb1)->end_seq);
+			} else {
+				skb1 = skb1->prev;
+			}
+		}
+		__skb_queue_after(&tp->out_of_order_queue, skb1, skb);
+
+		/* And clean segments covered by new one as whole. */
+		while ((skb1 = skb->next) !=
+		       (struct sk_buff *)&tp->out_of_order_queue &&
+		       after(end_seq, TCP_SKB_CB(skb1)->seq)) {
+			if (before(end_seq, TCP_SKB_CB(skb1)->end_seq)) {
+				tcp_dsack_extend(sk, TCP_SKB_CB(skb1)->seq,
+						 end_seq);
+				break;
+			}
+			__skb_unlink(skb1, &tp->out_of_order_queue);
+			tcp_dsack_extend(sk, TCP_SKB_CB(skb1)->seq,
+					 TCP_SKB_CB(skb1)->end_seq);
+			__kfree_skb(skb1);
+		}
+
+add_sack:
+		if (tcp_is_sack(tp))
+			tcp_sack_new_ofo_skb(sk, seq, end_seq);
+	}
+}
+
+static struct sk_buff *tcp_collapse_one(struct sock *sk, struct sk_buff *skb,
+					struct sk_buff_head *list)
+{
+	struct sk_buff *next = skb->next;
+
+	__skb_unlink(skb, list);
+	__kfree_skb(skb);
+	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPRCVCOLLAPSED);
+
+	return next;
+}
+
+/* Collapse contiguous sequence of skbs head..tail with
+ * sequence numbers start..end.
+ * Segments with FIN/SYN are not collapsed (only because this
+ * simplifies code)
+ */
+static void
+tcp_collapse(struct sock *sk, struct sk_buff_head *list,
+	     struct sk_buff *head, struct sk_buff *tail,
+	     u32 start, u32 end)
+{
+	struct sk_buff *skb;
+
+	/* First, check that queue is collapsible and find
+	 * the point where collapsing can be useful. */
+	for (skb = head; skb != tail;) {
+		/* No new bits? It is possible on ofo queue. */
+		if (!before(start, TCP_SKB_CB(skb)->end_seq)) {
+			skb = tcp_collapse_one(sk, skb, list);
+			continue;
+		}
+
+		/* The first skb to collapse is:
+		 * - not SYN/FIN and
+		 * - bloated or contains data before "start" or
+		 *   overlaps to the next one.
+		 */
+		if (!tcp_hdr(skb)->syn && !tcp_hdr(skb)->fin &&
+		    (tcp_win_from_space(skb->truesize) > skb->len ||
+		     before(TCP_SKB_CB(skb)->seq, start) ||
+		     (skb->next != tail &&
+		      TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb->next)->seq)))
+			break;
+
+		/* Decided to skip this, advance start seq. */
+		start = TCP_SKB_CB(skb)->end_seq;
+		skb = skb->next;
+	}
+	if (skb == tail || tcp_hdr(skb)->syn || tcp_hdr(skb)->fin)
+		return;
+
+	while (before(start, end)) {
+		struct sk_buff *nskb;
+		unsigned int header = skb_headroom(skb);
+		int copy = SKB_MAX_ORDER(header, 0);
+
+		/* Too big header? This can happen with IPv6. */
+		if (copy < 0)
+			return;
+		if (end - start < copy)
+			copy = end - start;
+		nskb = alloc_skb(copy + header, GFP_ATOMIC);
+		if (!nskb)
+			return;
+
+		skb_set_mac_header(nskb, skb_mac_header(skb) - skb->head);
+		skb_set_network_header(nskb, (skb_network_header(skb) -
+					      skb->head));
+		skb_set_transport_header(nskb, (skb_transport_header(skb) -
+						skb->head));
+		skb_reserve(nskb, header);
+		memcpy(nskb->head, skb->head, header);
+		memcpy(nskb->cb, skb->cb, sizeof(skb->cb));
+		TCP_SKB_CB(nskb)->seq = TCP_SKB_CB(nskb)->end_seq = start;
+		__skb_queue_before(list, skb, nskb);
+		skb_set_owner_r(nskb, sk);
+
+		/* Copy data, releasing collapsed skbs. */
+		while (copy > 0) {
+			int offset = start - TCP_SKB_CB(skb)->seq;
+			int size = TCP_SKB_CB(skb)->end_seq - start;
+
+			BUG_ON(offset < 0);
+			if (size > 0) {
+				size = min(copy, size);
+				if (skb_copy_bits(skb, offset, skb_put(nskb, size), size))
+					BUG();
+				TCP_SKB_CB(nskb)->end_seq += size;
+				copy -= size;
+				start += size;
+			}
+			if (!before(start, TCP_SKB_CB(skb)->end_seq)) {
+				skb = tcp_collapse_one(sk, skb, list);
+				if (skb == tail ||
+				    tcp_hdr(skb)->syn ||
+				    tcp_hdr(skb)->fin)
+					return;
+			}
+		}
+	}
+}
+
+/* Collapse ofo queue. Algorithm: select contiguous sequence of skbs
+ * and tcp_collapse() them until all the queue is collapsed.
+ */
+static void tcp_collapse_ofo_queue(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct sk_buff *skb = skb_peek(&tp->out_of_order_queue);
+	struct sk_buff *head;
+	u32 start, end;
+
+	if (skb == NULL)
+		return;
+
+	start = TCP_SKB_CB(skb)->seq;
+	end = TCP_SKB_CB(skb)->end_seq;
+	head = skb;
+
+	for (;;) {
+		skb = skb->next;
+
+		/* Segment is terminated when we see gap or when
+		 * we are at the end of all the queue. */
+		if (skb == (struct sk_buff *)&tp->out_of_order_queue ||
+		    after(TCP_SKB_CB(skb)->seq, end) ||
+		    before(TCP_SKB_CB(skb)->end_seq, start)) {
+			tcp_collapse(sk, &tp->out_of_order_queue,
+				     head, skb, start, end);
+			head = skb;
+			if (skb == (struct sk_buff *)&tp->out_of_order_queue)
+				break;
+			/* Start new segment */
+			start = TCP_SKB_CB(skb)->seq;
+			end = TCP_SKB_CB(skb)->end_seq;
+		} else {
+			if (before(TCP_SKB_CB(skb)->seq, start))
+				start = TCP_SKB_CB(skb)->seq;
+			if (after(TCP_SKB_CB(skb)->end_seq, end))
+				end = TCP_SKB_CB(skb)->end_seq;
+		}
+	}
+}
+
+/*
+ * Purge the out-of-order queue.
+ * Return true if queue was pruned.
+ */
+static int tcp_prune_ofo_queue(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int res = 0;
+
+	if (!skb_queue_empty(&tp->out_of_order_queue)) {
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_OFOPRUNED);
+		__skb_queue_purge(&tp->out_of_order_queue);
+
+		/* Reset SACK state.  A conforming SACK implementation will
+		 * do the same at a timeout based retransmit.  When a connection
+		 * is in a sad state like this, we care only about integrity
+		 * of the connection not performance.
+		 */
+		if (tp->rx_opt.sack_ok)
+			tcp_sack_reset(&tp->rx_opt);
+		sk_mem_reclaim(sk);
+		res = 1;
+	}
+	return res;
+}
+
+/* Reduce allocated memory if we can, trying to get
+ * the socket within its memory limits again.
+ *
+ * Return less than zero if we should start dropping frames
+ * until the socket owning process reads some of the data
+ * to stabilize the situation.
+ */
+static int tcp_prune_queue(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	SOCK_DEBUG(sk, "prune_queue: c=%x\n", tp->copied_seq);
+
+	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PRUNECALLED);
+
+	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)
+		tcp_clamp_window(sk);
+	else if (tcp_memory_pressure)
+		tp->rcv_ssthresh = min(tp->rcv_ssthresh, 4U * tp->advmss);
+
+	tcp_collapse_ofo_queue(sk);
+	tcp_collapse(sk, &sk->sk_receive_queue,
+		     sk->sk_receive_queue.next,
+		     (struct sk_buff *)&sk->sk_receive_queue,
+		     tp->copied_seq, tp->rcv_nxt);
+	sk_mem_reclaim(sk);
+
+	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)
+		return 0;
+
+	/* Collapsing did not help, destructive actions follow.
+	 * This must not ever occur. */
+
+	tcp_prune_ofo_queue(sk);
+
+	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)
+		return 0;
+
+	/* If we are really being abused, tell the caller to silently
+	 * drop receive data on the floor.  It will get retransmitted
+	 * and hopefully then we'll have sufficient space.
+	 */
+	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_RCVPRUNED);
+
+	/* Massive buffer overcommit. */
+	tp->pred_flags = 0;
+	return -1;
+}
+
+/* RFC2861, slow part. Adjust cwnd, after it was not full during one rto.
+ * As additional protections, we do not touch cwnd in retransmission phases,
+ * and if application hit its sndbuf limit recently.
+ */
+void tcp_cwnd_application_limited(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (inet_csk(sk)->icsk_ca_state == TCP_CA_Open &&
+	    sk->sk_socket && !test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {
+		/* Limited by application or receiver window. */
+		u32 init_win = tcp_init_cwnd(tp, __sk_dst_get(sk));
+		u32 win_used = max(tp->snd_cwnd_used, init_win);
+		if (win_used < tp->snd_cwnd) {
+			tp->snd_ssthresh = tcp_current_ssthresh(sk);
+			tp->snd_cwnd = (tp->snd_cwnd + win_used) >> 1;
+		}
+		tp->snd_cwnd_used = 0;
+	}
+	tp->snd_cwnd_stamp = tcp_time_stamp;
+}
+
+static int tcp_should_expand_sndbuf(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	/* If the user specified a specific send buffer setting, do
+	 * not modify it.
+	 */
+	if (sk->sk_userlocks & SOCK_SNDBUF_LOCK)
+		return 0;
+
+	/* If we are under global TCP memory pressure, do not expand.  */
+	if (tcp_memory_pressure)
+		return 0;
+
+	/* If we are under soft global TCP memory pressure, do not expand.  */
+	if (atomic_read(&tcp_memory_allocated) >= sysctl_tcp_mem[0])
+		return 0;
+
+	/* If we filled the congestion window, do not expand.  */
+	if (tp->packets_out >= tp->snd_cwnd)
+		return 0;
+
+	return 1;
+}
+
+/* When incoming ACK allowed to free some skb from write_queue,
+ * we remember this event in flag SOCK_QUEUE_SHRUNK and wake up socket
+ * on the exit from tcp input handler.
+ *
+ * PROBLEM: sndbuf expansion does not work well with largesend.
+ */
+static void tcp_new_space(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	if (tcp_should_expand_sndbuf(sk)) {
+		int sndmem = max_t(u32, tp->rx_opt.mss_clamp, tp->mss_cache) +
+			MAX_TCP_HEADER + 16 + sizeof(struct sk_buff);
+		int demanded = max_t(unsigned int, tp->snd_cwnd,
+				     tp->reordering + 1);
+		sndmem *= 2 * demanded;
+		if (sndmem > sk->sk_sndbuf)
+			sk->sk_sndbuf = min(sndmem, sysctl_tcp_wmem[2]);
+		tp->snd_cwnd_stamp = tcp_time_stamp;
+	}
+
+	sk->sk_write_space(sk);
+}
+
+static void tcp_check_space(struct sock *sk)
+{
+	if (sock_flag(sk, SOCK_QUEUE_SHRUNK)) {
+		sock_reset_flag(sk, SOCK_QUEUE_SHRUNK);
+		if (sk->sk_socket &&
+		    test_bit(SOCK_NOSPACE, &sk->sk_socket->flags))
+			tcp_new_space(sk);
+	}
+}
+
+static inline void tcp_data_snd_check(struct sock *sk)
+{
+	tcp_push_pending_frames(sk);
+	tcp_check_space(sk);
+}
+
+/*
+ * Check if sending an ack is needed.
+ */
+static void __tcp_ack_snd_check(struct sock *sk, int ofo_possible)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	    /* More than one full frame received... */
+	if (((tp->rcv_nxt - tp->rcv_wup) > inet_csk(sk)->icsk_ack.rcv_mss
+	     /* ... and right edge of window advances far enough.
+	      * (tcp_recvmsg() will send ACK otherwise). Or...
+	      */
+	     && __tcp_select_window(sk) >= tp->rcv_wnd) ||
+	    /* We ACK each frame or... */
+	    tcp_in_quickack_mode(sk) ||
+	    /* We have out of order data. */
+	    (ofo_possible && skb_peek(&tp->out_of_order_queue))) {
+		/* Then ack it now */
+		tcp_send_ack(sk);
+	} else {
+		/* Else, send delayed ack. */
+		tcp_send_delayed_ack(sk);
+	}
+}
+
+static inline void tcp_ack_snd_check(struct sock *sk)
+{
+	if (!inet_csk_ack_scheduled(sk)) {
+		/* We sent a data segment already. */
+		return;
+	}
+	__tcp_ack_snd_check(sk, 1);
+}
+
+/*
+ *	This routine is only called when we have urgent data
+ *	signaled. Its the 'slow' part of tcp_urg. It could be
+ *	moved inline now as tcp_urg is only called from one
+ *	place. We handle URGent data wrong. We have to - as
+ *	BSD still doesn't use the correction from RFC961.
+ *	For 1003.1g we should support a new option TCP_STDURG to permit
+ *	either form (or just set the sysctl tcp_stdurg).
+ */
+
+static void tcp_check_urg(struct sock *sk, struct tcphdr *th)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u32 ptr = ntohs(th->urg_ptr);
+
+	if (ptr && !sysctl_tcp_stdurg)
+		ptr--;
+	ptr += ntohl(th->seq);
+
+	/* Ignore urgent data that we've already seen and read. */
+	if (after(tp->copied_seq, ptr))
+		return;
+
+	/* Do not replay urg ptr.
+	 *
+	 * NOTE: interesting situation not covered by specs.
+	 * Misbehaving sender may send urg ptr, pointing to segment,
+	 * which we already have in ofo queue. We are not able to fetch
+	 * such data and will stay in TCP_URG_NOTYET until will be eaten
+	 * by recvmsg(). Seems, we are not obliged to handle such wicked
+	 * situations. But it is worth to think about possibility of some
+	 * DoSes using some hypothetical application level deadlock.
+	 */
+	if (before(ptr, tp->rcv_nxt))
+		return;
+
+	/* Do we already have a newer (or duplicate) urgent pointer? */
+	if (tp->urg_data && !after(ptr, tp->urg_seq))
+		return;
+
+	/* Tell the world about our new urgent pointer. */
+	sk_send_sigurg(sk);
+
+	/* We may be adding urgent data when the last byte read was
+	 * urgent. To do this requires some care. We cannot just ignore
+	 * tp->copied_seq since we would read the last urgent byte again
+	 * as data, nor can we alter copied_seq until this data arrives
+	 * or we break the semantics of SIOCATMARK (and thus sockatmark())
+	 *
+	 * NOTE. Double Dutch. Rendering to plain English: author of comment
+	 * above did something sort of 	send("A", MSG_OOB); send("B", MSG_OOB);
+	 * and expect that both A and B disappear from stream. This is _wrong_.
+	 * Though this happens in BSD with high probability, this is occasional.
+	 * Any application relying on this is buggy. Note also, that fix "works"
+	 * only in this artificial test. Insert some normal data between A and B and we will
+	 * decline of BSD again. Verdict: it is better to remove to trap
+	 * buggy users.
+	 */
+	if (tp->urg_seq == tp->copied_seq && tp->urg_data &&
+	    !sock_flag(sk, SOCK_URGINLINE) && tp->copied_seq != tp->rcv_nxt) {
+		struct sk_buff *skb = skb_peek(&sk->sk_receive_queue);
+		tp->copied_seq++;
+		if (skb && !before(tp->copied_seq, TCP_SKB_CB(skb)->end_seq)) {
+			__skb_unlink(skb, &sk->sk_receive_queue);
+			__kfree_skb(skb);
+		}
+	}
+
+	tp->urg_data = TCP_URG_NOTYET;
+	tp->urg_seq = ptr;
+
+	/* Disable header prediction. */
+	tp->pred_flags = 0;
+}
+
+/* This is the 'fast' part of urgent handling. */
+static void tcp_urg(struct sock *sk, struct sk_buff *skb, struct tcphdr *th)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	/* Check if we get a new urgent pointer - normally not. */
+	if (th->urg)
+		tcp_check_urg(sk, th);
+
+	/* Do we wait for any urgent data? - normally not... */
+	if (tp->urg_data == TCP_URG_NOTYET) {
+		u32 ptr = tp->urg_seq - ntohl(th->seq) + (th->doff * 4) -
+			  th->syn;
+
+		/* Is the urgent pointer pointing into this packet? */
+		if (ptr < skb->len) {
+			u8 tmp;
+			if (skb_copy_bits(skb, ptr, &tmp, 1))
+				BUG();
+			tp->urg_data = TCP_URG_VALID | tmp;
+			if (!sock_flag(sk, SOCK_DEAD))
+				sk->sk_data_ready(sk, 0);
+		}
+	}
+}
+
+static int tcp_copy_to_iovec(struct sock *sk, struct sk_buff *skb, int hlen)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int chunk = skb->len - hlen;
+	int err;
+
+	local_bh_enable();
+	if (skb_csum_unnecessary(skb))
+		err = skb_copy_datagram_iovec(skb, hlen, tp->ucopy.iov, chunk);
+	else
+		err = skb_copy_and_csum_datagram_iovec(skb, hlen,
+						       tp->ucopy.iov);
+
+	if (!err) {
+		tp->ucopy.len -= chunk;
+		tp->copied_seq += chunk;
+		tcp_rcv_space_adjust(sk);
+	}
+
+	local_bh_disable();
+	return err;
+}
+
+static __sum16 __tcp_checksum_complete_user(struct sock *sk,
+					    struct sk_buff *skb)
+{
+	__sum16 result;
+
+	if (sock_owned_by_user(sk)) {
+		local_bh_enable();
+		result = __tcp_checksum_complete(skb);
+		local_bh_disable();
+	} else {
+		result = __tcp_checksum_complete(skb);
+	}
+	return result;
+}
+
+static inline int tcp_checksum_complete_user(struct sock *sk,
+					     struct sk_buff *skb)
+{
+	return !skb_csum_unnecessary(skb) &&
+	       __tcp_checksum_complete_user(sk, skb);
+}
+
+#ifdef CONFIG_NET_DMA
+static int tcp_dma_try_early_copy(struct sock *sk, struct sk_buff *skb,
+				  int hlen)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int chunk = skb->len - hlen;
+	int dma_cookie;
+	int copied_early = 0;
+
+	if (tp->ucopy.wakeup)
+		return 0;
+
+	if (!tp->ucopy.dma_chan && tp->ucopy.pinned_list)
+		tp->ucopy.dma_chan = dma_find_channel(DMA_MEMCPY);
+
+	if (tp->ucopy.dma_chan && skb_csum_unnecessary(skb)) {
+
+		dma_cookie = dma_skb_copy_datagram_iovec(tp->ucopy.dma_chan,
+							 skb, hlen,
+							 tp->ucopy.iov, chunk,
+							 tp->ucopy.pinned_list);
+
+		if (dma_cookie < 0)
+			goto out;
+
+		tp->ucopy.dma_cookie = dma_cookie;
+		copied_early = 1;
+
+		tp->ucopy.len -= chunk;
+		tp->copied_seq += chunk;
+		tcp_rcv_space_adjust(sk);
+
+		if ((tp->ucopy.len == 0) ||
+		    (tcp_flag_word(tcp_hdr(skb)) & TCP_FLAG_PSH) ||
+		    (atomic_read(&sk->sk_rmem_alloc) > (sk->sk_rcvbuf >> 1))) {
+			tp->ucopy.wakeup = 1;
+			sk->sk_data_ready(sk, 0);
+		}
+	} else if (chunk > 0) {
+		tp->ucopy.wakeup = 1;
+		sk->sk_data_ready(sk, 0);
+	}
+out:
+	return copied_early;
+}
+#endif /* CONFIG_NET_DMA */
+
+/* Does PAWS and seqno based validation of an incoming segment, flags will
+ * play significant role here.
+ */
+static int tcp_validate_incoming(struct sock *sk, struct sk_buff *skb,
+			      struct tcphdr *th, int syn_inerr)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	/* RFC1323: H1. Apply PAWS check first. */
+	if (tcp_fast_parse_options(skb, th, tp) && tp->rx_opt.saw_tstamp &&
+	    tcp_paws_discard(sk, skb)) {
+		if (!th->rst) {
+			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSESTABREJECTED);
+			tcp_send_dupack(sk, skb);
+			goto discard;
+		}
+		/* Reset is accepted even if it did not pass PAWS. */
+	}
+
+	/* Step 1: check sequence number */
+	if (!tcp_sequence(tp, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq)) {
+		/* RFC793, page 37: "In all states except SYN-SENT, all reset
+		 * (RST) segments are validated by checking their SEQ-fields."
+		 * And page 69: "If an incoming segment is not acceptable,
+		 * an acknowledgment should be sent in reply (unless the RST
+		 * bit is set, if so drop the segment and return)".
+		 */
+		if (!th->rst)
+			tcp_send_dupack(sk, skb);
+		goto discard;
+	}
+
+	/* Step 2: check RST bit */
+	if (th->rst) {
+		tcp_reset(sk);
+		goto discard;
+	}
+
+	/* ts_recent update must be made after we are sure that the packet
+	 * is in window.
+	 */
+	tcp_replace_ts_recent(tp, TCP_SKB_CB(skb)->seq);
+
+	/* step 3: check security and precedence [ignored] */
+
+	/* step 4: Check for a SYN in window. */
+	if (th->syn && !before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {
+		if (syn_inerr)
+			TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);
+		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONSYN);
+		tcp_reset(sk);
+		return -1;
+	}
+
+	return 1;
+
+discard:
+	__kfree_skb(skb);
+	return 0;
+}
+
+/*
+ *	TCP receive function for the ESTABLISHED state.
+ *
+ *	It is split into a fast path and a slow path. The fast path is
+ * 	disabled when:
+ *	- A zero window was announced from us - zero window probing
+ *        is only handled properly in the slow path.
+ *	- Out of order segments arrived.
+ *	- Urgent data is expected.
+ *	- There is no buffer space left
+ *	- Unexpected TCP flags/window values/header lengths are received
+ *	  (detected by checking the TCP header against pred_flags)
+ *	- Data is sent in both directions. Fast path only supports pure senders
+ *	  or pure receivers (this means either the sequence number or the ack
+ *	  value must stay constant)
+ *	- Unexpected TCP option.
+ *
+ *	When these conditions are not satisfied it drops into a standard
+ *	receive procedure patterned after RFC793 to handle all cases.
+ *	The first three cases are guaranteed by proper pred_flags setting,
+ *	the rest is checked inline. Fast processing is turned on in
+ *	tcp_data_queue when everything is OK.
+ */
+int tcp_rcv_established(struct sock *sk, struct sk_buff *skb,
+			struct tcphdr *th, unsigned len)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	int res;
+
+	/*
+	 *	Header prediction.
+	 *	The code loosely follows the one in the famous
+	 *	"30 instruction TCP receive" Van Jacobson mail.
+	 *
+	 *	Van's trick is to deposit buffers into socket queue
+	 *	on a device interrupt, to call tcp_recv function
+	 *	on the receive process context and checksum and copy
+	 *	the buffer to user space. smart...
+	 *
+	 *	Our current scheme is not silly either but we take the
+	 *	extra cost of the net_bh soft interrupt processing...
+	 *	We do checksum and copy also but from device to kernel.
+	 */
+
+	tp->rx_opt.saw_tstamp = 0;
+
+	/*	pred_flags is 0xS?10 << 16 + snd_wnd
+	 *	if header_prediction is to be made
+	 *	'S' will always be tp->tcp_header_len >> 2
+	 *	'?' will be 0 for the fast path, otherwise pred_flags is 0 to
+	 *  turn it off	(when there are holes in the receive
+	 *	 space for instance)
+	 *	PSH flag is ignored.
+	 */
+
+	if ((tcp_flag_word(th) & TCP_HP_BITS) == tp->pred_flags &&
+	    TCP_SKB_CB(skb)->seq == tp->rcv_nxt &&
+	    !after(TCP_SKB_CB(skb)->ack_seq, tp->snd_nxt)) {
+		int tcp_header_len = tp->tcp_header_len;
+
+		/* Timestamp header prediction: tcp_header_len
+		 * is automatically equal to th->doff*4 due to pred_flags
+		 * match.
+		 */
+
+		/* Check timestamp */
+		if (tcp_header_len == sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED) {
+			/* No? Slow path! */
+			if (!tcp_parse_aligned_timestamp(tp, th))
+				goto slow_path;
+
+			/* If PAWS failed, check it more carefully in slow path */
+			if ((s32)(tp->rx_opt.rcv_tsval - tp->rx_opt.ts_recent) < 0)
+				goto slow_path;
+
+			/* DO NOT update ts_recent here, if checksum fails
+			 * and timestamp was corrupted part, it will result
+			 * in a hung connection since we will drop all
+			 * future packets due to the PAWS test.
+			 */
+		}
+
+		if (len <= tcp_header_len) {
+			/* Bulk data transfer: sender */
+			if (len == tcp_header_len) {
+				/* Predicted packet is in window by definition.
+				 * seq == rcv_nxt and rcv_wup <= rcv_nxt.
+				 * Hence, check seq<=rcv_wup reduces to:
+				 */
+				if (tcp_header_len ==
+				    (sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED) &&
+				    tp->rcv_nxt == tp->rcv_wup)
+					tcp_store_ts_recent(tp);
+
+				/* We know that such packets are checksummed
+				 * on entry.
+				 */
+				tcp_ack(sk, skb, 0);
+				__kfree_skb(skb);
+				tcp_data_snd_check(sk);
+				return 0;
+			} else { /* Header too small */
+				TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);
+				goto discard;
+			}
+		} else {
+			int eaten = 0;
+			int copied_early = 0;
+
+			if (tp->copied_seq == tp->rcv_nxt &&
+			    len - tcp_header_len <= tp->ucopy.len) {
+#ifdef CONFIG_NET_DMA
+				if (tcp_dma_try_early_copy(sk, skb, tcp_header_len)) {
+					copied_early = 1;
+					eaten = 1;
+				}
+#endif
+				if (tp->ucopy.task == current &&
+				    sock_owned_by_user(sk) && !copied_early) {
+					__set_current_state(TASK_RUNNING);
+
+					if (!tcp_copy_to_iovec(sk, skb, tcp_header_len))
+						eaten = 1;
+				}
+				if (eaten) {
+					/* Predicted packet is in window by definition.
+					 * seq == rcv_nxt and rcv_wup <= rcv_nxt.
+					 * Hence, check seq<=rcv_wup reduces to:
+					 */
+					if (tcp_header_len ==
+					    (sizeof(struct tcphdr) +
+					     TCPOLEN_TSTAMP_ALIGNED) &&
+					    tp->rcv_nxt == tp->rcv_wup)
+						tcp_store_ts_recent(tp);
+
+					tcp_rcv_rtt_measure_ts(sk, skb);
+
+					__skb_pull(skb, tcp_header_len);
+					tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;
+					NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPHITSTOUSER);
+				}
+				if (copied_early)
+					tcp_cleanup_rbuf(sk, skb->len);
+			}
+			if (!eaten) {
+				if (tcp_checksum_complete_user(sk, skb))
+					goto csum_error;
+
+				/* Predicted packet is in window by definition.
+				 * seq == rcv_nxt and rcv_wup <= rcv_nxt.
+				 * Hence, check seq<=rcv_wup reduces to:
+				 */
+				if (tcp_header_len ==
+				    (sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED) &&
+				    tp->rcv_nxt == tp->rcv_wup)
+					tcp_store_ts_recent(tp);
+
+				tcp_rcv_rtt_measure_ts(sk, skb);
+
+				if ((int)skb->truesize > sk->sk_forward_alloc)
+					goto step5;
+
+				NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPHITS);
+
+				/* Bulk data transfer: receiver */
+				__skb_pull(skb, tcp_header_len);
+				__skb_queue_tail(&sk->sk_receive_queue, skb);
+				skb_set_owner_r(skb, sk);
+				tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;
+			}
+
+			tcp_event_data_recv(sk, skb);
+
+			if (TCP_SKB_CB(skb)->ack_seq != tp->snd_una) {
+				/* Well, only one small jumplet in fast path... */
+				tcp_ack(sk, skb, FLAG_DATA);
+				tcp_data_snd_check(sk);
+				if (!inet_csk_ack_scheduled(sk))
+					goto no_ack;
+			}
+
+			if (!copied_early || tp->rcv_nxt != tp->rcv_wup)
+				__tcp_ack_snd_check(sk, 0);
+no_ack:
+#ifdef CONFIG_NET_DMA
+			if (copied_early)
+				__skb_queue_tail(&sk->sk_async_wait_queue, skb);
+			else
+#endif
+			if (eaten)
+				__kfree_skb(skb);
+			else
+				sk->sk_data_ready(sk, 0);
+			return 0;
+		}
+	}
+
+slow_path:
+	if (len < (th->doff << 2) || tcp_checksum_complete_user(sk, skb))
+		goto csum_error;
+
+	/*
+	 *	Standard slow path.
+	 */
+
+	res = tcp_validate_incoming(sk, skb, th, 1);
+	if (res <= 0)
+		return -res;
+
+step5:
+	if (th->ack && tcp_ack(sk, skb, FLAG_SLOWPATH) < 0)
+		goto discard;
+
+	tcp_rcv_rtt_measure_ts(sk, skb);
+
+	/* Process urgent data. */
+	tcp_urg(sk, skb, th);
+
+	/* step 7: process the segment text */
+	tcp_data_queue(sk, skb);
+
+	tcp_data_snd_check(sk);
+	tcp_ack_snd_check(sk);
+	return 0;
+
+csum_error:
+	TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);
+
+discard:
+	__kfree_skb(skb);
+	return 0;
+}
+
+static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,
+					 struct tcphdr *th, unsigned len)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	int saved_clamp = tp->rx_opt.mss_clamp;
+
+	tcp_parse_options(skb, &tp->rx_opt, 0);
+
+	if (th->ack) {
+		/* rfc793:
+		 * "If the state is SYN-SENT then
+		 *    first check the ACK bit
+		 *      If the ACK bit is set
+		 *	  If SEG.ACK =< ISS, or SEG.ACK > SND.NXT, send
+		 *        a reset (unless the RST bit is set, if so drop
+		 *        the segment and return)"
+		 *
+		 *  We do not send data with SYN, so that RFC-correct
+		 *  test reduces to:
+		 */
+		if (TCP_SKB_CB(skb)->ack_seq != tp->snd_nxt)
+			goto reset_and_undo;
+
+		if (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&
+		    !between(tp->rx_opt.rcv_tsecr, tp->retrans_stamp,
+			     tcp_time_stamp)) {
+			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSACTIVEREJECTED);
+			goto reset_and_undo;
+		}
+
+		/* Now ACK is acceptable.
+		 *
+		 * "If the RST bit is set
+		 *    If the ACK was acceptable then signal the user "error:
+		 *    connection reset", drop the segment, enter CLOSED state,
+		 *    delete TCB, and return."
+		 */
+
+		if (th->rst) {
+			tcp_reset(sk);
+			goto discard;
+		}
+
+		/* rfc793:
+		 *   "fifth, if neither of the SYN or RST bits is set then
+		 *    drop the segment and return."
+		 *
+		 *    See note below!
+		 *                                        --ANK(990513)
+		 */
+		if (!th->syn)
+			goto discard_and_undo;
+
+		/* rfc793:
+		 *   "If the SYN bit is on ...
+		 *    are acceptable then ...
+		 *    (our SYN has been ACKed), change the connection
+		 *    state to ESTABLISHED..."
+		 */
+
+		TCP_ECN_rcv_synack(tp, th);
+
+		tp->snd_wl1 = TCP_SKB_CB(skb)->seq;
+		tcp_ack(sk, skb, FLAG_SLOWPATH);
+
+		/* Ok.. it's good. Set up sequence numbers and
+		 * move to established.
+		 */
+		tp->rcv_nxt = TCP_SKB_CB(skb)->seq + 1;
+		tp->rcv_wup = TCP_SKB_CB(skb)->seq + 1;
+
+		/* RFC1323: The window in SYN & SYN/ACK segments is
+		 * never scaled.
+		 */
+		tp->snd_wnd = ntohs(th->window);
+		tcp_init_wl(tp, TCP_SKB_CB(skb)->seq);
+
+		if (!tp->rx_opt.wscale_ok) {
+			tp->rx_opt.snd_wscale = tp->rx_opt.rcv_wscale = 0;
+			tp->window_clamp = min(tp->window_clamp, 65535U);
+		}
+
+		if (tp->rx_opt.saw_tstamp) {
+			tp->rx_opt.tstamp_ok	   = 1;
+			tp->tcp_header_len =
+				sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;
+			tp->advmss	    -= TCPOLEN_TSTAMP_ALIGNED;
+			tcp_store_ts_recent(tp);
+		} else {
+			tp->tcp_header_len = sizeof(struct tcphdr);
+		}
+
+		if (tcp_is_sack(tp) && sysctl_tcp_fack)
+			tcp_enable_fack(tp);
+
+		tcp_mtup_init(sk);
+		tcp_sync_mss(sk, icsk->icsk_pmtu_cookie);
+		tcp_initialize_rcv_mss(sk);
+
+		/* Remember, tcp_poll() does not lock socket!
+		 * Change state from SYN-SENT only after copied_seq
+		 * is initialized. */
+		tp->copied_seq = tp->rcv_nxt;
+		smp_mb();
+		tcp_set_state(sk, TCP_ESTABLISHED);
+
+		security_inet_conn_established(sk, skb);
+
+		/* Make sure socket is routed, for correct metrics.  */
+		icsk->icsk_af_ops->rebuild_header(sk);
+
+		tcp_init_metrics(sk);
+
+		tcp_init_congestion_control(sk);
+
+		/* Prevent spurious tcp_cwnd_restart() on first data
+		 * packet.
+		 */
+		tp->lsndtime = tcp_time_stamp;
+
+		tcp_init_buffer_space(sk);
+
+		if (sock_flag(sk, SOCK_KEEPOPEN))
+			inet_csk_reset_keepalive_timer(sk, keepalive_time_when(tp));
+
+		if (!tp->rx_opt.snd_wscale)
+			__tcp_fast_path_on(tp, tp->snd_wnd);
+		else
+			tp->pred_flags = 0;
+
+		if (!sock_flag(sk, SOCK_DEAD)) {
+			sk->sk_state_change(sk);
+			sk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);
+		}
+
+		if (sk->sk_write_pending ||
+		    icsk->icsk_accept_queue.rskq_defer_accept ||
+		    icsk->icsk_ack.pingpong) {
+			/* Save one ACK. Data will be ready after
+			 * several ticks, if write_pending is set.
+			 *
+			 * It may be deleted, but with this feature tcpdumps
+			 * look so _wonderfully_ clever, that I was not able
+			 * to stand against the temptation 8)     --ANK
+			 */
+			inet_csk_schedule_ack(sk);
+			icsk->icsk_ack.lrcvtime = tcp_time_stamp;
+			icsk->icsk_ack.ato	 = TCP_ATO_MIN;
+			tcp_incr_quickack(sk);
+			tcp_enter_quickack_mode(sk);
+			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+						  TCP_DELACK_MAX, TCP_RTO_MAX);
+
+discard:
+			__kfree_skb(skb);
+			return 0;
+		} else {
+			tcp_send_ack(sk);
+		}
+		return -1;
+	}
+
+	/* No ACK in the segment */
+
+	if (th->rst) {
+		/* rfc793:
+		 * "If the RST bit is set
+		 *
+		 *      Otherwise (no ACK) drop the segment and return."
+		 */
+
+		goto discard_and_undo;
+	}
+
+	/* PAWS check. */
+	if (tp->rx_opt.ts_recent_stamp && tp->rx_opt.saw_tstamp &&
+	    tcp_paws_reject(&tp->rx_opt, 0))
+		goto discard_and_undo;
+
+	if (th->syn) {
+		/* We see SYN without ACK. It is attempt of
+		 * simultaneous connect with crossed SYNs.
+		 * Particularly, it can be connect to self.
+		 */
+		tcp_set_state(sk, TCP_SYN_RECV);
+
+		if (tp->rx_opt.saw_tstamp) {
+			tp->rx_opt.tstamp_ok = 1;
+			tcp_store_ts_recent(tp);
+			tp->tcp_header_len =
+				sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;
+		} else {
+			tp->tcp_header_len = sizeof(struct tcphdr);
+		}
+
+		tp->rcv_nxt = TCP_SKB_CB(skb)->seq + 1;
+		tp->rcv_wup = TCP_SKB_CB(skb)->seq + 1;
+
+		/* RFC1323: The window in SYN & SYN/ACK segments is
+		 * never scaled.
+		 */
+		tp->snd_wnd    = ntohs(th->window);
+		tp->snd_wl1    = TCP_SKB_CB(skb)->seq;
+		tp->max_window = tp->snd_wnd;
+
+		TCP_ECN_rcv_syn(tp, th);
+
+		tcp_mtup_init(sk);
+		tcp_sync_mss(sk, icsk->icsk_pmtu_cookie);
+		tcp_initialize_rcv_mss(sk);
+
+		tcp_send_synack(sk);
+#if 0
+		/* Note, we could accept data and URG from this segment.
+		 * There are no obstacles to make this.
+		 *
+		 * However, if we ignore data in ACKless segments sometimes,
+		 * we have no reasons to accept it sometimes.
+		 * Also, seems the code doing it in step6 of tcp_rcv_state_process
+		 * is not flawless. So, discard packet for sanity.
+		 * Uncomment this return to process the data.
+		 */
+		return -1;
+#else
+		goto discard;
+#endif
+	}
+	/* "fifth, if neither of the SYN or RST bits is set then
+	 * drop the segment and return."
+	 */
+
+discard_and_undo:
+	tcp_clear_options(&tp->rx_opt);
+	tp->rx_opt.mss_clamp = saved_clamp;
+	goto discard;
+
+reset_and_undo:
+	tcp_clear_options(&tp->rx_opt);
+	tp->rx_opt.mss_clamp = saved_clamp;
+	return 1;
+}
+
+/*
+ *	This function implements the receiving procedure of RFC 793 for
+ *	all states except ESTABLISHED and TIME_WAIT.
+ *	It's called from both tcp_v4_rcv and tcp_v6_rcv and should be
+ *	address independent.
+ */
+
+int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
+			  struct tcphdr *th, unsigned len)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	int queued = 0;
+	int res;
+
+	tp->rx_opt.saw_tstamp = 0;
+
+	switch (sk->sk_state) {
+	case TCP_CLOSE:
+		goto discard;
+
+	case TCP_LISTEN:
+		if (th->ack)
+			return 1;
+
+		if (th->rst)
+			goto discard;
+
+		if (th->syn) {
+			if (icsk->icsk_af_ops->conn_request(sk, skb) < 0)
+				return 1;
+
+			/* Now we have several options: In theory there is
+			 * nothing else in the frame. KA9Q has an option to
+			 * send data with the syn, BSD accepts data with the
+			 * syn up to the [to be] advertised window and
+			 * Solaris 2.1 gives you a protocol error. For now
+			 * we just ignore it, that fits the spec precisely
+			 * and avoids incompatibilities. It would be nice in
+			 * future to drop through and process the data.
+			 *
+			 * Now that TTCP is starting to be used we ought to
+			 * queue this data.
+			 * But, this leaves one open to an easy denial of
+			 * service attack, and SYN cookies can't defend
+			 * against this problem. So, we drop the data
+			 * in the interest of security over speed unless
+			 * it's still in use.
+			 */
+			kfree_skb(skb);
+			return 0;
+		}
+		goto discard;
+
+	case TCP_SYN_SENT:
+		queued = tcp_rcv_synsent_state_process(sk, skb, th, len);
+		if (queued >= 0)
+			return queued;
+
+		/* Do step6 onward by hand. */
+		tcp_urg(sk, skb, th);
+		__kfree_skb(skb);
+		tcp_data_snd_check(sk);
+		return 0;
+	}
+
+	res = tcp_validate_incoming(sk, skb, th, 0);
+	if (res <= 0)
+		return -res;
+
+	/* step 5: check the ACK field */
+	if (th->ack) {
+		int acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH) > 0;
+
+		switch (sk->sk_state) {
+		case TCP_SYN_RECV:
+			if (acceptable) {
+				tp->copied_seq = tp->rcv_nxt;
+				smp_mb();
+				tcp_set_state(sk, TCP_ESTABLISHED);
+				sk->sk_state_change(sk);
+
+				/* Note, that this wakeup is only for marginal
+				 * crossed SYN case. Passively open sockets
+				 * are not waked up, because sk->sk_sleep ==
+				 * NULL and sk->sk_socket == NULL.
+				 */
+				if (sk->sk_socket)
+					sk_wake_async(sk,
+						      SOCK_WAKE_IO, POLL_OUT);
+
+				tp->snd_una = TCP_SKB_CB(skb)->ack_seq;
+				tp->snd_wnd = ntohs(th->window) <<
+					      tp->rx_opt.snd_wscale;
+				tcp_init_wl(tp, TCP_SKB_CB(skb)->seq);
+
+				/* tcp_ack considers this ACK as duplicate
+				 * and does not calculate rtt.
+				 * Fix it at least with timestamps.
+				 */
+				if (tp->rx_opt.saw_tstamp &&
+				    tp->rx_opt.rcv_tsecr && !tp->srtt)
+					tcp_ack_saw_tstamp(sk, 0);
+
+				if (tp->rx_opt.tstamp_ok)
+					tp->advmss -= TCPOLEN_TSTAMP_ALIGNED;
+
+				/* Make sure socket is routed, for
+				 * correct metrics.
+				 */
+				icsk->icsk_af_ops->rebuild_header(sk);
+
+				tcp_init_metrics(sk);
+
+				tcp_init_congestion_control(sk);
+
+				/* Prevent spurious tcp_cwnd_restart() on
+				 * first data packet.
+				 */
+				tp->lsndtime = tcp_time_stamp;
+
+				tcp_mtup_init(sk);
+				tcp_initialize_rcv_mss(sk);
+				tcp_init_buffer_space(sk);
+				tcp_fast_path_on(tp);
+			} else {
+				return 1;
+			}
+			break;
+
+		case TCP_FIN_WAIT1:
+			if (tp->snd_una == tp->write_seq) {
+				tcp_set_state(sk, TCP_FIN_WAIT2);
+				sk->sk_shutdown |= SEND_SHUTDOWN;
+				dst_confirm(sk->sk_dst_cache);
+
+				if (!sock_flag(sk, SOCK_DEAD))
+					/* Wake up lingering close() */
+					sk->sk_state_change(sk);
+				else {
+					int tmo;
+
+					if (tp->linger2 < 0 ||
+					    (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
+					     after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt))) {
+						tcp_done(sk);
+						NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
+						return 1;
+					}
+
+					tmo = tcp_fin_time(sk);
+					if (tmo > TCP_TIMEWAIT_LEN) {
+						inet_csk_reset_keepalive_timer(sk, tmo - TCP_TIMEWAIT_LEN);
+					} else if (th->fin || sock_owned_by_user(sk)) {
+						/* Bad case. We could lose such FIN otherwise.
+						 * It is not a big problem, but it looks confusing
+						 * and not so rare event. We still can lose it now,
+						 * if it spins in bh_lock_sock(), but it is really
+						 * marginal case.
+						 */
+						inet_csk_reset_keepalive_timer(sk, tmo);
+					} else {
+						tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
+						goto discard;
+					}
+				}
+			}
+			break;
+
+		case TCP_CLOSING:
+			if (tp->snd_una == tp->write_seq) {
+				tcp_time_wait(sk, TCP_TIME_WAIT, 0);
+				goto discard;
+			}
+			break;
+
+		case TCP_LAST_ACK:
+			if (tp->snd_una == tp->write_seq) {
+				tcp_update_metrics(sk);
+				tcp_done(sk);
+				goto discard;
+			}
+			break;
+		}
+	} else
+		goto discard;
+
+	/* step 6: check the URG bit */
+	tcp_urg(sk, skb, th);
+
+	/* step 7: process the segment text */
+	switch (sk->sk_state) {
+	case TCP_CLOSE_WAIT:
+	case TCP_CLOSING:
+	case TCP_LAST_ACK:
+		if (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))
+			break;
+	case TCP_FIN_WAIT1:
+	case TCP_FIN_WAIT2:
+		/* RFC 793 says to queue data in these states,
+		 * RFC 1122 says we MUST send a reset.
+		 * BSD 4.4 also does reset.
+		 */
+		if (sk->sk_shutdown & RCV_SHUTDOWN) {
+			if (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
+			    after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {
+				NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
+				tcp_reset(sk);
+				return 1;
+			}
+		}
+		/* Fall through */
+	case TCP_ESTABLISHED:
+		tcp_data_queue(sk, skb);
+		queued = 1;
+		break;
+	}
+
+	/* tcp_data could move socket to TIME-WAIT */
+	if (sk->sk_state != TCP_CLOSE) {
+		tcp_data_snd_check(sk);
+		tcp_ack_snd_check(sk);
+	}
+
+	if (!queued) {
+discard:
+		__kfree_skb(skb);
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL(sysctl_tcp_ecn);
+EXPORT_SYMBOL(sysctl_tcp_reordering);
+EXPORT_SYMBOL(sysctl_tcp_adv_win_scale);
+EXPORT_SYMBOL(tcp_parse_options);
+#ifdef CONFIG_TCP_MD5SIG
+EXPORT_SYMBOL(tcp_parse_md5sig_option);
+#endif
+EXPORT_SYMBOL(tcp_rcv_established);
+EXPORT_SYMBOL(tcp_rcv_state_process);
+EXPORT_SYMBOL(tcp_initialize_rcv_mss);
diff -Naur linux-2.6.30-ori/net/ipv4/tcp_ipv4.c linux-2.6.30-test/net/ipv4/tcp_ipv4.c
--- linux-2.6.30-ori/net/ipv4/tcp_ipv4.c	2009-06-09 23:05:27.000000000 -0400
+++ linux-2.6.30-test/net/ipv4/tcp_ipv4.c	2009-06-12 18:32:56.000000000 -0400
@@ -1423,10 +1423,15 @@
 	return sk;
 }
 
+extern long long em86_netstats[];
+
 static __sum16 tcp_v4_checksum_init(struct sk_buff *skb)
 {
 	const struct iphdr *iph = ip_hdr(skb);
 
+    em86_netstats[9]+=1;
+    em86_netstats[11]=skb->ip_summed;
+
 	if (skb->ip_summed == CHECKSUM_COMPLETE) {
 		if (!tcp_v4_check(skb->len, iph->saddr,
 				  iph->daddr, skb->csum)) {
